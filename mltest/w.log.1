2016-12-14 14:26:43,948 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:43,949 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,956 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 52). 2324 bytes result sent to driver
2016-12-14 14:26:43,956 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 53). 2324 bytes result sent to driver
2016-12-14 14:26:43,959 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 52) in 18 ms on localhost (1/2)
2016-12-14 14:26:43,959 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 53) in 17 ms on localhost (2/2)
2016-12-14 14:26:43,960 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.019 s
2016-12-14 14:26:43,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 14:26:43,961 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,961 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:43,962 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 2.9 KB, free 379.4 KB)
2016-12-14 14:26:43,966 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1668.0 B, free 381.0 KB)
2016-12-14 14:26:43,967 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:55377 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:26:43,967 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:43,968 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 14:26:43,969 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 54, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,970 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 55, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,970 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 54)
2016-12-14 14:26:43,970 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 55)
2016-12-14 14:26:43,971 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,971 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:43,972 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,973 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:43,976 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 54). 1324 bytes result sent to driver
2016-12-14 14:26:43,981 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 54) in 12 ms on localhost (1/2)
2016-12-14 14:26:43,984 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 55). 1324 bytes result sent to driver
2016-12-14 14:26:43,986 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 55) in 17 ms on localhost (2/2)
2016-12-14 14:26:43,986 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,986 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:26:43,987 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.057654 s
2016-12-14 14:26:43,989 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 640.0 B, free 381.7 KB)
2016-12-14 14:26:43,993 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 356.0 B, free 382.0 KB)
2016-12-14 14:26:43,993 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:55377 (size: 356.0 B, free: 529.9 MB)
2016-12-14 14:26:43,994 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at KMeans.scala:276
2016-12-14 14:26:44,010 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:44,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 45 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:44,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:44,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:44,012 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 14:26:44,012 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 14:26:44,013 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:44,016 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 6.6 KB, free 388.6 KB)
2016-12-14 14:26:44,021 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.5 KB, free 392.1 KB)
2016-12-14 14:26:44,022 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:55377 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:26:44,023 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,023 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:44,024 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 14:26:44,025 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 56, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:44,026 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 57, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:44,026 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 56)
2016-12-14 14:26:44,026 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 57)
2016-12-14 14:26:44,029 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,029 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:44,030 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,031 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:44,033 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 57). 2324 bytes result sent to driver
2016-12-14 14:26:44,036 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 57) in 10 ms on localhost (1/2)
2016-12-14 14:26:44,038 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 56). 2324 bytes result sent to driver
2016-12-14 14:26:44,041 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 56) in 16 ms on localhost (2/2)
2016-12-14 14:26:44,041 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:26:44,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:44,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:44,043 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 14:26:44,043 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:44,043 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:44,044 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 2.9 KB, free 395.0 KB)
2016-12-14 14:26:44,049 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1668.0 B, free 396.7 KB)
2016-12-14 14:26:44,049 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:55377 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:26:44,050 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,050 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:44,051 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 14:26:44,052 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 58, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,053 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 59, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,053 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 59)
2016-12-14 14:26:44,054 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 58)
2016-12-14 14:26:44,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,056 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,056 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,060 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 59). 1324 bytes result sent to driver
2016-12-14 14:26:44,063 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 59) in 11 ms on localhost (1/2)
2016-12-14 14:26:44,066 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 58). 1324 bytes result sent to driver
2016-12-14 14:26:44,068 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 58) in 16 ms on localhost (2/2)
2016-12-14 14:26:44,068 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,068 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:26:44,069 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.058639 s
2016-12-14 14:26:44,070 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 8 iterations
2016-12-14 14:26:44,071 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 344.0 B, free 397.0 KB)
2016-12-14 14:26:44,075 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 243.0 B, free 397.2 KB)
2016-12-14 14:26:44,075 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:55377 (size: 243.0 B, free: 529.9 MB)
2016-12-14 14:26:44,076 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at KMeans.scala:276
2016-12-14 14:26:44,092 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:44,093 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 47 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:44,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:44,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:44,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 14:26:44,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 14:26:44,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:44,097 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 6.5 KB, free 403.8 KB)
2016-12-14 14:26:44,100 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.5 KB, free 407.3 KB)
2016-12-14 14:26:44,100 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:55377 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:26:44,101 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,101 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:44,101 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 14:26:44,102 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 60, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:44,103 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 61, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:44,103 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 61)
2016-12-14 14:26:44,103 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 60)
2016-12-14 14:26:44,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:44,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,107 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:44,109 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 61). 2300 bytes result sent to driver
2016-12-14 14:26:44,112 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 61) in 10 ms on localhost (1/2)
2016-12-14 14:26:44,113 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 60). 2300 bytes result sent to driver
2016-12-14 14:26:44,116 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 60) in 13 ms on localhost (2/2)
2016-12-14 14:26:44,116 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,116 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.015 s
2016-12-14 14:26:44,116 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:44,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:44,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 14:26:44,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:44,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:44,119 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 2.9 KB, free 410.2 KB)
2016-12-14 14:26:44,123 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1668.0 B, free 411.8 KB)
2016-12-14 14:26:44,123 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:55377 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:26:44,124 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,124 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:44,125 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 14:26:44,125 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 62, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,126 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 63, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,126 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 62)
2016-12-14 14:26:44,126 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 63)
2016-12-14 14:26:44,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,136 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 63). 1271 bytes result sent to driver
2016-12-14 14:26:44,138 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 63) in 12 ms on localhost (1/2)
2016-12-14 14:26:44,139 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 62). 1218 bytes result sent to driver
2016-12-14 14:26:44,142 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 62) in 17 ms on localhost (2/2)
2016-12-14 14:26:44,142 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,142 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:26:44,143 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.050801 s
2016-12-14 14:26:44,144 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 344.0 B, free 412.1 KB)
2016-12-14 14:26:44,147 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 249.0 B, free 412.4 KB)
2016-12-14 14:26:44,147 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:55377 (size: 249.0 B, free: 529.9 MB)
2016-12-14 14:26:44,148 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at KMeans.scala:276
2016-12-14 14:26:44,155 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:44,156 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 49 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:44,157 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:44,157 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:44,157 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 14:26:44,158 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 14:26:44,159 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:44,161 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 6.5 KB, free 418.9 KB)
2016-12-14 14:26:44,165 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.5 KB, free 422.4 KB)
2016-12-14 14:26:44,166 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:55377 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:26:44,167 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,167 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:44,167 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 14:26:44,169 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 64, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:44,169 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 65, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:44,170 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 65)
2016-12-14 14:26:44,170 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 64)
2016-12-14 14:26:44,172 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,172 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:44,174 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,175 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:44,176 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 65). 2300 bytes result sent to driver
2016-12-14 14:26:44,178 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 65) in 9 ms on localhost (1/2)
2016-12-14 14:26:44,180 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 64). 2300 bytes result sent to driver
2016-12-14 14:26:44,182 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 64) in 14 ms on localhost (2/2)
2016-12-14 14:26:44,182 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 14:26:44,182 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,182 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:44,182 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:44,183 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 14:26:44,183 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:44,183 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:44,184 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 2.9 KB, free 425.3 KB)
2016-12-14 14:26:44,186 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1665.0 B, free 427.0 KB)
2016-12-14 14:26:44,186 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:55377 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:26:44,187 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,187 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:44,187 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 14:26:44,188 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 66, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,188 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 67, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,188 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 66)
2016-12-14 14:26:44,188 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 67)
2016-12-14 14:26:44,189 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,190 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:44,190 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,190 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,195 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 67). 1271 bytes result sent to driver
2016-12-14 14:26:44,199 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 67) in 11 ms on localhost (1/2)
2016-12-14 14:26:44,202 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 66). 1218 bytes result sent to driver
2016-12-14 14:26:44,205 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 66) in 18 ms on localhost (2/2)
2016-12-14 14:26:44,206 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.018 s
2016-12-14 14:26:44,206 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,206 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.050330 s
2016-12-14 14:26:44,207 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 10 iterations
2016-12-14 14:26:44,208 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.891 seconds.
2016-12-14 14:26:44,208 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 10 iterations.
2016-12-14 14:26:44,210 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 78.94084142614686.
2016-12-14 14:26:44,210 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 4 from persistence list
2016-12-14 14:26:44,211 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:26:44,212 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:26:44,218 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:110
2016-12-14 14:26:44,218 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (foreach at K_means.scala:110) with 2 output partitions
2016-12-14 14:26:44,218 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 34 (foreach at K_means.scala:110)
2016-12-14 14:26:44,218 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:44,219 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:44,219 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 34 (MapPartitionsRDD[3] at map at K_means.scala:100), which has no missing parents
2016-12-14 14:26:44,220 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 4.0 KB, free 426.8 KB)
2016-12-14 14:26:44,222 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.3 KB, free 429.2 KB)
2016-12-14 14:26:44,223 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:55377 (size: 2.3 KB, free: 529.9 MB)
2016-12-14 14:26:44,223 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,223 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 34 (MapPartitionsRDD[3] at map at K_means.scala:100)
2016-12-14 14:26:44,223 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 14:26:44,224 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 68, localhost, partition 0,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,225 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 69, localhost, partition 1,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,225 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 69)
2016-12-14 14:26:44,225 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 68)
2016-12-14 14:26:44,227 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.6,3.0,4.4,1.4] belong to cluster 2
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,2.8,4.8,1.4] belong to cluster 2
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.0,5.0,1.7] belong to cluster 1
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.9,4.5,1.5] belong to cluster 2
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.6,3.5,1.0] belong to cluster 2
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.4,3.8,1.1] belong to cluster 2
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.4,3.7,1.0] belong to cluster 2
2016-12-14 14:26:44,228 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,228 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,3.9,1.2] belong to cluster 2
2016-12-14 14:26:44,229 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.5,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,229 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.7,5.1,1.6] belong to cluster 2
2016-12-14 14:26:44,229 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.0,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,229 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.0,4.5,1.5] belong to cluster 2
2016-12-14 14:26:44,229 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,3.4,4.5,1.6] belong to cluster 2
2016-12-14 14:26:44,229 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.7,3.2,1.3,0.2] belong to cluster 0
2016-12-14 14:26:44,229 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,4.7,1.5] belong to cluster 2
2016-12-14 14:26:44,230 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.1,1.5,0.2] belong to cluster 0
2016-12-14 14:26:44,230 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.3,4.4,1.3] belong to cluster 2
2016-12-14 14:26:44,230 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.6,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,230 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,3.0,4.1,1.3] belong to cluster 2
2016-12-14 14:26:44,230 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.9,1.7,0.4] belong to cluster 0
2016-12-14 14:26:44,230 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.5,4.0,1.3] belong to cluster 2
2016-12-14 14:26:44,231 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.4,1.4,0.3] belong to cluster 0
2016-12-14 14:26:44,231 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.6,4.4,1.2] belong to cluster 2
2016-12-14 14:26:44,231 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.4,1.5,0.2] belong to cluster 0
2016-12-14 14:26:44,231 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,3.0,4.6,1.4] belong to cluster 2
2016-12-14 14:26:44,231 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,2.9,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,231 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.6,4.0,1.2] belong to cluster 2
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 0
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,2.3,3.3,1.0] belong to cluster 2
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.7,1.5,0.2] belong to cluster 0
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.7,4.2,1.3] belong to cluster 2
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.4,1.6,0.2] belong to cluster 0
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,3.0,4.2,1.2] belong to cluster 2
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.0,1.4,0.1] belong to cluster 0
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.9,4.2,1.3] belong to cluster 2
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.3,3.0,1.1,0.1] belong to cluster 0
2016-12-14 14:26:44,232 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.9,4.3,1.3] belong to cluster 2
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,4.0,1.2,0.2] belong to cluster 0
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,2.5,3.0,1.1] belong to cluster 2
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,4.4,1.5,0.4] belong to cluster 0
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.8,4.1,1.3] belong to cluster 2
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.9,1.3,0.4] belong to cluster 0
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.3,6.0,2.5] belong to cluster 1
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.5,1.4,0.3] belong to cluster 0
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,5.1,1.9] belong to cluster 2
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,3.8,1.7,0.3] belong to cluster 0
2016-12-14 14:26:44,233 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.1,3.0,5.9,2.1] belong to cluster 1
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.9,5.6,1.8] belong to cluster 1
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.5,0.3] belong to cluster 0
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.8,2.2] belong to cluster 1
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.4,1.7,0.2] belong to cluster 0
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.6,3.0,6.6,2.1] belong to cluster 1
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.7,1.5,0.4] belong to cluster 0
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,2.5,4.5,1.7] belong to cluster 2
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.6,1.0,0.2] belong to cluster 0
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.3,2.9,6.3,1.8] belong to cluster 1
2016-12-14 14:26:44,234 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.3,1.7,0.5] belong to cluster 0
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,2.5,5.8,1.8] belong to cluster 1
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.4,1.9,0.2] belong to cluster 0
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.6,6.1,2.5] belong to cluster 1
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.0,1.6,0.2] belong to cluster 0
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.2,5.1,2.0] belong to cluster 1
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.4,1.6,0.4] belong to cluster 0
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.7,5.3,1.9] belong to cluster 1
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,3.5,1.5,0.2] belong to cluster 0
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,3.0,5.5,2.1] belong to cluster 1
2016-12-14 14:26:44,235 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,3.4,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.5,5.0,2.0] belong to cluster 2
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.7,3.2,1.6,0.2] belong to cluster 0
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.8,5.1,2.4] belong to cluster 2
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.1,1.6,0.2] belong to cluster 0
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.2,5.3,2.3] belong to cluster 1
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.4,1.5,0.4] belong to cluster 0
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.5,1.8] belong to cluster 1
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,4.1,1.5,0.1] belong to cluster 0
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,3.8,6.7,2.2] belong to cluster 1
2016-12-14 14:26:44,236 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,4.2,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,2.6,6.9,2.3] belong to cluster 1
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 0
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.2,5.0,1.5] belong to cluster 2
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.2,1.2,0.2] belong to cluster 0
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.2,5.7,2.3] belong to cluster 1
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,3.5,1.3,0.2] belong to cluster 0
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.8,4.9,2.0] belong to cluster 2
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 0
2016-12-14 14:26:44,237 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,2.8,6.7,2.0] belong to cluster 1
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,3.0,1.3,0.2] belong to cluster 0
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.7,4.9,1.8] belong to cluster 2
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.4,1.5,0.2] belong to cluster 0
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.3,5.7,2.1] belong to cluster 1
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.5,1.3,0.3] belong to cluster 0
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.2,6.0,1.8] belong to cluster 1
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.5,2.3,1.3,0.3] belong to cluster 0
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.8,4.8,1.8] belong to cluster 2
2016-12-14 14:26:44,238 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,3.2,1.3,0.2] belong to cluster 0
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,3.0,4.9,1.8] belong to cluster 2
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.5,1.6,0.6] belong to cluster 0
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.8,5.6,2.1] belong to cluster 1
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.9,0.4] belong to cluster 0
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.0,5.8,1.6] belong to cluster 1
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.0,1.4,0.3] belong to cluster 0
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.4,2.8,6.1,1.9] belong to cluster 1
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.6,0.2] belong to cluster 0
2016-12-14 14:26:44,239 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.9,3.8,6.4,2.0] belong to cluster 1
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.2,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.8,5.6,2.2] belong to cluster 1
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.3,3.7,1.5,0.2] belong to cluster 0
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.8,5.1,1.5] belong to cluster 2
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.3,1.4,0.2] belong to cluster 0
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.6,5.6,1.4] belong to cluster 1
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.0,3.2,4.7,1.4] belong to cluster 2
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,3.0,6.1,2.3] belong to cluster 1
2016-12-14 14:26:44,240 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.2,4.5,1.5] belong to cluster 2
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.4,5.6,2.4] belong to cluster 1
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,4.9,1.5] belong to cluster 1
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.1,5.5,1.8] belong to cluster 1
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.3,4.0,1.3] belong to cluster 2
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,3.0,4.8,1.8] belong to cluster 2
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,2.8,4.6,1.5] belong to cluster 2
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,5.4,2.1] belong to cluster 1
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.8,4.5,1.3] belong to cluster 2
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,5.6,2.4] belong to cluster 1
2016-12-14 14:26:44,241 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.3,4.7,1.6] belong to cluster 2
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,5.1,2.3] belong to cluster 1
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,2.4,3.3,1.0] belong to cluster 2
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,5.1,1.9] belong to cluster 2
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.6,2.9,4.6,1.3] belong to cluster 2
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,3.2,5.9,2.3] belong to cluster 1
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,2.7,3.9,1.4] belong to cluster 2
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.3,5.7,2.5] belong to cluster 1
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,2.0,3.5,1.0] belong to cluster 2
2016-12-14 14:26:44,242 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.0,5.2,2.3] belong to cluster 1
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.0,4.2,1.5] belong to cluster 2
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.5,5.0,1.9] belong to cluster 2
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.2,4.0,1.0] belong to cluster 2
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.2,2.0] belong to cluster 1
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.9,4.7,1.4] belong to cluster 2
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,3.4,5.4,2.3] belong to cluster 1
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.9,3.6,1.3] belong to cluster 2
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.0,5.1,1.8] belong to cluster 2
2016-12-14 14:26:44,243 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,4.4,1.4] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,3.0,4.5,1.5] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,4.1,1.0] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.2,4.5,1.5] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.5,3.9,1.1] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.2,4.8,1.8] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.8,4.0,1.3] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.5,4.9,1.5] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.8,4.7,1.2] belong to cluster 2
2016-12-14 14:26:44,244 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.9,4.3,1.3] belong to cluster 2
2016-12-14 14:26:44,245 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 69). 2057 bytes result sent to driver
2016-12-14 14:26:44,246 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 68). 2057 bytes result sent to driver
2016-12-14 14:26:44,246 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 69) in 22 ms on localhost (1/2)
2016-12-14 14:26:44,247 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 68) in 23 ms on localhost (2/2)
2016-12-14 14:26:44,247 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 34 (foreach at K_means.scala:110) finished in 0.023 s
2016-12-14 14:26:44,247 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,247 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: foreach at K_means.scala:110, took 0.029676 s
2016-12-14 14:26:44,254 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:121
2016-12-14 14:26:44,255 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (foreach at K_means.scala:121) with 2 output partitions
2016-12-14 14:26:44,255 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (foreach at K_means.scala:121)
2016-12-14 14:26:44,255 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:44,255 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:44,255 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (MapPartitionsRDD[51] at map at K_means.scala:119), which has no missing parents
2016-12-14 14:26:44,256 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 4.0 KB, free 433.1 KB)
2016-12-14 14:26:44,259 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.3 KB, free 435.4 KB)
2016-12-14 14:26:44,259 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:55377 (size: 2.3 KB, free: 529.9 MB)
2016-12-14 14:26:44,260 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (MapPartitionsRDD[51] at map at K_means.scala:119)
2016-12-14 14:26:44,260 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 14:26:44,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,262 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,262 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 70)
2016-12-14 14:26:44,262 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 71)
2016-12-14 14:26:44,265 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,265 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,265 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,265 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,266 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,266 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,266 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,266 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:26:44,266 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,266 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,267 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,267 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,267 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,267 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,267 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,268 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,268 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,268 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,268 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,268 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,268 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,268 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,269 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,269 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,269 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,269 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,269 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,269 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,270 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,270 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,270 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,270 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,270 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,270 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,270 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,271 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,271 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,271 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,271 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,271 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,271 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,272 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,272 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,272 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,272 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,272 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,272 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,272 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,273 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,274 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,274 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,274 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,274 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,274 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,274 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,274 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,275 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,275 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,275 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,275 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,275 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,275 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,275 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,276 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,277 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,277 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,277 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,277 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,277 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,277 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,277 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,278 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,278 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,278 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,278 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,278 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,278 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,278 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,279 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,280 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:26:44,280 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,280 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,280 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,280 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,280 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,280 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:26:44,281 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,281 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,281 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,281 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,281 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,281 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,281 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,282 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,283 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,283 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,283 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,283 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,283 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,283 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,283 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,284 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,284 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,284 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,284 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,284 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,284 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,284 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,285 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,285 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,285 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,285 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,285 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,285 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,285 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,286 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:26:44,287 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:26:44,288 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 71). 2057 bytes result sent to driver
2016-12-14 14:26:44,289 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 70). 2057 bytes result sent to driver
2016-12-14 14:26:44,290 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 71) in 28 ms on localhost (1/2)
2016-12-14 14:26:44,291 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 70) in 31 ms on localhost (2/2)
2016-12-14 14:26:44,291 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (foreach at K_means.scala:121) finished in 0.031 s
2016-12-14 14:26:44,291 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,291 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: foreach at K_means.scala:121, took 0.036903 s
2016-12-14 14:26:44,313 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:13
2016-12-14 14:26:44,314 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 52 (map at Relabel.scala:13)
2016-12-14 14:26:44,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (sortBy at Relabel.scala:13) with 2 output partitions
2016-12-14 14:26:44,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (sortBy at Relabel.scala:13)
2016-12-14 14:26:44,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 36)
2016-12-14 14:26:44,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 36)
2016-12-14 14:26:44,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 36 (MapPartitionsRDD[52] at map at Relabel.scala:13), which has no missing parents
2016-12-14 14:26:44,316 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 4.8 KB, free 440.2 KB)
2016-12-14 14:26:44,319 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.8 KB, free 443.0 KB)
2016-12-14 14:26:44,319 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:55377 (size: 2.8 KB, free: 529.9 MB)
2016-12-14 14:26:44,320 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,321 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[52] at map at Relabel.scala:13)
2016-12-14 14:26:44,321 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 14:26:44,322 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 72, localhost, partition 0,PROCESS_LOCAL, 2378 bytes)
2016-12-14 14:26:44,322 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 73, localhost, partition 1,PROCESS_LOCAL, 2378 bytes)
2016-12-14 14:26:44,322 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 72)
2016-12-14 14:26:44,322 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 73)
2016-12-14 14:26:44,324 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,325 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,331 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 73). 2237 bytes result sent to driver
2016-12-14 14:26:44,333 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 73) in 11 ms on localhost (1/2)
2016-12-14 14:26:44,333 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 72). 2237 bytes result sent to driver
2016-12-14 14:26:44,335 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 72) in 14 ms on localhost (2/2)
2016-12-14 14:26:44,335 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 36 (map at Relabel.scala:13) finished in 0.014 s
2016-12-14 14:26:44,336 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,336 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:44,336 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:44,336 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 37)
2016-12-14 14:26:44,336 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:44,336 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (MapPartitionsRDD[56] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:26:44,337 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 3.5 KB, free 446.5 KB)
2016-12-14 14:26:44,341 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2022.0 B, free 448.5 KB)
2016-12-14 14:26:44,341 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:55377 (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:26:44,342 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[56] at sortBy at Relabel.scala:13)
2016-12-14 14:26:44,343 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 2 tasks
2016-12-14 14:26:44,344 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 74, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,344 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 37.0 (TID 75, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,345 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 74)
2016-12-14 14:26:44,345 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 37.0 (TID 75)
2016-12-14 14:26:44,346 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,347 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:44,347 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,347 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,353 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 37.0 (TID 75). 1160 bytes result sent to driver
2016-12-14 14:26:44,354 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 74). 1152 bytes result sent to driver
2016-12-14 14:26:44,356 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 37.0 (TID 75) in 12 ms on localhost (1/2)
2016-12-14 14:26:44,357 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 74) in 14 ms on localhost (2/2)
2016-12-14 14:26:44,357 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (sortBy at Relabel.scala:13) finished in 0.014 s
2016-12-14 14:26:44,357 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: sortBy at Relabel.scala:13, took 0.044219 s
2016-12-14 14:26:44,531 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 14:26:44,533 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:55377 in memory (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:26:44,534 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 14:26:44,535 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:55377 in memory (size: 2.8 KB, free: 529.9 MB)
2016-12-14 14:26:44,536 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 14:26:44,537 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:55377 in memory (size: 2.3 KB, free: 529.9 MB)
2016-12-14 14:26:44,538 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 14:26:44,539 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:55377 in memory (size: 2.3 KB, free: 529.9 MB)
2016-12-14 14:26:44,540 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 14:26:44,541 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:55377 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:26:44,542 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 14:26:44,543 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:55377 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:26:44,543 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 14:26:44,544 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 14:26:44,545 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:55377 in memory (size: 249.0 B, free: 529.9 MB)
2016-12-14 14:26:44,546 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 14:26:44,547 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:55377 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:26:44,548 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 14:26:44,549 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:55377 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:26:44,549 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 14:26:44,551 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:55377 in memory (size: 243.0 B, free: 529.9 MB)
2016-12-14 14:26:44,551 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 14:26:44,552 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:55377 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:26:44,553 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 14:26:44,554 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:55377 in memory (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:26:44,555 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 14:26:44,556 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:55377 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:26:44,556 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 14:26:44,557 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 14:26:44,558 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 14:26:44,558 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:55377 in memory (size: 348.0 B, free: 530.0 MB)
2016-12-14 14:26:44,558 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 14:26:44,559 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 14:26:44,560 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:55377 in memory (size: 1666.0 B, free: 530.0 MB)
2016-12-14 14:26:44,560 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 14:26:44,561 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:55377 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:26:44,562 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 14:26:44,562 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 14:26:44,563 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:55377 in memory (size: 345.0 B, free: 530.0 MB)
2016-12-14 14:26:44,564 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 14:26:44,564 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 14:26:44,565 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:26:44,565 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 11 is 155 bytes
2016-12-14 14:26:44,565 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 4
2016-12-14 14:26:44,566 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:55377 in memory (size: 340.0 B, free: 530.0 MB)
2016-12-14 14:26:44,567 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 14:26:44,568 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 14:26:44,569 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:55377 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:26:44,570 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 14:26:44,571 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 14:26:44,572 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:55377 in memory (size: 356.0 B, free: 530.0 MB)
2016-12-14 14:26:44,572 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 14:26:44,572 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 14:26:44,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 54 (sortBy at Relabel.scala:13)
2016-12-14 14:26:44,573 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (collect at Relabel.scala:14) with 2 output partitions
2016-12-14 14:26:44,573 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 40 (collect at Relabel.scala:14)
2016-12-14 14:26:44,573 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 39)
2016-12-14 14:26:44,573 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:55377 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:26:44,573 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 39)
2016-12-14 14:26:44,574 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 14:26:44,574 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 39 (MapPartitionsRDD[54] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:26:44,575 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:55377 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:26:44,575 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 14:26:44,576 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 14:26:44,577 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:55377 in memory (size: 338.0 B, free: 530.0 MB)
2016-12-14 14:26:44,577 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 14:26:44,577 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 14:26:44,578 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:55377 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:26:44,579 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 14:26:44,580 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:55377 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:26:44,580 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 14:26:44,580 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 14:26:44,580 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 3.6 KB, free 318.1 KB)
2016-12-14 14:26:44,584 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.0 KB, free 320.1 KB)
2016-12-14 14:26:44,585 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:55377 (size: 2.0 KB, free: 530.0 MB)
2016-12-14 14:26:44,586 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,586 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[54] at sortBy at Relabel.scala:13)
2016-12-14 14:26:44,586 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 2 tasks
2016-12-14 14:26:44,588 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 76, localhost, partition 0,NODE_LOCAL, 2128 bytes)
2016-12-14 14:26:44,588 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 39.0 (TID 77, localhost, partition 1,NODE_LOCAL, 2128 bytes)
2016-12-14 14:26:44,589 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 76)
2016-12-14 14:26:44,589 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 39.0 (TID 77)
2016-12-14 14:26:44,597 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,597 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,597 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,597 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,608 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 76). 1303 bytes result sent to driver
2016-12-14 14:26:44,608 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 39.0 (TID 77). 1303 bytes result sent to driver
2016-12-14 14:26:44,612 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 76) in 24 ms on localhost (1/2)
2016-12-14 14:26:44,612 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 39.0 (TID 77) in 24 ms on localhost (2/2)
2016-12-14 14:26:44,612 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 39 (sortBy at Relabel.scala:13) finished in 0.025 s
2016-12-14 14:26:44,612 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,612 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:44,613 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:44,613 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 40)
2016-12-14 14:26:44,613 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:44,613 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 40 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:26:44,616 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 3.4 KB, free 323.5 KB)
2016-12-14 14:26:44,618 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 1946.0 B, free 325.4 KB)
2016-12-14 14:26:44,618 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:55377 (size: 1946.0 B, free: 530.0 MB)
2016-12-14 14:26:44,618 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,619 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13)
2016-12-14 14:26:44,619 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 2 tasks
2016-12-14 14:26:44,619 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 78, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,620 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 40.0 (TID 79, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,620 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 40.0 (TID 79)
2016-12-14 14:26:44,620 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 78)
2016-12-14 14:26:44,627 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,627 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,628 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,628 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:44,649 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 78). 1182 bytes result sent to driver
2016-12-14 14:26:44,649 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 40.0 (TID 79). 1211 bytes result sent to driver
2016-12-14 14:26:44,650 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 78) in 31 ms on localhost (1/2)
2016-12-14 14:26:44,651 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 40.0 (TID 79) in 30 ms on localhost (2/2)
2016-12-14 14:26:44,651 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 40 (collect at Relabel.scala:14) finished in 0.031 s
2016-12-14 14:26:44,651 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,651 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: collect at Relabel.scala:14, took 0.093051 s
2016-12-14 14:26:44,670 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:125
2016-12-14 14:26:44,671 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (foreach at K_means.scala:125) with 2 output partitions
2016-12-14 14:26:44,671 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (foreach at K_means.scala:125)
2016-12-14 14:26:44,671 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:44,672 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:44,672 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (MapPartitionsRDD[59] at map at Relabel.scala:31), which has no missing parents
2016-12-14 14:26:44,673 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 4.4 KB, free 329.8 KB)
2016-12-14 14:26:44,676 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.5 KB, free 332.3 KB)
2016-12-14 14:26:44,676 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:55377 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:26:44,676 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,677 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 41 (MapPartitionsRDD[59] at map at Relabel.scala:31)
2016-12-14 14:26:44,677 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 14:26:44,678 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 80, localhost, partition 0,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,678 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 81, localhost, partition 1,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,678 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 80)
2016-12-14 14:26:44,678 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 81)
2016-12-14 14:26:44,681 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,681 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,682 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,682 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,682 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,682 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,682 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:26:44,682 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,683 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,683 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,683 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,683 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,683 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,682 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,683 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,684 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,684 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,684 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,684 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,684 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,685 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,685 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,685 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,685 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,685 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,686 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,686 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,686 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,686 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,686 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,686 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,686 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,685 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,687 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,688 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,689 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,690 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,691 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,692 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,693 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,694 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,695 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,696 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,697 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:26:44,698 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,699 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:26:44,700 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:26:44,700 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 80). 2057 bytes result sent to driver
2016-12-14 14:26:44,701 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 81). 2057 bytes result sent to driver
2016-12-14 14:26:44,703 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 80) in 25 ms on localhost (1/2)
2016-12-14 14:26:44,704 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 81) in 26 ms on localhost (2/2)
2016-12-14 14:26:44,704 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (foreach at K_means.scala:125) finished in 0.027 s
2016-12-14 14:26:44,704 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,704 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: foreach at K_means.scala:125, took 0.033864 s
2016-12-14 14:26:44,725 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 14:26:44,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 60 (map at MulticlassMetrics.scala:46)
2016-12-14 14:26:44,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 14:26:44,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 43 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 14:26:44,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 42)
2016-12-14 14:26:44,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 42)
2016-12-14 14:26:44,727 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 42 (MapPartitionsRDD[60] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 14:26:44,728 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 5.3 KB, free 337.6 KB)
2016-12-14 14:26:44,731 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.0 KB, free 340.6 KB)
2016-12-14 14:26:44,731 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:55377 (size: 3.0 KB, free: 530.0 MB)
2016-12-14 14:26:44,731 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,732 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[60] at map at MulticlassMetrics.scala:46)
2016-12-14 14:26:44,732 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 14:26:44,733 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 82, localhost, partition 0,PROCESS_LOCAL, 2378 bytes)
2016-12-14 14:26:44,733 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 83, localhost, partition 1,PROCESS_LOCAL, 2378 bytes)
2016-12-14 14:26:44,734 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 83)
2016-12-14 14:26:44,734 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 82)
2016-12-14 14:26:44,736 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,736 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,740 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 82). 2237 bytes result sent to driver
2016-12-14 14:26:44,740 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 83). 2237 bytes result sent to driver
2016-12-14 14:26:44,742 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 82) in 10 ms on localhost (1/2)
2016-12-14 14:26:44,742 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 83) in 9 ms on localhost (2/2)
2016-12-14 14:26:44,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 42 (map at MulticlassMetrics.scala:46) finished in 0.010 s
2016-12-14 14:26:44,743 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:44,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:44,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 43)
2016-12-14 14:26:44,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:44,744 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 43 (ShuffledRDD[61] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 14:26:44,745 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 2.6 KB, free 343.2 KB)
2016-12-14 14:26:44,747 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 1592.0 B, free 344.8 KB)
2016-12-14 14:26:44,747 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:55377 (size: 1592.0 B, free: 530.0 MB)
2016-12-14 14:26:44,748 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,748 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 43 (ShuffledRDD[61] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 14:26:44,748 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 14:26:44,749 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 84, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,750 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 85, localhost, partition 1,PROCESS_LOCAL, 2139 bytes)
2016-12-14 14:26:44,750 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 85)
2016-12-14 14:26:44,750 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 84)
2016-12-14 14:26:44,752 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,752 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,752 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,752 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:44,755 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 85). 1124 bytes result sent to driver
2016-12-14 14:26:44,756 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 84). 1163 bytes result sent to driver
2016-12-14 14:26:44,756 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 85) in 6 ms on localhost (1/2)
2016-12-14 14:26:44,758 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 84) in 9 ms on localhost (2/2)
2016-12-14 14:26:44,759 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 43 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.010 s
2016-12-14 14:26:44,759 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,759 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.033986 s
2016-12-14 14:26:44,779 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 14:26:44,780 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 64 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:26:44,780 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 14:26:44,780 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 45 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:26:44,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 44)
2016-12-14 14:26:44,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 44)
2016-12-14 14:26:44,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 44 (MapPartitionsRDD[64] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:26:44,783 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 5.8 KB, free 350.6 KB)
2016-12-14 14:26:44,786 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.2 KB, free 353.8 KB)
2016-12-14 14:26:44,786 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:55377 (size: 3.2 KB, free: 530.0 MB)
2016-12-14 14:26:44,787 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,787 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[64] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:26:44,787 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 2 tasks
2016-12-14 14:26:44,788 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 86, localhost, partition 0,PROCESS_LOCAL, 2378 bytes)
2016-12-14 14:26:44,788 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 44.0 (TID 87, localhost, partition 1,PROCESS_LOCAL, 2378 bytes)
2016-12-14 14:26:44,788 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 86)
2016-12-14 14:26:44,788 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 44.0 (TID 87)
2016-12-14 14:26:44,792 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,792 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,801 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 44.0 (TID 87). 2237 bytes result sent to driver
2016-12-14 14:26:44,801 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 86). 2237 bytes result sent to driver
2016-12-14 14:26:44,803 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 44.0 (TID 87) in 15 ms on localhost (1/2)
2016-12-14 14:26:44,803 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 86) in 16 ms on localhost (2/2)
2016-12-14 14:26:44,803 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,803 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 44 (countByValue at MulticlassMetrics.scala:43) finished in 0.016 s
2016-12-14 14:26:44,804 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:44,804 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:44,804 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 45)
2016-12-14 14:26:44,804 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:44,804 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 45 (ShuffledRDD[65] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:26:44,805 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 2.6 KB, free 356.5 KB)
2016-12-14 14:26:44,808 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 1561.0 B, free 358.0 KB)
2016-12-14 14:26:44,808 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:55377 (size: 1561.0 B, free: 530.0 MB)
2016-12-14 14:26:44,809 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,809 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 45 (ShuffledRDD[65] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:26:44,809 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 45.0 with 2 tasks
2016-12-14 14:26:44,810 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 45.0 (TID 88, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:44,811 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 45.0 (TID 89, localhost, partition 1,PROCESS_LOCAL, 2139 bytes)
2016-12-14 14:26:44,811 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 45.0 (TID 88)
2016-12-14 14:26:44,811 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 45.0 (TID 89)
2016-12-14 14:26:44,813 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,813 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:26:44,814 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:44,814 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:44,819 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 45.0 (TID 89). 1124 bytes result sent to driver
2016-12-14 14:26:44,820 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 45.0 (TID 88). 1163 bytes result sent to driver
2016-12-14 14:26:44,821 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 45.0 (TID 89) in 10 ms on localhost (1/2)
2016-12-14 14:26:44,821 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 45.0 (TID 88) in 11 ms on localhost (2/2)
2016-12-14 14:26:44,821 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 45 (countByValue at MulticlassMetrics.scala:43) finished in 0.012 s
2016-12-14 14:26:44,821 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,822 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: countByValue at MulticlassMetrics.scala:43, took 0.042294 s
2016-12-14 14:26:44,823 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.8933333333333333
2016-12-14 14:26:44,824 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 344.0 B, free 358.3 KB)
2016-12-14 14:26:44,829 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 294.0 B, free 358.6 KB)
2016-12-14 14:26:44,829 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:55377 (size: 294.0 B, free: 530.0 MB)
2016-12-14 14:26:44,830 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at KMeansModel.scala:87
2016-12-14 14:26:44,843 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 14:26:44,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 14:26:44,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 46 (sum at KMeansModel.scala:88)
2016-12-14 14:26:44,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:44,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:44,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 46 (MapPartitionsRDD[66] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 14:26:44,846 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 4.2 KB, free 362.8 KB)
2016-12-14 14:26:44,849 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.4 KB, free 365.3 KB)
2016-12-14 14:26:44,849 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:55377 (size: 2.4 KB, free: 530.0 MB)
2016-12-14 14:26:44,849 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:44,849 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[66] at map at KMeansModel.scala:88)
2016-12-14 14:26:44,850 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 46.0 with 2 tasks
2016-12-14 14:26:44,850 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 46.0 (TID 90, localhost, partition 0,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,851 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 46.0 (TID 91, localhost, partition 1,PROCESS_LOCAL, 2389 bytes)
2016-12-14 14:26:44,851 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 46.0 (TID 91)
2016-12-14 14:26:44,851 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 46.0 (TID 90)
2016-12-14 14:26:44,853 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:44,853 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:44,856 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 46.0 (TID 91). 2064 bytes result sent to driver
2016-12-14 14:26:44,856 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 46.0 (TID 90). 2064 bytes result sent to driver
2016-12-14 14:26:44,858 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 46.0 (TID 91) in 8 ms on localhost (1/2)
2016-12-14 14:26:44,858 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 46.0 (TID 90) in 8 ms on localhost (2/2)
2016-12-14 14:26:44,859 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 46 (sum at KMeansModel.scala:88) finished in 0.008 s
2016-12-14 14:26:44,859 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 14:26:44,859 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: sum at KMeansModel.scala:88, took 0.016077 s
2016-12-14 14:26:44,860 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 78.94084142614686
2016-12-14 14:26:44,860 INFO  com.datageek.test.K_means$ - main: ==(-_-)~====END====(-_-)~==
2016-12-14 14:26:44,957 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:26:44,958 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:26:44,958 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:26:44,958 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:26:44,958 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:26:44,959 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:26:44,959 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:26:44,959 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:26:44,959 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:26:44,960 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:26:44,960 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:26:44,960 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:26:44,960 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:26:44,961 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:26:44,961 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:26:44,961 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:26:44,962 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:26:44,962 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:26:44,962 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:26:44,963 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:26:44,963 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:26:44,963 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:26:44,964 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:26:44,964 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:26:44,964 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:26:45,023 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 14:26:45,122 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:26:45,132 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 14:26:45,133 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 14:26:45,133 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 14:26:45,135 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 14:26:45,142 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 14:26:45,142 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 14:26:45,146 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 14:26:45,146 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:26:45,148 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824
2016-12-14 14:26:45,191 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 14:26:45,192 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 14:47:31,588 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 14:47:32,725 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 14:47:32,731 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 14:47:32,732 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 14:47:33,119 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 20934.
2016-12-14 14:47:33,723 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 14:47:33,793 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 14:47:34,021 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:25226]
2016-12-14 14:47:34,023 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:25226]
2016-12-14 14:47:34,029 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 25226.
2016-12-14 14:47:34,044 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 14:47:34,058 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 14:47:34,070 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-4e5ddd04-51fd-4ca0-b0b7-8b1ed0ff11a2
2016-12-14 14:47:34,083 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 14:47:34,141 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 14:47:34,314 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 14:47:34,407 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:47:34,408 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:47:34,411 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 14:47:34,461 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:20934/jars/mysql-connector-java-5.1.25.jar with timestamp 1481698054460
2016-12-14 14:47:34,461 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:20934/jars/ojdbc6.jar with timestamp 1481698054461
2016-12-14 14:47:34,462 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:20934/jars/orai18n.jar with timestamp 1481698054462
2016-12-14 14:47:34,462 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:20934/jars/machine_learning_2.10-1.0.jar with timestamp 1481698054462
2016-12-14 14:47:34,573 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 14:47:34,608 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64382.
2016-12-14 14:47:34,609 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 64382
2016-12-14 14:47:34,613 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 14:47:34,614 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 14:47:34,619 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:64382 with 530.0 MB RAM, BlockManagerId(driver, localhost, 64382)
2016-12-14 14:47:34,623 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 14:47:36,558 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481698054520
2016-12-14 14:47:36,617 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/wine.txt
2016-12-14 14:47:36,617 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 14:47:36,617 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 14:47:36,617 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 14:47:36,618 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 14:47:36,618 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 14:47:37,326 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 14:47:37,687 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 14:47:37,690 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:64382 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 14:47:37,698 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:90
2016-12-14 14:47:37,810 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:47:37,918 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 14:47:37,949 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:47:37,982 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:47:37,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (takeSample at KMeans.scala:378)
2016-12-14 14:47:37,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:37,989 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:37,996 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210), which has no missing parents
2016-12-14 14:47:38,046 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 305.3 KB)
2016-12-14 14:47:38,062 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 307.7 KB)
2016-12-14 14:47:38,063 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:64382 (size: 2.4 KB, free: 530.0 MB)
2016-12-14 14:47:38,065 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:38,068 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210)
2016-12-14 14:47:38,069 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 2 tasks
2016-12-14 14:47:38,128 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:47:38,132 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:47:38,145 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:47:38,145 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 0.0 (TID 1)
2016-12-14 14:47:38,160 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 14:47:38,161 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20934/jars/mysql-connector-java-5.1.25.jar with timestamp 1481698054460
2016-12-14 14:47:38,277 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20934/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/fetchFileTemp7850179175118975943.tmp
2016-12-14 14:47:38,412 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 14:47:38,412 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20934/jars/machine_learning_2.10-1.0.jar with timestamp 1481698054462
2016-12-14 14:47:38,413 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20934/jars/machine_learning_2.10-1.0.jar to /tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/fetchFileTemp1504564305184023072.tmp
2016-12-14 14:47:38,423 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/machine_learning_2.10-1.0.jar to class loader
2016-12-14 14:47:38,423 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20934/jars/ojdbc6.jar with timestamp 1481698054461
2016-12-14 14:47:38,424 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20934/jars/ojdbc6.jar to /tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/fetchFileTemp2027493740398606151.tmp
2016-12-14 14:47:38,441 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/ojdbc6.jar to class loader
2016-12-14 14:47:38,441 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20934/jars/orai18n.jar with timestamp 1481698054462
2016-12-14 14:47:38,442 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20934/jars/orai18n.jar to /tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/fetchFileTemp121963471282230369.tmp
2016-12-14 14:47:38,453 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a/userFiles-fce3bb6b-cb02-4dab-b21b-d5eaa653ba85/orai18n.jar to class loader
2016-12-14 14:47:38,475 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 14:47:38,475 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 14:47:38,478 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/wine.txt:0+5738
2016-12-14 14:47:38,478 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/wine.txt:5738+5739
2016-12-14 14:47:38,496 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 14:47:38,496 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 14:47:38,496 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 14:47:38,496 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 14:47:38,496 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 14:47:38,540 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 14.3 KB, free 321.9 KB)
2016-12-14 14:47:38,540 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 14.3 KB, free 336.2 KB)
2016-12-14 14:47:38,541 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:64382 (size: 14.3 KB, free: 530.0 MB)
2016-12-14 14:47:38,541 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:64382 (size: 14.3 KB, free: 530.0 MB)
2016-12-14 14:47:38,542 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_0 not found, computing it
2016-12-14 14:47:38,542 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_1 not found, computing it
2016-12-14 14:47:38,542 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:38,542 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:38,548 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_0 stored as values in memory (estimated size 2.5 KB, free 338.7 KB)
2016-12-14 14:47:38,549 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_1 stored as values in memory (estimated size 2.5 KB, free 341.1 KB)
2016-12-14 14:47:38,549 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_0 in memory on localhost:64382 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:47:38,551 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_1 in memory on localhost:64382 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:47:38,594 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2638 bytes result sent to driver
2016-12-14 14:47:38,594 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 0.0 (TID 1). 2638 bytes result sent to driver
2016-12-14 14:47:38,611 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 0.0 (TID 1) in 479 ms on localhost (1/2)
2016-12-14 14:47:38,612 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 519 ms on localhost (2/2)
2016-12-14 14:47:38,613 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:47:38,614 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (takeSample at KMeans.scala:378) finished in 0.537 s
2016-12-14 14:47:38,619 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: takeSample at KMeans.scala:378, took 0.669918 s
2016-12-14 14:47:38,714 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:47:38,716 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:47:38,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (takeSample at KMeans.scala:378)
2016-12-14 14:47:38,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:38,720 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:38,720 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 14:47:38,723 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 21.3 KB, free 362.4 KB)
2016-12-14 14:47:38,729 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.9 KB, free 371.3 KB)
2016-12-14 14:47:38,730 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:64382 (size: 8.9 KB, free: 529.9 MB)
2016-12-14 14:47:38,731 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:38,732 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378)
2016-12-14 14:47:38,732 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 2 tasks
2016-12-14 14:47:38,738 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:47:38,739 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:47:38,740 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 2)
2016-12-14 14:47:38,740 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 1.0 (TID 3)
2016-12-14 14:47:38,755 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:38,755 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:38,755 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:38,755 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:38,785 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 2). 4858 bytes result sent to driver
2016-12-14 14:47:38,785 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 1.0 (TID 3). 4747 bytes result sent to driver
2016-12-14 14:47:38,805 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 2) in 69 ms on localhost (1/2)
2016-12-14 14:47:38,807 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 1.0 (TID 3) in 68 ms on localhost (2/2)
2016-12-14 14:47:38,807 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (takeSample at KMeans.scala:378) finished in 0.073 s
2016-12-14 14:47:38,807 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:47:38,808 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: takeSample at KMeans.scala:378, took 0.092788 s
2016-12-14 14:47:38,813 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 2.7 KB, free 374.0 KB)
2016-12-14 14:47:38,819 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 944.0 B, free 374.9 KB)
2016-12-14 14:47:38,821 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:64382 (size: 944.0 B, free: 529.9 MB)
2016-12-14 14:47:38,822 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at KMeans.scala:396
2016-12-14 14:47:38,855 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:47:38,856 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:47:38,857 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (aggregate at KMeans.scala:404)
2016-12-14 14:47:38,857 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:38,858 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:38,859 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:47:38,862 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 380.7 KB)
2016-12-14 14:47:38,868 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.0 KB, free 383.7 KB)
2016-12-14 14:47:38,868 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:64382 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:47:38,869 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:38,869 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398)
2016-12-14 14:47:38,869 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 14:47:38,871 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:47:38,872 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:47:38,873 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 4)
2016-12-14 14:47:38,873 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 5)
2016-12-14 14:47:38,880 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_0 not found, computing it
2016-12-14 14:47:38,881 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:38,881 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_1 not found, computing it
2016-12-14 14:47:38,881 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:38,882 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:38,882 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:38,882 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:38,882 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:38,883 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:38,883 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:38,899 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 14:47:38,900 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 14:47:38,912 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_0 stored as values in memory (estimated size 8.7 KB, free 392.4 KB)
2016-12-14 14:47:38,913 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_1 stored as values in memory (estimated size 8.7 KB, free 401.2 KB)
2016-12-14 14:47:38,913 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_0 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:38,913 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_1 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:38,921 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 4). 2721 bytes result sent to driver
2016-12-14 14:47:38,922 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 5). 2721 bytes result sent to driver
2016-12-14 14:47:38,929 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
2016-12-14 14:47:38,934 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 5) in 61 ms on localhost (2/2)
2016-12-14 14:47:38,934 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (aggregate at KMeans.scala:404) finished in 0.064 s
2016-12-14 14:47:38,934 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:47:38,934 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: aggregate at KMeans.scala:404, took 0.078912 s
2016-12-14 14:47:38,943 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 7 from persistence list
2016-12-14 14:47:38,952 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 7
2016-12-14 14:47:38,965 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:47:38,966 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:47:38,966 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (collect at KMeans.scala:436)
2016-12-14 14:47:38,966 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:38,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:38,969 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:47:38,972 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 6.0 KB, free 407.2 KB)
2016-12-14 14:47:38,981 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 410.3 KB)
2016-12-14 14:47:38,983 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:64382 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:38,984 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:38,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:47:38,984 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 14:47:38,986 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:47:38,986 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:47:38,986 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 6)
2016-12-14 14:47:38,987 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 7)
2016-12-14 14:47:38,992 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:38,992 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:38,993 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:38,993 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:38,993 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:47:38,993 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:47:39,007 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 7). 3935 bytes result sent to driver
2016-12-14 14:47:39,009 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 6). 6392 bytes result sent to driver
2016-12-14 14:47:39,017 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 6) in 32 ms on localhost (1/2)
2016-12-14 14:47:39,022 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (collect at KMeans.scala:436) finished in 0.037 s
2016-12-14 14:47:39,022 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 7) in 35 ms on localhost (2/2)
2016-12-14 14:47:39,022 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: collect at KMeans.scala:436, took 0.057129 s
2016-12-14 14:47:39,022 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,026 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 9.1 KB, free 419.5 KB)
2016-12-14 14:47:39,033 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.2 KB, free 422.7 KB)
2016-12-14 14:47:39,034 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:64382 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:39,035 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at KMeans.scala:396
2016-12-14 14:47:39,057 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:47:39,059 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:47:39,059 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (aggregate at KMeans.scala:404)
2016-12-14 14:47:39,059 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:47:39,063 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 6.1 KB, free 428.7 KB)
2016-12-14 14:47:39,068 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.1 KB, free 431.8 KB)
2016-12-14 14:47:39,069 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:64382 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:47:39,069 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,070 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398)
2016-12-14 14:47:39,070 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 14:47:39,072 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:47:39,072 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:47:39,072 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 8)
2016-12-14 14:47:39,073 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 9)
2016-12-14 14:47:39,078 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_0 not found, computing it
2016-12-14 14:47:39,078 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_1 not found, computing it
2016-12-14 14:47:39,078 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,079 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,079 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,079 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,079 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:47:39,079 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:47:39,090 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_1 stored as values in memory (estimated size 8.7 KB, free 440.5 KB)
2016-12-14 14:47:39,091 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_0 stored as values in memory (estimated size 8.7 KB, free 449.2 KB)
2016-12-14 14:47:39,091 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_1 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,092 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_0 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,099 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 9). 2721 bytes result sent to driver
2016-12-14 14:47:39,099 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 8). 2721 bytes result sent to driver
2016-12-14 14:47:39,104 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 8) in 34 ms on localhost (1/2)
2016-12-14 14:47:39,105 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 9) in 32 ms on localhost (2/2)
2016-12-14 14:47:39,105 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (aggregate at KMeans.scala:404) finished in 0.035 s
2016-12-14 14:47:39,105 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,105 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: aggregate at KMeans.scala:404, took 0.047732 s
2016-12-14 14:47:39,106 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 10 from persistence list
2016-12-14 14:47:39,109 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:47:39,128 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:47:39,129 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:47:39,130 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (collect at KMeans.scala:436)
2016-12-14 14:47:39,130 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,132 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,132 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:47:39,136 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.2 KB, free 438.1 KB)
2016-12-14 14:47:39,143 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.2 KB, free 441.3 KB)
2016-12-14 14:47:39,144 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:64382 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:39,145 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,145 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:47:39,145 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 14:47:39,148 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:47:39,149 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:47:39,150 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 10)
2016-12-14 14:47:39,150 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 11)
2016-12-14 14:47:39,153 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,153 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,153 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,153 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,154 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:47:39,154 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:47:39,162 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 11). 4702 bytes result sent to driver
2016-12-14 14:47:39,164 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 10). 6754 bytes result sent to driver
2016-12-14 14:47:39,170 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 11) in 21 ms on localhost (1/2)
2016-12-14 14:47:39,171 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 10) in 24 ms on localhost (2/2)
2016-12-14 14:47:39,171 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (collect at KMeans.scala:436) finished in 0.025 s
2016-12-14 14:47:39,171 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,171 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: collect at KMeans.scala:436, took 0.043124 s
2016-12-14 14:47:39,176 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 10.1 KB, free 451.4 KB)
2016-12-14 14:47:39,186 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.6 KB, free 455.0 KB)
2016-12-14 14:47:39,187 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:39,187 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at KMeans.scala:396
2016-12-14 14:47:39,208 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:47:39,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:47:39,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 14:47:39,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,212 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,213 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:47:39,217 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 461.3 KB)
2016-12-14 14:47:39,227 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.1 KB, free 464.5 KB)
2016-12-14 14:47:39,227 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:64382 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:47:39,228 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,228 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398)
2016-12-14 14:47:39,228 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 14:47:39,230 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:47:39,230 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:47:39,231 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 12)
2016-12-14 14:47:39,231 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 13)
2016-12-14 14:47:39,234 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_0 not found, computing it
2016-12-14 14:47:39,234 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_1 not found, computing it
2016-12-14 14:47:39,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:47:39,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:47:39,242 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_1 stored as values in memory (estimated size 8.7 KB, free 473.2 KB)
2016-12-14 14:47:39,243 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_0 stored as values in memory (estimated size 8.7 KB, free 481.9 KB)
2016-12-14 14:47:39,243 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_1 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,244 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_0 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,250 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 12). 2721 bytes result sent to driver
2016-12-14 14:47:39,250 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 13). 2721 bytes result sent to driver
2016-12-14 14:47:39,254 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 13) in 24 ms on localhost (1/2)
2016-12-14 14:47:39,256 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 12) in 27 ms on localhost (2/2)
2016-12-14 14:47:39,256 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.027 s
2016-12-14 14:47:39,257 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,257 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.048775 s
2016-12-14 14:47:39,258 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 14 from persistence list
2016-12-14 14:47:39,258 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:47:39,294 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:47:39,296 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:47:39,296 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:64382 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:47:39,296 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 14:47:39,297 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,298 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,299 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:47:39,300 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 14:47:39,301 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:64382 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:39,302 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.5 KB, free 458.2 KB)
2016-12-14 14:47:39,303 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 14:47:39,305 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:64382 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:47:39,306 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 14:47:39,307 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:64382 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:39,308 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 14:47:39,309 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:64382 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:47:39,310 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 434.0 KB)
2016-12-14 14:47:39,310 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 14:47:39,311 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:64382 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:47:39,312 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,312 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:64382 in memory (size: 8.9 KB, free: 529.9 MB)
2016-12-14 14:47:39,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:47:39,313 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 14:47:39,313 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 14:47:39,314 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:64382 in memory (size: 2.4 KB, free: 529.9 MB)
2016-12-14 14:47:39,314 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 14:47:39,315 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:47:39,317 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:47:39,317 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 15)
2016-12-14 14:47:39,317 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 14)
2016-12-14 14:47:39,320 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,321 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,321 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:47:39,322 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,322 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,323 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:47:39,328 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 14). 6245 bytes result sent to driver
2016-12-14 14:47:39,329 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 15). 5341 bytes result sent to driver
2016-12-14 14:47:39,340 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 14) in 26 ms on localhost (1/2)
2016-12-14 14:47:39,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 15) in 26 ms on localhost (2/2)
2016-12-14 14:47:39,341 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 14:47:39,341 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.047511 s
2016-12-14 14:47:39,344 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 10.4 KB, free 401.6 KB)
2016-12-14 14:47:39,353 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 405.4 KB)
2016-12-14 14:47:39,354 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:64382 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,355 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at KMeans.scala:396
2016-12-14 14:47:39,373 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:47:39,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:47:39,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 14:47:39,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,378 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,379 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:47:39,382 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 6.5 KB, free 411.9 KB)
2016-12-14 14:47:39,389 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.2 KB, free 415.1 KB)
2016-12-14 14:47:39,390 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:64382 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:39,391 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,392 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398)
2016-12-14 14:47:39,392 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 14:47:39,394 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:47:39,396 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:47:39,397 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 17)
2016-12-14 14:47:39,397 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 16)
2016-12-14 14:47:39,400 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_1 not found, computing it
2016-12-14 14:47:39,400 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_0 not found, computing it
2016-12-14 14:47:39,400 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:47:39,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:47:39,404 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_1 stored as values in memory (estimated size 8.7 KB, free 423.8 KB)
2016-12-14 14:47:39,404 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_0 stored as values in memory (estimated size 8.7 KB, free 432.5 KB)
2016-12-14 14:47:39,405 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_1 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,405 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_0 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,408 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 17). 2721 bytes result sent to driver
2016-12-14 14:47:39,409 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 16). 2721 bytes result sent to driver
2016-12-14 14:47:39,413 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 17) in 18 ms on localhost (1/2)
2016-12-14 14:47:39,414 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 16) in 21 ms on localhost (2/2)
2016-12-14 14:47:39,414 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.021 s
2016-12-14 14:47:39,414 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,415 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.040939 s
2016-12-14 14:47:39,416 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 18 from persistence list
2016-12-14 14:47:39,417 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:47:39,434 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:47:39,437 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:47:39,437 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 14:47:39,437 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,439 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,439 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:47:39,443 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.7 KB, free 421.8 KB)
2016-12-14 14:47:39,451 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 425.2 KB)
2016-12-14 14:47:39,452 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:64382 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:47:39,453 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,453 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:47:39,454 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 14:47:39,455 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:47:39,456 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:47:39,456 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 19)
2016-12-14 14:47:39,456 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 18)
2016-12-14 14:47:39,460 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,460 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,460 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,460 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,460 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:47:39,460 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:47:39,466 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 18). 6508 bytes result sent to driver
2016-12-14 14:47:39,466 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 19). 4575 bytes result sent to driver
2016-12-14 14:47:39,478 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 19) in 22 ms on localhost (1/2)
2016-12-14 14:47:39,479 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 18) in 24 ms on localhost (2/2)
2016-12-14 14:47:39,479 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.025 s
2016-12-14 14:47:39,479 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.044698 s
2016-12-14 14:47:39,482 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 9.8 KB, free 435.0 KB)
2016-12-14 14:47:39,491 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.5 KB, free 438.5 KB)
2016-12-14 14:47:39,492 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:64382 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:47:39,492 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at KMeans.scala:396
2016-12-14 14:47:39,510 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:47:39,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:47:39,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 14:47:39,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,516 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,516 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:47:39,519 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 6.8 KB, free 445.2 KB)
2016-12-14 14:47:39,526 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.3 KB, free 448.5 KB)
2016-12-14 14:47:39,526 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:64382 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:47:39,527 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,527 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398)
2016-12-14 14:47:39,528 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 14:47:39,529 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:47:39,530 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:47:39,530 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 21)
2016-12-14 14:47:39,530 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 20)
2016-12-14 14:47:39,534 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_1 not found, computing it
2016-12-14 14:47:39,534 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_0 not found, computing it
2016-12-14 14:47:39,534 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,534 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,534 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,535 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,535 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:47:39,535 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:47:39,537 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_0 stored as values in memory (estimated size 8.7 KB, free 457.2 KB)
2016-12-14 14:47:39,537 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_1 stored as values in memory (estimated size 8.7 KB, free 465.9 KB)
2016-12-14 14:47:39,538 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_0 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,538 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_1 in memory on localhost:64382 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:47:39,541 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 21). 2721 bytes result sent to driver
2016-12-14 14:47:39,541 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 20). 2721 bytes result sent to driver
2016-12-14 14:47:39,544 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 21) in 14 ms on localhost (1/2)
2016-12-14 14:47:39,549 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 20) in 19 ms on localhost (2/2)
2016-12-14 14:47:39,549 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.020 s
2016-12-14 14:47:39,549 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,549 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.038463 s
2016-12-14 14:47:39,551 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 22 from persistence list
2016-12-14 14:47:39,551 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:47:39,568 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:47:39,569 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:47:39,570 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 14:47:39,570 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:39,571 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:39,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:47:39,574 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 6.9 KB, free 455.4 KB)
2016-12-14 14:47:39,578 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.4 KB, free 458.9 KB)
2016-12-14 14:47:39,578 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:64382 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:47:39,579 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,579 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:47:39,579 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 14:47:39,581 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:47:39,581 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:47:39,582 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 22)
2016-12-14 14:47:39,582 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 23)
2016-12-14 14:47:39,584 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,584 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,585 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,585 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,585 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_1 locally
2016-12-14 14:47:39,585 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_0 locally
2016-12-14 14:47:39,589 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 23). 5349 bytes result sent to driver
2016-12-14 14:47:39,589 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 22). 4841 bytes result sent to driver
2016-12-14 14:47:39,594 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 23) in 13 ms on localhost (1/2)
2016-12-14 14:47:39,595 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 22) in 15 ms on localhost (2/2)
2016-12-14 14:47:39,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.015 s
2016-12-14 14:47:39,595 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,596 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.027804 s
2016-12-14 14:47:39,597 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 26 from persistence list
2016-12-14 14:47:39,598 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:47:39,599 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 46.5 KB, free 487.9 KB)
2016-12-14 14:47:39,609 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.8 KB, free 497.8 KB)
2016-12-14 14:47:39,611 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:64382 (size: 9.8 KB, free: 529.9 MB)
2016-12-14 14:47:39,612 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at KMeans.scala:450
2016-12-14 14:47:39,659 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 14:47:39,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 29 (flatMap at KMeans.scala:451)
2016-12-14 14:47:39,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 14:47:39,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collectAsMap at KMeans.scala:455)
2016-12-14 14:47:39,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 12)
2016-12-14 14:47:39,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 12)
2016-12-14 14:47:39,683 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 14:47:39,693 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 5.9 KB, free 503.7 KB)
2016-12-14 14:47:39,700 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.2 KB, free 506.9 KB)
2016-12-14 14:47:39,701 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:64382 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:39,701 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,705 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451)
2016-12-14 14:47:39,705 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 14:47:39,708 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:39,708 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:39,709 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 24)
2016-12-14 14:47:39,709 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 25)
2016-12-14 14:47:39,714 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:39,714 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:39,714 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:39,715 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:39,827 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 25). 2237 bytes result sent to driver
2016-12-14 14:47:39,827 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 24). 2237 bytes result sent to driver
2016-12-14 14:47:39,834 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 25) in 126 ms on localhost (1/2)
2016-12-14 14:47:39,836 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 24) in 130 ms on localhost (2/2)
2016-12-14 14:47:39,837 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,837 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 12 (flatMap at KMeans.scala:451) finished in 0.130 s
2016-12-14 14:47:39,837 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:39,838 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:39,838 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 13)
2016-12-14 14:47:39,839 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:39,841 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 14:47:39,846 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 2.6 KB, free 509.4 KB)
2016-12-14 14:47:39,850 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1555.0 B, free 510.9 KB)
2016-12-14 14:47:39,851 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:64382 (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:47:39,851 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:39,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455)
2016-12-14 14:47:39,852 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 14:47:39,855 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 26, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:39,855 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 27, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:39,856 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 26)
2016-12-14 14:47:39,856 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 27)
2016-12-14 14:47:39,875 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:39,875 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:39,878 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 8 ms
2016-12-14 14:47:39,878 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 8 ms
2016-12-14 14:47:39,946 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 26). 4608 bytes result sent to driver
2016-12-14 14:47:39,946 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 27). 4545 bytes result sent to driver
2016-12-14 14:47:39,950 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 26) in 97 ms on localhost (1/2)
2016-12-14 14:47:39,950 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 27) in 95 ms on localhost (2/2)
2016-12-14 14:47:39,951 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collectAsMap at KMeans.scala:455) finished in 0.098 s
2016-12-14 14:47:39,951 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:47:39,951 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: collectAsMap at KMeans.scala:455, took 0.292148 s
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:47:40,044 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 7 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:47:40,043 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 14:47:40,060 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 2.223 seconds.
2016-12-14 14:47:40,066 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 5.1 KB, free 516.0 KB)
2016-12-14 14:47:40,070 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.4 KB, free 519.4 KB)
2016-12-14 14:47:40,070 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:64382 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:47:40,071 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,089 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,090 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 31 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,091 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,091 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,091 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 14)
2016-12-14 14:47:40,091 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 14)
2016-12-14 14:47:40,092 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,095 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 6.9 KB, free 526.3 KB)
2016-12-14 14:47:40,099 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.6 KB, free 529.9 KB)
2016-12-14 14:47:40,100 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,100 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,100 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,100 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 14:47:40,102 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,102 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,102 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 29)
2016-12-14 14:47:40,102 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 28)
2016-12-14 14:47:40,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,118 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 29). 2516 bytes result sent to driver
2016-12-14 14:47:40,118 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 28). 2516 bytes result sent to driver
2016-12-14 14:47:40,124 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 28) in 23 ms on localhost (1/2)
2016-12-14 14:47:40,125 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 29) in 23 ms on localhost (2/2)
2016-12-14 14:47:40,125 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 14 (mapPartitions at KMeans.scala:279) finished in 0.024 s
2016-12-14 14:47:40,125 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,125 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 15)
2016-12-14 14:47:40,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,128 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 2.9 KB, free 532.8 KB)
2016-12-14 14:47:40,132 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1669.0 B, free 534.4 KB)
2016-12-14 14:47:40,133 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:64382 (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:47:40,133 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,133 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,133 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 14:47:40,135 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 30, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,135 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 31, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,135 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 30)
2016-12-14 14:47:40,135 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 31)
2016-12-14 14:47:40,137 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,137 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,138 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,138 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,148 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 31). 3054 bytes result sent to driver
2016-12-14 14:47:40,148 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 30). 3052 bytes result sent to driver
2016-12-14 14:47:40,153 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 31) in 18 ms on localhost (1/2)
2016-12-14 14:47:40,153 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 30) in 19 ms on localhost (2/2)
2016-12-14 14:47:40,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 14:47:40,154 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,154 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collectAsMap at KMeans.scala:302, took 0.064450 s
2016-12-14 14:47:40,157 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 5.1 KB, free 539.5 KB)
2016-12-14 14:47:40,161 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 541.8 KB)
2016-12-14 14:47:40,162 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:64382 (size: 2.2 KB, free: 529.9 MB)
2016-12-14 14:47:40,162 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,171 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,172 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 33 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,172 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,172 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,173 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 14:47:40,173 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 14:47:40,174 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,176 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 6.9 KB, free 548.6 KB)
2016-12-14 14:47:40,180 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.6 KB, free 552.2 KB)
2016-12-14 14:47:40,181 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,181 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,182 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,182 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 14:47:40,183 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,183 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 33, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,184 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 33)
2016-12-14 14:47:40,184 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 32)
2016-12-14 14:47:40,187 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,187 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,187 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,187 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,196 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 32). 2516 bytes result sent to driver
2016-12-14 14:47:40,196 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 33). 2516 bytes result sent to driver
2016-12-14 14:47:40,200 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 32) in 17 ms on localhost (1/2)
2016-12-14 14:47:40,202 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 33) in 19 ms on localhost (2/2)
2016-12-14 14:47:40,203 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (mapPartitions at KMeans.scala:279) finished in 0.020 s
2016-12-14 14:47:40,203 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,203 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,203 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,203 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 14:47:40,203 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,204 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,205 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 2.9 KB, free 555.1 KB)
2016-12-14 14:47:40,209 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1665.0 B, free 556.7 KB)
2016-12-14 14:47:40,209 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:64382 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:47:40,210 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,210 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 14:47:40,211 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 34, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,212 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 35, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,212 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 34)
2016-12-14 14:47:40,212 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 35)
2016-12-14 14:47:40,214 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,214 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,214 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,214 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,224 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 34). 3052 bytes result sent to driver
2016-12-14 14:47:40,224 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 35). 3054 bytes result sent to driver
2016-12-14 14:47:40,228 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 34) in 17 ms on localhost (1/2)
2016-12-14 14:47:40,229 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 35) in 17 ms on localhost (2/2)
2016-12-14 14:47:40,229 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:302) finished in 0.018 s
2016-12-14 14:47:40,229 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,229 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: collectAsMap at KMeans.scala:302, took 0.058233 s
2016-12-14 14:47:40,232 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 2 iterations
2016-12-14 14:47:40,232 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 2 iterations
2016-12-14 14:47:40,233 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 2 iterations
2016-12-14 14:47:40,233 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 2 iterations
2016-12-14 14:47:40,233 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 2 iterations
2016-12-14 14:47:40,234 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 2.6 KB, free 559.3 KB)
2016-12-14 14:47:40,240 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 1554.0 B, free 560.8 KB)
2016-12-14 14:47:40,241 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:64382 (size: 1554.0 B, free: 529.9 MB)
2016-12-14 14:47:40,242 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,259 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 35 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 14:47:40,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 14:47:40,263 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,264 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 6.7 KB, free 567.5 KB)
2016-12-14 14:47:40,268 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.6 KB, free 571.1 KB)
2016-12-14 14:47:40,269 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,269 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,269 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,270 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 14:47:40,271 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 36, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,272 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 37, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,272 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 37)
2016-12-14 14:47:40,272 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 36)
2016-12-14 14:47:40,275 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,275 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,276 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,276 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,283 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 37). 2396 bytes result sent to driver
2016-12-14 14:47:40,283 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 36). 2396 bytes result sent to driver
2016-12-14 14:47:40,287 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 37) in 15 ms on localhost (1/2)
2016-12-14 14:47:40,288 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 36) in 18 ms on localhost (2/2)
2016-12-14 14:47:40,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:47:40,288 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 14:47:40,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,290 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,292 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 2.9 KB, free 574.0 KB)
2016-12-14 14:47:40,297 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1667.0 B, free 575.6 KB)
2016-12-14 14:47:40,297 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:64382 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:47:40,298 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,299 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,299 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 14:47:40,300 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 38, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,301 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 39, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,301 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 38)
2016-12-14 14:47:40,301 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 39)
2016-12-14 14:47:40,303 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,303 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,303 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,303 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,311 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 39). 2173 bytes result sent to driver
2016-12-14 14:47:40,311 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 38). 2045 bytes result sent to driver
2016-12-14 14:47:40,315 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 39) in 14 ms on localhost (1/2)
2016-12-14 14:47:40,318 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 38) in 18 ms on localhost (2/2)
2016-12-14 14:47:40,318 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.018 s
2016-12-14 14:47:40,318 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,318 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collectAsMap at KMeans.scala:302, took 0.058977 s
2016-12-14 14:47:40,319 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 3 iterations
2016-12-14 14:47:40,320 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 3 iterations
2016-12-14 14:47:40,320 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 1592.0 B, free 577.2 KB)
2016-12-14 14:47:40,324 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 954.0 B, free 578.1 KB)
2016-12-14 14:47:40,325 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:64382 (size: 954.0 B, free: 529.9 MB)
2016-12-14 14:47:40,325 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,352 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:64382 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:47:40,354 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:64382 in memory (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:47:40,355 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 14:47:40,356 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,357 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 14:47:40,359 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,361 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 14:47:40,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 37 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,361 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:64382 in memory (size: 1554.0 B, free: 529.9 MB)
2016-12-14 14:47:40,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 14:47:40,362 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 14:47:40,362 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 14:47:40,362 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 14:47:40,362 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 14:47:40,362 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 14:47:40,362 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 14:47:40,363 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,363 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:64382 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:47:40,364 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 14:47:40,364 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,364 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 6.6 KB, free 547.6 KB)
2016-12-14 14:47:40,366 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:47:40,367 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 14
2016-12-14 14:47:40,368 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:64382 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:40,368 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:47:40,368 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.6 KB, free 528.7 KB)
2016-12-14 14:47:40,369 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 10
2016-12-14 14:47:40,369 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,369 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,370 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:64382 in memory (size: 944.0 B, free: 529.9 MB)
2016-12-14 14:47:40,370 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,370 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 14:47:40,371 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:64382 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:40,372 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 14:47:40,372 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,372 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 41, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,373 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 40)
2016-12-14 14:47:40,373 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 14:47:40,373 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 41)
2016-12-14 14:47:40,373 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:64382 in memory (size: 9.8 KB, free: 529.9 MB)
2016-12-14 14:47:40,375 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:64382 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:47:40,376 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 14:47:40,377 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:64382 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:47:40,377 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 14:47:40,378 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:47:40,378 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,378 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,378 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,378 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,378 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 26
2016-12-14 14:47:40,380 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:64382 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:47:40,380 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 14:47:40,381 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:64382 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:40,382 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 14:47:40,383 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:47:40,383 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 22
2016-12-14 14:47:40,384 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:64382 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:47:40,385 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:64382 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:47:40,385 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 14:47:40,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:47:40,386 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 18
2016-12-14 14:47:40,387 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 14:47:40,387 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 14:47:40,387 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 14:47:40,387 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 14:47:40,387 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 14:47:40,387 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 14:47:40,387 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 14:47:40,388 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:64382 in memory (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:47:40,388 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 14:47:40,389 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,389 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 41). 2348 bytes result sent to driver
2016-12-14 14:47:40,389 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 40). 2348 bytes result sent to driver
2016-12-14 14:47:40,389 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 14:47:40,390 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 14:47:40,391 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:64382 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:47:40,391 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 14:47:40,391 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 14:47:40,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 14:47:40,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 14:47:40,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 14:47:40,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 14:47:40,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 14:47:40,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 14:47:40,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 14:47:40,393 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 14:47:40,393 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 41) in 21 ms on localhost (1/2)
2016-12-14 14:47:40,393 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:64382 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:47:40,394 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 40) in 22 ms on localhost (2/2)
2016-12-14 14:47:40,394 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 14:47:40,394 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.022 s
2016-12-14 14:47:40,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,394 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 14:47:40,395 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,395 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 14:47:40,395 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,395 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 14:47:40,396 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:64382 in memory (size: 2.2 KB, free: 529.9 MB)
2016-12-14 14:47:40,396 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 14:47:40,396 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 2.9 KB, free 350.0 KB)
2016-12-14 14:47:40,396 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 14:47:40,396 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 14:47:40,399 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1666.0 B, free 351.6 KB)
2016-12-14 14:47:40,399 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:64382 (size: 1666.0 B, free: 529.9 MB)
2016-12-14 14:47:40,400 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,400 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,400 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 14:47:40,402 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 42, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,402 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 43, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,402 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 42)
2016-12-14 14:47:40,402 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 43)
2016-12-14 14:47:40,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,406 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,406 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,418 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 43). 1794 bytes result sent to driver
2016-12-14 14:47:40,418 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 42). 1670 bytes result sent to driver
2016-12-14 14:47:40,422 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 43) in 20 ms on localhost (1/2)
2016-12-14 14:47:40,424 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 42) in 23 ms on localhost (2/2)
2016-12-14 14:47:40,424 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.023 s
2016-12-14 14:47:40,424 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,424 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:302, took 0.064192 s
2016-12-14 14:47:40,426 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 1592.0 B, free 353.2 KB)
2016-12-14 14:47:40,431 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 831.0 B, free 354.0 KB)
2016-12-14 14:47:40,432 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:64382 (size: 831.0 B, free: 529.9 MB)
2016-12-14 14:47:40,432 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,449 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 39 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 14:47:40,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 14:47:40,453 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,455 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 6.6 KB, free 360.6 KB)
2016-12-14 14:47:40,460 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.6 KB, free 364.1 KB)
2016-12-14 14:47:40,460 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,461 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,462 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,462 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 14:47:40,464 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 44, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,464 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 45, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,465 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 44)
2016-12-14 14:47:40,465 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 45)
2016-12-14 14:47:40,469 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,469 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,470 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,470 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,479 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 45). 2348 bytes result sent to driver
2016-12-14 14:47:40,479 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 44). 2348 bytes result sent to driver
2016-12-14 14:47:40,483 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 44) in 20 ms on localhost (1/2)
2016-12-14 14:47:40,484 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 45) in 20 ms on localhost (2/2)
2016-12-14 14:47:40,484 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.021 s
2016-12-14 14:47:40,484 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,484 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,484 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,484 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 14:47:40,484 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,485 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,487 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 2.9 KB, free 367.1 KB)
2016-12-14 14:47:40,491 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1664.0 B, free 368.7 KB)
2016-12-14 14:47:40,491 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:64382 (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:47:40,492 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,492 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,492 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 14:47:40,493 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 46, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,493 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 47, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,494 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 46)
2016-12-14 14:47:40,494 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 47)
2016-12-14 14:47:40,496 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,496 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,497 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,497 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,508 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 47). 1794 bytes result sent to driver
2016-12-14 14:47:40,508 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 46). 1670 bytes result sent to driver
2016-12-14 14:47:40,511 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 47) in 18 ms on localhost (1/2)
2016-12-14 14:47:40,514 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 46) in 21 ms on localhost (2/2)
2016-12-14 14:47:40,515 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:47:40,515 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,515 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.065946 s
2016-12-14 14:47:40,517 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 1592.0 B, free 370.2 KB)
2016-12-14 14:47:40,522 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 846.0 B, free 371.1 KB)
2016-12-14 14:47:40,523 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:64382 (size: 846.0 B, free: 529.9 MB)
2016-12-14 14:47:40,524 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,541 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,542 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 41 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 14:47:40,544 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 14:47:40,545 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,547 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 6.6 KB, free 377.7 KB)
2016-12-14 14:47:40,552 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.6 KB, free 381.2 KB)
2016-12-14 14:47:40,552 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,553 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,553 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,554 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 14:47:40,555 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 48, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,556 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 49, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,557 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 48)
2016-12-14 14:47:40,557 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 49)
2016-12-14 14:47:40,561 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,561 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,561 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,561 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,571 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 48). 2348 bytes result sent to driver
2016-12-14 14:47:40,571 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 49). 2348 bytes result sent to driver
2016-12-14 14:47:40,573 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 48) in 18 ms on localhost (1/2)
2016-12-14 14:47:40,577 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 49) in 21 ms on localhost (2/2)
2016-12-14 14:47:40,577 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.023 s
2016-12-14 14:47:40,578 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,578 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,578 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,578 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 14:47:40,578 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,579 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,581 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 2.9 KB, free 384.1 KB)
2016-12-14 14:47:40,584 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1668.0 B, free 385.8 KB)
2016-12-14 14:47:40,584 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:64382 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:40,585 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,585 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,585 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 14:47:40,587 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 50, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,588 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 51, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,589 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 50)
2016-12-14 14:47:40,589 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 51)
2016-12-14 14:47:40,591 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,591 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,592 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,592 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,602 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 50). 1670 bytes result sent to driver
2016-12-14 14:47:40,603 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 51). 1794 bytes result sent to driver
2016-12-14 14:47:40,605 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 50) in 19 ms on localhost (1/2)
2016-12-14 14:47:40,611 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 51) in 23 ms on localhost (2/2)
2016-12-14 14:47:40,611 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.025 s
2016-12-14 14:47:40,611 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,612 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.070402 s
2016-12-14 14:47:40,614 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 1592.0 B, free 387.3 KB)
2016-12-14 14:47:40,619 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 838.0 B, free 388.1 KB)
2016-12-14 14:47:40,620 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:64382 (size: 838.0 B, free: 529.9 MB)
2016-12-14 14:47:40,621 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,631 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 43 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 14:47:40,635 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 14:47:40,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,637 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 6.6 KB, free 394.7 KB)
2016-12-14 14:47:40,641 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.6 KB, free 398.3 KB)
2016-12-14 14:47:40,642 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,642 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,643 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,643 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 14:47:40,645 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 52, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,646 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 53, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,646 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 52)
2016-12-14 14:47:40,646 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 53)
2016-12-14 14:47:40,650 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,650 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,651 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,651 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,656 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 53). 2348 bytes result sent to driver
2016-12-14 14:47:40,656 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 52). 2348 bytes result sent to driver
2016-12-14 14:47:40,659 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 53) in 14 ms on localhost (1/2)
2016-12-14 14:47:40,663 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 52) in 19 ms on localhost (2/2)
2016-12-14 14:47:40,663 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.019 s
2016-12-14 14:47:40,663 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,663 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,663 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,664 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 14:47:40,664 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,665 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,667 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 2.9 KB, free 401.2 KB)
2016-12-14 14:47:40,671 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1668.0 B, free 402.8 KB)
2016-12-14 14:47:40,672 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:64382 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:40,673 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,673 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,674 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 14:47:40,675 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 54, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,675 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 55, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,676 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 54)
2016-12-14 14:47:40,676 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 55)
2016-12-14 14:47:40,678 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,678 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,678 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,678 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,687 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 55). 1794 bytes result sent to driver
2016-12-14 14:47:40,687 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 54). 1670 bytes result sent to driver
2016-12-14 14:47:40,689 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 55) in 14 ms on localhost (1/2)
2016-12-14 14:47:40,690 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 54) in 16 ms on localhost (2/2)
2016-12-14 14:47:40,691 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.016 s
2016-12-14 14:47:40,691 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,691 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.059832 s
2016-12-14 14:47:40,693 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 1592.0 B, free 404.4 KB)
2016-12-14 14:47:40,698 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 846.0 B, free 405.2 KB)
2016-12-14 14:47:40,698 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:64382 (size: 846.0 B, free: 529.9 MB)
2016-12-14 14:47:40,699 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,715 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,716 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 45 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 14:47:40,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 14:47:40,719 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,721 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 6.6 KB, free 411.8 KB)
2016-12-14 14:47:40,725 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.6 KB, free 415.4 KB)
2016-12-14 14:47:40,726 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,726 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,727 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,727 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 14:47:40,728 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 56, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,729 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 57, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,730 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 56)
2016-12-14 14:47:40,730 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 57)
2016-12-14 14:47:40,734 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,734 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,734 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,734 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,741 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 56). 2348 bytes result sent to driver
2016-12-14 14:47:40,741 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 57). 2348 bytes result sent to driver
2016-12-14 14:47:40,744 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 56) in 16 ms on localhost (1/2)
2016-12-14 14:47:40,745 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 57) in 16 ms on localhost (2/2)
2016-12-14 14:47:40,745 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 14:47:40,745 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,746 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,746 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,746 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 14:47:40,746 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,747 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,749 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 2.9 KB, free 418.3 KB)
2016-12-14 14:47:40,753 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1668.0 B, free 419.9 KB)
2016-12-14 14:47:40,753 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:64382 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:40,754 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,754 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,754 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 14:47:40,755 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 58, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,755 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 59, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,755 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 59)
2016-12-14 14:47:40,755 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 58)
2016-12-14 14:47:40,757 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,757 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,757 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,757 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,767 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 59). 1794 bytes result sent to driver
2016-12-14 14:47:40,767 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 58). 1670 bytes result sent to driver
2016-12-14 14:47:40,769 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 59) in 14 ms on localhost (1/2)
2016-12-14 14:47:40,774 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 58) in 20 ms on localhost (2/2)
2016-12-14 14:47:40,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 14:47:40,775 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,775 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.060226 s
2016-12-14 14:47:40,778 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 1592.0 B, free 421.4 KB)
2016-12-14 14:47:40,782 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 735.0 B, free 422.2 KB)
2016-12-14 14:47:40,783 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:64382 (size: 735.0 B, free: 529.9 MB)
2016-12-14 14:47:40,784 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,800 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,801 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 47 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 14:47:40,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 14:47:40,804 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,806 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 6.6 KB, free 428.8 KB)
2016-12-14 14:47:40,810 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.6 KB, free 432.3 KB)
2016-12-14 14:47:40,811 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,812 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,812 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,813 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 14:47:40,814 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 60, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,814 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 61, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,815 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 61)
2016-12-14 14:47:40,815 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 60)
2016-12-14 14:47:40,819 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,819 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,819 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,819 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,826 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 60). 2348 bytes result sent to driver
2016-12-14 14:47:40,826 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 61). 2348 bytes result sent to driver
2016-12-14 14:47:40,830 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 60) in 16 ms on localhost (1/2)
2016-12-14 14:47:40,832 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 61) in 18 ms on localhost (2/2)
2016-12-14 14:47:40,832 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:47:40,833 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,833 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,833 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,833 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 14:47:40,833 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,834 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,836 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 2.9 KB, free 435.2 KB)
2016-12-14 14:47:40,840 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1668.0 B, free 436.9 KB)
2016-12-14 14:47:40,841 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:64382 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:40,841 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,842 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,842 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 14:47:40,844 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 62, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,845 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 63, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,845 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 62)
2016-12-14 14:47:40,845 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 63)
2016-12-14 14:47:40,848 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,848 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,848 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,849 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,854 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 62). 1670 bytes result sent to driver
2016-12-14 14:47:40,854 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 63). 1794 bytes result sent to driver
2016-12-14 14:47:40,858 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 62) in 14 ms on localhost (1/2)
2016-12-14 14:47:40,860 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 63) in 16 ms on localhost (2/2)
2016-12-14 14:47:40,860 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:47:40,860 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.060666 s
2016-12-14 14:47:40,863 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 1592.0 B, free 438.4 KB)
2016-12-14 14:47:40,866 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 721.0 B, free 439.1 KB)
2016-12-14 14:47:40,867 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:64382 (size: 721.0 B, free: 529.9 MB)
2016-12-14 14:47:40,867 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,883 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 49 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 14:47:40,886 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 14:47:40,887 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,888 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 6.6 KB, free 445.7 KB)
2016-12-14 14:47:40,892 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.6 KB, free 449.3 KB)
2016-12-14 14:47:40,892 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:64382 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:40,893 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,893 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,893 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 14:47:40,894 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 64, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,895 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 65, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,896 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 64)
2016-12-14 14:47:40,896 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 65)
2016-12-14 14:47:40,899 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,900 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,902 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,902 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,907 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 64). 2348 bytes result sent to driver
2016-12-14 14:47:40,909 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 65). 2348 bytes result sent to driver
2016-12-14 14:47:40,910 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 64) in 16 ms on localhost (1/2)
2016-12-14 14:47:40,911 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 65) in 16 ms on localhost (2/2)
2016-12-14 14:47:40,911 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 14:47:40,912 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,912 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,912 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 14:47:40,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,914 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,915 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 2.9 KB, free 452.2 KB)
2016-12-14 14:47:40,921 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1665.0 B, free 453.8 KB)
2016-12-14 14:47:40,923 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:64382 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:47:40,923 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,924 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:40,924 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 14:47:40,925 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 66, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,926 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 67, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:40,926 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 67)
2016-12-14 14:47:40,926 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 66)
2016-12-14 14:47:40,929 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,929 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:40,929 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:40,930 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:40,938 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 66). 1670 bytes result sent to driver
2016-12-14 14:47:40,938 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 67). 1794 bytes result sent to driver
2016-12-14 14:47:40,942 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 66) in 17 ms on localhost (1/2)
2016-12-14 14:47:40,944 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 67) in 19 ms on localhost (2/2)
2016-12-14 14:47:40,944 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 14:47:40,944 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,945 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.061217 s
2016-12-14 14:47:40,946 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 10 iterations
2016-12-14 14:47:40,947 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 1072.0 B, free 454.8 KB)
2016-12-14 14:47:40,953 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 495.0 B, free 455.3 KB)
2016-12-14 14:47:40,954 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:64382 (size: 495.0 B, free: 529.9 MB)
2016-12-14 14:47:40,955 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at KMeans.scala:276
2016-12-14 14:47:40,971 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:40,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 51 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:40,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:40,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 34)
2016-12-14 14:47:40,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 34)
2016-12-14 14:47:40,973 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 34 (MapPartitionsRDD[51] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:40,975 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 6.6 KB, free 461.9 KB)
2016-12-14 14:47:40,978 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.5 KB, free 465.4 KB)
2016-12-14 14:47:40,979 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:64382 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:47:40,980 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:40,980 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[51] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:40,980 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 14:47:40,981 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 68, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,982 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 69, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:40,982 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 69)
2016-12-14 14:47:40,982 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 68)
2016-12-14 14:47:40,984 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:40,984 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:40,985 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:40,985 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:40,992 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 68). 2324 bytes result sent to driver
2016-12-14 14:47:40,992 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 69). 2324 bytes result sent to driver
2016-12-14 14:47:40,994 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 68) in 13 ms on localhost (1/2)
2016-12-14 14:47:40,995 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 69) in 14 ms on localhost (2/2)
2016-12-14 14:47:40,995 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 34 (mapPartitions at KMeans.scala:279) finished in 0.015 s
2016-12-14 14:47:40,995 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:47:40,995 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:40,995 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:40,996 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 35)
2016-12-14 14:47:40,996 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:40,996 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (ShuffledRDD[52] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:40,997 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 2.9 KB, free 468.3 KB)
2016-12-14 14:47:41,002 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 1668.0 B, free 470.0 KB)
2016-12-14 14:47:41,003 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:64382 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:41,003 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,004 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (ShuffledRDD[52] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:41,004 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 14:47:41,005 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 70, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,006 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 71, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,006 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 71)
2016-12-14 14:47:41,006 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 70)
2016-12-14 14:47:41,008 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,008 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,008 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,008 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,014 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 70). 1544 bytes result sent to driver
2016-12-14 14:47:41,014 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 71). 1544 bytes result sent to driver
2016-12-14 14:47:41,018 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 70) in 13 ms on localhost (1/2)
2016-12-14 14:47:41,021 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 71) in 15 ms on localhost (2/2)
2016-12-14 14:47:41,021 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,022 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:47:41,022 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: collectAsMap at KMeans.scala:302, took 0.051150 s
2016-12-14 14:47:41,024 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 1072.0 B, free 471.0 KB)
2016-12-14 14:47:41,027 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 491.0 B, free 471.5 KB)
2016-12-14 14:47:41,027 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:64382 (size: 491.0 B, free: 529.9 MB)
2016-12-14 14:47:41,028 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at KMeans.scala:276
2016-12-14 14:47:41,037 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:47:41,039 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 53 (mapPartitions at KMeans.scala:279)
2016-12-14 14:47:41,039 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:47:41,039 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (collectAsMap at KMeans.scala:302)
2016-12-14 14:47:41,039 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 36)
2016-12-14 14:47:41,039 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 36)
2016-12-14 14:47:41,040 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 36 (MapPartitionsRDD[53] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:47:41,042 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 6.6 KB, free 478.1 KB)
2016-12-14 14:47:41,046 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 3.5 KB, free 481.6 KB)
2016-12-14 14:47:41,047 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:64382 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:47:41,048 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,048 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[53] at mapPartitions at KMeans.scala:279)
2016-12-14 14:47:41,048 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 14:47:41,050 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 72, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:41,050 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 73, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:47:41,050 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 73)
2016-12-14 14:47:41,050 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 72)
2016-12-14 14:47:41,052 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,052 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,053 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:47:41,053 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:47:41,061 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 72). 2324 bytes result sent to driver
2016-12-14 14:47:41,064 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 73). 2324 bytes result sent to driver
2016-12-14 14:47:41,064 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 72) in 15 ms on localhost (1/2)
2016-12-14 14:47:41,068 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 73) in 18 ms on localhost (2/2)
2016-12-14 14:47:41,068 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 36 (mapPartitions at KMeans.scala:279) finished in 0.019 s
2016-12-14 14:47:41,068 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,068 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:41,069 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:41,069 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 37)
2016-12-14 14:47:41,069 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:41,070 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (ShuffledRDD[54] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:47:41,071 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 2.9 KB, free 484.5 KB)
2016-12-14 14:47:41,073 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 1668.0 B, free 486.1 KB)
2016-12-14 14:47:41,074 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:64382 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:41,075 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 37 (ShuffledRDD[54] at reduceByKey at KMeans.scala:302)
2016-12-14 14:47:41,075 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 2 tasks
2016-12-14 14:47:41,077 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 74, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,077 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 37.0 (TID 75, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,078 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 74)
2016-12-14 14:47:41,078 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 37.0 (TID 75)
2016-12-14 14:47:41,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,087 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 74). 1544 bytes result sent to driver
2016-12-14 14:47:41,087 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 37.0 (TID 75). 1544 bytes result sent to driver
2016-12-14 14:47:41,093 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 37.0 (TID 75) in 16 ms on localhost (1/2)
2016-12-14 14:47:41,093 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 74) in 17 ms on localhost (2/2)
2016-12-14 14:47:41,093 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:47:41,093 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: collectAsMap at KMeans.scala:302, took 0.055986 s
2016-12-14 14:47:41,095 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 12 iterations
2016-12-14 14:47:41,096 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 12 iterations
2016-12-14 14:47:41,097 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 1.033 seconds.
2016-12-14 14:47:41,098 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 12 iterations.
2016-12-14 14:47:41,104 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 2370689.6867946046.
2016-12-14 14:47:41,106 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 4 from persistence list
2016-12-14 14:47:41,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:47:41,107 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:47:41,122 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:110
2016-12-14 14:47:41,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (foreach at K_means.scala:110) with 2 output partitions
2016-12-14 14:47:41,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 38 (foreach at K_means.scala:110)
2016-12-14 14:47:41,124 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:41,124 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:41,124 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 38 (MapPartitionsRDD[3] at map at K_means.scala:100), which has no missing parents
2016-12-14 14:47:41,126 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 4.2 KB, free 485.4 KB)
2016-12-14 14:47:41,144 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 14:47:41,146 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_56_piece0 on localhost:64382 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:41,147 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.5 KB, free 483.4 KB)
2016-12-14 14:47:41,147 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 88
2016-12-14 14:47:41,147 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:64382 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:47:41,148 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,148 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_55_piece0 on localhost:64382 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:47:41,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[3] at map at K_means.scala:100)
2016-12-14 14:47:41,149 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 2 tasks
2016-12-14 14:47:41,149 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 87
2016-12-14 14:47:41,149 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 12
2016-12-14 14:47:41,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 76, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,150 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:64382 in memory (size: 491.0 B, free: 529.9 MB)
2016-12-14 14:47:41,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 38.0 (TID 77, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,151 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 86
2016-12-14 14:47:41,151 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 76)
2016-12-14 14:47:41,151 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 38.0 (TID 77)
2016-12-14 14:47:41,151 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 85
2016-12-14 14:47:41,153 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:64382 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:41,153 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 84
2016-12-14 14:47:41,153 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,153 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,154 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:64382 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:47:41,154 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 83
2016-12-14 14:47:41,155 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 11
2016-12-14 14:47:41,155 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.23,1.71,2.43,15.6,127.0,2.8,3.06,0.28,2.29,5.64,1.04,3.92,1065.0] belong to cluster 1
2016-12-14 14:47:41,155 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.33,2.3,23.6,70.0,2.2,1.59,0.42,1.38,1.74,1.07,3.21,625.0] belong to cluster 0
2016-12-14 14:47:41,155 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.2,1.78,2.14,11.2,100.0,2.65,2.76,0.26,1.28,4.38,1.05,3.4,1050.0] belong to cluster 1
2016-12-14 14:47:41,155 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.83,2.32,18.5,81.0,1.6,1.5,0.52,1.64,2.4,1.08,2.27,480.0] belong to cluster 2
2016-12-14 14:47:41,155 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.16,2.36,2.67,18.6,101.0,2.8,3.24,0.3,2.81,5.68,1.03,3.17,1185.0] belong to cluster 1
2016-12-14 14:47:41,156 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.0,1.51,2.42,22.0,86.0,1.45,1.25,0.5,1.63,3.6,1.05,2.65,450.0] belong to cluster 2
2016-12-14 14:47:41,156 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.37,1.95,2.5,16.8,113.0,3.85,3.49,0.24,2.18,7.8,0.86,3.45,1480.0] belong to cluster 1
2016-12-14 14:47:41,156 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:64382 in memory (size: 495.0 B, free: 529.9 MB)
2016-12-14 14:47:41,156 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.69,1.53,2.26,20.7,80.0,1.38,1.46,0.58,1.62,3.05,0.96,2.06,495.0] belong to cluster 2
2016-12-14 14:47:41,156 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.24,2.59,2.87,21.0,118.0,2.8,2.69,0.39,1.82,4.32,1.04,2.93,735.0] belong to cluster 0
2016-12-14 14:47:41,157 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.2,1.76,2.45,15.2,112.0,3.27,3.39,0.34,1.97,6.75,1.05,2.85,1450.0] belong to cluster 1
2016-12-14 14:47:41,157 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,2.83,2.22,18.0,88.0,2.45,2.25,0.25,1.99,2.15,1.15,3.3,290.0] belong to cluster 2
2016-12-14 14:47:41,157 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.39,1.87,2.45,14.6,96.0,2.5,2.52,0.3,1.98,5.25,1.02,3.58,1290.0] belong to cluster 1
2016-12-14 14:47:41,157 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.62,1.99,2.28,18.0,98.0,3.02,2.26,0.17,1.35,3.25,1.16,2.96,345.0] belong to cluster 2
2016-12-14 14:47:41,157 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.06,2.15,2.61,17.6,121.0,2.6,2.51,0.31,1.25,5.05,1.06,3.58,1295.0] belong to cluster 1
2016-12-14 14:47:41,157 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 14:47:41,157 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.83,1.64,2.17,14.0,97.0,2.8,2.98,0.29,1.98,5.2,1.08,2.85,1045.0] belong to cluster 1
2016-12-14 14:47:41,157 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.47,1.52,2.2,19.0,162.0,2.5,2.27,0.32,3.28,2.6,1.16,2.63,937.0] belong to cluster 0
2016-12-14 14:47:41,158 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.86,1.35,2.27,16.0,98.0,2.98,3.15,0.22,1.85,7.22,1.01,3.55,1045.0] belong to cluster 1
2016-12-14 14:47:41,158 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.81,2.12,2.74,21.5,134.0,1.6,0.99,0.14,1.56,2.5,0.95,2.26,625.0] belong to cluster 0
2016-12-14 14:47:41,158 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:64382 in memory (size: 831.0 B, free: 529.9 MB)
2016-12-14 14:47:41,158 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.1,2.16,2.3,18.0,105.0,2.95,3.32,0.22,2.38,5.75,1.25,3.17,1510.0] belong to cluster 1
2016-12-14 14:47:41,158 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,1.41,1.98,16.0,85.0,2.55,2.5,0.29,1.77,2.9,1.23,2.74,428.0] belong to cluster 2
2016-12-14 14:47:41,159 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 14:47:41,159 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.07,2.1,18.5,88.0,3.52,3.75,0.24,1.95,4.5,1.04,2.77,660.0] belong to cluster 0
2016-12-14 14:47:41,159 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.12,1.48,2.32,16.8,95.0,2.2,2.43,0.26,1.57,5.0,1.17,2.82,1280.0] belong to cluster 1
2016-12-14 14:47:41,159 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 14:47:41,159 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.75,1.73,2.41,16.0,89.0,2.6,2.76,0.29,1.81,5.6,1.15,2.9,1320.0] belong to cluster 1
2016-12-14 14:47:41,159 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,3.17,2.21,18.0,88.0,2.85,2.99,0.45,2.81,2.3,1.42,2.83,406.0] belong to cluster 2
2016-12-14 14:47:41,159 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 14:47:41,160 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,2.08,1.7,17.5,97.0,2.23,2.17,0.26,1.4,3.3,1.27,2.96,710.0] belong to cluster 0
2016-12-14 14:47:41,160 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.75,1.73,2.39,11.4,91.0,3.1,3.69,0.43,2.81,5.4,1.25,2.73,1150.0] belong to cluster 1
2016-12-14 14:47:41,160 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.6,1.34,1.9,18.5,88.0,1.45,1.36,0.29,1.35,2.45,1.04,2.77,562.0] belong to cluster 2
2016-12-14 14:47:41,160 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.38,1.87,2.38,12.0,102.0,3.3,3.64,0.29,2.96,7.5,1.2,3.0,1547.0] belong to cluster 1
2016-12-14 14:47:41,160 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.34,2.45,2.46,21.0,98.0,2.56,2.11,0.34,1.31,2.8,0.8,3.38,438.0] belong to cluster 2
2016-12-14 14:47:41,160 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.82,1.72,1.88,19.5,86.0,2.5,1.64,0.37,1.42,2.06,0.94,2.44,415.0] belong to cluster 2
2016-12-14 14:47:41,160 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.63,1.81,2.7,17.2,112.0,2.85,2.91,0.3,1.46,7.3,1.28,2.88,1310.0] belong to cluster 1
2016-12-14 14:47:41,161 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:64382 in memory (size: 1666.0 B, free: 529.9 MB)
2016-12-14 14:47:41,161 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.51,1.73,1.98,20.5,85.0,2.2,1.92,0.32,1.48,2.94,1.04,3.57,672.0] belong to cluster 0
2016-12-14 14:47:41,161 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.3,1.92,2.72,20.0,120.0,2.8,3.14,0.33,1.97,6.2,1.07,2.65,1280.0] belong to cluster 1
2016-12-14 14:47:41,161 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.42,2.55,2.27,22.0,90.0,1.68,1.84,0.66,1.42,2.7,0.86,3.3,315.0] belong to cluster 2
2016-12-14 14:47:41,161 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 14:47:41,161 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.83,1.57,2.62,20.0,115.0,2.95,3.4,0.4,1.72,6.6,1.13,2.57,1130.0] belong to cluster 1
2016-12-14 14:47:41,161 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.25,1.73,2.12,19.0,80.0,1.65,2.03,0.37,1.63,3.4,1.0,3.17,510.0] belong to cluster 2
2016-12-14 14:47:41,162 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.19,1.59,2.48,16.5,108.0,3.3,3.93,0.32,1.86,8.7,1.23,2.82,1680.0] belong to cluster 1
2016-12-14 14:47:41,162 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.72,1.75,2.28,22.5,84.0,1.38,1.76,0.48,1.63,3.3,0.88,2.42,488.0] belong to cluster 2
2016-12-14 14:47:41,162 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.64,3.1,2.56,15.2,116.0,2.7,3.03,0.17,1.66,5.1,0.96,3.36,845.0] belong to cluster 0
2016-12-14 14:47:41,162 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.22,1.29,1.94,19.0,92.0,2.36,2.04,0.39,2.08,2.7,0.86,3.02,312.0] belong to cluster 2
2016-12-14 14:47:41,162 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.06,1.63,2.28,16.0,126.0,3.0,3.17,0.24,2.1,5.65,1.09,3.71,780.0] belong to cluster 0
2016-12-14 14:47:41,162 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:41,162 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.61,1.35,2.7,20.0,94.0,2.74,2.92,0.29,2.49,2.65,0.96,3.26,680.0] belong to cluster 0
2016-12-14 14:47:41,162 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.93,3.8,2.65,18.6,102.0,2.41,2.41,0.25,1.98,4.5,1.03,3.52,770.0] belong to cluster 0
2016-12-14 14:47:41,163 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.46,3.74,1.82,19.5,107.0,3.18,2.58,0.24,3.58,2.9,0.75,2.81,562.0] belong to cluster 2
2016-12-14 14:47:41,163 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 14:47:41,163 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.71,1.86,2.36,16.6,101.0,2.61,2.88,0.27,1.69,3.8,1.11,4.0,1035.0] belong to cluster 1
2016-12-14 14:47:41,163 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.52,2.43,2.17,21.0,88.0,2.55,2.27,0.26,1.22,2.0,0.9,2.78,325.0] belong to cluster 2
2016-12-14 14:47:41,163 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.85,1.6,2.52,17.8,95.0,2.48,2.37,0.26,1.46,3.93,1.09,3.63,1015.0] belong to cluster 1
2016-12-14 14:47:41,163 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.76,2.68,2.92,20.0,103.0,1.75,2.03,0.6,1.05,3.8,1.23,2.5,607.0] belong to cluster 0
2016-12-14 14:47:41,163 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 14:47:41,164 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.41,0.74,2.5,21.0,88.0,2.48,2.01,0.42,1.44,3.08,1.1,2.31,434.0] belong to cluster 2
2016-12-14 14:47:41,163 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.5,1.81,2.61,20.0,96.0,2.53,2.61,0.28,1.66,3.52,1.12,3.82,845.0] belong to cluster 0
2016-12-14 14:47:41,164 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.39,2.5,22.5,84.0,2.56,2.29,0.43,1.04,2.9,0.93,3.19,385.0] belong to cluster 2
2016-12-14 14:47:41,164 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,2.05,3.22,25.0,124.0,2.63,2.68,0.47,1.92,3.58,1.13,3.2,830.0] belong to cluster 0
2016-12-14 14:47:41,164 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.03,1.51,2.2,21.5,85.0,2.46,2.17,0.52,2.01,1.9,1.71,2.87,407.0] belong to cluster 2
2016-12-14 14:47:41,164 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:64382 in memory (size: 954.0 B, free: 529.9 MB)
2016-12-14 14:47:41,164 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.39,1.77,2.62,16.1,93.0,2.85,2.94,0.34,1.45,4.8,0.92,3.22,1195.0] belong to cluster 1
2016-12-14 14:47:41,164 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.82,1.47,1.99,20.8,86.0,1.98,1.6,0.3,1.53,1.95,0.95,3.33,495.0] belong to cluster 2
2016-12-14 14:47:41,165 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 14:47:41,165 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.3,1.72,2.14,17.0,94.0,2.4,2.19,0.27,1.35,3.95,1.02,2.77,1285.0] belong to cluster 1
2016-12-14 14:47:41,165 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 14:47:41,165 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 14:47:41,165 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.42,1.61,2.19,22.5,108.0,2.0,2.09,0.34,1.61,2.06,1.06,2.96,345.0] belong to cluster 2
2016-12-14 14:47:41,165 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.87,1.9,2.8,19.4,107.0,2.95,2.97,0.37,1.76,4.5,1.25,3.4,915.0] belong to cluster 0
2016-12-14 14:47:41,166 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.77,3.43,1.98,16.0,80.0,1.63,1.25,0.43,0.83,3.4,0.7,2.12,372.0] belong to cluster 2
2016-12-14 14:47:41,166 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:47:41,166 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.02,1.68,2.21,16.0,96.0,2.65,2.33,0.26,1.98,4.7,1.04,3.59,1035.0] belong to cluster 1
2016-12-14 14:47:41,166 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.0,3.43,2.0,19.0,87.0,2.0,1.64,0.37,1.87,1.28,0.93,3.05,564.0] belong to cluster 2
2016-12-14 14:47:41,166 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.73,1.5,2.7,22.5,101.0,3.0,3.25,0.29,2.38,5.7,1.19,2.71,1285.0] belong to cluster 1
2016-12-14 14:47:41,166 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 4
2016-12-14 14:47:41,166 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.45,2.4,2.42,20.0,96.0,2.9,2.79,0.32,1.83,3.25,0.8,3.39,625.0] belong to cluster 0
2016-12-14 14:47:41,166 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 14:47:41,166 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.58,1.66,2.36,19.1,106.0,2.86,3.19,0.22,1.95,6.9,1.09,2.88,1515.0] belong to cluster 1
2016-12-14 14:47:41,167 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.56,2.05,3.23,28.5,119.0,3.18,5.08,0.47,1.87,6.0,0.93,3.69,465.0] belong to cluster 2
2016-12-14 14:47:41,167 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 14:47:41,167 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.68,1.83,2.36,17.2,104.0,2.42,2.69,0.42,1.97,3.84,1.23,2.87,990.0] belong to cluster 1
2016-12-14 14:47:41,167 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.42,4.43,2.73,26.5,102.0,2.2,2.13,0.43,1.71,2.08,0.92,3.12,365.0] belong to cluster 2
2016-12-14 14:47:41,168 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.76,1.53,2.7,19.5,132.0,2.95,2.74,0.5,1.35,5.4,1.25,3.0,1235.0] belong to cluster 1
2016-12-14 14:47:41,168 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,5.8,2.13,21.5,86.0,2.62,2.65,0.3,2.01,2.6,0.73,3.1,380.0] belong to cluster 2
2016-12-14 14:47:41,168 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.51,1.8,2.65,19.0,110.0,2.35,2.53,0.29,1.54,4.2,1.1,2.87,1095.0] belong to cluster 1
2016-12-14 14:47:41,168 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.87,4.31,2.39,21.0,82.0,2.86,3.03,0.21,2.91,2.8,0.75,3.64,380.0] belong to cluster 2
2016-12-14 14:47:41,168 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:64382 in memory (size: 838.0 B, free: 529.9 MB)
2016-12-14 14:47:41,168 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.07,2.16,2.17,21.0,85.0,2.6,2.65,0.37,1.35,2.76,0.86,3.28,378.0] belong to cluster 2
2016-12-14 14:47:41,168 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.48,1.81,2.41,20.5,100.0,2.7,2.98,0.26,1.86,5.1,1.04,3.47,920.0] belong to cluster 0
2016-12-14 14:47:41,168 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 14:47:41,168 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.43,1.53,2.29,21.5,86.0,2.74,3.15,0.39,1.77,3.94,0.69,2.84,352.0] belong to cluster 2
2016-12-14 14:47:41,169 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 14:47:41,169 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.28,1.64,2.84,15.5,110.0,2.6,2.68,0.34,1.36,4.6,1.09,2.78,880.0] belong to cluster 0
2016-12-14 14:47:41,169 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 14:47:41,169 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.79,2.13,2.78,28.5,92.0,2.13,2.24,0.58,1.76,3.0,0.97,2.44,466.0] belong to cluster 2
2016-12-14 14:47:41,169 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,1.65,2.55,18.0,98.0,2.45,2.43,0.29,1.44,4.25,1.12,2.51,1105.0] belong to cluster 1
2016-12-14 14:47:41,169 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.63,2.3,24.5,88.0,2.22,2.45,0.4,1.9,2.12,0.89,2.78,342.0] belong to cluster 2
2016-12-14 14:47:41,170 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.07,1.5,2.1,15.5,98.0,2.4,2.64,0.28,1.37,3.7,1.18,2.69,1020.0] belong to cluster 1
2016-12-14 14:47:41,170 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.04,4.3,2.38,22.0,80.0,2.1,1.75,0.42,1.35,2.6,0.79,2.57,580.0] belong to cluster 2
2016-12-14 14:47:41,170 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.22,3.99,2.51,13.2,128.0,3.0,3.04,0.2,2.08,5.1,0.89,3.53,760.0] belong to cluster 0
2016-12-14 14:47:41,170 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.86,1.35,2.32,18.0,122.0,1.51,1.25,0.21,0.94,4.1,0.76,1.29,630.0] belong to cluster 0
2016-12-14 14:47:41,170 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:64382 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:41,170 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.88,2.99,2.4,20.0,104.0,1.3,1.22,0.24,0.83,5.4,0.74,1.42,530.0] belong to cluster 2
2016-12-14 14:47:41,170 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.56,1.71,2.31,16.2,117.0,3.15,3.29,0.34,2.34,6.13,0.95,3.38,795.0] belong to cluster 0
2016-12-14 14:47:41,171 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 14:47:41,171 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.81,2.31,2.4,24.0,98.0,1.15,1.09,0.27,0.83,5.7,0.66,1.36,560.0] belong to cluster 2
2016-12-14 14:47:41,171 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.41,3.84,2.12,18.8,90.0,2.45,2.68,0.27,1.48,4.28,0.91,3.0,1035.0] belong to cluster 1
2016-12-14 14:47:41,171 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.7,3.55,2.36,21.5,106.0,1.7,1.2,0.17,0.84,5.0,0.78,1.29,600.0] belong to cluster 0
2016-12-14 14:47:41,171 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.88,1.89,2.59,15.0,101.0,3.25,3.56,0.17,1.7,5.43,0.88,3.56,1095.0] belong to cluster 1
2016-12-14 14:47:41,171 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:41,171 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.51,1.24,2.25,17.5,85.0,2.0,0.58,0.6,1.25,5.45,0.75,1.51,650.0] belong to cluster 0
2016-12-14 14:47:41,171 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.24,3.98,2.29,17.5,103.0,2.64,2.63,0.32,1.66,4.36,0.82,3.0,680.0] belong to cluster 0
2016-12-14 14:47:41,172 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 14:47:41,172 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.6,2.46,2.2,18.5,94.0,1.62,0.66,0.63,0.94,7.1,0.73,1.58,695.0] belong to cluster 0
2016-12-14 14:47:41,172 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,1.77,2.1,17.0,107.0,3.0,3.0,0.28,2.03,5.04,0.88,3.35,885.0] belong to cluster 0
2016-12-14 14:47:41,172 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.25,4.72,2.54,21.0,89.0,1.38,0.47,0.53,0.8,3.85,0.75,1.27,720.0] belong to cluster 0
2016-12-14 14:47:41,173 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:64382 in memory (size: 846.0 B, free: 529.9 MB)
2016-12-14 14:47:41,173 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.21,4.04,2.44,18.9,111.0,2.85,2.65,0.3,1.25,5.24,0.87,3.33,1080.0] belong to cluster 1
2016-12-14 14:47:41,173 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.53,5.51,2.64,25.0,96.0,1.79,0.6,0.63,1.1,5.0,0.82,1.69,515.0] belong to cluster 2
2016-12-14 14:47:41,173 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 14:47:41,173 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.38,3.59,2.28,16.0,102.0,3.25,3.17,0.27,2.19,4.9,1.04,3.44,1065.0] belong to cluster 1
2016-12-14 14:47:41,174 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 14:47:41,173 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.49,3.59,2.19,19.5,88.0,1.62,0.48,0.58,0.88,5.7,0.81,1.82,580.0] belong to cluster 2
2016-12-14 14:47:41,174 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 14:47:41,174 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.9,1.68,2.12,16.0,101.0,3.1,3.39,0.21,2.14,6.1,0.91,3.33,985.0] belong to cluster 1
2016-12-14 14:47:41,174 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.84,2.96,2.61,24.0,101.0,2.32,0.6,0.53,0.81,4.92,0.89,2.15,590.0] belong to cluster 2
2016-12-14 14:47:41,175 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.1,2.02,2.4,18.8,103.0,2.75,2.92,0.32,2.38,6.2,1.07,2.75,1060.0] belong to cluster 1
2016-12-14 14:47:41,175 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.93,2.81,2.7,21.0,96.0,1.54,0.5,0.53,0.75,4.6,0.77,2.31,600.0] belong to cluster 0
2016-12-14 14:47:41,175 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.94,1.73,2.27,17.4,108.0,2.88,3.54,0.32,2.08,8.9,1.12,3.1,1260.0] belong to cluster 1
2016-12-14 14:47:41,175 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.36,2.56,2.35,20.0,89.0,1.4,0.5,0.37,0.64,5.6,0.7,2.47,780.0] belong to cluster 0
2016-12-14 14:47:41,176 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,1.73,2.04,12.4,92.0,2.72,3.27,0.17,2.91,7.2,1.12,2.91,1150.0] belong to cluster 1
2016-12-14 14:47:41,176 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:64382 in memory (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:47:41,176 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.83,1.65,2.6,17.2,94.0,2.45,2.99,0.22,2.29,5.6,1.24,3.37,1265.0] belong to cluster 1
2016-12-14 14:47:41,176 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.52,3.17,2.72,23.5,97.0,1.55,0.52,0.5,0.55,4.35,0.89,2.06,520.0] belong to cluster 2
2016-12-14 14:47:41,177 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.82,1.75,2.42,14.0,111.0,3.88,3.74,0.32,1.87,7.05,1.01,3.26,1190.0] belong to cluster 1
2016-12-14 14:47:41,177 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 14:47:41,177 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.62,4.95,2.35,20.0,92.0,2.0,0.8,0.47,1.02,4.4,0.91,2.05,550.0] belong to cluster 2
2016-12-14 14:47:41,177 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.77,1.9,2.68,17.1,115.0,3.0,2.79,0.39,1.68,6.3,1.13,2.93,1375.0] belong to cluster 1
2016-12-14 14:47:41,177 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.25,3.88,2.2,18.5,112.0,1.38,0.78,0.29,1.14,8.21,0.65,2.0,855.0] belong to cluster 0
2016-12-14 14:47:41,177 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.74,1.67,2.25,16.4,118.0,2.6,2.9,0.21,1.62,5.85,0.92,3.2,1060.0] belong to cluster 1
2016-12-14 14:47:41,177 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.16,3.57,2.15,21.0,102.0,1.5,0.55,0.43,1.3,4.0,0.6,1.68,830.0] belong to cluster 0
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.56,1.73,2.46,20.5,116.0,2.96,2.78,0.2,2.45,6.25,0.98,3.03,1120.0] belong to cluster 1
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.88,5.04,2.23,20.0,80.0,0.98,0.34,0.4,0.68,4.9,0.58,1.33,415.0] belong to cluster 2
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.22,1.7,2.3,16.3,118.0,3.2,3.0,0.26,2.03,6.38,0.94,3.31,970.0] belong to cluster 1
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.87,4.61,2.48,21.5,86.0,1.7,0.65,0.47,0.86,7.65,0.54,1.86,625.0] belong to cluster 0
2016-12-14 14:47:41,178 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.29,1.97,2.68,16.8,102.0,3.0,3.23,0.31,1.66,6.0,1.07,2.84,1270.0] belong to cluster 1
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.32,3.24,2.38,21.5,92.0,1.93,0.76,0.45,1.25,8.42,0.55,1.62,650.0] belong to cluster 0
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.72,1.43,2.5,16.7,108.0,3.4,3.67,0.19,2.04,6.8,0.89,2.87,1285.0] belong to cluster 1
2016-12-14 14:47:41,178 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.08,3.9,2.36,21.5,113.0,1.41,1.39,0.34,1.14,9.4,0.57,1.33,550.0] belong to cluster 2
2016-12-14 14:47:41,179 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,0.94,1.36,10.6,88.0,1.98,0.57,0.28,0.42,1.95,1.05,1.82,520.0] belong to cluster 2
2016-12-14 14:47:41,179 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 14:47:41,179 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.33,1.1,2.28,16.0,101.0,2.05,1.09,0.63,0.41,3.27,1.25,1.67,680.0] belong to cluster 0
2016-12-14 14:47:41,179 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.5,3.12,2.62,24.0,123.0,1.4,1.57,0.22,1.25,8.6,0.59,1.3,500.0] belong to cluster 2
2016-12-14 14:47:41,179 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.64,1.36,2.02,16.8,100.0,2.02,1.41,0.53,0.62,5.75,0.98,1.59,450.0] belong to cluster 2
2016-12-14 14:47:41,179 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.79,2.67,2.48,22.0,112.0,1.48,1.36,0.24,1.26,10.8,0.48,1.47,480.0] belong to cluster 2
2016-12-14 14:47:41,179 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.67,1.25,1.92,18.0,94.0,2.1,1.79,0.32,0.73,3.8,1.23,2.46,630.0] belong to cluster 0
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.11,1.9,2.75,25.5,116.0,2.2,1.28,0.26,1.56,7.1,0.61,1.33,425.0] belong to cluster 2
2016-12-14 14:47:41,180 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.13,2.16,19.0,87.0,3.5,3.1,0.19,1.87,4.45,1.22,2.87,420.0] belong to cluster 2
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.23,3.3,2.28,18.5,98.0,1.8,0.83,0.61,1.87,10.52,0.56,1.51,675.0] belong to cluster 0
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.17,1.45,2.53,19.0,104.0,1.89,1.75,0.45,1.03,2.95,1.45,2.23,355.0] belong to cluster 2
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.58,1.29,2.1,20.0,103.0,1.48,0.58,0.53,1.4,7.6,0.58,1.55,640.0] belong to cluster 0
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.21,2.56,18.1,98.0,2.42,2.65,0.37,2.08,4.6,1.19,2.3,678.0] belong to cluster 0
2016-12-14 14:47:41,180 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.17,5.19,2.32,22.0,93.0,1.74,0.63,0.61,1.55,7.9,0.6,1.48,725.0] belong to cluster 0
2016-12-14 14:47:41,180 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.11,1.01,1.7,15.0,78.0,2.98,3.18,0.26,2.28,5.3,1.12,3.18,502.0] belong to cluster 2
2016-12-14 14:47:41,181 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.84,4.12,2.38,19.5,89.0,1.8,0.83,0.48,1.56,9.01,0.57,1.64,480.0] belong to cluster 2
2016-12-14 14:47:41,181 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 14:47:41,181 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.17,1.92,19.6,78.0,2.11,2.0,0.27,1.04,4.68,1.12,3.48,510.0] belong to cluster 2
2016-12-14 14:47:41,181 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.45,3.03,2.64,27.0,97.0,1.9,0.58,0.63,1.14,7.5,0.67,1.73,880.0] belong to cluster 0
2016-12-14 14:47:41,182 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.34,0.94,2.36,17.0,110.0,2.53,1.3,0.55,0.42,3.17,1.02,1.93,750.0] belong to cluster 0
2016-12-14 14:47:41,182 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.34,1.68,2.7,25.0,98.0,2.8,1.31,0.53,2.7,13.0,0.57,1.96,660.0] belong to cluster 0
2016-12-14 14:47:41,182 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:64382 in memory (size: 846.0 B, free: 529.9 MB)
2016-12-14 14:47:41,182 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.21,1.19,1.75,16.8,151.0,1.85,1.28,0.14,2.5,2.85,1.28,3.07,718.0] belong to cluster 0
2016-12-14 14:47:41,182 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.48,1.67,2.64,22.5,89.0,2.6,1.1,0.52,2.29,11.75,0.57,1.78,620.0] belong to cluster 0
2016-12-14 14:47:41,182 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 14:47:41,182 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,1.61,2.21,20.4,103.0,1.1,1.02,0.37,1.46,3.05,0.906,1.82,870.0] belong to cluster 0
2016-12-14 14:47:41,182 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 14:47:41,182 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.36,3.83,2.38,21.0,88.0,2.3,0.92,0.5,1.04,7.65,0.56,1.58,520.0] belong to cluster 2
2016-12-14 14:47:41,183 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 14:47:41,183 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.86,1.51,2.67,25.0,86.0,2.95,2.86,0.21,1.87,3.38,1.36,3.16,410.0] belong to cluster 2
2016-12-14 14:47:41,183 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.69,3.26,2.54,20.0,107.0,1.83,0.56,0.5,0.8,5.88,0.96,1.82,680.0] belong to cluster 0
2016-12-14 14:47:41,183 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.49,1.66,2.24,24.0,87.0,1.88,1.84,0.27,1.03,3.74,0.98,2.78,472.0] belong to cluster 2
2016-12-14 14:47:41,183 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.85,3.27,2.58,22.0,106.0,1.65,0.6,0.6,0.96,5.58,0.87,2.11,570.0] belong to cluster 2
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.99,1.67,2.6,30.0,139.0,3.3,2.89,0.21,1.96,3.35,1.31,3.5,985.0] belong to cluster 1
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.96,3.45,2.35,18.5,106.0,1.39,0.7,0.4,0.94,5.28,0.68,1.75,675.0] belong to cluster 0
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.96,1.09,2.3,21.0,101.0,3.38,2.14,0.13,1.65,3.21,0.99,3.13,886.0] belong to cluster 0
2016-12-14 14:47:41,184 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:64382 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.78,2.76,2.3,22.0,90.0,1.35,0.68,0.41,1.03,9.58,0.7,1.68,615.0] belong to cluster 0
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.66,1.88,1.92,16.0,97.0,1.61,1.57,0.34,1.15,3.8,1.23,2.14,428.0] belong to cluster 2
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.73,4.36,2.26,22.5,88.0,1.28,0.47,0.52,1.15,6.62,0.78,1.75,520.0] belong to cluster 2
2016-12-14 14:47:41,184 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.03,0.9,1.71,16.0,86.0,1.95,2.03,0.24,1.46,4.6,1.19,2.48,392.0] belong to cluster 2
2016-12-14 14:47:41,184 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.45,3.7,2.6,23.0,111.0,1.7,0.92,0.43,1.46,10.68,0.85,1.56,695.0] belong to cluster 0
2016-12-14 14:47:41,185 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.84,2.89,2.23,18.0,112.0,1.72,1.32,0.43,0.95,2.65,0.96,2.52,500.0] belong to cluster 2
2016-12-14 14:47:41,185 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.82,3.37,2.3,19.5,88.0,1.48,0.66,0.4,0.97,10.26,0.72,1.75,685.0] belong to cluster 0
2016-12-14 14:47:41,185 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.33,0.99,1.95,14.8,136.0,1.9,1.85,0.35,2.76,3.4,1.06,2.31,750.0] belong to cluster 0
2016-12-14 14:47:41,185 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.58,2.58,2.69,24.5,105.0,1.55,0.84,0.39,1.54,8.66,0.74,1.8,750.0] belong to cluster 0
2016-12-14 14:47:41,185 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.7,3.87,2.4,23.0,101.0,2.83,2.55,0.43,1.95,2.57,1.19,3.13,463.0] belong to cluster 2
2016-12-14 14:47:41,185 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:41,186 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.0,0.92,2.0,19.0,86.0,2.42,2.26,0.3,1.43,2.5,1.38,3.12,278.0] belong to cluster 2
2016-12-14 14:47:41,185 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.4,4.6,2.86,25.0,112.0,1.98,0.96,0.27,1.11,8.5,0.67,1.92,630.0] belong to cluster 0
2016-12-14 14:47:41,186 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 82
2016-12-14 14:47:41,186 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.72,1.81,2.2,18.8,86.0,2.2,2.53,0.26,1.77,3.9,1.16,3.14,714.0] belong to cluster 0
2016-12-14 14:47:41,186 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 81
2016-12-14 14:47:41,186 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.2,3.03,2.32,19.0,96.0,1.25,0.49,0.4,0.73,5.5,0.66,1.83,510.0] belong to cluster 2
2016-12-14 14:47:41,186 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.13,2.51,24.0,78.0,2.0,1.58,0.4,1.4,2.2,1.31,2.72,630.0] belong to cluster 0
2016-12-14 14:47:41,187 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.77,2.39,2.28,19.5,86.0,1.39,0.51,0.48,0.64,9.9,0.57,1.63,470.0] belong to cluster 2
2016-12-14 14:47:41,187 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,3.86,2.32,22.5,85.0,1.65,1.59,0.61,1.62,4.8,0.84,2.01,515.0] belong to cluster 2
2016-12-14 14:47:41,187 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.16,2.51,2.48,20.0,91.0,1.68,0.7,0.44,1.24,9.7,0.62,1.71,660.0] belong to cluster 0
2016-12-14 14:47:41,187 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.84,0.89,2.58,18.0,94.0,2.2,2.21,0.22,2.35,3.05,0.79,3.08,520.0] belong to cluster 2
2016-12-14 14:47:41,187 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:64382 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:47:41,187 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.71,5.65,2.45,20.5,95.0,1.68,0.61,0.52,1.06,7.7,0.64,1.74,740.0] belong to cluster 0
2016-12-14 14:47:41,187 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.67,0.98,2.24,18.0,99.0,2.2,1.94,0.3,1.46,2.62,1.23,3.16,450.0] belong to cluster 2
2016-12-14 14:47:41,188 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 14:47:41,188 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.4,3.91,2.48,23.0,102.0,1.8,0.75,0.43,1.41,7.3,0.7,1.56,750.0] belong to cluster 0
2016-12-14 14:47:41,188 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.16,1.61,2.31,22.8,90.0,1.78,1.69,0.43,1.56,2.45,1.33,2.26,495.0] belong to cluster 2
2016-12-14 14:47:41,188 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.27,4.28,2.26,20.0,120.0,1.59,0.69,0.43,1.35,10.2,0.59,1.56,835.0] belong to cluster 0
2016-12-14 14:47:41,189 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.65,1.67,2.62,26.0,88.0,1.92,1.61,0.4,1.34,2.6,1.36,3.21,562.0] belong to cluster 2
2016-12-14 14:47:41,189 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:47:41,189 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.17,2.59,2.37,20.0,120.0,1.65,0.68,0.53,1.46,9.3,0.6,1.62,840.0] belong to cluster 0
2016-12-14 14:47:41,189 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.64,2.06,2.46,21.6,84.0,1.95,1.69,0.48,1.35,2.8,1.0,2.75,680.0] belong to cluster 0
2016-12-14 14:47:41,189 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.13,4.1,2.74,24.5,96.0,2.05,0.76,0.56,1.35,9.2,0.61,1.6,560.0] belong to cluster 2
2016-12-14 14:47:41,189 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 14:47:41,190 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 14:47:41,190 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:64382 in memory (size: 721.0 B, free: 529.9 MB)
2016-12-14 14:47:41,191 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 14:47:41,191 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 14:47:41,191 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 14:47:41,191 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 38.0 (TID 77). 2057 bytes result sent to driver
2016-12-14 14:47:41,191 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 76). 2057 bytes result sent to driver
2016-12-14 14:47:41,191 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:64382 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:47:41,192 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 14:47:41,193 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:64382 in memory (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:47:41,193 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 14:47:41,193 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 14:47:41,194 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 38.0 (TID 77) in 43 ms on localhost (1/2)
2016-12-14 14:47:41,194 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:64382 in memory (size: 735.0 B, free: 530.0 MB)
2016-12-14 14:47:41,195 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 14:47:41,195 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 14:47:41,195 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 76) in 45 ms on localhost (2/2)
2016-12-14 14:47:41,195 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 14:47:41,195 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 38 (foreach at K_means.scala:110) finished in 0.046 s
2016-12-14 14:47:41,195 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,196 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: foreach at K_means.scala:110, took 0.073052 s
2016-12-14 14:47:41,196 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:64382 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:47:41,196 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 14:47:41,209 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:121
2016-12-14 14:47:41,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (foreach at K_means.scala:121) with 2 output partitions
2016-12-14 14:47:41,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (foreach at K_means.scala:121)
2016-12-14 14:47:41,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:41,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:41,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (MapPartitionsRDD[55] at map at K_means.scala:119), which has no missing parents
2016-12-14 14:47:41,213 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 4.2 KB, free 340.5 KB)
2016-12-14 14:47:41,217 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KB, free 343.0 KB)
2016-12-14 14:47:41,218 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:64382 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:47:41,218 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,219 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[55] at map at K_means.scala:119)
2016-12-14 14:47:41,219 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 2 tasks
2016-12-14 14:47:41,221 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 78, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,221 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 39.0 (TID 79, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,222 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 78)
2016-12-14 14:47:41,222 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 39.0 (TID 79)
2016-12-14 14:47:41,224 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,224 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,225 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,225 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,225 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,226 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,226 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,226 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,226 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,226 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,226 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,226 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,227 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,228 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,229 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,229 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,229 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,229 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,229 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,230 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,230 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,230 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,230 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,230 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,230 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,230 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,231 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,231 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,231 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,231 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,231 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,231 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,232 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,232 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,232 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,232 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,232 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,232 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,233 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,233 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,233 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,233 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,233 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,233 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,233 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,234 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,234 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,234 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,234 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,234 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,234 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,235 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,235 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,235 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,235 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,235 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,235 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,236 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,236 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,236 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,236 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,236 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,236 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,237 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,237 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,237 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,237 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,237 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,237 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,237 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,238 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,239 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,240 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,240 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,240 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,240 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,240 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,240 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,240 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,241 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,242 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,243 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,244 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,245 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,246 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,247 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:47:41,248 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,248 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:47:41,248 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,248 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,248 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,248 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,249 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,249 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:47:41,249 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:47:41,251 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 78). 2057 bytes result sent to driver
2016-12-14 14:47:41,251 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 39.0 (TID 79). 2057 bytes result sent to driver
2016-12-14 14:47:41,254 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 78) in 34 ms on localhost (1/2)
2016-12-14 14:47:41,254 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 39.0 (TID 79) in 33 ms on localhost (2/2)
2016-12-14 14:47:41,254 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (foreach at K_means.scala:121) finished in 0.034 s
2016-12-14 14:47:41,255 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,255 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: foreach at K_means.scala:121, took 0.045871 s
2016-12-14 14:47:41,438 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_58_piece0 on localhost:64382 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:47:41,439 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 90
2016-12-14 14:47:41,439 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_57_piece0 on localhost:64382 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:47:41,439 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:13
2016-12-14 14:47:41,439 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 89
2016-12-14 14:47:41,440 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 56 (map at Relabel.scala:13)
2016-12-14 14:47:41,441 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (sortBy at Relabel.scala:13) with 2 output partitions
2016-12-14 14:47:41,441 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (sortBy at Relabel.scala:13)
2016-12-14 14:47:41,441 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 40)
2016-12-14 14:47:41,441 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 40)
2016-12-14 14:47:41,442 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 40 (MapPartitionsRDD[56] at map at Relabel.scala:13), which has no missing parents
2016-12-14 14:47:41,443 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 5.0 KB, free 334.6 KB)
2016-12-14 14:47:41,446 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.0 KB, free 337.5 KB)
2016-12-14 14:47:41,447 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:64382 (size: 3.0 KB, free: 530.0 MB)
2016-12-14 14:47:41,447 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,447 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[56] at map at Relabel.scala:13)
2016-12-14 14:47:41,448 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 2 tasks
2016-12-14 14:47:41,449 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 80, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:47:41,449 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 40.0 (TID 81, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:47:41,450 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 40.0 (TID 81)
2016-12-14 14:47:41,450 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 80)
2016-12-14 14:47:41,453 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,453 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,461 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 80). 2237 bytes result sent to driver
2016-12-14 14:47:41,461 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 40.0 (TID 81). 2237 bytes result sent to driver
2016-12-14 14:47:41,464 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 80) in 16 ms on localhost (1/2)
2016-12-14 14:47:41,465 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 40.0 (TID 81) in 16 ms on localhost (2/2)
2016-12-14 14:47:41,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 40 (map at Relabel.scala:13) finished in 0.017 s
2016-12-14 14:47:41,465 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:41,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:41,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 41)
2016-12-14 14:47:41,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:41,466 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (MapPartitionsRDD[60] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:47:41,467 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 3.5 KB, free 341.1 KB)
2016-12-14 14:47:41,469 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2019.0 B, free 343.1 KB)
2016-12-14 14:47:41,470 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:64382 (size: 2019.0 B, free: 530.0 MB)
2016-12-14 14:47:41,470 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,470 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 41 (MapPartitionsRDD[60] at sortBy at Relabel.scala:13)
2016-12-14 14:47:41,471 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 14:47:41,471 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 82, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,472 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 83, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,472 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 82)
2016-12-14 14:47:41,472 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 83)
2016-12-14 14:47:41,474 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,474 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,474 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:41,474 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:41,480 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 82). 1160 bytes result sent to driver
2016-12-14 14:47:41,480 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 83). 1168 bytes result sent to driver
2016-12-14 14:47:41,482 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 83) in 11 ms on localhost (1/2)
2016-12-14 14:47:41,483 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 82) in 12 ms on localhost (2/2)
2016-12-14 14:47:41,483 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (sortBy at Relabel.scala:13) finished in 0.012 s
2016-12-14 14:47:41,483 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,483 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: sortBy at Relabel.scala:13, took 0.043599 s
2016-12-14 14:47:41,501 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 14:47:41,505 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 13 is 155 bytes
2016-12-14 14:47:41,508 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 58 (sortBy at Relabel.scala:13)
2016-12-14 14:47:41,508 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (collect at Relabel.scala:14) with 2 output partitions
2016-12-14 14:47:41,508 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 44 (collect at Relabel.scala:14)
2016-12-14 14:47:41,508 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 43)
2016-12-14 14:47:41,508 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 43)
2016-12-14 14:47:41,508 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 43 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:47:41,512 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 3.6 KB, free 346.6 KB)
2016-12-14 14:47:41,514 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.0 KB, free 348.6 KB)
2016-12-14 14:47:41,514 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:64382 (size: 2.0 KB, free: 530.0 MB)
2016-12-14 14:47:41,515 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,515 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13)
2016-12-14 14:47:41,515 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 14:47:41,516 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 84, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 14:47:41,516 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 85, localhost, partition 1,NODE_LOCAL, 2132 bytes)
2016-12-14 14:47:41,517 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 85)
2016-12-14 14:47:41,517 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 84)
2016-12-14 14:47:41,525 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,525 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,525 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,526 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:41,539 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 84). 1303 bytes result sent to driver
2016-12-14 14:47:41,539 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 85). 1303 bytes result sent to driver
2016-12-14 14:47:41,542 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 84) in 25 ms on localhost (1/2)
2016-12-14 14:47:41,542 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 85) in 26 ms on localhost (2/2)
2016-12-14 14:47:41,542 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 43 (sortBy at Relabel.scala:13) finished in 0.026 s
2016-12-14 14:47:41,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:41,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:41,543 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 44)
2016-12-14 14:47:41,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:41,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 44 (MapPartitionsRDD[62] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:47:41,546 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 3.4 KB, free 352.0 KB)
2016-12-14 14:47:41,548 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 1946.0 B, free 353.9 KB)
2016-12-14 14:47:41,548 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:64382 (size: 1946.0 B, free: 530.0 MB)
2016-12-14 14:47:41,549 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,549 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 44 (MapPartitionsRDD[62] at sortBy at Relabel.scala:13)
2016-12-14 14:47:41,549 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 2 tasks
2016-12-14 14:47:41,550 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 86, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,550 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 44.0 (TID 87, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,551 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 86)
2016-12-14 14:47:41,551 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 44.0 (TID 87)
2016-12-14 14:47:41,556 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,556 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,557 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,557 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,574 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 44.0 (TID 87). 1240 bytes result sent to driver
2016-12-14 14:47:41,575 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 86). 1211 bytes result sent to driver
2016-12-14 14:47:41,577 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 44.0 (TID 87) in 26 ms on localhost (1/2)
2016-12-14 14:47:41,577 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 86) in 27 ms on localhost (2/2)
2016-12-14 14:47:41,577 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 44 (collect at Relabel.scala:14) finished in 0.027 s
2016-12-14 14:47:41,577 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,577 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: collect at Relabel.scala:14, took 0.076302 s
2016-12-14 14:47:41,593 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:125
2016-12-14 14:47:41,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (foreach at K_means.scala:125) with 2 output partitions
2016-12-14 14:47:41,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 45 (foreach at K_means.scala:125)
2016-12-14 14:47:41,596 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:41,596 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:41,597 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 45 (MapPartitionsRDD[63] at map at Relabel.scala:31), which has no missing parents
2016-12-14 14:47:41,599 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 4.6 KB, free 358.5 KB)
2016-12-14 14:47:41,602 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.8 KB, free 361.3 KB)
2016-12-14 14:47:41,602 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:64382 (size: 2.8 KB, free: 529.9 MB)
2016-12-14 14:47:41,603 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,603 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[63] at map at Relabel.scala:31)
2016-12-14 14:47:41,604 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 45.0 with 2 tasks
2016-12-14 14:47:41,605 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 45.0 (TID 88, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,606 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 45.0 (TID 89, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,606 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 45.0 (TID 88)
2016-12-14 14:47:41,606 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 45.0 (TID 89)
2016-12-14 14:47:41,608 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,609 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,610 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,611 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,612 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,613 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,614 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,615 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,616 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,617 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,618 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,619 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,620 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,621 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,621 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,621 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,621 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,621 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,621 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,621 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,622 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,622 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,622 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,622 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,622 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,623 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,623 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,623 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,623 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 14:47:41,623 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,624 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,624 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,624 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,624 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,624 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,624 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,625 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,625 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,625 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,625 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,625 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,626 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,626 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,626 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,626 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,626 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,626 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,627 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,627 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,627 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,627 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,627 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,628 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:47:41,629 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:47:41,630 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 45.0 (TID 89). 2057 bytes result sent to driver
2016-12-14 14:47:41,630 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 45.0 (TID 88). 2057 bytes result sent to driver
2016-12-14 14:47:41,633 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 45.0 (TID 89) in 27 ms on localhost (1/2)
2016-12-14 14:47:41,634 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 45.0 (TID 88) in 29 ms on localhost (2/2)
2016-12-14 14:47:41,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 45 (foreach at K_means.scala:125) finished in 0.030 s
2016-12-14 14:47:41,634 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,635 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: foreach at K_means.scala:125, took 0.040895 s
2016-12-14 14:47:41,652 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 14:47:41,653 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 64 (map at MulticlassMetrics.scala:46)
2016-12-14 14:47:41,653 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 14:47:41,654 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 47 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 14:47:41,654 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 46)
2016-12-14 14:47:41,654 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 46)
2016-12-14 14:47:41,655 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 46 (MapPartitionsRDD[64] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 14:47:41,656 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64 stored as values in memory (estimated size 5.5 KB, free 366.8 KB)
2016-12-14 14:47:41,659 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.2 KB, free 370.0 KB)
2016-12-14 14:47:41,660 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_64_piece0 in memory on localhost:64382 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:47:41,661 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,662 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[64] at map at MulticlassMetrics.scala:46)
2016-12-14 14:47:41,662 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 46.0 with 2 tasks
2016-12-14 14:47:41,663 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 46.0 (TID 90, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:47:41,664 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 46.0 (TID 91, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:47:41,664 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 46.0 (TID 91)
2016-12-14 14:47:41,664 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 46.0 (TID 90)
2016-12-14 14:47:41,667 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,667 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,676 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 46.0 (TID 90). 2237 bytes result sent to driver
2016-12-14 14:47:41,676 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 46.0 (TID 91). 2237 bytes result sent to driver
2016-12-14 14:47:41,680 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 46.0 (TID 91) in 16 ms on localhost (1/2)
2016-12-14 14:47:41,680 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 46.0 (TID 90) in 17 ms on localhost (2/2)
2016-12-14 14:47:41,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 46 (map at MulticlassMetrics.scala:46) finished in 0.018 s
2016-12-14 14:47:41,680 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:41,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:41,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 47)
2016-12-14 14:47:41,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:41,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 47 (ShuffledRDD[65] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 14:47:41,683 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65 stored as values in memory (estimated size 2.6 KB, free 372.6 KB)
2016-12-14 14:47:41,685 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65_piece0 stored as bytes in memory (estimated size 1593.0 B, free 374.2 KB)
2016-12-14 14:47:41,686 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_65_piece0 in memory on localhost:64382 (size: 1593.0 B, free: 529.9 MB)
2016-12-14 14:47:41,686 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,686 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 47 (ShuffledRDD[65] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 14:47:41,686 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 47.0 with 2 tasks
2016-12-14 14:47:41,688 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 47.0 (TID 92, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,690 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 47.0 (TID 93, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:47:41,690 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 47.0 (TID 92)
2016-12-14 14:47:41,690 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 47.0 (TID 93)
2016-12-14 14:47:41,692 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,692 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,692 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,693 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:41,697 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 47.0 (TID 93). 1124 bytes result sent to driver
2016-12-14 14:47:41,698 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 47.0 (TID 92). 1163 bytes result sent to driver
2016-12-14 14:47:41,699 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 47.0 (TID 93) in 10 ms on localhost (1/2)
2016-12-14 14:47:41,702 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 47.0 (TID 92) in 15 ms on localhost (2/2)
2016-12-14 14:47:41,702 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 47 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.015 s
2016-12-14 14:47:41,703 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,703 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.050420 s
2016-12-14 14:47:41,724 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 14:47:41,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 68 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:47:41,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 31 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 14:47:41,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 49 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:47:41,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 48)
2016-12-14 14:47:41,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 48)
2016-12-14 14:47:41,727 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 48 (MapPartitionsRDD[68] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:47:41,729 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66 stored as values in memory (estimated size 6.0 KB, free 380.2 KB)
2016-12-14 14:47:41,733 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.4 KB, free 383.7 KB)
2016-12-14 14:47:41,734 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_66_piece0 in memory on localhost:64382 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:47:41,735 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,735 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[68] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:47:41,735 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 48.0 with 2 tasks
2016-12-14 14:47:41,737 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 48.0 (TID 94, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:47:41,738 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 48.0 (TID 95, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:47:41,738 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 48.0 (TID 94)
2016-12-14 14:47:41,738 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 48.0 (TID 95)
2016-12-14 14:47:41,742 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,742 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,749 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 48.0 (TID 95). 2237 bytes result sent to driver
2016-12-14 14:47:41,749 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 48.0 (TID 94). 2237 bytes result sent to driver
2016-12-14 14:47:41,751 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 48.0 (TID 95) in 14 ms on localhost (1/2)
2016-12-14 14:47:41,752 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 48.0 (TID 94) in 16 ms on localhost (2/2)
2016-12-14 14:47:41,752 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,753 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 48 (countByValue at MulticlassMetrics.scala:43) finished in 0.017 s
2016-12-14 14:47:41,753 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:47:41,754 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:47:41,754 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 49)
2016-12-14 14:47:41,754 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:47:41,755 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 49 (ShuffledRDD[69] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:47:41,756 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67 stored as values in memory (estimated size 2.6 KB, free 386.3 KB)
2016-12-14 14:47:41,759 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67_piece0 stored as bytes in memory (estimated size 1562.0 B, free 387.8 KB)
2016-12-14 14:47:41,760 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_67_piece0 in memory on localhost:64382 (size: 1562.0 B, free: 529.9 MB)
2016-12-14 14:47:41,760 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,760 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 49 (ShuffledRDD[69] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:47:41,760 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 49.0 with 2 tasks
2016-12-14 14:47:41,761 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 49.0 (TID 96, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:47:41,762 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 49.0 (TID 97, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:47:41,762 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 49.0 (TID 97)
2016-12-14 14:47:41,763 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 49.0 (TID 96)
2016-12-14 14:47:41,764 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,764 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:47:41,765 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:47:41,765 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:47:41,769 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 49.0 (TID 97). 1124 bytes result sent to driver
2016-12-14 14:47:41,769 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 49.0 (TID 96). 1164 bytes result sent to driver
2016-12-14 14:47:41,771 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 49.0 (TID 97) in 8 ms on localhost (1/2)
2016-12-14 14:47:41,772 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 49.0 (TID 96) in 11 ms on localhost (2/2)
2016-12-14 14:47:41,772 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 49 (countByValue at MulticlassMetrics.scala:43) finished in 0.011 s
2016-12-14 14:47:41,772 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,772 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 31 finished: countByValue at MulticlassMetrics.scala:43, took 0.047943 s
2016-12-14 14:47:41,773 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.702247191011236
2016-12-14 14:47:41,775 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68 stored as values in memory (estimated size 560.0 B, free 388.4 KB)
2016-12-14 14:47:41,780 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68_piece0 stored as bytes in memory (estimated size 515.0 B, free 388.9 KB)
2016-12-14 14:47:41,780 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_68_piece0 in memory on localhost:64382 (size: 515.0 B, free: 529.9 MB)
2016-12-14 14:47:41,781 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 68 from broadcast at KMeansModel.scala:87
2016-12-14 14:47:41,795 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 14:47:41,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 32 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 14:47:41,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 50 (sum at KMeansModel.scala:88)
2016-12-14 14:47:41,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:47:41,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:47:41,798 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 50 (MapPartitionsRDD[70] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 14:47:41,799 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_69 stored as values in memory (estimated size 4.2 KB, free 393.1 KB)
2016-12-14 14:47:41,806 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.4 KB, free 395.5 KB)
2016-12-14 14:47:41,807 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_69_piece0 in memory on localhost:64382 (size: 2.4 KB, free: 529.9 MB)
2016-12-14 14:47:41,808 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:47:41,808 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 50 (MapPartitionsRDD[70] at map at KMeansModel.scala:88)
2016-12-14 14:47:41,809 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 50.0 with 2 tasks
2016-12-14 14:47:41,810 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 50.0 (TID 98, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,810 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 50.0 (TID 99, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:47:41,811 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 50.0 (TID 99)
2016-12-14 14:47:41,811 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 50.0 (TID 98)
2016-12-14 14:47:41,813 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:47:41,813 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:47:41,816 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 50.0 (TID 98). 2064 bytes result sent to driver
2016-12-14 14:47:41,816 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 50.0 (TID 99). 2064 bytes result sent to driver
2016-12-14 14:47:41,819 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 50.0 (TID 98) in 10 ms on localhost (1/2)
2016-12-14 14:47:41,819 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 50.0 (TID 99) in 9 ms on localhost (2/2)
2016-12-14 14:47:41,820 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 50 (sum at KMeansModel.scala:88) finished in 0.010 s
2016-12-14 14:47:41,820 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 50.0, whose tasks have all completed, from pool 
2016-12-14 14:47:41,820 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 32 finished: sum at KMeansModel.scala:88, took 0.024588 s
2016-12-14 14:47:41,820 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 2370689.6867946046
2016-12-14 14:47:42,166 INFO  org.apache.spark.SparkContext - logInfo: Invoking stop() from shutdown hook
2016-12-14 14:47:42,253 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
2016-12-14 14:47:42,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
2016-12-14 14:47:42,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
2016-12-14 14:47:42,255 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
2016-12-14 14:47:42,255 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL,null}
2016-12-14 14:47:42,256 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:47:42,257 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:47:42,257 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:47:42,257 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:47:42,258 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:47:42,258 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:47:42,258 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:47:42,259 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:47:42,259 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:47:42,259 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:47:42,260 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:47:42,260 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:47:42,260 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:47:42,260 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:47:42,261 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:47:42,261 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:47:42,261 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:47:42,261 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:47:42,261 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:47:42,261 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:47:42,262 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:47:42,262 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:47:42,262 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:47:42,262 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:47:42,262 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:47:42,324 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 14:47:42,399 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:47:42,412 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 14:47:42,412 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 14:47:42,413 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 14:47:42,416 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 14:47:42,422 WARN  org.apache.spark.rpc.netty.Dispatcher - logWarning: Message RemoteProcessDisconnected(hadoop103.dategeek.com.cn:12438) dropped. RpcEnv already stopped.
2016-12-14 14:47:42,422 WARN  org.apache.spark.rpc.netty.Dispatcher - logWarning: Message RemoteProcessDisconnected(hadoop103.dategeek.com.cn:12438) dropped. RpcEnv already stopped.
2016-12-14 14:47:42,425 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 14:47:42,426 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 14:47:42,426 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 14:47:42,428 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-50f62375-9fa6-42c3-ae06-45d6c7d05d2a
2016-12-14 14:47:42,430 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:47:42,470 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 14:47:42,471 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 14:49:51,766 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 14:49:52,346 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 14:49:52,349 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 14:49:52,350 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 14:49:52,555 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 19166.
2016-12-14 14:49:52,883 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 14:49:52,926 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 14:49:53,153 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:24140]
2016-12-14 14:49:53,155 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:24140]
2016-12-14 14:49:53,161 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 24140.
2016-12-14 14:49:53,176 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 14:49:53,191 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 14:49:53,203 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-507f4557-01d3-4c48-a22a-f4289e64e157
2016-12-14 14:49:53,215 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 14:49:53,273 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 14:49:53,414 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 14:49:53,460 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:49:53,461 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:49:53,463 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 14:49:53,489 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:19166/jars/mysql-connector-java-5.1.25.jar with timestamp 1481698193489
2016-12-14 14:49:53,489 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:19166/jars/ojdbc6.jar with timestamp 1481698193489
2016-12-14 14:49:53,490 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:19166/jars/orai18n.jar with timestamp 1481698193490
2016-12-14 14:49:53,490 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:19166/jars/machine_learning_2.10-1.0.jar with timestamp 1481698193490
2016-12-14 14:49:53,544 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 14:49:53,562 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 31023.
2016-12-14 14:49:53,563 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 31023
2016-12-14 14:49:53,565 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 14:49:53,566 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 14:49:53,570 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:31023 with 530.0 MB RAM, BlockManagerId(driver, localhost, 31023)
2016-12-14 14:49:53,574 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 14:49:54,537 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481698193519
2016-12-14 14:49:54,566 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/wine.txt
2016-12-14 14:49:54,566 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 14:49:54,566 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 14:49:54,567 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 14:49:54,567 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 14:49:54,567 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 14:49:54,956 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 14:49:55,154 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 14:49:55,158 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:31023 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 14:49:55,162 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:88
2016-12-14 14:49:55,218 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:49:55,274 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 14:49:55,289 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:49:55,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:49:55,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (takeSample at KMeans.scala:378)
2016-12-14 14:49:55,317 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:55,336 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:55,350 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210), which has no missing parents
2016-12-14 14:49:55,437 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 305.3 KB)
2016-12-14 14:49:55,458 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 307.7 KB)
2016-12-14 14:49:55,459 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:31023 (size: 2.4 KB, free: 530.0 MB)
2016-12-14 14:49:55,461 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:55,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210)
2016-12-14 14:49:55,469 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 2 tasks
2016-12-14 14:49:55,545 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:49:55,552 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:49:55,566 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 0.0 (TID 1)
2016-12-14 14:49:55,566 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:49:55,577 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 14:49:55,581 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:19166/jars/orai18n.jar with timestamp 1481698193490
2016-12-14 14:49:55,697 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:19166/jars/orai18n.jar to /tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/fetchFileTemp313676515423264430.tmp
2016-12-14 14:49:55,809 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/orai18n.jar to class loader
2016-12-14 14:49:55,810 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:19166/jars/mysql-connector-java-5.1.25.jar with timestamp 1481698193489
2016-12-14 14:49:55,811 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:19166/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/fetchFileTemp5628141961306993296.tmp
2016-12-14 14:49:55,822 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 14:49:55,823 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:19166/jars/machine_learning_2.10-1.0.jar with timestamp 1481698193490
2016-12-14 14:49:55,824 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:19166/jars/machine_learning_2.10-1.0.jar to /tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/fetchFileTemp3059249377485308440.tmp
2016-12-14 14:49:55,830 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/machine_learning_2.10-1.0.jar to class loader
2016-12-14 14:49:55,830 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:19166/jars/ojdbc6.jar with timestamp 1481698193489
2016-12-14 14:49:55,830 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:19166/jars/ojdbc6.jar to /tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/fetchFileTemp785465959085101963.tmp
2016-12-14 14:49:55,845 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc/userFiles-d4838bb1-67d0-4d3b-ba2c-fd530297a245/ojdbc6.jar to class loader
2016-12-14 14:49:55,880 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 14:49:55,880 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 14:49:55,886 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/wine.txt:5738+5739
2016-12-14 14:49:55,886 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/wine.txt:0+5738
2016-12-14 14:49:55,914 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 14:49:55,915 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 14:49:55,915 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 14:49:55,915 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 14:49:55,916 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 14:49:55,981 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 14.3 KB, free 321.9 KB)
2016-12-14 14:49:55,982 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:31023 (size: 14.3 KB, free: 530.0 MB)
2016-12-14 14:49:55,983 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_1 not found, computing it
2016-12-14 14:49:55,984 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:55,992 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 14.3 KB, free 336.2 KB)
2016-12-14 14:49:55,994 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:31023 (size: 14.3 KB, free: 530.0 MB)
2016-12-14 14:49:55,995 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_1 stored as values in memory (estimated size 2.5 KB, free 338.7 KB)
2016-12-14 14:49:55,995 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_0 not found, computing it
2016-12-14 14:49:55,996 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:55,996 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_1 in memory on localhost:31023 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:49:56,002 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_0 stored as values in memory (estimated size 2.5 KB, free 341.1 KB)
2016-12-14 14:49:56,004 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_0 in memory on localhost:31023 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:49:56,064 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 0.0 (TID 1). 2638 bytes result sent to driver
2016-12-14 14:49:56,064 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2638 bytes result sent to driver
2016-12-14 14:49:56,094 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 0.0 (TID 1) in 541 ms on localhost (1/2)
2016-12-14 14:49:56,095 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 589 ms on localhost (2/2)
2016-12-14 14:49:56,097 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,099 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (takeSample at KMeans.scala:378) finished in 0.613 s
2016-12-14 14:49:56,109 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: takeSample at KMeans.scala:378, took 0.819310 s
2016-12-14 14:49:56,208 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:49:56,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:49:56,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (takeSample at KMeans.scala:378)
2016-12-14 14:49:56,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,216 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 14:49:56,221 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 21.3 KB, free 362.4 KB)
2016-12-14 14:49:56,230 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.9 KB, free 371.3 KB)
2016-12-14 14:49:56,231 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:31023 (size: 8.9 KB, free: 529.9 MB)
2016-12-14 14:49:56,232 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,233 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378)
2016-12-14 14:49:56,233 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 2 tasks
2016-12-14 14:49:56,242 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:49:56,243 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:49:56,244 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 2)
2016-12-14 14:49:56,244 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 1.0 (TID 3)
2016-12-14 14:49:56,262 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,262 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,262 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,262 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,288 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 2). 4981 bytes result sent to driver
2016-12-14 14:49:56,288 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 1.0 (TID 3). 4258 bytes result sent to driver
2016-12-14 14:49:56,311 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 1.0 (TID 3) in 69 ms on localhost (1/2)
2016-12-14 14:49:56,312 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 2) in 74 ms on localhost (2/2)
2016-12-14 14:49:56,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (takeSample at KMeans.scala:378) finished in 0.074 s
2016-12-14 14:49:56,313 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,313 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: takeSample at KMeans.scala:378, took 0.104795 s
2016-12-14 14:49:56,320 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 2.7 KB, free 374.0 KB)
2016-12-14 14:49:56,330 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 917.0 B, free 374.9 KB)
2016-12-14 14:49:56,331 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:31023 (size: 917.0 B, free: 529.9 MB)
2016-12-14 14:49:56,332 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at KMeans.scala:396
2016-12-14 14:49:56,355 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:49:56,357 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:49:56,357 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (aggregate at KMeans.scala:404)
2016-12-14 14:49:56,357 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,360 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,360 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:49:56,363 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 380.7 KB)
2016-12-14 14:49:56,371 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.0 KB, free 383.7 KB)
2016-12-14 14:49:56,372 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:31023 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:56,373 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398)
2016-12-14 14:49:56,374 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 14:49:56,377 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:49:56,378 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:49:56,379 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 5)
2016-12-14 14:49:56,379 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 4)
2016-12-14 14:49:56,385 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_1 not found, computing it
2016-12-14 14:49:56,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,386 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_0 not found, computing it
2016-12-14 14:49:56,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,387 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,387 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,403 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 14:49:56,404 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 14:49:56,423 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_0 stored as values in memory (estimated size 8.7 KB, free 392.4 KB)
2016-12-14 14:49:56,424 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_0 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,425 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_1 stored as values in memory (estimated size 8.7 KB, free 401.1 KB)
2016-12-14 14:49:56,426 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_1 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,432 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 5). 2721 bytes result sent to driver
2016-12-14 14:49:56,432 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 4). 2721 bytes result sent to driver
2016-12-14 14:49:56,440 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 4) in 65 ms on localhost (1/2)
2016-12-14 14:49:56,441 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 5) in 63 ms on localhost (2/2)
2016-12-14 14:49:56,441 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (aggregate at KMeans.scala:404) finished in 0.066 s
2016-12-14 14:49:56,441 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,442 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: aggregate at KMeans.scala:404, took 0.086270 s
2016-12-14 14:49:56,449 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 7 from persistence list
2016-12-14 14:49:56,456 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 7
2016-12-14 14:49:56,480 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:49:56,482 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:49:56,483 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (collect at KMeans.scala:436)
2016-12-14 14:49:56,483 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,485 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,486 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:49:56,489 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 6.0 KB, free 407.1 KB)
2016-12-14 14:49:56,497 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 410.3 KB)
2016-12-14 14:49:56,499 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:31023 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:56,500 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,500 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:49:56,501 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 14:49:56,503 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:49:56,504 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:49:56,505 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 6)
2016-12-14 14:49:56,505 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 7)
2016-12-14 14:49:56,510 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,511 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,511 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:49:56,512 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,512 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,513 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:49:56,522 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 6). 6132 bytes result sent to driver
2016-12-14 14:49:56,525 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 7). 3808 bytes result sent to driver
2016-12-14 14:49:56,530 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 7) in 27 ms on localhost (1/2)
2016-12-14 14:49:56,531 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 6) in 28 ms on localhost (2/2)
2016-12-14 14:49:56,531 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (collect at KMeans.scala:436) finished in 0.029 s
2016-12-14 14:49:56,532 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: collect at KMeans.scala:436, took 0.051453 s
2016-12-14 14:49:56,539 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 8.6 KB, free 418.9 KB)
2016-12-14 14:49:56,550 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.0 KB, free 421.9 KB)
2016-12-14 14:49:56,552 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:31023 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:56,553 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at KMeans.scala:396
2016-12-14 14:49:56,570 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:49:56,571 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:49:56,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (aggregate at KMeans.scala:404)
2016-12-14 14:49:56,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,575 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,575 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:49:56,579 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 6.1 KB, free 428.0 KB)
2016-12-14 14:49:56,586 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.1 KB, free 431.1 KB)
2016-12-14 14:49:56,587 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:31023 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:49:56,588 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,588 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398)
2016-12-14 14:49:56,589 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 14:49:56,592 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:49:56,593 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:49:56,594 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 8)
2016-12-14 14:49:56,594 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 9)
2016-12-14 14:49:56,601 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_0 not found, computing it
2016-12-14 14:49:56,601 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_1 not found, computing it
2016-12-14 14:49:56,601 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,602 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,602 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,602 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,602 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:49:56,602 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:49:56,615 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_1 stored as values in memory (estimated size 8.7 KB, free 439.8 KB)
2016-12-14 14:49:56,616 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_0 stored as values in memory (estimated size 8.7 KB, free 448.5 KB)
2016-12-14 14:49:56,616 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_1 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,617 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_0 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,623 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 9). 2721 bytes result sent to driver
2016-12-14 14:49:56,624 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 8). 2721 bytes result sent to driver
2016-12-14 14:49:56,627 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 9) in 34 ms on localhost (1/2)
2016-12-14 14:49:56,627 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 8) in 37 ms on localhost (2/2)
2016-12-14 14:49:56,627 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,628 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (aggregate at KMeans.scala:404) finished in 0.038 s
2016-12-14 14:49:56,628 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: aggregate at KMeans.scala:404, took 0.058263 s
2016-12-14 14:49:56,629 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 10 from persistence list
2016-12-14 14:49:56,631 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:49:56,650 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:49:56,652 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:49:56,652 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (collect at KMeans.scala:436)
2016-12-14 14:49:56,652 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,654 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,654 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:49:56,656 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.2 KB, free 437.3 KB)
2016-12-14 14:49:56,661 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.2 KB, free 440.5 KB)
2016-12-14 14:49:56,662 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:31023 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:56,662 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,663 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:49:56,663 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 14:49:56,664 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:49:56,665 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:49:56,666 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 11)
2016-12-14 14:49:56,666 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 10)
2016-12-14 14:49:56,672 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,672 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,672 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,672 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:49:56,673 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,673 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:49:56,685 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 11). 4831 bytes result sent to driver
2016-12-14 14:49:56,685 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 10). 5220 bytes result sent to driver
2016-12-14 14:49:56,695 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 11) in 31 ms on localhost (1/2)
2016-12-14 14:49:56,695 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 10) in 31 ms on localhost (2/2)
2016-12-14 14:49:56,695 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (collect at KMeans.scala:436) finished in 0.032 s
2016-12-14 14:49:56,695 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,696 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: collect at KMeans.scala:436, took 0.045411 s
2016-12-14 14:49:56,698 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 8.4 KB, free 448.9 KB)
2016-12-14 14:49:56,710 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.0 KB, free 451.9 KB)
2016-12-14 14:49:56,711 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:31023 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:56,712 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at KMeans.scala:396
2016-12-14 14:49:56,733 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:49:56,736 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:49:56,736 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 14:49:56,736 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,738 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,739 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:49:56,743 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 458.3 KB)
2016-12-14 14:49:56,752 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.1 KB, free 461.4 KB)
2016-12-14 14:49:56,753 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:31023 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:49:56,754 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,754 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398)
2016-12-14 14:49:56,754 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 14:49:56,757 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:49:56,758 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:49:56,759 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 12)
2016-12-14 14:49:56,759 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 13)
2016-12-14 14:49:56,765 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_1 not found, computing it
2016-12-14 14:49:56,765 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_0 not found, computing it
2016-12-14 14:49:56,765 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,766 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,766 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,766 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,766 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:49:56,766 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:49:56,772 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_1 stored as values in memory (estimated size 8.7 KB, free 470.1 KB)
2016-12-14 14:49:56,773 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_0 stored as values in memory (estimated size 8.7 KB, free 478.8 KB)
2016-12-14 14:49:56,773 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_1 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,773 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_0 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,777 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 13). 2721 bytes result sent to driver
2016-12-14 14:49:56,779 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 12). 2721 bytes result sent to driver
2016-12-14 14:49:56,782 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 13) in 25 ms on localhost (1/2)
2016-12-14 14:49:56,785 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 12) in 29 ms on localhost (2/2)
2016-12-14 14:49:56,785 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,785 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.029 s
2016-12-14 14:49:56,786 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.052004 s
2016-12-14 14:49:56,787 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 14 from persistence list
2016-12-14 14:49:56,787 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:49:56,829 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:49:56,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:49:56,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 14:49:56,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,833 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:31023 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:49:56,834 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,835 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:49:56,837 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 14:49:56,839 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:31023 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:56,839 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.5 KB, free 455.2 KB)
2016-12-14 14:49:56,840 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 14:49:56,842 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:31023 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:49:56,843 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 14:49:56,844 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:31023 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:56,844 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 14:49:56,845 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:31023 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:56,846 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 14:49:56,846 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 425.1 KB)
2016-12-14 14:49:56,847 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:31023 in memory (size: 8.9 KB, free: 529.9 MB)
2016-12-14 14:49:56,848 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:31023 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:49:56,848 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 14:49:56,848 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,849 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:49:56,849 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:31023 in memory (size: 2.4 KB, free: 529.9 MB)
2016-12-14 14:49:56,849 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 14:49:56,850 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 14:49:56,852 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:49:56,854 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:49:56,855 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 15)
2016-12-14 14:49:56,855 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 14)
2016-12-14 14:49:56,858 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,858 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,858 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:49:56,861 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,862 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,862 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:49:56,863 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 15). 5339 bytes result sent to driver
2016-12-14 14:49:56,868 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 14). 5856 bytes result sent to driver
2016-12-14 14:49:56,869 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 15) in 17 ms on localhost (1/2)
2016-12-14 14:49:56,879 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 14) in 28 ms on localhost (2/2)
2016-12-14 14:49:56,879 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,880 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.029 s
2016-12-14 14:49:56,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.050580 s
2016-12-14 14:49:56,882 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 9.7 KB, free 397.9 KB)
2016-12-14 14:49:56,888 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.5 KB, free 401.5 KB)
2016-12-14 14:49:56,888 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:31023 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:49:56,889 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at KMeans.scala:396
2016-12-14 14:49:56,899 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:49:56,902 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:49:56,902 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 14:49:56,902 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,906 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:49:56,911 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 6.5 KB, free 408.0 KB)
2016-12-14 14:49:56,919 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.2 KB, free 411.2 KB)
2016-12-14 14:49:56,920 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:31023 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:56,920 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,921 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398)
2016-12-14 14:49:56,921 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 14:49:56,923 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:49:56,924 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:49:56,924 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 16)
2016-12-14 14:49:56,924 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 17)
2016-12-14 14:49:56,929 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_1 not found, computing it
2016-12-14 14:49:56,929 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:56,929 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:56,929 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_0 not found, computing it
2016-12-14 14:49:56,930 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:49:56,930 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:56,930 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:56,931 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:49:56,933 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_1 stored as values in memory (estimated size 8.7 KB, free 419.9 KB)
2016-12-14 14:49:56,934 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_1 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,936 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_0 stored as values in memory (estimated size 8.7 KB, free 428.6 KB)
2016-12-14 14:49:56,936 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_0 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:56,937 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 17). 2721 bytes result sent to driver
2016-12-14 14:49:56,943 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 16). 2721 bytes result sent to driver
2016-12-14 14:49:56,945 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 17) in 22 ms on localhost (1/2)
2016-12-14 14:49:56,952 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 16) in 29 ms on localhost (2/2)
2016-12-14 14:49:56,952 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.030 s
2016-12-14 14:49:56,952 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:49:56,953 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.052851 s
2016-12-14 14:49:56,954 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 18 from persistence list
2016-12-14 14:49:56,954 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:49:56,973 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:49:56,976 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:49:56,976 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 14:49:56,976 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:56,979 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:56,980 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:49:56,985 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.7 KB, free 417.9 KB)
2016-12-14 14:49:56,996 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 421.3 KB)
2016-12-14 14:49:56,997 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:31023 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:56,997 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:56,998 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:49:56,998 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 14:49:57,001 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:49:57,003 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:49:57,004 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 18)
2016-12-14 14:49:57,004 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 19)
2016-12-14 14:49:57,008 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,008 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,008 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:49:57,009 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,010 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,010 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:49:57,012 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 19). 5991 bytes result sent to driver
2016-12-14 14:49:57,019 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 18). 4837 bytes result sent to driver
2016-12-14 14:49:57,021 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 19) in 19 ms on localhost (1/2)
2016-12-14 14:49:57,027 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 18) in 27 ms on localhost (2/2)
2016-12-14 14:49:57,027 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,028 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 14:49:57,028 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.055005 s
2016-12-14 14:49:57,030 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 9.6 KB, free 430.8 KB)
2016-12-14 14:49:57,035 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.4 KB, free 434.2 KB)
2016-12-14 14:49:57,036 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:31023 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:57,037 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at KMeans.scala:396
2016-12-14 14:49:57,050 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:49:57,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:49:57,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 14:49:57,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:57,056 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:57,057 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:49:57,063 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 6.8 KB, free 441.0 KB)
2016-12-14 14:49:57,072 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.3 KB, free 444.3 KB)
2016-12-14 14:49:57,073 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:31023 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:49:57,074 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398)
2016-12-14 14:49:57,075 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 14:49:57,077 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:49:57,078 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:49:57,079 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 20)
2016-12-14 14:49:57,079 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 21)
2016-12-14 14:49:57,083 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_1 not found, computing it
2016-12-14 14:49:57,083 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,083 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,083 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:49:57,084 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_0 not found, computing it
2016-12-14 14:49:57,084 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,084 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,084 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:49:57,085 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_1 stored as values in memory (estimated size 8.7 KB, free 453.0 KB)
2016-12-14 14:49:57,086 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_1 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:57,087 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_0 stored as values in memory (estimated size 8.7 KB, free 461.7 KB)
2016-12-14 14:49:57,088 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_0 in memory on localhost:31023 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:49:57,089 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 21). 2721 bytes result sent to driver
2016-12-14 14:49:57,093 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 20). 2721 bytes result sent to driver
2016-12-14 14:49:57,095 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 21) in 18 ms on localhost (1/2)
2016-12-14 14:49:57,101 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 20) in 24 ms on localhost (2/2)
2016-12-14 14:49:57,101 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.025 s
2016-12-14 14:49:57,101 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,102 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.052138 s
2016-12-14 14:49:57,103 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 22 from persistence list
2016-12-14 14:49:57,104 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:49:57,117 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:49:57,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:49:57,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 14:49:57,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:57,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:57,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:49:57,127 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 6.9 KB, free 451.2 KB)
2016-12-14 14:49:57,137 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.4 KB, free 454.6 KB)
2016-12-14 14:49:57,138 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:31023 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:57,138 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:49:57,139 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 14:49:57,141 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:49:57,142 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:49:57,142 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 22)
2016-12-14 14:49:57,142 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 23)
2016-12-14 14:49:57,146 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,146 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,146 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_1 locally
2016-12-14 14:49:57,147 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,147 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,148 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_0 locally
2016-12-14 14:49:57,150 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 23). 4829 bytes result sent to driver
2016-12-14 14:49:57,154 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 22). 6776 bytes result sent to driver
2016-12-14 14:49:57,156 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 23) in 15 ms on localhost (1/2)
2016-12-14 14:49:57,160 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 22) in 20 ms on localhost (2/2)
2016-12-14 14:49:57,161 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.020 s
2016-12-14 14:49:57,161 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,161 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.043749 s
2016-12-14 14:49:57,162 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 26 from persistence list
2016-12-14 14:49:57,163 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:49:57,164 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 45.4 KB, free 482.6 KB)
2016-12-14 14:49:57,171 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.5 KB, free 492.1 KB)
2016-12-14 14:49:57,172 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:31023 (size: 9.5 KB, free: 529.9 MB)
2016-12-14 14:49:57,172 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at KMeans.scala:450
2016-12-14 14:49:57,200 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 14:49:57,218 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 29 (flatMap at KMeans.scala:451)
2016-12-14 14:49:57,219 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 14:49:57,219 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collectAsMap at KMeans.scala:455)
2016-12-14 14:49:57,219 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 12)
2016-12-14 14:49:57,220 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 12)
2016-12-14 14:49:57,221 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 14:49:57,229 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 5.9 KB, free 498.0 KB)
2016-12-14 14:49:57,236 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.2 KB, free 501.2 KB)
2016-12-14 14:49:57,237 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:31023 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:57,238 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,241 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451)
2016-12-14 14:49:57,241 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 14:49:57,244 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,244 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,245 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 24)
2016-12-14 14:49:57,245 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 25)
2016-12-14 14:49:57,250 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,250 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,250 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,250 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,346 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 25). 2237 bytes result sent to driver
2016-12-14 14:49:57,354 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 25) in 110 ms on localhost (1/2)
2016-12-14 14:49:57,354 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 24). 2237 bytes result sent to driver
2016-12-14 14:49:57,359 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 24) in 117 ms on localhost (2/2)
2016-12-14 14:49:57,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 12 (flatMap at KMeans.scala:451) finished in 0.117 s
2016-12-14 14:49:57,359 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,360 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:57,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:57,362 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 13)
2016-12-14 14:49:57,363 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:57,366 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 14:49:57,373 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 2.6 KB, free 503.8 KB)
2016-12-14 14:49:57,380 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1555.0 B, free 505.3 KB)
2016-12-14 14:49:57,381 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:31023 (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:49:57,382 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,382 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455)
2016-12-14 14:49:57,382 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 14:49:57,386 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 26, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,387 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 27, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,388 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 26)
2016-12-14 14:49:57,388 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 27)
2016-12-14 14:49:57,398 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,398 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,400 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 14:49:57,400 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 14:49:57,443 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 27). 4437 bytes result sent to driver
2016-12-14 14:49:57,443 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 26). 4566 bytes result sent to driver
2016-12-14 14:49:57,448 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 26) in 63 ms on localhost (1/2)
2016-12-14 14:49:57,448 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 27) in 61 ms on localhost (2/2)
2016-12-14 14:49:57,448 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,448 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collectAsMap at KMeans.scala:455) finished in 0.064 s
2016-12-14 14:49:57,449 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: collectAsMap at KMeans.scala:455, took 0.248330 s
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 14:49:57,541 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:49:57,542 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 14:49:57,561 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 2.326 seconds.
2016-12-14 14:49:57,564 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 5.1 KB, free 510.4 KB)
2016-12-14 14:49:57,568 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.4 KB, free 513.8 KB)
2016-12-14 14:49:57,569 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:31023 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:57,569 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at KMeans.scala:276
2016-12-14 14:49:57,588 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:57,590 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 31 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,591 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:57,591 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:57,591 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 14)
2016-12-14 14:49:57,591 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 14)
2016-12-14 14:49:57,592 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:57,595 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 6.9 KB, free 520.7 KB)
2016-12-14 14:49:57,601 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.6 KB, free 524.3 KB)
2016-12-14 14:49:57,602 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:57,603 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,603 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,603 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 14:49:57,605 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,605 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,606 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 28)
2016-12-14 14:49:57,606 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 29)
2016-12-14 14:49:57,610 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,610 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,610 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,610 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,624 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 29). 2516 bytes result sent to driver
2016-12-14 14:49:57,627 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 29) in 22 ms on localhost (1/2)
2016-12-14 14:49:57,628 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 28). 2516 bytes result sent to driver
2016-12-14 14:49:57,632 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 28) in 27 ms on localhost (2/2)
2016-12-14 14:49:57,632 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 14 (mapPartitions at KMeans.scala:279) finished in 0.028 s
2016-12-14 14:49:57,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:57,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:57,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 15)
2016-12-14 14:49:57,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:57,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:57,634 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 2.9 KB, free 527.2 KB)
2016-12-14 14:49:57,640 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1671.0 B, free 528.8 KB)
2016-12-14 14:49:57,641 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:31023 (size: 1671.0 B, free: 529.9 MB)
2016-12-14 14:49:57,642 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,643 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:57,643 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 14:49:57,644 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 30, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,644 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 31, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,645 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 30)
2016-12-14 14:49:57,645 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 31)
2016-12-14 14:49:57,647 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,647 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:57,648 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,648 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:57,656 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 31). 3052 bytes result sent to driver
2016-12-14 14:49:57,663 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 31) in 19 ms on localhost (1/2)
2016-12-14 14:49:57,665 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 30). 3054 bytes result sent to driver
2016-12-14 14:49:57,672 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 30) in 28 ms on localhost (2/2)
2016-12-14 14:49:57,672 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,673 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collectAsMap at KMeans.scala:302) finished in 0.028 s
2016-12-14 14:49:57,673 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collectAsMap at KMeans.scala:302, took 0.084790 s
2016-12-14 14:49:57,677 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 5.1 KB, free 533.9 KB)
2016-12-14 14:49:57,683 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.8 KB, free 536.7 KB)
2016-12-14 14:49:57,684 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:31023 (size: 2.8 KB, free: 529.9 MB)
2016-12-14 14:49:57,684 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at KMeans.scala:276
2016-12-14 14:49:57,709 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:57,711 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 33 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:57,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:57,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 14:49:57,713 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 14:49:57,715 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:57,717 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 6.9 KB, free 543.5 KB)
2016-12-14 14:49:57,724 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.6 KB, free 547.1 KB)
2016-12-14 14:49:57,725 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:57,726 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,726 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,726 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 14:49:57,728 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,728 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 33, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,729 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 32)
2016-12-14 14:49:57,729 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 33)
2016-12-14 14:49:57,734 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,735 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,736 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,737 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,749 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 32). 2516 bytes result sent to driver
2016-12-14 14:49:57,754 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 32) in 26 ms on localhost (1/2)
2016-12-14 14:49:57,756 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 33). 2516 bytes result sent to driver
2016-12-14 14:49:57,759 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 33) in 31 ms on localhost (2/2)
2016-12-14 14:49:57,759 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,759 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (mapPartitions at KMeans.scala:279) finished in 0.032 s
2016-12-14 14:49:57,759 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:57,759 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:57,760 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 14:49:57,760 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:57,760 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:57,763 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 2.9 KB, free 550.0 KB)
2016-12-14 14:49:57,769 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1667.0 B, free 551.7 KB)
2016-12-14 14:49:57,769 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:31023 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:49:57,770 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:57,770 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 14:49:57,772 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 34, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,773 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 35, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,773 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 34)
2016-12-14 14:49:57,773 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 35)
2016-12-14 14:49:57,776 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,776 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:57,777 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,777 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:57,793 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 35). 3052 bytes result sent to driver
2016-12-14 14:49:57,798 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 34). 3054 bytes result sent to driver
2016-12-14 14:49:57,799 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 35) in 27 ms on localhost (1/2)
2016-12-14 14:49:57,802 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 34) in 30 ms on localhost (2/2)
2016-12-14 14:49:57,802 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,803 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:302) finished in 0.031 s
2016-12-14 14:49:57,803 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: collectAsMap at KMeans.scala:302, took 0.094312 s
2016-12-14 14:49:57,805 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 2 iterations
2016-12-14 14:49:57,806 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 2 iterations
2016-12-14 14:49:57,807 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 4.1 KB, free 555.7 KB)
2016-12-14 14:49:57,810 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.1 KB, free 557.8 KB)
2016-12-14 14:49:57,811 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:31023 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:49:57,811 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at KMeans.scala:276
2016-12-14 14:49:57,827 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:57,829 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 35 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,830 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:57,830 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:57,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 14:49:57,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 14:49:57,833 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:57,836 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 6.8 KB, free 564.6 KB)
2016-12-14 14:49:57,845 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.6 KB, free 568.2 KB)
2016-12-14 14:49:57,846 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:57,847 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,848 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 14:49:57,849 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 36, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,850 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 37, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,850 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 36)
2016-12-14 14:49:57,850 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 37)
2016-12-14 14:49:57,854 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,854 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,855 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,856 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,867 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 36). 2468 bytes result sent to driver
2016-12-14 14:49:57,870 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 37). 2468 bytes result sent to driver
2016-12-14 14:49:57,871 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 36) in 22 ms on localhost (1/2)
2016-12-14 14:49:57,873 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 37) in 24 ms on localhost (2/2)
2016-12-14 14:49:57,873 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.025 s
2016-12-14 14:49:57,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:57,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:57,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 14:49:57,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:57,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:57,877 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 2.9 KB, free 571.1 KB)
2016-12-14 14:49:57,881 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1669.0 B, free 572.7 KB)
2016-12-14 14:49:57,882 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:31023 (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:49:57,882 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,883 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:57,883 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 14:49:57,884 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 38, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,884 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 39, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,884 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 38)
2016-12-14 14:49:57,884 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 39)
2016-12-14 14:49:57,886 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,886 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:57,887 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,887 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:57,896 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 38). 2553 bytes result sent to driver
2016-12-14 14:49:57,901 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 38) in 18 ms on localhost (1/2)
2016-12-14 14:49:57,904 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 39). 2801 bytes result sent to driver
2016-12-14 14:49:57,907 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 39) in 23 ms on localhost (2/2)
2016-12-14 14:49:57,907 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,907 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.024 s
2016-12-14 14:49:57,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collectAsMap at KMeans.scala:302, took 0.080025 s
2016-12-14 14:49:57,908 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 3 iterations
2016-12-14 14:49:57,908 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 3 iterations
2016-12-14 14:49:57,909 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 3.1 KB, free 575.8 KB)
2016-12-14 14:49:57,912 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 1588.0 B, free 577.3 KB)
2016-12-14 14:49:57,912 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:31023 (size: 1588.0 B, free: 529.9 MB)
2016-12-14 14:49:57,913 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at KMeans.scala:276
2016-12-14 14:49:57,945 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:57,946 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 14:49:57,946 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 37 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,947 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:57,947 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:57,947 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 14:49:57,947 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 14:49:57,948 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:31023 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:57,948 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 14:49:57,948 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:57,950 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 6.7 KB, free 575.0 KB)
2016-12-14 14:49:57,951 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 14:49:57,951 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:31023 in memory (size: 9.5 KB, free: 529.9 MB)
2016-12-14 14:49:57,953 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:31023 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:57,953 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.6 KB, free 513.3 KB)
2016-12-14 14:49:57,953 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 14:49:57,954 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:57,954 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,954 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:57,954 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 14:49:57,955 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:31023 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:49:57,955 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 14:49:57,956 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,956 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:49:57,956 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 41, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:57,956 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 41)
2016-12-14 14:49:57,956 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 40)
2016-12-14 14:49:57,957 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 26
2016-12-14 14:49:57,958 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:31023 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:57,959 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:31023 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:57,959 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 14:49:57,960 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:57,960 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:57,960 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:57,960 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:57,960 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:31023 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:57,961 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 14:49:57,961 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:49:57,962 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 22
2016-12-14 14:49:57,962 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:31023 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:49:57,964 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:31023 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:49:57,964 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 14:49:57,964 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:49:57,965 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 18
2016-12-14 14:49:57,965 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:31023 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:57,966 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:49:57,967 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 14
2016-12-14 14:49:57,967 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 41). 2420 bytes result sent to driver
2016-12-14 14:49:57,967 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:31023 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:57,968 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 40). 2420 bytes result sent to driver
2016-12-14 14:49:57,968 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:49:57,969 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 10
2016-12-14 14:49:57,969 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:31023 in memory (size: 917.0 B, free: 529.9 MB)
2016-12-14 14:49:57,970 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 14:49:57,970 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 14:49:57,970 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 14:49:57,970 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 41) in 14 ms on localhost (1/2)
2016-12-14 14:49:57,971 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:31023 in memory (size: 1671.0 B, free: 529.9 MB)
2016-12-14 14:49:57,971 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 40) in 15 ms on localhost (2/2)
2016-12-14 14:49:57,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 14:49:57,971 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:49:57,971 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 14:49:57,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:57,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:57,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 14:49:57,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:57,972 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:57,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:57,972 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 14:49:57,973 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 14:49:57,973 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 2.9 KB, free 408.8 KB)
2016-12-14 14:49:57,974 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:31023 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:57,974 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 14:49:57,974 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 14:49:57,974 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 14:49:57,974 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 14:49:57,974 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 14:49:57,975 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 14:49:57,975 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 14:49:57,975 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 14:49:57,975 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 14:49:57,975 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 14:49:57,976 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:31023 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:49:57,976 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1668.0 B, free 400.4 KB)
2016-12-14 14:49:57,976 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:31023 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:49:57,976 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 14:49:57,977 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 14:49:57,977 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:57,978 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:57,978 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 14:49:57,978 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:31023 in memory (size: 2.8 KB, free: 529.9 MB)
2016-12-14 14:49:57,979 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 14:49:57,979 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 14:49:57,979 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 14:49:57,979 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 14:49:57,979 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 14:49:57,980 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 14:49:57,980 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 42, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,980 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:31023 in memory (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:49:57,981 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 43, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:57,981 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 14:49:57,981 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 42)
2016-12-14 14:49:57,982 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 43)
2016-12-14 14:49:57,982 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:57,982 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 14:49:57,983 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 14:49:57,983 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,983 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:31023 in memory (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:49:57,984 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:57,984 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:57,984 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 14:49:57,984 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:57,985 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 14:49:57,985 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 14:49:57,985 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 14:49:57,985 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 14:49:57,985 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 14:49:57,985 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 14:49:57,985 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 14:49:57,986 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:31023 in memory (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:49:57,987 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 14:49:57,987 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:57,988 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 14:49:57,990 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 43). 2298 bytes result sent to driver
2016-12-14 14:49:57,997 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 43) in 17 ms on localhost (1/2)
2016-12-14 14:49:57,998 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 42). 2298 bytes result sent to driver
2016-12-14 14:49:58,002 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 42) in 23 ms on localhost (2/2)
2016-12-14 14:49:58,003 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.024 s
2016-12-14 14:49:58,003 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,003 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:302, took 0.057776 s
2016-12-14 14:49:58,006 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 3.1 KB, free 357.0 KB)
2016-12-14 14:49:58,012 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 1473.0 B, free 358.4 KB)
2016-12-14 14:49:58,013 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:31023 (size: 1473.0 B, free: 529.9 MB)
2016-12-14 14:49:58,013 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at KMeans.scala:276
2016-12-14 14:49:58,030 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:58,032 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 39 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,033 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:58,033 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:58,033 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 14:49:58,033 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 14:49:58,035 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:58,037 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 6.7 KB, free 365.1 KB)
2016-12-14 14:49:58,042 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.6 KB, free 368.7 KB)
2016-12-14 14:49:58,043 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,044 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,044 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,044 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 14:49:58,045 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 44, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,046 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 45, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,046 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 45)
2016-12-14 14:49:58,046 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 44)
2016-12-14 14:49:58,049 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,050 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:58,050 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,050 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:58,056 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 44). 2420 bytes result sent to driver
2016-12-14 14:49:58,059 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 45). 2420 bytes result sent to driver
2016-12-14 14:49:58,060 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 44) in 15 ms on localhost (1/2)
2016-12-14 14:49:58,061 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 45) in 15 ms on localhost (2/2)
2016-12-14 14:49:58,061 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 14:49:58,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,062 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 14:49:58,062 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,062 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:58,064 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 2.9 KB, free 371.6 KB)
2016-12-14 14:49:58,068 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1666.0 B, free 373.2 KB)
2016-12-14 14:49:58,069 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:31023 (size: 1666.0 B, free: 529.9 MB)
2016-12-14 14:49:58,069 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,070 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:58,070 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 14:49:58,071 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 46, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,071 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 47, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,072 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 47)
2016-12-14 14:49:58,072 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 46)
2016-12-14 14:49:58,073 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,074 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,074 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,075 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,086 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 47). 2298 bytes result sent to driver
2016-12-14 14:49:58,087 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 46). 2298 bytes result sent to driver
2016-12-14 14:49:58,091 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 47) in 20 ms on localhost (1/2)
2016-12-14 14:49:58,091 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 46) in 20 ms on localhost (2/2)
2016-12-14 14:49:58,092 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,092 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:49:58,092 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.061487 s
2016-12-14 14:49:58,094 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 3.1 KB, free 376.3 KB)
2016-12-14 14:49:58,099 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1470.0 B, free 377.7 KB)
2016-12-14 14:49:58,099 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:31023 (size: 1470.0 B, free: 529.9 MB)
2016-12-14 14:49:58,100 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at KMeans.scala:276
2016-12-14 14:49:58,118 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:58,119 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 41 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:58,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:58,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 14:49:58,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 14:49:58,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:58,124 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 6.7 KB, free 384.4 KB)
2016-12-14 14:49:58,129 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.6 KB, free 388.0 KB)
2016-12-14 14:49:58,130 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,130 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,131 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,131 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 14:49:58,133 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 48, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,133 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 49, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,134 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 48)
2016-12-14 14:49:58,134 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 49)
2016-12-14 14:49:58,138 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,138 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:58,138 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,138 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:58,145 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 48). 2420 bytes result sent to driver
2016-12-14 14:49:58,146 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 49). 2420 bytes result sent to driver
2016-12-14 14:49:58,148 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 48) in 15 ms on localhost (1/2)
2016-12-14 14:49:58,149 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 49) in 16 ms on localhost (2/2)
2016-12-14 14:49:58,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 14:49:58,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,150 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 14:49:58,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:58,151 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 2.9 KB, free 390.9 KB)
2016-12-14 14:49:58,155 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1670.0 B, free 392.5 KB)
2016-12-14 14:49:58,156 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:31023 (size: 1670.0 B, free: 529.9 MB)
2016-12-14 14:49:58,157 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,157 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:58,158 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 14:49:58,159 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 50, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,159 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 51, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,160 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 51)
2016-12-14 14:49:58,160 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 50)
2016-12-14 14:49:58,162 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,163 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,163 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,163 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,171 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 50). 2298 bytes result sent to driver
2016-12-14 14:49:58,176 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 50) in 18 ms on localhost (1/2)
2016-12-14 14:49:58,180 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 51). 2298 bytes result sent to driver
2016-12-14 14:49:58,183 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 51) in 24 ms on localhost (2/2)
2016-12-14 14:49:58,184 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.026 s
2016-12-14 14:49:58,184 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,184 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.065973 s
2016-12-14 14:49:58,186 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 6 iterations
2016-12-14 14:49:58,187 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 2.6 KB, free 395.1 KB)
2016-12-14 14:49:58,190 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 1110.0 B, free 396.2 KB)
2016-12-14 14:49:58,190 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:31023 (size: 1110.0 B, free: 529.9 MB)
2016-12-14 14:49:58,191 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at KMeans.scala:276
2016-12-14 14:49:58,211 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:58,214 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 43 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:58,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:58,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 14:49:58,216 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 14:49:58,217 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:58,219 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 6.7 KB, free 402.9 KB)
2016-12-14 14:49:58,224 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.6 KB, free 406.4 KB)
2016-12-14 14:49:58,224 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,225 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,226 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,226 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 14:49:58,228 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 52, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,229 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 53, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,230 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 52)
2016-12-14 14:49:58,230 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 53)
2016-12-14 14:49:58,234 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,234 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:58,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,235 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:58,242 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 53). 2396 bytes result sent to driver
2016-12-14 14:49:58,246 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 53) in 17 ms on localhost (1/2)
2016-12-14 14:49:58,247 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 52). 2396 bytes result sent to driver
2016-12-14 14:49:58,250 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 52) in 23 ms on localhost (2/2)
2016-12-14 14:49:58,251 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,251 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.024 s
2016-12-14 14:49:58,251 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,251 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,251 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 14:49:58,251 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,252 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:58,254 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 2.9 KB, free 409.3 KB)
2016-12-14 14:49:58,258 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1670.0 B, free 411.0 KB)
2016-12-14 14:49:58,258 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:31023 (size: 1670.0 B, free: 529.9 MB)
2016-12-14 14:49:58,259 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:58,260 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 14:49:58,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 54, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,262 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 55, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,262 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 54)
2016-12-14 14:49:58,262 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 55)
2016-12-14 14:49:58,265 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,265 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,266 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,266 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,275 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 55). 2171 bytes result sent to driver
2016-12-14 14:49:58,278 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 55) in 17 ms on localhost (1/2)
2016-12-14 14:49:58,282 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 54). 2047 bytes result sent to driver
2016-12-14 14:49:58,286 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 54) in 25 ms on localhost (2/2)
2016-12-14 14:49:58,287 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.026 s
2016-12-14 14:49:58,287 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,287 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.075369 s
2016-12-14 14:49:58,288 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 7 iterations
2016-12-14 14:49:58,288 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 7 iterations
2016-12-14 14:49:58,289 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 1592.0 B, free 412.5 KB)
2016-12-14 14:49:58,293 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 737.0 B, free 413.2 KB)
2016-12-14 14:49:58,294 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:31023 (size: 737.0 B, free: 529.9 MB)
2016-12-14 14:49:58,294 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at KMeans.scala:276
2016-12-14 14:49:58,310 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:58,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 45 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:58,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:58,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 14:49:58,313 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 14:49:58,314 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:58,316 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 6.6 KB, free 419.8 KB)
2016-12-14 14:49:58,320 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.6 KB, free 423.4 KB)
2016-12-14 14:49:58,321 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:31023 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,322 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,322 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,322 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 14:49:58,324 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 56, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,325 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 57, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,325 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 56)
2016-12-14 14:49:58,325 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 57)
2016-12-14 14:49:58,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:58,331 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,331 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:58,337 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 57). 2348 bytes result sent to driver
2016-12-14 14:49:58,340 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 57) in 16 ms on localhost (1/2)
2016-12-14 14:49:58,342 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 56). 2348 bytes result sent to driver
2016-12-14 14:49:58,346 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 56) in 23 ms on localhost (2/2)
2016-12-14 14:49:58,346 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.023 s
2016-12-14 14:49:58,346 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,347 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,347 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,347 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 14:49:58,347 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,348 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:58,349 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 2.9 KB, free 426.3 KB)
2016-12-14 14:49:58,353 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1670.0 B, free 427.9 KB)
2016-12-14 14:49:58,354 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:31023 (size: 1670.0 B, free: 529.9 MB)
2016-12-14 14:49:58,355 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,355 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:58,355 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 14:49:58,356 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 58, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,357 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 59, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,357 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 58)
2016-12-14 14:49:58,357 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 59)
2016-12-14 14:49:58,360 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,360 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,360 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,361 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,370 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 59). 1795 bytes result sent to driver
2016-12-14 14:49:58,371 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 58). 1669 bytes result sent to driver
2016-12-14 14:49:58,372 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 59) in 16 ms on localhost (1/2)
2016-12-14 14:49:58,375 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 58) in 18 ms on localhost (2/2)
2016-12-14 14:49:58,375 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 14:49:58,375 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,375 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.064521 s
2016-12-14 14:49:58,376 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 8 iterations
2016-12-14 14:49:58,376 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 1072.0 B, free 429.0 KB)
2016-12-14 14:49:58,378 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 497.0 B, free 429.5 KB)
2016-12-14 14:49:58,379 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:31023 (size: 497.0 B, free: 529.9 MB)
2016-12-14 14:49:58,379 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at KMeans.scala:276
2016-12-14 14:49:58,387 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:58,388 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 47 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:58,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:58,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 14:49:58,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 14:49:58,390 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:58,391 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 6.6 KB, free 436.0 KB)
2016-12-14 14:49:58,394 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.5 KB, free 439.6 KB)
2016-12-14 14:49:58,395 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:31023 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:49:58,395 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,396 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,396 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 14:49:58,397 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 60, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,397 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 61, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,397 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 60)
2016-12-14 14:49:58,398 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 61)
2016-12-14 14:49:58,400 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,400 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:58,400 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:58,404 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 61). 2324 bytes result sent to driver
2016-12-14 14:49:58,405 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 60). 2324 bytes result sent to driver
2016-12-14 14:49:58,406 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 61) in 9 ms on localhost (1/2)
2016-12-14 14:49:58,407 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 60) in 11 ms on localhost (2/2)
2016-12-14 14:49:58,408 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,408 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.012 s
2016-12-14 14:49:58,408 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,408 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,408 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 14:49:58,408 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,409 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:58,411 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 2.9 KB, free 442.5 KB)
2016-12-14 14:49:58,415 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1670.0 B, free 444.1 KB)
2016-12-14 14:49:58,415 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:31023 (size: 1670.0 B, free: 529.9 MB)
2016-12-14 14:49:58,416 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,416 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:58,417 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 14:49:58,418 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 62, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,418 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 63, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,418 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 63)
2016-12-14 14:49:58,418 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 62)
2016-12-14 14:49:58,420 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,420 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,421 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,421 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,425 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 63). 1544 bytes result sent to driver
2016-12-14 14:49:58,427 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 62). 1544 bytes result sent to driver
2016-12-14 14:49:58,428 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 63) in 10 ms on localhost (1/2)
2016-12-14 14:49:58,429 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 62) in 12 ms on localhost (2/2)
2016-12-14 14:49:58,429 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.012 s
2016-12-14 14:49:58,429 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,429 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.041883 s
2016-12-14 14:49:58,431 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 1072.0 B, free 445.2 KB)
2016-12-14 14:49:58,433 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 495.0 B, free 445.6 KB)
2016-12-14 14:49:58,434 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:31023 (size: 495.0 B, free: 529.9 MB)
2016-12-14 14:49:58,434 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at KMeans.scala:276
2016-12-14 14:49:58,451 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:49:58,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 49 (mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:49:58,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 14:49:58,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 14:49:58,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 14:49:58,453 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:49:58,455 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 6.6 KB, free 452.2 KB)
2016-12-14 14:49:58,457 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.5 KB, free 455.7 KB)
2016-12-14 14:49:58,457 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:31023 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:49:58,458 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,458 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279)
2016-12-14 14:49:58,458 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 14:49:58,459 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 64, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,460 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 65, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:49:58,461 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 64)
2016-12-14 14:49:58,461 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 65)
2016-12-14 14:49:58,465 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,465 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,465 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:49:58,465 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:49:58,472 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 65). 2324 bytes result sent to driver
2016-12-14 14:49:58,476 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 65) in 15 ms on localhost (1/2)
2016-12-14 14:49:58,476 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 64). 2324 bytes result sent to driver
2016-12-14 14:49:58,481 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 64) in 22 ms on localhost (2/2)
2016-12-14 14:49:58,481 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.022 s
2016-12-14 14:49:58,481 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,482 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,482 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,482 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 14:49:58,482 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,483 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:49:58,485 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 2.9 KB, free 458.6 KB)
2016-12-14 14:49:58,489 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1667.0 B, free 460.3 KB)
2016-12-14 14:49:58,490 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:31023 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:49:58,490 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,490 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302)
2016-12-14 14:49:58,491 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 14:49:58,492 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 66, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,493 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 67, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,493 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 66)
2016-12-14 14:49:58,493 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 67)
2016-12-14 14:49:58,496 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,496 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,496 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,496 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,504 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 67). 1544 bytes result sent to driver
2016-12-14 14:49:58,504 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 66). 1544 bytes result sent to driver
2016-12-14 14:49:58,507 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 67) in 14 ms on localhost (1/2)
2016-12-14 14:49:58,507 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 66) in 15 ms on localhost (2/2)
2016-12-14 14:49:58,507 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.016 s
2016-12-14 14:49:58,507 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,508 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.056336 s
2016-12-14 14:49:58,509 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 10 iterations
2016-12-14 14:49:58,509 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 10 iterations
2016-12-14 14:49:58,510 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.947 seconds.
2016-12-14 14:49:58,511 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 10 iterations.
2016-12-14 14:49:58,514 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 2370689.6867946046.
2016-12-14 14:49:58,516 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 4 from persistence list
2016-12-14 14:49:58,517 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:49:58,518 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:49:58,530 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:108
2016-12-14 14:49:58,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (foreach at K_means.scala:108) with 2 output partitions
2016-12-14 14:49:58,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 34 (foreach at K_means.scala:108)
2016-12-14 14:49:58,532 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:58,532 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:58,533 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 34 (MapPartitionsRDD[3] at map at K_means.scala:98), which has no missing parents
2016-12-14 14:49:58,535 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 4.2 KB, free 459.6 KB)
2016-12-14 14:49:58,540 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.5 KB, free 462.1 KB)
2016-12-14 14:49:58,540 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:31023 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:49:58,541 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 34 (MapPartitionsRDD[3] at map at K_means.scala:98)
2016-12-14 14:49:58,542 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 14:49:58,543 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 68, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:58,543 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 69, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:58,543 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 68)
2016-12-14 14:49:58,543 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 69)
2016-12-14 14:49:58,546 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,546 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,548 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.23,1.71,2.43,15.6,127.0,2.8,3.06,0.28,2.29,5.64,1.04,3.92,1065.0] belong to cluster 1
2016-12-14 14:49:58,548 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.33,2.3,23.6,70.0,2.2,1.59,0.42,1.38,1.74,1.07,3.21,625.0] belong to cluster 2
2016-12-14 14:49:58,548 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.83,2.32,18.5,81.0,1.6,1.5,0.52,1.64,2.4,1.08,2.27,480.0] belong to cluster 0
2016-12-14 14:49:58,549 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.2,1.78,2.14,11.2,100.0,2.65,2.76,0.26,1.28,4.38,1.05,3.4,1050.0] belong to cluster 1
2016-12-14 14:49:58,549 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.0,1.51,2.42,22.0,86.0,1.45,1.25,0.5,1.63,3.6,1.05,2.65,450.0] belong to cluster 0
2016-12-14 14:49:58,549 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.16,2.36,2.67,18.6,101.0,2.8,3.24,0.3,2.81,5.68,1.03,3.17,1185.0] belong to cluster 1
2016-12-14 14:49:58,549 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.69,1.53,2.26,20.7,80.0,1.38,1.46,0.58,1.62,3.05,0.96,2.06,495.0] belong to cluster 0
2016-12-14 14:49:58,549 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.37,1.95,2.5,16.8,113.0,3.85,3.49,0.24,2.18,7.8,0.86,3.45,1480.0] belong to cluster 1
2016-12-14 14:49:58,550 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,2.83,2.22,18.0,88.0,2.45,2.25,0.25,1.99,2.15,1.15,3.3,290.0] belong to cluster 0
2016-12-14 14:49:58,550 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.24,2.59,2.87,21.0,118.0,2.8,2.69,0.39,1.82,4.32,1.04,2.93,735.0] belong to cluster 2
2016-12-14 14:49:58,550 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.62,1.99,2.28,18.0,98.0,3.02,2.26,0.17,1.35,3.25,1.16,2.96,345.0] belong to cluster 0
2016-12-14 14:49:58,550 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.2,1.76,2.45,15.2,112.0,3.27,3.39,0.34,1.97,6.75,1.05,2.85,1450.0] belong to cluster 1
2016-12-14 14:49:58,550 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.47,1.52,2.2,19.0,162.0,2.5,2.27,0.32,3.28,2.6,1.16,2.63,937.0] belong to cluster 2
2016-12-14 14:49:58,550 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.39,1.87,2.45,14.6,96.0,2.5,2.52,0.3,1.98,5.25,1.02,3.58,1290.0] belong to cluster 1
2016-12-14 14:49:58,551 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.81,2.12,2.74,21.5,134.0,1.6,0.99,0.14,1.56,2.5,0.95,2.26,625.0] belong to cluster 2
2016-12-14 14:49:58,551 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.06,2.15,2.61,17.6,121.0,2.6,2.51,0.31,1.25,5.05,1.06,3.58,1295.0] belong to cluster 1
2016-12-14 14:49:58,551 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,1.41,1.98,16.0,85.0,2.55,2.5,0.29,1.77,2.9,1.23,2.74,428.0] belong to cluster 0
2016-12-14 14:49:58,551 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.83,1.64,2.17,14.0,97.0,2.8,2.98,0.29,1.98,5.2,1.08,2.85,1045.0] belong to cluster 1
2016-12-14 14:49:58,551 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.07,2.1,18.5,88.0,3.52,3.75,0.24,1.95,4.5,1.04,2.77,660.0] belong to cluster 2
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.86,1.35,2.27,16.0,98.0,2.98,3.15,0.22,1.85,7.22,1.01,3.55,1045.0] belong to cluster 1
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,3.17,2.21,18.0,88.0,2.85,2.99,0.45,2.81,2.3,1.42,2.83,406.0] belong to cluster 0
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.1,2.16,2.3,18.0,105.0,2.95,3.32,0.22,2.38,5.75,1.25,3.17,1510.0] belong to cluster 1
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,2.08,1.7,17.5,97.0,2.23,2.17,0.26,1.4,3.3,1.27,2.96,710.0] belong to cluster 2
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.12,1.48,2.32,16.8,95.0,2.2,2.43,0.26,1.57,5.0,1.17,2.82,1280.0] belong to cluster 1
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.6,1.34,1.9,18.5,88.0,1.45,1.36,0.29,1.35,2.45,1.04,2.77,562.0] belong to cluster 0
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.75,1.73,2.41,16.0,89.0,2.6,2.76,0.29,1.81,5.6,1.15,2.9,1320.0] belong to cluster 1
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.34,2.45,2.46,21.0,98.0,2.56,2.11,0.34,1.31,2.8,0.8,3.38,438.0] belong to cluster 0
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.75,1.73,2.39,11.4,91.0,3.1,3.69,0.43,2.81,5.4,1.25,2.73,1150.0] belong to cluster 1
2016-12-14 14:49:58,552 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.82,1.72,1.88,19.5,86.0,2.5,1.64,0.37,1.42,2.06,0.94,2.44,415.0] belong to cluster 0
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.38,1.87,2.38,12.0,102.0,3.3,3.64,0.29,2.96,7.5,1.2,3.0,1547.0] belong to cluster 1
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.51,1.73,1.98,20.5,85.0,2.2,1.92,0.32,1.48,2.94,1.04,3.57,672.0] belong to cluster 2
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.63,1.81,2.7,17.2,112.0,2.85,2.91,0.3,1.46,7.3,1.28,2.88,1310.0] belong to cluster 1
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.42,2.55,2.27,22.0,90.0,1.68,1.84,0.66,1.42,2.7,0.86,3.3,315.0] belong to cluster 0
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.3,1.92,2.72,20.0,120.0,2.8,3.14,0.33,1.97,6.2,1.07,2.65,1280.0] belong to cluster 1
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.25,1.73,2.12,19.0,80.0,1.65,2.03,0.37,1.63,3.4,1.0,3.17,510.0] belong to cluster 0
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.83,1.57,2.62,20.0,115.0,2.95,3.4,0.4,1.72,6.6,1.13,2.57,1130.0] belong to cluster 1
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.72,1.75,2.28,22.5,84.0,1.38,1.76,0.48,1.63,3.3,0.88,2.42,488.0] belong to cluster 0
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.19,1.59,2.48,16.5,108.0,3.3,3.93,0.32,1.86,8.7,1.23,2.82,1680.0] belong to cluster 1
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.22,1.29,1.94,19.0,92.0,2.36,2.04,0.39,2.08,2.7,0.86,3.02,312.0] belong to cluster 0
2016-12-14 14:49:58,553 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.64,3.1,2.56,15.2,116.0,2.7,3.03,0.17,1.66,5.1,0.96,3.36,845.0] belong to cluster 2
2016-12-14 14:49:58,554 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.61,1.35,2.7,20.0,94.0,2.74,2.92,0.29,2.49,2.65,0.96,3.26,680.0] belong to cluster 2
2016-12-14 14:49:58,554 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.06,1.63,2.28,16.0,126.0,3.0,3.17,0.24,2.1,5.65,1.09,3.71,780.0] belong to cluster 2
2016-12-14 14:49:58,554 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.46,3.74,1.82,19.5,107.0,3.18,2.58,0.24,3.58,2.9,0.75,2.81,562.0] belong to cluster 0
2016-12-14 14:49:58,554 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.93,3.8,2.65,18.6,102.0,2.41,2.41,0.25,1.98,4.5,1.03,3.52,770.0] belong to cluster 2
2016-12-14 14:49:58,554 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.52,2.43,2.17,21.0,88.0,2.55,2.27,0.26,1.22,2.0,0.9,2.78,325.0] belong to cluster 0
2016-12-14 14:49:58,555 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.76,2.68,2.92,20.0,103.0,1.75,2.03,0.6,1.05,3.8,1.23,2.5,607.0] belong to cluster 2
2016-12-14 14:49:58,555 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.71,1.86,2.36,16.6,101.0,2.61,2.88,0.27,1.69,3.8,1.11,4.0,1035.0] belong to cluster 1
2016-12-14 14:49:58,555 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.41,0.74,2.5,21.0,88.0,2.48,2.01,0.42,1.44,3.08,1.1,2.31,434.0] belong to cluster 0
2016-12-14 14:49:58,555 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.85,1.6,2.52,17.8,95.0,2.48,2.37,0.26,1.46,3.93,1.09,3.63,1015.0] belong to cluster 1
2016-12-14 14:49:58,555 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.39,2.5,22.5,84.0,2.56,2.29,0.43,1.04,2.9,0.93,3.19,385.0] belong to cluster 0
2016-12-14 14:49:58,555 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.5,1.81,2.61,20.0,96.0,2.53,2.61,0.28,1.66,3.52,1.12,3.82,845.0] belong to cluster 2
2016-12-14 14:49:58,556 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.03,1.51,2.2,21.5,85.0,2.46,2.17,0.52,2.01,1.9,1.71,2.87,407.0] belong to cluster 0
2016-12-14 14:49:58,556 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,2.05,3.22,25.0,124.0,2.63,2.68,0.47,1.92,3.58,1.13,3.2,830.0] belong to cluster 2
2016-12-14 14:49:58,556 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.82,1.47,1.99,20.8,86.0,1.98,1.6,0.3,1.53,1.95,0.95,3.33,495.0] belong to cluster 0
2016-12-14 14:49:58,556 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.39,1.77,2.62,16.1,93.0,2.85,2.94,0.34,1.45,4.8,0.92,3.22,1195.0] belong to cluster 1
2016-12-14 14:49:58,556 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.42,1.61,2.19,22.5,108.0,2.0,2.09,0.34,1.61,2.06,1.06,2.96,345.0] belong to cluster 0
2016-12-14 14:49:58,556 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.3,1.72,2.14,17.0,94.0,2.4,2.19,0.27,1.35,3.95,1.02,2.77,1285.0] belong to cluster 1
2016-12-14 14:49:58,557 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.77,3.43,1.98,16.0,80.0,1.63,1.25,0.43,0.83,3.4,0.7,2.12,372.0] belong to cluster 0
2016-12-14 14:49:58,557 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.87,1.9,2.8,19.4,107.0,2.95,2.97,0.37,1.76,4.5,1.25,3.4,915.0] belong to cluster 2
2016-12-14 14:49:58,557 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.0,3.43,2.0,19.0,87.0,2.0,1.64,0.37,1.87,1.28,0.93,3.05,564.0] belong to cluster 0
2016-12-14 14:49:58,557 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.02,1.68,2.21,16.0,96.0,2.65,2.33,0.26,1.98,4.7,1.04,3.59,1035.0] belong to cluster 1
2016-12-14 14:49:58,557 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.45,2.4,2.42,20.0,96.0,2.9,2.79,0.32,1.83,3.25,0.8,3.39,625.0] belong to cluster 2
2016-12-14 14:49:58,557 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.73,1.5,2.7,22.5,101.0,3.0,3.25,0.29,2.38,5.7,1.19,2.71,1285.0] belong to cluster 1
2016-12-14 14:49:58,558 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.56,2.05,3.23,28.5,119.0,3.18,5.08,0.47,1.87,6.0,0.93,3.69,465.0] belong to cluster 0
2016-12-14 14:49:58,558 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.58,1.66,2.36,19.1,106.0,2.86,3.19,0.22,1.95,6.9,1.09,2.88,1515.0] belong to cluster 1
2016-12-14 14:49:58,558 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.42,4.43,2.73,26.5,102.0,2.2,2.13,0.43,1.71,2.08,0.92,3.12,365.0] belong to cluster 0
2016-12-14 14:49:58,558 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.68,1.83,2.36,17.2,104.0,2.42,2.69,0.42,1.97,3.84,1.23,2.87,990.0] belong to cluster 1
2016-12-14 14:49:58,558 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,5.8,2.13,21.5,86.0,2.62,2.65,0.3,2.01,2.6,0.73,3.1,380.0] belong to cluster 0
2016-12-14 14:49:58,558 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.76,1.53,2.7,19.5,132.0,2.95,2.74,0.5,1.35,5.4,1.25,3.0,1235.0] belong to cluster 1
2016-12-14 14:49:58,559 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.87,4.31,2.39,21.0,82.0,2.86,3.03,0.21,2.91,2.8,0.75,3.64,380.0] belong to cluster 0
2016-12-14 14:49:58,559 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.51,1.8,2.65,19.0,110.0,2.35,2.53,0.29,1.54,4.2,1.1,2.87,1095.0] belong to cluster 1
2016-12-14 14:49:58,559 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.07,2.16,2.17,21.0,85.0,2.6,2.65,0.37,1.35,2.76,0.86,3.28,378.0] belong to cluster 0
2016-12-14 14:49:58,559 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.48,1.81,2.41,20.5,100.0,2.7,2.98,0.26,1.86,5.1,1.04,3.47,920.0] belong to cluster 2
2016-12-14 14:49:58,559 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.43,1.53,2.29,21.5,86.0,2.74,3.15,0.39,1.77,3.94,0.69,2.84,352.0] belong to cluster 0
2016-12-14 14:49:58,560 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.28,1.64,2.84,15.5,110.0,2.6,2.68,0.34,1.36,4.6,1.09,2.78,880.0] belong to cluster 2
2016-12-14 14:49:58,560 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.79,2.13,2.78,28.5,92.0,2.13,2.24,0.58,1.76,3.0,0.97,2.44,466.0] belong to cluster 0
2016-12-14 14:49:58,560 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,1.65,2.55,18.0,98.0,2.45,2.43,0.29,1.44,4.25,1.12,2.51,1105.0] belong to cluster 1
2016-12-14 14:49:58,560 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.63,2.3,24.5,88.0,2.22,2.45,0.4,1.9,2.12,0.89,2.78,342.0] belong to cluster 0
2016-12-14 14:49:58,560 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.07,1.5,2.1,15.5,98.0,2.4,2.64,0.28,1.37,3.7,1.18,2.69,1020.0] belong to cluster 1
2016-12-14 14:49:58,560 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.04,4.3,2.38,22.0,80.0,2.1,1.75,0.42,1.35,2.6,0.79,2.57,580.0] belong to cluster 0
2016-12-14 14:49:58,561 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.22,3.99,2.51,13.2,128.0,3.0,3.04,0.2,2.08,5.1,0.89,3.53,760.0] belong to cluster 2
2016-12-14 14:49:58,561 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.86,1.35,2.32,18.0,122.0,1.51,1.25,0.21,0.94,4.1,0.76,1.29,630.0] belong to cluster 2
2016-12-14 14:49:58,561 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.56,1.71,2.31,16.2,117.0,3.15,3.29,0.34,2.34,6.13,0.95,3.38,795.0] belong to cluster 2
2016-12-14 14:49:58,561 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.88,2.99,2.4,20.0,104.0,1.3,1.22,0.24,0.83,5.4,0.74,1.42,530.0] belong to cluster 0
2016-12-14 14:49:58,561 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.41,3.84,2.12,18.8,90.0,2.45,2.68,0.27,1.48,4.28,0.91,3.0,1035.0] belong to cluster 1
2016-12-14 14:49:58,561 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.81,2.31,2.4,24.0,98.0,1.15,1.09,0.27,0.83,5.7,0.66,1.36,560.0] belong to cluster 0
2016-12-14 14:49:58,562 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.88,1.89,2.59,15.0,101.0,3.25,3.56,0.17,1.7,5.43,0.88,3.56,1095.0] belong to cluster 1
2016-12-14 14:49:58,562 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.7,3.55,2.36,21.5,106.0,1.7,1.2,0.17,0.84,5.0,0.78,1.29,600.0] belong to cluster 2
2016-12-14 14:49:58,562 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.24,3.98,2.29,17.5,103.0,2.64,2.63,0.32,1.66,4.36,0.82,3.0,680.0] belong to cluster 2
2016-12-14 14:49:58,562 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.51,1.24,2.25,17.5,85.0,2.0,0.58,0.6,1.25,5.45,0.75,1.51,650.0] belong to cluster 2
2016-12-14 14:49:58,562 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,1.77,2.1,17.0,107.0,3.0,3.0,0.28,2.03,5.04,0.88,3.35,885.0] belong to cluster 2
2016-12-14 14:49:58,562 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.6,2.46,2.2,18.5,94.0,1.62,0.66,0.63,0.94,7.1,0.73,1.58,695.0] belong to cluster 2
2016-12-14 14:49:58,563 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.21,4.04,2.44,18.9,111.0,2.85,2.65,0.3,1.25,5.24,0.87,3.33,1080.0] belong to cluster 1
2016-12-14 14:49:58,563 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.25,4.72,2.54,21.0,89.0,1.38,0.47,0.53,0.8,3.85,0.75,1.27,720.0] belong to cluster 2
2016-12-14 14:49:58,563 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.38,3.59,2.28,16.0,102.0,3.25,3.17,0.27,2.19,4.9,1.04,3.44,1065.0] belong to cluster 1
2016-12-14 14:49:58,563 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.53,5.51,2.64,25.0,96.0,1.79,0.6,0.63,1.1,5.0,0.82,1.69,515.0] belong to cluster 0
2016-12-14 14:49:58,563 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.9,1.68,2.12,16.0,101.0,3.1,3.39,0.21,2.14,6.1,0.91,3.33,985.0] belong to cluster 1
2016-12-14 14:49:58,564 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.49,3.59,2.19,19.5,88.0,1.62,0.48,0.58,0.88,5.7,0.81,1.82,580.0] belong to cluster 0
2016-12-14 14:49:58,564 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.1,2.02,2.4,18.8,103.0,2.75,2.92,0.32,2.38,6.2,1.07,2.75,1060.0] belong to cluster 1
2016-12-14 14:49:58,564 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.84,2.96,2.61,24.0,101.0,2.32,0.6,0.53,0.81,4.92,0.89,2.15,590.0] belong to cluster 0
2016-12-14 14:49:58,564 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.94,1.73,2.27,17.4,108.0,2.88,3.54,0.32,2.08,8.9,1.12,3.1,1260.0] belong to cluster 1
2016-12-14 14:49:58,564 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.93,2.81,2.7,21.0,96.0,1.54,0.5,0.53,0.75,4.6,0.77,2.31,600.0] belong to cluster 2
2016-12-14 14:49:58,564 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,1.73,2.04,12.4,92.0,2.72,3.27,0.17,2.91,7.2,1.12,2.91,1150.0] belong to cluster 1
2016-12-14 14:49:58,565 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.36,2.56,2.35,20.0,89.0,1.4,0.5,0.37,0.64,5.6,0.7,2.47,780.0] belong to cluster 2
2016-12-14 14:49:58,565 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.83,1.65,2.6,17.2,94.0,2.45,2.99,0.22,2.29,5.6,1.24,3.37,1265.0] belong to cluster 1
2016-12-14 14:49:58,565 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.52,3.17,2.72,23.5,97.0,1.55,0.52,0.5,0.55,4.35,0.89,2.06,520.0] belong to cluster 0
2016-12-14 14:49:58,565 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.82,1.75,2.42,14.0,111.0,3.88,3.74,0.32,1.87,7.05,1.01,3.26,1190.0] belong to cluster 1
2016-12-14 14:49:58,565 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.62,4.95,2.35,20.0,92.0,2.0,0.8,0.47,1.02,4.4,0.91,2.05,550.0] belong to cluster 0
2016-12-14 14:49:58,565 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.77,1.9,2.68,17.1,115.0,3.0,2.79,0.39,1.68,6.3,1.13,2.93,1375.0] belong to cluster 1
2016-12-14 14:49:58,566 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.25,3.88,2.2,18.5,112.0,1.38,0.78,0.29,1.14,8.21,0.65,2.0,855.0] belong to cluster 2
2016-12-14 14:49:58,566 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.74,1.67,2.25,16.4,118.0,2.6,2.9,0.21,1.62,5.85,0.92,3.2,1060.0] belong to cluster 1
2016-12-14 14:49:58,566 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.16,3.57,2.15,21.0,102.0,1.5,0.55,0.43,1.3,4.0,0.6,1.68,830.0] belong to cluster 2
2016-12-14 14:49:58,566 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.56,1.73,2.46,20.5,116.0,2.96,2.78,0.2,2.45,6.25,0.98,3.03,1120.0] belong to cluster 1
2016-12-14 14:49:58,566 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.88,5.04,2.23,20.0,80.0,0.98,0.34,0.4,0.68,4.9,0.58,1.33,415.0] belong to cluster 0
2016-12-14 14:49:58,566 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.22,1.7,2.3,16.3,118.0,3.2,3.0,0.26,2.03,6.38,0.94,3.31,970.0] belong to cluster 1
2016-12-14 14:49:58,567 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.87,4.61,2.48,21.5,86.0,1.7,0.65,0.47,0.86,7.65,0.54,1.86,625.0] belong to cluster 2
2016-12-14 14:49:58,567 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.29,1.97,2.68,16.8,102.0,3.0,3.23,0.31,1.66,6.0,1.07,2.84,1270.0] belong to cluster 1
2016-12-14 14:49:58,567 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.32,3.24,2.38,21.5,92.0,1.93,0.76,0.45,1.25,8.42,0.55,1.62,650.0] belong to cluster 2
2016-12-14 14:49:58,567 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.72,1.43,2.5,16.7,108.0,3.4,3.67,0.19,2.04,6.8,0.89,2.87,1285.0] belong to cluster 1
2016-12-14 14:49:58,567 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.08,3.9,2.36,21.5,113.0,1.41,1.39,0.34,1.14,9.4,0.57,1.33,550.0] belong to cluster 0
2016-12-14 14:49:58,567 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,0.94,1.36,10.6,88.0,1.98,0.57,0.28,0.42,1.95,1.05,1.82,520.0] belong to cluster 0
2016-12-14 14:49:58,568 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.5,3.12,2.62,24.0,123.0,1.4,1.57,0.22,1.25,8.6,0.59,1.3,500.0] belong to cluster 0
2016-12-14 14:49:58,568 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.33,1.1,2.28,16.0,101.0,2.05,1.09,0.63,0.41,3.27,1.25,1.67,680.0] belong to cluster 2
2016-12-14 14:49:58,568 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.79,2.67,2.48,22.0,112.0,1.48,1.36,0.24,1.26,10.8,0.48,1.47,480.0] belong to cluster 0
2016-12-14 14:49:58,568 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.64,1.36,2.02,16.8,100.0,2.02,1.41,0.53,0.62,5.75,0.98,1.59,450.0] belong to cluster 0
2016-12-14 14:49:58,568 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.11,1.9,2.75,25.5,116.0,2.2,1.28,0.26,1.56,7.1,0.61,1.33,425.0] belong to cluster 0
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.67,1.25,1.92,18.0,94.0,2.1,1.79,0.32,0.73,3.8,1.23,2.46,630.0] belong to cluster 2
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.23,3.3,2.28,18.5,98.0,1.8,0.83,0.61,1.87,10.52,0.56,1.51,675.0] belong to cluster 2
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.13,2.16,19.0,87.0,3.5,3.1,0.19,1.87,4.45,1.22,2.87,420.0] belong to cluster 0
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.58,1.29,2.1,20.0,103.0,1.48,0.58,0.53,1.4,7.6,0.58,1.55,640.0] belong to cluster 2
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.17,1.45,2.53,19.0,104.0,1.89,1.75,0.45,1.03,2.95,1.45,2.23,355.0] belong to cluster 0
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.17,5.19,2.32,22.0,93.0,1.74,0.63,0.61,1.55,7.9,0.6,1.48,725.0] belong to cluster 2
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.21,2.56,18.1,98.0,2.42,2.65,0.37,2.08,4.6,1.19,2.3,678.0] belong to cluster 2
2016-12-14 14:49:58,569 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.84,4.12,2.38,19.5,89.0,1.8,0.83,0.48,1.56,9.01,0.57,1.64,480.0] belong to cluster 0
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.11,1.01,1.7,15.0,78.0,2.98,3.18,0.26,2.28,5.3,1.12,3.18,502.0] belong to cluster 0
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.45,3.03,2.64,27.0,97.0,1.9,0.58,0.63,1.14,7.5,0.67,1.73,880.0] belong to cluster 2
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.37,1.17,1.92,19.6,78.0,2.11,2.0,0.27,1.04,4.68,1.12,3.48,510.0] belong to cluster 0
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.34,1.68,2.7,25.0,98.0,2.8,1.31,0.53,2.7,13.0,0.57,1.96,660.0] belong to cluster 2
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.34,0.94,2.36,17.0,110.0,2.53,1.3,0.55,0.42,3.17,1.02,1.93,750.0] belong to cluster 2
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.48,1.67,2.64,22.5,89.0,2.6,1.1,0.52,2.29,11.75,0.57,1.78,620.0] belong to cluster 2
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.21,1.19,1.75,16.8,151.0,1.85,1.28,0.14,2.5,2.85,1.28,3.07,718.0] belong to cluster 2
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.36,3.83,2.38,21.0,88.0,2.3,0.92,0.5,1.04,7.65,0.56,1.58,520.0] belong to cluster 0
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.29,1.61,2.21,20.4,103.0,1.1,1.02,0.37,1.46,3.05,0.906,1.82,870.0] belong to cluster 2
2016-12-14 14:49:58,570 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.69,3.26,2.54,20.0,107.0,1.83,0.56,0.5,0.8,5.88,0.96,1.82,680.0] belong to cluster 2
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.86,1.51,2.67,25.0,86.0,2.95,2.86,0.21,1.87,3.38,1.36,3.16,410.0] belong to cluster 0
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.85,3.27,2.58,22.0,106.0,1.65,0.6,0.6,0.96,5.58,0.87,2.11,570.0] belong to cluster 0
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.49,1.66,2.24,24.0,87.0,1.88,1.84,0.27,1.03,3.74,0.98,2.78,472.0] belong to cluster 0
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.96,3.45,2.35,18.5,106.0,1.39,0.7,0.4,0.94,5.28,0.68,1.75,675.0] belong to cluster 2
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.99,1.67,2.6,30.0,139.0,3.3,2.89,0.21,1.96,3.35,1.31,3.5,985.0] belong to cluster 1
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.78,2.76,2.3,22.0,90.0,1.35,0.68,0.41,1.03,9.58,0.7,1.68,615.0] belong to cluster 2
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.96,1.09,2.3,21.0,101.0,3.38,2.14,0.13,1.65,3.21,0.99,3.13,886.0] belong to cluster 2
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.73,4.36,2.26,22.5,88.0,1.28,0.47,0.52,1.15,6.62,0.78,1.75,520.0] belong to cluster 0
2016-12-14 14:49:58,571 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.66,1.88,1.92,16.0,97.0,1.61,1.57,0.34,1.15,3.8,1.23,2.14,428.0] belong to cluster 0
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.45,3.7,2.6,23.0,111.0,1.7,0.92,0.43,1.46,10.68,0.85,1.56,695.0] belong to cluster 2
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.03,0.9,1.71,16.0,86.0,1.95,2.03,0.24,1.46,4.6,1.19,2.48,392.0] belong to cluster 0
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.82,3.37,2.3,19.5,88.0,1.48,0.66,0.4,0.97,10.26,0.72,1.75,685.0] belong to cluster 2
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.84,2.89,2.23,18.0,112.0,1.72,1.32,0.43,0.95,2.65,0.96,2.52,500.0] belong to cluster 0
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.58,2.58,2.69,24.5,105.0,1.55,0.84,0.39,1.54,8.66,0.74,1.8,750.0] belong to cluster 2
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.33,0.99,1.95,14.8,136.0,1.9,1.85,0.35,2.76,3.4,1.06,2.31,750.0] belong to cluster 2
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.4,4.6,2.86,25.0,112.0,1.98,0.96,0.27,1.11,8.5,0.67,1.92,630.0] belong to cluster 2
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.7,3.87,2.4,23.0,101.0,2.83,2.55,0.43,1.95,2.57,1.19,3.13,463.0] belong to cluster 0
2016-12-14 14:49:58,572 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.2,3.03,2.32,19.0,96.0,1.25,0.49,0.4,0.73,5.5,0.66,1.83,510.0] belong to cluster 0
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.0,0.92,2.0,19.0,86.0,2.42,2.26,0.3,1.43,2.5,1.38,3.12,278.0] belong to cluster 0
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.77,2.39,2.28,19.5,86.0,1.39,0.51,0.48,0.64,9.9,0.57,1.63,470.0] belong to cluster 0
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.72,1.81,2.2,18.8,86.0,2.2,2.53,0.26,1.77,3.9,1.16,3.14,714.0] belong to cluster 2
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.16,2.51,2.48,20.0,91.0,1.68,0.7,0.44,1.24,9.7,0.62,1.71,660.0] belong to cluster 2
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.08,1.13,2.51,24.0,78.0,2.0,1.58,0.4,1.4,2.2,1.31,2.72,630.0] belong to cluster 2
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.71,5.65,2.45,20.5,95.0,1.68,0.61,0.52,1.06,7.7,0.64,1.74,740.0] belong to cluster 2
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.05,3.86,2.32,22.5,85.0,1.65,1.59,0.61,1.62,4.8,0.84,2.01,515.0] belong to cluster 0
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.4,3.91,2.48,23.0,102.0,1.8,0.75,0.43,1.41,7.3,0.7,1.56,750.0] belong to cluster 2
2016-12-14 14:49:58,573 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.84,0.89,2.58,18.0,94.0,2.2,2.21,0.22,2.35,3.05,0.79,3.08,520.0] belong to cluster 0
2016-12-14 14:49:58,574 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.27,4.28,2.26,20.0,120.0,1.59,0.69,0.43,1.35,10.2,0.59,1.56,835.0] belong to cluster 2
2016-12-14 14:49:58,574 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.67,0.98,2.24,18.0,99.0,2.2,1.94,0.3,1.46,2.62,1.23,3.16,450.0] belong to cluster 0
2016-12-14 14:49:58,574 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[13.17,2.59,2.37,20.0,120.0,1.65,0.68,0.53,1.46,9.3,0.6,1.62,840.0] belong to cluster 2
2016-12-14 14:49:58,574 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[12.16,1.61,2.31,22.8,90.0,1.78,1.69,0.43,1.56,2.45,1.33,2.26,495.0] belong to cluster 0
2016-12-14 14:49:58,574 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[14.13,4.1,2.74,24.5,96.0,2.05,0.76,0.56,1.35,9.2,0.61,1.6,560.0] belong to cluster 0
2016-12-14 14:49:58,574 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.65,1.67,2.62,26.0,88.0,1.92,1.61,0.4,1.34,2.6,1.36,3.21,562.0] belong to cluster 0
2016-12-14 14:49:58,574 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[11.64,2.06,2.46,21.6,84.0,1.95,1.69,0.48,1.35,2.8,1.0,2.75,680.0] belong to cluster 2
2016-12-14 14:49:58,578 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 68). 2057 bytes result sent to driver
2016-12-14 14:49:58,578 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 69). 2057 bytes result sent to driver
2016-12-14 14:49:58,580 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 68) in 38 ms on localhost (1/2)
2016-12-14 14:49:58,581 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 69) in 38 ms on localhost (2/2)
2016-12-14 14:49:58,581 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 34 (foreach at K_means.scala:108) finished in 0.039 s
2016-12-14 14:49:58,581 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,582 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: foreach at K_means.scala:108, took 0.051327 s
2016-12-14 14:49:58,595 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:119
2016-12-14 14:49:58,596 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (foreach at K_means.scala:119) with 2 output partitions
2016-12-14 14:49:58,596 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (foreach at K_means.scala:119)
2016-12-14 14:49:58,596 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:58,597 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:58,597 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (MapPartitionsRDD[51] at map at K_means.scala:117), which has no missing parents
2016-12-14 14:49:58,599 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 4.2 KB, free 466.3 KB)
2016-12-14 14:49:58,603 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.5 KB, free 468.8 KB)
2016-12-14 14:49:58,603 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:31023 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:49:58,603 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,604 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (MapPartitionsRDD[51] at map at K_means.scala:117)
2016-12-14 14:49:58,604 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 14:49:58,605 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:58,606 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:58,606 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 71)
2016-12-14 14:49:58,606 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 70)
2016-12-14 14:49:58,608 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,608 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,608 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,608 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,609 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,609 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,609 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,609 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,609 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,609 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,609 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,610 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,610 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,610 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,610 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,610 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,610 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,611 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,612 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,612 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,612 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,612 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,612 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,612 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,613 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,613 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,613 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,613 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,613 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,613 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,613 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,614 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,614 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,614 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,614 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,614 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,614 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,614 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,615 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,615 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,615 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,615 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,615 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,615 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,616 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,616 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,616 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,616 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,616 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,616 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,616 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,617 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,617 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,617 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,617 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,617 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,617 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,617 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,618 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,618 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,618 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,618 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,618 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,618 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,619 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,620 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,621 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,622 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,623 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,624 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,625 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,626 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,627 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,628 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,629 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,630 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:49:58,631 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,631 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:49:58,631 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,631 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,631 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,631 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:49:58,631 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:49:58,632 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 71). 2057 bytes result sent to driver
2016-12-14 14:49:58,632 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 70). 2057 bytes result sent to driver
2016-12-14 14:49:58,634 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 71) in 28 ms on localhost (1/2)
2016-12-14 14:49:58,634 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 70) in 29 ms on localhost (2/2)
2016-12-14 14:49:58,635 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (foreach at K_means.scala:119) finished in 0.029 s
2016-12-14 14:49:58,635 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,635 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: foreach at K_means.scala:119, took 0.040119 s
2016-12-14 14:49:58,677 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:13
2016-12-14 14:49:58,679 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 52 (map at Relabel.scala:13)
2016-12-14 14:49:58,679 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (sortBy at Relabel.scala:13) with 2 output partitions
2016-12-14 14:49:58,679 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (sortBy at Relabel.scala:13)
2016-12-14 14:49:58,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 36)
2016-12-14 14:49:58,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 36)
2016-12-14 14:49:58,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 36 (MapPartitionsRDD[52] at map at Relabel.scala:13), which has no missing parents
2016-12-14 14:49:58,682 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 5.0 KB, free 473.8 KB)
2016-12-14 14:49:58,686 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.0 KB, free 476.8 KB)
2016-12-14 14:49:58,687 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:31023 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:58,688 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,688 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[52] at map at Relabel.scala:13)
2016-12-14 14:49:58,688 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 14:49:58,689 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 72, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:49:58,690 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 73, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:49:58,691 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 72)
2016-12-14 14:49:58,691 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 73)
2016-12-14 14:49:58,693 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,693 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,701 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 73). 2237 bytes result sent to driver
2016-12-14 14:49:58,701 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 72). 2237 bytes result sent to driver
2016-12-14 14:49:58,702 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 73) in 12 ms on localhost (1/2)
2016-12-14 14:49:58,703 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 72) in 14 ms on localhost (2/2)
2016-12-14 14:49:58,703 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 36 (map at Relabel.scala:13) finished in 0.014 s
2016-12-14 14:49:58,703 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,703 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,703 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,703 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 37)
2016-12-14 14:49:58,703 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,704 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (MapPartitionsRDD[56] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:49:58,705 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 3.5 KB, free 480.4 KB)
2016-12-14 14:49:58,709 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2022.0 B, free 482.3 KB)
2016-12-14 14:49:58,709 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:31023 (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:49:58,710 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[56] at sortBy at Relabel.scala:13)
2016-12-14 14:49:58,710 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 2 tasks
2016-12-14 14:49:58,711 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 74, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,712 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 37.0 (TID 75, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,712 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 74)
2016-12-14 14:49:58,712 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 37.0 (TID 75)
2016-12-14 14:49:58,714 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,714 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,714 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,714 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,718 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 74). 1160 bytes result sent to driver
2016-12-14 14:49:58,718 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 37.0 (TID 75). 1168 bytes result sent to driver
2016-12-14 14:49:58,720 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 74) in 9 ms on localhost (1/2)
2016-12-14 14:49:58,720 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 37.0 (TID 75) in 8 ms on localhost (2/2)
2016-12-14 14:49:58,720 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (sortBy at Relabel.scala:13) finished in 0.009 s
2016-12-14 14:49:58,721 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,721 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: sortBy at Relabel.scala:13, took 0.043124 s
2016-12-14 14:49:58,854 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 14:49:58,856 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:31023 in memory (size: 1473.0 B, free: 529.9 MB)
2016-12-14 14:49:58,857 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 14:49:58,857 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 14:49:58,857 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 14:49:58,858 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 14:49:58,858 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 14:49:58,858 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 14:49:58,859 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:31023 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:49:58,860 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,861 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 14:49:58,861 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 14:49:58,862 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:31023 in memory (size: 1588.0 B, free: 529.9 MB)
2016-12-14 14:49:58,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 14:49:58,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 14:49:58,863 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 14:49:58,863 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 14:49:58,863 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 14:49:58,863 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 14:49:58,863 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:49:58,864 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 4
2016-12-14 14:49:58,864 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 14:49:58,864 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 14:49:58,865 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:31023 in memory (size: 1670.0 B, free: 529.9 MB)
2016-12-14 14:49:58,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 14:49:58,866 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 14:49:58,867 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 14:49:58,867 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:31023 in memory (size: 1470.0 B, free: 529.9 MB)
2016-12-14 14:49:58,868 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 14:49:58,869 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 14:49:58,869 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 14:49:58,869 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 14:49:58,869 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 14:49:58,869 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 14:49:58,870 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:31023 in memory (size: 1666.0 B, free: 529.9 MB)
2016-12-14 14:49:58,870 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 14:49:58,871 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,872 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 14:49:58,872 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 14:49:58,873 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:31023 in memory (size: 1670.0 B, free: 529.9 MB)
2016-12-14 14:49:58,874 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 14:49:58,874 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,875 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 14:49:58,875 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 14:49:58,876 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:31023 in memory (size: 1110.0 B, free: 529.9 MB)
2016-12-14 14:49:58,876 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 14:49:58,877 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 14:49:58,877 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 14:49:58,877 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:31023 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:49:58,878 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 83
2016-12-14 14:49:58,878 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 14:49:58,878 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:31023 in memory (size: 737.0 B, free: 529.9 MB)
2016-12-14 14:49:58,879 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 82
2016-12-14 14:49:58,879 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 81
2016-12-14 14:49:58,879 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 14:49:58,879 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:31023 in memory (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:49:58,880 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 96
2016-12-14 14:49:58,880 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:31023 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:49:58,880 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 95
2016-12-14 14:49:58,881 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 14:49:58,881 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:31023 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:49:58,881 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 94
2016-12-14 14:49:58,882 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:31023 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:49:58,883 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 93
2016-12-14 14:49:58,883 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:31023 in memory (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:49:58,884 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 92
2016-12-14 14:49:58,884 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:31023 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:49:58,885 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 91
2016-12-14 14:49:58,885 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 14:49:58,886 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:31023 in memory (size: 495.0 B, free: 530.0 MB)
2016-12-14 14:49:58,887 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 90
2016-12-14 14:49:58,887 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 89
2016-12-14 14:49:58,888 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 11 is 155 bytes
2016-12-14 14:49:58,888 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:31023 in memory (size: 1670.0 B, free: 530.0 MB)
2016-12-14 14:49:58,888 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 88
2016-12-14 14:49:58,889 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:31023 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:49:58,890 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 87
2016-12-14 14:49:58,890 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 14:49:58,891 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:31023 in memory (size: 497.0 B, free: 530.0 MB)
2016-12-14 14:49:58,891 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 86
2016-12-14 14:49:58,891 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 85
2016-12-14 14:49:58,892 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:31023 in memory (size: 1670.0 B, free: 530.0 MB)
2016-12-14 14:49:58,893 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 84
2016-12-14 14:49:58,893 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 54 (sortBy at Relabel.scala:13)
2016-12-14 14:49:58,894 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (collect at Relabel.scala:14) with 2 output partitions
2016-12-14 14:49:58,894 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 40 (collect at Relabel.scala:14)
2016-12-14 14:49:58,894 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 39)
2016-12-14 14:49:58,895 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 39)
2016-12-14 14:49:58,895 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 39 (MapPartitionsRDD[54] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:49:58,903 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 3.6 KB, free 333.1 KB)
2016-12-14 14:49:58,906 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.0 KB, free 335.1 KB)
2016-12-14 14:49:58,907 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:31023 (size: 2.0 KB, free: 530.0 MB)
2016-12-14 14:49:58,907 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[54] at sortBy at Relabel.scala:13)
2016-12-14 14:49:58,908 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 2 tasks
2016-12-14 14:49:58,909 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 76, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 14:49:58,910 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 39.0 (TID 77, localhost, partition 1,NODE_LOCAL, 2132 bytes)
2016-12-14 14:49:58,911 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 76)
2016-12-14 14:49:58,911 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 39.0 (TID 77)
2016-12-14 14:49:58,918 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,918 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,919 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,919 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:49:58,931 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 39.0 (TID 77). 1303 bytes result sent to driver
2016-12-14 14:49:58,931 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 76). 1303 bytes result sent to driver
2016-12-14 14:49:58,932 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 39.0 (TID 77) in 22 ms on localhost (1/2)
2016-12-14 14:49:58,932 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 76) in 23 ms on localhost (2/2)
2016-12-14 14:49:58,933 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 39 (sortBy at Relabel.scala:13) finished in 0.023 s
2016-12-14 14:49:58,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:58,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:58,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 40)
2016-12-14 14:49:58,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:58,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 40 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:49:58,936 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 3.4 KB, free 338.5 KB)
2016-12-14 14:49:58,938 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 1948.0 B, free 340.4 KB)
2016-12-14 14:49:58,939 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:31023 (size: 1948.0 B, free: 530.0 MB)
2016-12-14 14:49:58,939 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,939 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13)
2016-12-14 14:49:58,939 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 2 tasks
2016-12-14 14:49:58,940 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 78, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,941 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 40.0 (TID 79, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:58,941 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 40.0 (TID 79)
2016-12-14 14:49:58,941 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 78)
2016-12-14 14:49:58,945 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,945 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:58,945 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,945 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:58,956 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 78). 1211 bytes result sent to driver
2016-12-14 14:49:58,956 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 40.0 (TID 79). 1240 bytes result sent to driver
2016-12-14 14:49:58,957 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 78) in 17 ms on localhost (1/2)
2016-12-14 14:49:58,957 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 40.0 (TID 79) in 17 ms on localhost (2/2)
2016-12-14 14:49:58,958 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 40 (collect at Relabel.scala:14) finished in 0.017 s
2016-12-14 14:49:58,958 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:49:58,958 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: collect at Relabel.scala:14, took 0.077191 s
2016-12-14 14:49:58,975 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:123
2016-12-14 14:49:58,976 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (foreach at K_means.scala:123) with 2 output partitions
2016-12-14 14:49:58,976 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (foreach at K_means.scala:123)
2016-12-14 14:49:58,977 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:58,977 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:58,977 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (MapPartitionsRDD[59] at map at Relabel.scala:31), which has no missing parents
2016-12-14 14:49:58,978 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 4.6 KB, free 345.0 KB)
2016-12-14 14:49:58,981 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.8 KB, free 347.8 KB)
2016-12-14 14:49:58,981 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:31023 (size: 2.8 KB, free: 530.0 MB)
2016-12-14 14:49:58,982 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:58,982 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 41 (MapPartitionsRDD[59] at map at Relabel.scala:31)
2016-12-14 14:49:58,982 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 14:49:58,983 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 80, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:58,983 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 81, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:58,984 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 80)
2016-12-14 14:49:58,984 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 81)
2016-12-14 14:49:58,985 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:58,985 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,987 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,988 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,989 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,990 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:58,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:58,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:49:58,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:49:58,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:49:59,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:49:59,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:49:59,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:49:59,007 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 80). 2057 bytes result sent to driver
2016-12-14 14:49:59,007 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 81). 2057 bytes result sent to driver
2016-12-14 14:49:59,009 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 80) in 26 ms on localhost (1/2)
2016-12-14 14:49:59,009 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 81) in 26 ms on localhost (2/2)
2016-12-14 14:49:59,009 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:49:59,009 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (foreach at K_means.scala:123) finished in 0.027 s
2016-12-14 14:49:59,010 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: foreach at K_means.scala:123, took 0.034124 s
2016-12-14 14:49:59,029 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 14:49:59,030 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 60 (map at MulticlassMetrics.scala:46)
2016-12-14 14:49:59,031 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 14:49:59,031 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 43 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 14:49:59,031 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 42)
2016-12-14 14:49:59,031 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 42)
2016-12-14 14:49:59,032 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 42 (MapPartitionsRDD[60] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 14:49:59,033 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 5.5 KB, free 353.3 KB)
2016-12-14 14:49:59,035 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.2 KB, free 356.5 KB)
2016-12-14 14:49:59,036 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:31023 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:49:59,036 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:59,036 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[60] at map at MulticlassMetrics.scala:46)
2016-12-14 14:49:59,037 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 14:49:59,037 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 82, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:49:59,038 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 83, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:49:59,038 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 82)
2016-12-14 14:49:59,038 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 83)
2016-12-14 14:49:59,040 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:59,040 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:59,044 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 82). 2237 bytes result sent to driver
2016-12-14 14:49:59,044 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 83). 2237 bytes result sent to driver
2016-12-14 14:49:59,046 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 82) in 9 ms on localhost (1/2)
2016-12-14 14:49:59,046 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 83) in 8 ms on localhost (2/2)
2016-12-14 14:49:59,046 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 42 (map at MulticlassMetrics.scala:46) finished in 0.009 s
2016-12-14 14:49:59,046 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:49:59,046 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:59,047 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:59,047 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 43)
2016-12-14 14:49:59,047 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:59,047 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 43 (ShuffledRDD[61] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 14:49:59,048 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 2.6 KB, free 359.1 KB)
2016-12-14 14:49:59,050 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 1592.0 B, free 360.7 KB)
2016-12-14 14:49:59,051 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:31023 (size: 1592.0 B, free: 529.9 MB)
2016-12-14 14:49:59,051 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:59,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 43 (ShuffledRDD[61] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 14:49:59,051 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 14:49:59,052 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 84, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:59,053 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 85, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:49:59,053 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 85)
2016-12-14 14:49:59,053 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 84)
2016-12-14 14:49:59,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:49:59,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:59,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:59,055 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:59,058 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 85). 1124 bytes result sent to driver
2016-12-14 14:49:59,059 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 84). 1163 bytes result sent to driver
2016-12-14 14:49:59,060 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 85) in 7 ms on localhost (1/2)
2016-12-14 14:49:59,061 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 84) in 9 ms on localhost (2/2)
2016-12-14 14:49:59,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 43 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.009 s
2016-12-14 14:49:59,061 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:49:59,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.031790 s
2016-12-14 14:49:59,083 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 14:49:59,084 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 64 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:49:59,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 14:49:59,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 45 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:49:59,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 44)
2016-12-14 14:49:59,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 44)
2016-12-14 14:49:59,086 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 44 (MapPartitionsRDD[64] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:49:59,088 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 6.0 KB, free 366.7 KB)
2016-12-14 14:49:59,090 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.4 KB, free 370.2 KB)
2016-12-14 14:49:59,090 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:31023 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:49:59,091 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:59,091 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[64] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:49:59,091 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 2 tasks
2016-12-14 14:49:59,092 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 86, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:49:59,092 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 44.0 (TID 87, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:49:59,093 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 86)
2016-12-14 14:49:59,093 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 44.0 (TID 87)
2016-12-14 14:49:59,097 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:59,097 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:59,107 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 44.0 (TID 87). 2237 bytes result sent to driver
2016-12-14 14:49:59,107 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 86). 2237 bytes result sent to driver
2016-12-14 14:49:59,109 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 44.0 (TID 87) in 17 ms on localhost (1/2)
2016-12-14 14:49:59,109 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 86) in 17 ms on localhost (2/2)
2016-12-14 14:49:59,109 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:49:59,109 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 44 (countByValue at MulticlassMetrics.scala:43) finished in 0.017 s
2016-12-14 14:49:59,109 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:49:59,110 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:49:59,110 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 45)
2016-12-14 14:49:59,110 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:49:59,110 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 45 (ShuffledRDD[65] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:49:59,111 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 2.6 KB, free 372.8 KB)
2016-12-14 14:49:59,114 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 1561.0 B, free 374.3 KB)
2016-12-14 14:49:59,114 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:31023 (size: 1561.0 B, free: 529.9 MB)
2016-12-14 14:49:59,114 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:59,115 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 45 (ShuffledRDD[65] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:49:59,115 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 45.0 with 2 tasks
2016-12-14 14:49:59,115 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 45.0 (TID 88, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:49:59,116 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 45.0 (TID 89, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:49:59,116 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 45.0 (TID 88)
2016-12-14 14:49:59,116 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 45.0 (TID 89)
2016-12-14 14:49:59,117 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:49:59,117 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:49:59,117 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:59,117 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:49:59,120 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 45.0 (TID 89). 1124 bytes result sent to driver
2016-12-14 14:49:59,120 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 45.0 (TID 88). 1164 bytes result sent to driver
2016-12-14 14:49:59,121 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 45.0 (TID 89) in 5 ms on localhost (1/2)
2016-12-14 14:49:59,121 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 45.0 (TID 88) in 6 ms on localhost (2/2)
2016-12-14 14:49:59,122 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 14:49:59,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 45 (countByValue at MulticlassMetrics.scala:43) finished in 0.006 s
2016-12-14 14:49:59,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: countByValue at MulticlassMetrics.scala:43, took 0.038418 s
2016-12-14 14:49:59,123 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.702247191011236
2016-12-14 14:49:59,124 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 560.0 B, free 374.9 KB)
2016-12-14 14:49:59,129 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 517.0 B, free 375.4 KB)
2016-12-14 14:49:59,130 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:31023 (size: 517.0 B, free: 529.9 MB)
2016-12-14 14:49:59,130 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at KMeansModel.scala:87
2016-12-14 14:49:59,142 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 14:49:59,143 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 14:49:59,143 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 46 (sum at KMeansModel.scala:88)
2016-12-14 14:49:59,143 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:49:59,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:49:59,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 46 (MapPartitionsRDD[66] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 14:49:59,145 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 4.2 KB, free 379.6 KB)
2016-12-14 14:49:59,148 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.4 KB, free 382.0 KB)
2016-12-14 14:49:59,148 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:31023 (size: 2.4 KB, free: 529.9 MB)
2016-12-14 14:49:59,148 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:49:59,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[66] at map at KMeansModel.scala:88)
2016-12-14 14:49:59,149 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 46.0 with 2 tasks
2016-12-14 14:49:59,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 46.0 (TID 90, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:59,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 46.0 (TID 91, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:49:59,150 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 46.0 (TID 90)
2016-12-14 14:49:59,150 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 46.0 (TID 91)
2016-12-14 14:49:59,153 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:49:59,154 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:49:59,157 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 46.0 (TID 91). 2064 bytes result sent to driver
2016-12-14 14:49:59,157 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 46.0 (TID 90). 2064 bytes result sent to driver
2016-12-14 14:49:59,158 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 46.0 (TID 91) in 8 ms on localhost (1/2)
2016-12-14 14:49:59,160 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 46.0 (TID 90) in 11 ms on localhost (2/2)
2016-12-14 14:49:59,160 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 46 (sum at KMeansModel.scala:88) finished in 0.011 s
2016-12-14 14:49:59,160 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 14:49:59,160 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: sum at KMeansModel.scala:88, took 0.017809 s
2016-12-14 14:49:59,161 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 2370689.6867946046
2016-12-14 14:49:59,161 INFO  com.datageek.test.K_means$ - main: ==(-_-)~====END====(-_-)~==
2016-12-14 14:49:59,246 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:49:59,247 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:49:59,247 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:49:59,248 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:49:59,248 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:49:59,248 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:49:59,249 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:49:59,249 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:49:59,249 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:49:59,250 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:49:59,250 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:49:59,250 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:49:59,251 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:49:59,251 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:49:59,251 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:49:59,252 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:49:59,252 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:49:59,252 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:49:59,253 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:49:59,253 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:49:59,253 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:49:59,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:49:59,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:49:59,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:49:59,255 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:49:59,308 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 14:49:59,392 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:49:59,411 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 14:49:59,412 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 14:49:59,414 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 14:49:59,418 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 14:49:59,423 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 14:49:59,424 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 14:49:59,427 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 14:49:59,428 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:49:59,430 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-ecfef825-6866-4bdd-8b62-43f15e2b43dc
2016-12-14 14:49:59,474 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 14:49:59,475 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 14:52:20,824 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 14:52:21,912 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 14:52:21,918 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 14:52:21,919 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 14:52:22,290 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 63427.
2016-12-14 14:52:22,801 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 14:52:22,842 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 14:52:23,049 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:24098]
2016-12-14 14:52:23,051 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:24098]
2016-12-14 14:52:23,057 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 24098.
2016-12-14 14:52:23,073 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 14:52:23,089 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 14:52:23,101 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-4b60a211-f309-45fd-a2ac-3b9cd8c8d818
2016-12-14 14:52:23,114 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 14:52:23,176 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 14:52:23,312 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 14:52:23,359 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:52:23,359 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:52:23,361 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 14:52:23,386 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:63427/jars/mysql-connector-java-5.1.25.jar with timestamp 1481698343386
2016-12-14 14:52:23,387 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:63427/jars/ojdbc6.jar with timestamp 1481698343387
2016-12-14 14:52:23,387 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:63427/jars/orai18n.jar with timestamp 1481698343387
2016-12-14 14:52:23,387 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:63427/jars/machine_learning_2.10-1.0.jar with timestamp 1481698343387
2016-12-14 14:52:23,441 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 14:52:23,460 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39109.
2016-12-14 14:52:23,461 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 39109
2016-12-14 14:52:23,463 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 14:52:23,464 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 14:52:23,469 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:39109 with 530.0 MB RAM, BlockManagerId(driver, localhost, 39109)
2016-12-14 14:52:23,474 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 14:52:24,500 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481698343417
2016-12-14 14:52:24,539 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/wine.txt
2016-12-14 14:52:24,541 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 14:52:24,541 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 14:52:24,541 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 14:52:24,541 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 14:52:24,542 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 14:52:24,944 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 14:52:25,291 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 14:52:25,296 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:39109 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 14:52:25,301 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:88
2016-12-14 14:52:25,469 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 14:52:25,562 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 14:52:25,586 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (first at PCA.scala:42) with 1 output partitions
2016-12-14 14:52:25,586 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (first at PCA.scala:42)
2016-12-14 14:52:25,587 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:25,591 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:25,599 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:100), which has no missing parents
2016-12-14 14:52:25,611 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 304.6 KB)
2016-12-14 14:52:25,632 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 306.7 KB)
2016-12-14 14:52:25,633 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:39109 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:52:25,635 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:25,638 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:100)
2016-12-14 14:52:25,639 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 1 tasks
2016-12-14 14:52:25,699 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:25,715 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:52:25,726 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:63427/jars/ojdbc6.jar with timestamp 1481698343387
2016-12-14 14:52:25,728 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 14:52:25,834 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:63427/jars/ojdbc6.jar to /tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/fetchFileTemp392309872493136291.tmp
2016-12-14 14:52:25,923 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/ojdbc6.jar to class loader
2016-12-14 14:52:25,923 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:63427/jars/machine_learning_2.10-1.0.jar with timestamp 1481698343387
2016-12-14 14:52:25,925 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:63427/jars/machine_learning_2.10-1.0.jar to /tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/fetchFileTemp6791253463072588280.tmp
2016-12-14 14:52:25,936 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/machine_learning_2.10-1.0.jar to class loader
2016-12-14 14:52:25,937 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:63427/jars/orai18n.jar with timestamp 1481698343387
2016-12-14 14:52:25,938 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:63427/jars/orai18n.jar to /tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/fetchFileTemp6184094543425225230.tmp
2016-12-14 14:52:25,958 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/orai18n.jar to class loader
2016-12-14 14:52:25,959 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:63427/jars/mysql-connector-java-5.1.25.jar with timestamp 1481698343386
2016-12-14 14:52:25,960 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:63427/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/fetchFileTemp7191959663350246978.tmp
2016-12-14 14:52:25,974 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60/userFiles-b4df8cc2-484d-4765-8c51-323f37f3b445/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 14:52:26,009 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 14:52:26,015 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/wine.txt:0+5738
2016-12-14 14:52:26,039 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 14:52:26,040 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 14:52:26,040 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 14:52:26,041 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 14:52:26,041 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 14:52:26,143 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 14.3 KB, free 321.0 KB)
2016-12-14 14:52:26,144 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:39109 (size: 14.3 KB, free: 530.0 MB)
2016-12-14 14:52:26,185 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2773 bytes result sent to driver
2016-12-14 14:52:26,222 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 554 ms on localhost (1/1)
2016-12-14 14:52:26,224 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:52:26,225 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (first at PCA.scala:42) finished in 0.575 s
2016-12-14 14:52:26,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: first at PCA.scala:42, took 0.668905 s
2016-12-14 14:52:26,256 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 14:52:26,258 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 14:52:26,258 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (first at RowMatrix.scala:61)
2016-12-14 14:52:26,258 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:26,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:26,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:100), which has no missing parents
2016-12-14 14:52:26,265 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 3.6 KB, free 324.6 KB)
2016-12-14 14:52:26,273 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 326.7 KB)
2016-12-14 14:52:26,274 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:39109 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:52:26,275 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:26,275 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:100)
2016-12-14 14:52:26,276 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 1 tasks
2016-12-14 14:52:26,281 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:26,282 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 14:52:26,287 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:26,292 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 1). 2248 bytes result sent to driver
2016-12-14 14:52:26,309 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (1/1)
2016-12-14 14:52:26,309 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (first at RowMatrix.scala:61) finished in 0.030 s
2016-12-14 14:52:26,309 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:52:26,310 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: first at RowMatrix.scala:61, took 0.052735 s
2016-12-14 14:52:26,873 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 14:52:26,876 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 14:52:26,876 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:331)
2016-12-14 14:52:26,876 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:26,878 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:26,879 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 14:52:26,884 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 4.6 KB, free 331.3 KB)
2016-12-14 14:52:26,894 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 333.7 KB)
2016-12-14 14:52:26,895 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:39109 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:52:26,896 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:26,897 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331)
2016-12-14 14:52:26,897 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 14:52:26,900 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:26,903 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:26,904 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 2)
2016-12-14 14:52:26,904 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 3)
2016-12-14 14:52:26,913 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:26,916 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 14:52:26,917 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/wine.txt:5738+5739
2016-12-14 14:52:26,949 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 2). 2208 bytes result sent to driver
2016-12-14 14:52:26,953 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 14.3 KB, free 348.0 KB)
2016-12-14 14:52:26,953 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:39109 (size: 14.3 KB, free: 530.0 MB)
2016-12-14 14:52:26,957 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 2) in 58 ms on localhost (1/2)
2016-12-14 14:52:26,961 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 3). 2788 bytes result sent to driver
2016-12-14 14:52:26,970 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 3) in 68 ms on localhost (2/2)
2016-12-14 14:52:26,970 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (treeAggregate at RowMatrix.scala:331) finished in 0.072 s
2016-12-14 14:52:26,970 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:52:26,975 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 14:52:26,975 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 14:52:26,981 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: treeAggregate at RowMatrix.scala:331, took 0.107217 s
2016-12-14 14:52:26,996 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 14:52:26,997 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 14:52:26,998 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (treeAggregate at RowMatrix.scala:121)
2016-12-14 14:52:26,998 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:26,998 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:26,999 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 14:52:27,000 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 5.2 KB, free 353.2 KB)
2016-12-14 14:52:27,005 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.5 KB, free 355.7 KB)
2016-12-14 14:52:27,006 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:39109 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:52:27,006 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:27,007 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121)
2016-12-14 14:52:27,007 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 14:52:27,008 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:27,010 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:27,010 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 5)
2016-12-14 14:52:27,010 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 4)
2016-12-14 14:52:27,014 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:27,016 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:27,023 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 4). 2831 bytes result sent to driver
2016-12-14 14:52:27,025 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 5). 2831 bytes result sent to driver
2016-12-14 14:52:27,028 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 4) in 20 ms on localhost (1/2)
2016-12-14 14:52:27,029 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 5) in 20 ms on localhost (2/2)
2016-12-14 14:52:27,029 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (treeAggregate at RowMatrix.scala:121) finished in 0.022 s
2016-12-14 14:52:27,030 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:52:27,030 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: treeAggregate at RowMatrix.scala:121, took 0.033731 s
2016-12-14 14:52:27,248 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:39109 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:52:27,256 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 14:52:27,258 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:39109 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:52:27,259 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 14:52:27,260 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:39109 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:52:27,261 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 14:52:27,262 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:39109 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:52:27,263 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 14:52:27,689 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2016-12-14 14:52:27,690 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2016-12-14 14:52:27,859 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:52:27,905 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:52:27,907 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:52:27,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (takeSample at KMeans.scala:378)
2016-12-14 14:52:27,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:27,910 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:27,911 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210), which has no missing parents
2016-12-14 14:52:27,924 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 4.9 KB, free 334.5 KB)
2016-12-14 14:52:27,932 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.8 KB, free 337.3 KB)
2016-12-14 14:52:27,934 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:39109 (size: 2.8 KB, free: 530.0 MB)
2016-12-14 14:52:27,935 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:27,935 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210)
2016-12-14 14:52:27,935 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 14:52:27,941 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:52:27,941 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:52:27,942 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 6)
2016-12-14 14:52:27,942 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 7)
2016-12-14 14:52:27,950 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:27,950 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:27,951 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_1 not found, computing it
2016-12-14 14:52:27,951 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_0 not found, computing it
2016-12-14 14:52:27,952 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:27,952 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:27,963 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_0 stored as values in memory (estimated size 2.5 KB, free 339.7 KB)
2016-12-14 14:52:27,964 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_0 in memory on localhost:39109 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:52:27,967 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_1 stored as values in memory (estimated size 2.5 KB, free 342.2 KB)
2016-12-14 14:52:27,968 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_1 in memory on localhost:39109 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:52:27,975 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 6). 2638 bytes result sent to driver
2016-12-14 14:52:27,978 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 7). 2638 bytes result sent to driver
2016-12-14 14:52:27,982 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 6) in 44 ms on localhost (1/2)
2016-12-14 14:52:27,985 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 7) in 43 ms on localhost (2/2)
2016-12-14 14:52:27,985 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (takeSample at KMeans.scala:378) finished in 0.049 s
2016-12-14 14:52:27,985 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:52:27,985 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: takeSample at KMeans.scala:378, took 0.080202 s
2016-12-14 14:52:28,078 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:52:28,081 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:52:28,081 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (takeSample at KMeans.scala:378)
2016-12-14 14:52:28,081 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,083 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,084 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 14:52:28,088 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 21.9 KB, free 364.1 KB)
2016-12-14 14:52:28,095 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.4 KB, free 373.4 KB)
2016-12-14 14:52:28,097 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:39109 (size: 9.4 KB, free: 529.9 MB)
2016-12-14 14:52:28,097 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,098 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378)
2016-12-14 14:52:28,098 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 14:52:28,102 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:52:28,103 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:52:28,104 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 9)
2016-12-14 14:52:28,104 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 8)
2016-12-14 14:52:28,114 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,114 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,115 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,115 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,133 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 8). 2938 bytes result sent to driver
2016-12-14 14:52:28,133 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 9). 2784 bytes result sent to driver
2016-12-14 14:52:28,140 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 8) in 40 ms on localhost (1/2)
2016-12-14 14:52:28,143 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 9) in 41 ms on localhost (2/2)
2016-12-14 14:52:28,143 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (takeSample at KMeans.scala:378) finished in 0.044 s
2016-12-14 14:52:28,144 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: takeSample at KMeans.scala:378, took 0.064983 s
2016-12-14 14:52:28,150 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 1840.0 B, free 375.2 KB)
2016-12-14 14:52:28,159 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 432.0 B, free 375.6 KB)
2016-12-14 14:52:28,160 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:39109 (size: 432.0 B, free: 529.9 MB)
2016-12-14 14:52:28,161 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at KMeans.scala:396
2016-12-14 14:52:28,195 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:52:28,196 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:52:28,196 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 14:52:28,196 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,199 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:52:28,202 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.5 KB, free 382.1 KB)
2016-12-14 14:52:28,207 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 385.5 KB)
2016-12-14 14:52:28,208 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:39109 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:52:28,208 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,209 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398)
2016-12-14 14:52:28,209 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 14:52:28,210 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:52:28,211 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:52:28,211 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 10)
2016-12-14 14:52:28,211 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 11)
2016-12-14 14:52:28,217 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_1 not found, computing it
2016-12-14 14:52:28,217 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,217 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_0 not found, computing it
2016-12-14 14:52:28,218 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,218 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,218 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,218 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,219 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,219 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,219 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,246 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_1 stored as values in memory (estimated size 8.7 KB, free 394.2 KB)
2016-12-14 14:52:28,247 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_0 stored as values in memory (estimated size 8.7 KB, free 402.9 KB)
2016-12-14 14:52:28,247 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_1 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,248 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_0 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,255 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 11). 2721 bytes result sent to driver
2016-12-14 14:52:28,255 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 10). 2721 bytes result sent to driver
2016-12-14 14:52:28,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 11) in 49 ms on localhost (1/2)
2016-12-14 14:52:28,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 10) in 51 ms on localhost (2/2)
2016-12-14 14:52:28,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.052 s
2016-12-14 14:52:28,261 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.066060 s
2016-12-14 14:52:28,264 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 12 from persistence list
2016-12-14 14:52:28,268 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 12
2016-12-14 14:52:28,293 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:52:28,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:52:28,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 14:52:28,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,296 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,296 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:52:28,299 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 6.6 KB, free 409.6 KB)
2016-12-14 14:52:28,303 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.6 KB, free 413.1 KB)
2016-12-14 14:52:28,304 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:39109 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:28,305 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,306 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:52:28,306 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 14:52:28,309 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:52:28,310 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:52:28,311 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 12)
2016-12-14 14:52:28,311 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 13)
2016-12-14 14:52:28,317 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,317 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,318 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,318 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,318 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 14:52:28,319 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 14:52:28,332 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 12). 3513 bytes result sent to driver
2016-12-14 14:52:28,333 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 13). 2657 bytes result sent to driver
2016-12-14 14:52:28,338 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 12) in 30 ms on localhost (1/2)
2016-12-14 14:52:28,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 13) in 31 ms on localhost (2/2)
2016-12-14 14:52:28,341 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.033 s
2016-12-14 14:52:28,341 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.049112 s
2016-12-14 14:52:28,347 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 5.0 KB, free 418.1 KB)
2016-12-14 14:52:28,354 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1574.0 B, free 419.7 KB)
2016-12-14 14:52:28,355 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:39109 (size: 1574.0 B, free: 529.9 MB)
2016-12-14 14:52:28,356 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at KMeans.scala:396
2016-12-14 14:52:28,376 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:52:28,377 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:52:28,378 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 14:52:28,378 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,380 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,380 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:52:28,382 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.7 KB, free 426.4 KB)
2016-12-14 14:52:28,386 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 429.9 KB)
2016-12-14 14:52:28,387 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:39109 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:52:28,387 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,388 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398)
2016-12-14 14:52:28,388 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 14:52:28,390 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:52:28,391 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:52:28,391 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 15)
2016-12-14 14:52:28,391 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 14)
2016-12-14 14:52:28,396 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_1 not found, computing it
2016-12-14 14:52:28,396 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,397 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,397 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 14:52:28,400 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_0 not found, computing it
2016-12-14 14:52:28,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 14:52:28,408 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_1 stored as values in memory (estimated size 8.7 KB, free 438.6 KB)
2016-12-14 14:52:28,409 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_1 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,411 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_0 stored as values in memory (estimated size 8.7 KB, free 447.3 KB)
2016-12-14 14:52:28,412 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_0 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,418 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 15). 2721 bytes result sent to driver
2016-12-14 14:52:28,418 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 14). 2721 bytes result sent to driver
2016-12-14 14:52:28,421 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 15) in 31 ms on localhost (1/2)
2016-12-14 14:52:28,424 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 14) in 35 ms on localhost (2/2)
2016-12-14 14:52:28,424 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.036 s
2016-12-14 14:52:28,424 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,424 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.048420 s
2016-12-14 14:52:28,426 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 15 from persistence list
2016-12-14 14:52:28,428 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 14:52:28,441 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:52:28,442 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:52:28,442 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 14:52:28,442 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:52:28,447 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 6.9 KB, free 436.7 KB)
2016-12-14 14:52:28,452 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.6 KB, free 440.4 KB)
2016-12-14 14:52:28,453 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:39109 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:28,453 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,454 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:52:28,454 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 14:52:28,456 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:52:28,457 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:52:28,457 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 16)
2016-12-14 14:52:28,457 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 17)
2016-12-14 14:52:28,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 14:52:28,462 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,463 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,463 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 14:52:28,466 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 17). 3096 bytes result sent to driver
2016-12-14 14:52:28,468 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 16). 3503 bytes result sent to driver
2016-12-14 14:52:28,471 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 17) in 13 ms on localhost (1/2)
2016-12-14 14:52:28,472 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 16) in 16 ms on localhost (2/2)
2016-12-14 14:52:28,473 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.017 s
2016-12-14 14:52:28,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.032103 s
2016-12-14 14:52:28,474 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 5.8 KB, free 446.1 KB)
2016-12-14 14:52:28,481 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1881.0 B, free 448.0 KB)
2016-12-14 14:52:28,482 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:39109 (size: 1881.0 B, free: 529.9 MB)
2016-12-14 14:52:28,482 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at KMeans.scala:396
2016-12-14 14:52:28,497 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:52:28,499 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:52:28,499 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 14:52:28,499 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,501 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,502 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:52:28,504 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.9 KB, free 454.9 KB)
2016-12-14 14:52:28,508 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.5 KB, free 458.4 KB)
2016-12-14 14:52:28,509 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:39109 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:52:28,509 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,509 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398)
2016-12-14 14:52:28,510 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 14:52:28,511 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:52:28,511 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:52:28,512 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 18)
2016-12-14 14:52:28,512 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 19)
2016-12-14 14:52:28,516 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_1 not found, computing it
2016-12-14 14:52:28,516 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,516 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,517 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 14:52:28,518 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_0 not found, computing it
2016-12-14 14:52:28,518 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,519 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,519 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 14:52:28,520 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_1 stored as values in memory (estimated size 8.7 KB, free 467.1 KB)
2016-12-14 14:52:28,521 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_1 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,524 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_0 stored as values in memory (estimated size 8.7 KB, free 475.8 KB)
2016-12-14 14:52:28,524 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 19). 2721 bytes result sent to driver
2016-12-14 14:52:28,524 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_0 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,528 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 18). 2721 bytes result sent to driver
2016-12-14 14:52:28,528 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 19) in 17 ms on localhost (1/2)
2016-12-14 14:52:28,531 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 18) in 20 ms on localhost (2/2)
2016-12-14 14:52:28,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.021 s
2016-12-14 14:52:28,531 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.033909 s
2016-12-14 14:52:28,532 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 19 from persistence list
2016-12-14 14:52:28,533 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 14:52:28,547 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:52:28,549 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:52:28,549 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 14:52:28,550 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,551 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,552 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:52:28,554 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 7.1 KB, free 465.5 KB)
2016-12-14 14:52:28,559 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 469.2 KB)
2016-12-14 14:52:28,559 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:39109 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,560 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,560 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:52:28,560 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 14:52:28,562 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:52:28,562 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:52:28,563 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 20)
2016-12-14 14:52:28,563 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 21)
2016-12-14 14:52:28,566 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,566 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,566 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 14:52:28,568 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,569 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,569 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 14:52:28,570 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 21). 3055 bytes result sent to driver
2016-12-14 14:52:28,576 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 20). 3252 bytes result sent to driver
2016-12-14 14:52:28,577 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 21) in 15 ms on localhost (1/2)
2016-12-14 14:52:28,581 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 20) in 19 ms on localhost (2/2)
2016-12-14 14:52:28,581 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.020 s
2016-12-14 14:52:28,581 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,581 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.033714 s
2016-12-14 14:52:28,582 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 5.0 KB, free 474.2 KB)
2016-12-14 14:52:28,586 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1652.0 B, free 475.8 KB)
2016-12-14 14:52:28,587 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:39109 (size: 1652.0 B, free: 529.9 MB)
2016-12-14 14:52:28,587 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at KMeans.scala:396
2016-12-14 14:52:28,597 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:52:28,599 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:52:28,600 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 12 (aggregate at KMeans.scala:404)
2016-12-14 14:52:28,600 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,602 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,603 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:52:28,607 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 7.2 KB, free 483.0 KB)
2016-12-14 14:52:28,612 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.6 KB, free 486.6 KB)
2016-12-14 14:52:28,613 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:39109 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:28,614 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,614 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398)
2016-12-14 14:52:28,614 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 14:52:28,615 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:52:28,616 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:52:28,616 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 23)
2016-12-14 14:52:28,616 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 22)
2016-12-14 14:52:28,619 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_1 not found, computing it
2016-12-14 14:52:28,619 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,619 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,620 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 14:52:28,621 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_0 not found, computing it
2016-12-14 14:52:28,622 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,622 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_1 stored as values in memory (estimated size 8.7 KB, free 495.3 KB)
2016-12-14 14:52:28,622 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,622 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 14:52:28,622 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_1 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,625 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 23). 2721 bytes result sent to driver
2016-12-14 14:52:28,625 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_0 stored as values in memory (estimated size 8.7 KB, free 504.0 KB)
2016-12-14 14:52:28,626 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_0 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,630 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 23) in 15 ms on localhost (1/2)
2016-12-14 14:52:28,630 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 22). 2721 bytes result sent to driver
2016-12-14 14:52:28,634 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 22) in 19 ms on localhost (2/2)
2016-12-14 14:52:28,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 12 (aggregate at KMeans.scala:404) finished in 0.020 s
2016-12-14 14:52:28,634 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: aggregate at KMeans.scala:404, took 0.036770 s
2016-12-14 14:52:28,635 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 23 from persistence list
2016-12-14 14:52:28,636 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 14:52:28,646 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:52:28,647 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:52:28,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collect at KMeans.scala:436)
2016-12-14 14:52:28,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,649 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,649 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:52:28,652 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 7.3 KB, free 493.9 KB)
2016-12-14 14:52:28,656 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.8 KB, free 497.7 KB)
2016-12-14 14:52:28,657 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:39109 (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:52:28,658 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,658 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:52:28,658 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 14:52:28,660 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:52:28,660 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:52:28,661 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 24)
2016-12-14 14:52:28,661 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 25)
2016-12-14 14:52:28,664 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,664 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,664 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 14:52:28,665 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,665 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,665 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 14:52:28,668 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 25). 2973 bytes result sent to driver
2016-12-14 14:52:28,671 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 24). 3020 bytes result sent to driver
2016-12-14 14:52:28,674 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 25) in 14 ms on localhost (1/2)
2016-12-14 14:52:28,676 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 24) in 17 ms on localhost (2/2)
2016-12-14 14:52:28,676 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collect at KMeans.scala:436) finished in 0.017 s
2016-12-14 14:52:28,676 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,676 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collect at KMeans.scala:436, took 0.029881 s
2016-12-14 14:52:28,679 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 4.4 KB, free 502.1 KB)
2016-12-14 14:52:28,686 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1407.0 B, free 503.5 KB)
2016-12-14 14:52:28,688 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:39109 (size: 1407.0 B, free: 529.9 MB)
2016-12-14 14:52:28,688 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at KMeans.scala:396
2016-12-14 14:52:28,707 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:52:28,709 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:52:28,709 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 14 (aggregate at KMeans.scala:404)
2016-12-14 14:52:28,709 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,711 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,711 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:52:28,714 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 7.4 KB, free 510.9 KB)
2016-12-14 14:52:28,721 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.7 KB, free 514.5 KB)
2016-12-14 14:52:28,722 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:39109 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,723 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,723 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398)
2016-12-14 14:52:28,723 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 14:52:28,725 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 26, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:52:28,725 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 27, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:52:28,726 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 26)
2016-12-14 14:52:28,726 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 27)
2016-12-14 14:52:28,729 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_1 not found, computing it
2016-12-14 14:52:28,729 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,730 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,730 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 14:52:28,732 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_1 stored as values in memory (estimated size 8.7 KB, free 523.2 KB)
2016-12-14 14:52:28,732 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_0 not found, computing it
2016-12-14 14:52:28,732 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_1 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,734 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 14:52:28,736 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 27). 2721 bytes result sent to driver
2016-12-14 14:52:28,739 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_0 stored as values in memory (estimated size 8.7 KB, free 532.0 KB)
2016-12-14 14:52:28,740 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_0 in memory on localhost:39109 (size: 8.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,741 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 27) in 16 ms on localhost (1/2)
2016-12-14 14:52:28,746 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 26). 2721 bytes result sent to driver
2016-12-14 14:52:28,755 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 26) in 30 ms on localhost (2/2)
2016-12-14 14:52:28,755 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 14 (aggregate at KMeans.scala:404) finished in 0.031 s
2016-12-14 14:52:28,755 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,756 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: aggregate at KMeans.scala:404, took 0.048068 s
2016-12-14 14:52:28,757 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 27 from persistence list
2016-12-14 14:52:28,759 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 14:52:28,775 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:52:28,778 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:52:28,779 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collect at KMeans.scala:436)
2016-12-14 14:52:28,779 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:28,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:28,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:52:28,783 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 7.6 KB, free 522.1 KB)
2016-12-14 14:52:28,796 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:39109 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:28,797 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 14:52:28,798 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:39109 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:52:28,798 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.8 KB, free 505.2 KB)
2016-12-14 14:52:28,799 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:39109 (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:52:28,799 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:39109 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,799 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,800 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:52:28,800 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 14:52:28,800 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 14:52:28,801 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:39109 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:52:28,801 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:52:28,802 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 14:52:28,802 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:52:28,802 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 29)
2016-12-14 14:52:28,802 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 28)
2016-12-14 14:52:28,803 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:39109 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:52:28,804 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 14:52:28,805 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:39109 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:28,806 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 14:52:28,806 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 14:52:28,807 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:39109 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:28,807 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 14:52:28,808 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,808 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:28,808 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_0 locally
2016-12-14 14:52:28,808 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:39109 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:52:28,809 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 14:52:28,809 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,810 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,810 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:39109 in memory (size: 2.8 KB, free: 529.9 MB)
2016-12-14 14:52:28,810 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_1 locally
2016-12-14 14:52:28,810 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 14:52:28,811 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:39109 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:52:28,812 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 14:52:28,813 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:39109 in memory (size: 9.4 KB, free: 529.9 MB)
2016-12-14 14:52:28,813 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 14:52:28,814 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 28). 3219 bytes result sent to driver
2016-12-14 14:52:28,815 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 29). 2971 bytes result sent to driver
2016-12-14 14:52:28,821 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 29) in 19 ms on localhost (1/2)
2016-12-14 14:52:28,821 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 28) in 20 ms on localhost (2/2)
2016-12-14 14:52:28,822 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:52:28,822 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collect at KMeans.scala:436) finished in 0.021 s
2016-12-14 14:52:28,823 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collect at KMeans.scala:436, took 0.046876 s
2016-12-14 14:52:28,824 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 31 from persistence list
2016-12-14 14:52:28,825 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 14:52:28,826 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 22.6 KB, free 397.2 KB)
2016-12-14 14:52:28,837 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.9 KB, free 402.0 KB)
2016-12-14 14:52:28,838 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:39109 (size: 4.9 KB, free: 529.9 MB)
2016-12-14 14:52:28,839 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at KMeans.scala:450
2016-12-14 14:52:28,891 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 14:52:28,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 34 (flatMap at KMeans.scala:451)
2016-12-14 14:52:28,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 14:52:28,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:455)
2016-12-14 14:52:28,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 14:52:28,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 14:52:28,907 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 14:52:28,914 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 6.5 KB, free 408.6 KB)
2016-12-14 14:52:28,920 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.6 KB, free 412.2 KB)
2016-12-14 14:52:28,922 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:39109 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:28,923 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:28,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451)
2016-12-14 14:52:28,926 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 14:52:28,930 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:28,931 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:28,931 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 30)
2016-12-14 14:52:28,932 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 31)
2016-12-14 14:52:28,936 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:28,936 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:28,936 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:28,937 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,092 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 31). 2237 bytes result sent to driver
2016-12-14 14:52:29,092 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 30). 2237 bytes result sent to driver
2016-12-14 14:52:29,103 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 30) in 174 ms on localhost (1/2)
2016-12-14 14:52:29,103 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 31) in 173 ms on localhost (2/2)
2016-12-14 14:52:29,103 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,104 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (flatMap at KMeans.scala:451) finished in 0.177 s
2016-12-14 14:52:29,105 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:29,105 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:29,105 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 14:52:29,106 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:29,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 14:52:29,118 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 2.6 KB, free 414.8 KB)
2016-12-14 14:52:29,124 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1555.0 B, free 416.3 KB)
2016-12-14 14:52:29,125 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:39109 (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:52:29,126 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455)
2016-12-14 14:52:29,127 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 14:52:29,131 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 32, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,131 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 33, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,132 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 32)
2016-12-14 14:52:29,132 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 33)
2016-12-14 14:52:29,143 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,143 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,145 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 14:52:29,145 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 14:52:29,182 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 32). 4416 bytes result sent to driver
2016-12-14 14:52:29,182 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 33). 4416 bytes result sent to driver
2016-12-14 14:52:29,186 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 33) in 55 ms on localhost (1/2)
2016-12-14 14:52:29,186 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 32) in 57 ms on localhost (2/2)
2016-12-14 14:52:29,187 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,187 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:455) finished in 0.059 s
2016-12-14 14:52:29,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:455, took 0.296040 s
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:52:29,326 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:52:29,348 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 1.467 seconds.
2016-12-14 14:52:29,353 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 2.5 KB, free 418.8 KB)
2016-12-14 14:52:29,360 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 955.0 B, free 419.7 KB)
2016-12-14 14:52:29,361 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:39109 (size: 955.0 B, free: 529.9 MB)
2016-12-14 14:52:29,361 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at KMeans.scala:276
2016-12-14 14:52:29,400 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:29,402 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 36 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,403 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:29,403 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:29,403 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 14:52:29,403 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 14:52:29,405 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:29,408 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 7.5 KB, free 427.2 KB)
2016-12-14 14:52:29,411 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 4.0 KB, free 431.2 KB)
2016-12-14 14:52:29,412 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:29,412 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,412 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,413 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 14:52:29,414 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 34, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,414 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 35, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,415 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 35)
2016-12-14 14:52:29,415 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 34)
2016-12-14 14:52:29,418 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:29,418 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:29,421 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:29,421 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,435 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 35). 2516 bytes result sent to driver
2016-12-14 14:52:29,437 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 34). 2516 bytes result sent to driver
2016-12-14 14:52:29,439 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 35) in 24 ms on localhost (1/2)
2016-12-14 14:52:29,439 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 34) in 26 ms on localhost (2/2)
2016-12-14 14:52:29,439 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,440 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.026 s
2016-12-14 14:52:29,440 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:29,440 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:29,440 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 14:52:29,440 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:29,441 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:29,443 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 2.9 KB, free 434.1 KB)
2016-12-14 14:52:29,449 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 1668.0 B, free 435.8 KB)
2016-12-14 14:52:29,450 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:39109 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:29,450 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,450 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:29,450 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 14:52:29,452 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 36, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,452 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 37, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,453 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 37)
2016-12-14 14:52:29,453 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 36)
2016-12-14 14:52:29,456 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,456 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,456 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,457 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:29,469 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 37). 1726 bytes result sent to driver
2016-12-14 14:52:29,472 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 36). 1730 bytes result sent to driver
2016-12-14 14:52:29,474 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 37) in 22 ms on localhost (1/2)
2016-12-14 14:52:29,476 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 36) in 25 ms on localhost (2/2)
2016-12-14 14:52:29,476 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,476 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.025 s
2016-12-14 14:52:29,477 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.076635 s
2016-12-14 14:52:29,484 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 2.5 KB, free 438.3 KB)
2016-12-14 14:52:29,489 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 676.0 B, free 438.9 KB)
2016-12-14 14:52:29,490 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:39109 (size: 676.0 B, free: 529.9 MB)
2016-12-14 14:52:29,491 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at KMeans.scala:276
2016-12-14 14:52:29,510 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:29,512 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 38 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:29,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:29,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 14:52:29,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 14:52:29,515 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:29,518 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 7.5 KB, free 446.4 KB)
2016-12-14 14:52:29,525 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 4.0 KB, free 450.4 KB)
2016-12-14 14:52:29,526 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:29,527 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,527 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,527 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 14:52:29,529 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 38, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,530 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 39, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,530 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 39)
2016-12-14 14:52:29,530 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 38)
2016-12-14 14:52:29,535 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:29,535 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:29,536 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:29,536 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,551 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 39). 2516 bytes result sent to driver
2016-12-14 14:52:29,553 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 38). 2516 bytes result sent to driver
2016-12-14 14:52:29,556 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 38) in 28 ms on localhost (1/2)
2016-12-14 14:52:29,557 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 39) in 27 ms on localhost (2/2)
2016-12-14 14:52:29,557 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,557 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.029 s
2016-12-14 14:52:29,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:29,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:29,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 14:52:29,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:29,559 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:29,560 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 2.9 KB, free 453.3 KB)
2016-12-14 14:52:29,566 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 1665.0 B, free 455.0 KB)
2016-12-14 14:52:29,567 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:39109 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:52:29,567 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,568 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:29,568 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 14:52:29,570 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,570 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,570 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 41)
2016-12-14 14:52:29,571 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 40)
2016-12-14 14:52:29,573 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,574 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:29,574 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,575 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:29,583 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 40). 1730 bytes result sent to driver
2016-12-14 14:52:29,587 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 40) in 17 ms on localhost (1/2)
2016-12-14 14:52:29,591 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 41). 1726 bytes result sent to driver
2016-12-14 14:52:29,595 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 41) in 25 ms on localhost (2/2)
2016-12-14 14:52:29,595 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.026 s
2016-12-14 14:52:29,596 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.085338 s
2016-12-14 14:52:29,599 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 2 iterations
2016-12-14 14:52:29,599 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 2 iterations
2016-12-14 14:52:29,599 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 2 iterations
2016-12-14 14:52:29,600 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 1808.0 B, free 456.7 KB)
2016-12-14 14:52:29,605 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 539.0 B, free 457.3 KB)
2016-12-14 14:52:29,606 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:39109 (size: 539.0 B, free: 529.9 MB)
2016-12-14 14:52:29,607 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at KMeans.scala:276
2016-12-14 14:52:29,625 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:29,628 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 40 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:29,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:29,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 14:52:29,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 14:52:29,631 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:29,635 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 7.4 KB, free 464.6 KB)
2016-12-14 14:52:29,640 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.0 KB, free 468.6 KB)
2016-12-14 14:52:29,641 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:29,642 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,643 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,643 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 14:52:29,645 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 42, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,646 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 43, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,646 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 42)
2016-12-14 14:52:29,646 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 43)
2016-12-14 14:52:29,651 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:29,652 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:29,652 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:29,653 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,661 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 43). 2444 bytes result sent to driver
2016-12-14 14:52:29,666 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 43) in 20 ms on localhost (1/2)
2016-12-14 14:52:29,668 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 42). 2444 bytes result sent to driver
2016-12-14 14:52:29,671 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 42) in 27 ms on localhost (2/2)
2016-12-14 14:52:29,671 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.027 s
2016-12-14 14:52:29,671 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,671 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:29,672 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:29,672 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 14:52:29,672 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:29,672 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:29,674 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 2.9 KB, free 471.5 KB)
2016-12-14 14:52:29,679 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 1667.0 B, free 473.2 KB)
2016-12-14 14:52:29,680 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:39109 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:52:29,681 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:29,681 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 14:52:29,682 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 44, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,683 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 45, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,683 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 44)
2016-12-14 14:52:29,683 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 45)
2016-12-14 14:52:29,686 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,686 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:29,687 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,687 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,695 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 45). 1580 bytes result sent to driver
2016-12-14 14:52:29,700 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 45) in 17 ms on localhost (1/2)
2016-12-14 14:52:29,706 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 44). 1540 bytes result sent to driver
2016-12-14 14:52:29,709 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 44) in 27 ms on localhost (2/2)
2016-12-14 14:52:29,710 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.028 s
2016-12-14 14:52:29,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.085203 s
2016-12-14 14:52:29,712 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 3 iterations
2016-12-14 14:52:29,712 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 3 iterations
2016-12-14 14:52:29,713 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 3 iterations
2016-12-14 14:52:29,714 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 1048.0 B, free 474.2 KB)
2016-12-14 14:52:29,719 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 454.0 B, free 474.6 KB)
2016-12-14 14:52:29,720 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:39109 (size: 454.0 B, free: 529.9 MB)
2016-12-14 14:52:29,720 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at KMeans.scala:276
2016-12-14 14:52:29,739 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:29,740 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 42 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,741 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:29,741 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:29,741 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 14:52:29,741 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 14:52:29,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:29,745 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 7.3 KB, free 481.9 KB)
2016-12-14 14:52:29,750 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 4.0 KB, free 485.9 KB)
2016-12-14 14:52:29,751 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:29,752 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,752 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,752 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 14:52:29,754 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 46, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,755 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 47, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,755 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 46)
2016-12-14 14:52:29,755 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 47)
2016-12-14 14:52:29,758 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:29,758 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,759 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:29,760 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:29,764 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 46). 2372 bytes result sent to driver
2016-12-14 14:52:29,766 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 47). 2372 bytes result sent to driver
2016-12-14 14:52:29,768 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 46) in 15 ms on localhost (1/2)
2016-12-14 14:52:29,768 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 47) in 14 ms on localhost (2/2)
2016-12-14 14:52:29,768 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 14:52:29,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:29,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:29,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 14:52:29,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:29,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:29,772 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 2.9 KB, free 488.8 KB)
2016-12-14 14:52:29,777 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1668.0 B, free 490.4 KB)
2016-12-14 14:52:29,777 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:39109 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:29,778 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,779 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:29,779 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 14:52:29,780 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 48, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,781 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 49, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,781 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 49)
2016-12-14 14:52:29,781 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 48)
2016-12-14 14:52:29,784 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,784 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,784 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,784 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,796 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 48). 1392 bytes result sent to driver
2016-12-14 14:52:29,797 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 49). 1392 bytes result sent to driver
2016-12-14 14:52:29,800 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 48) in 19 ms on localhost (1/2)
2016-12-14 14:52:29,801 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 49) in 19 ms on localhost (2/2)
2016-12-14 14:52:29,801 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,801 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:52:29,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.062568 s
2016-12-14 14:52:29,804 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 1048.0 B, free 491.5 KB)
2016-12-14 14:52:29,807 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 453.0 B, free 491.9 KB)
2016-12-14 14:52:29,807 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:39109 (size: 453.0 B, free: 529.9 MB)
2016-12-14 14:52:29,808 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at KMeans.scala:276
2016-12-14 14:52:29,816 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:29,817 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 44 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,818 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:29,818 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:29,819 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 14:52:29,819 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 14:52:29,820 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:29,823 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 7.3 KB, free 499.2 KB)
2016-12-14 14:52:29,828 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.0 KB, free 503.2 KB)
2016-12-14 14:52:29,828 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:29,829 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,829 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,829 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 14:52:29,831 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 50, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,831 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 51, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,832 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 50)
2016-12-14 14:52:29,832 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 51)
2016-12-14 14:52:29,835 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:29,835 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:29,837 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:29,838 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,840 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 51). 2372 bytes result sent to driver
2016-12-14 14:52:29,844 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 51) in 13 ms on localhost (1/2)
2016-12-14 14:52:29,850 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 50). 2372 bytes result sent to driver
2016-12-14 14:52:29,852 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 50) in 22 ms on localhost (2/2)
2016-12-14 14:52:29,852 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.022 s
2016-12-14 14:52:29,853 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,853 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:29,853 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:29,853 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 14:52:29,853 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:29,853 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:29,854 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 2.9 KB, free 506.1 KB)
2016-12-14 14:52:29,857 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 1664.0 B, free 507.7 KB)
2016-12-14 14:52:29,857 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:39109 (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:52:29,858 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,858 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:29,858 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 14:52:29,859 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 52, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,859 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 53, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,860 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 52)
2016-12-14 14:52:29,860 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 53)
2016-12-14 14:52:29,861 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,861 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,862 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,862 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,869 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 53). 1392 bytes result sent to driver
2016-12-14 14:52:29,871 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 52). 1392 bytes result sent to driver
2016-12-14 14:52:29,873 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 53) in 14 ms on localhost (1/2)
2016-12-14 14:52:29,875 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 52) in 17 ms on localhost (2/2)
2016-12-14 14:52:29,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:52:29,875 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,876 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.059174 s
2016-12-14 14:52:29,878 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 1048.0 B, free 508.7 KB)
2016-12-14 14:52:29,883 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 453.0 B, free 509.2 KB)
2016-12-14 14:52:29,883 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:39109 (size: 453.0 B, free: 529.9 MB)
2016-12-14 14:52:29,884 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at KMeans.scala:276
2016-12-14 14:52:29,896 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:29,896 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 46 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,897 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:29,897 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:29,897 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 14:52:29,897 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 14:52:29,898 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:29,900 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 7.3 KB, free 516.4 KB)
2016-12-14 14:52:29,902 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 4.0 KB, free 520.4 KB)
2016-12-14 14:52:29,903 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:29,903 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,904 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,904 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 14:52:29,905 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 54, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,905 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 55, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,906 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 54)
2016-12-14 14:52:29,906 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 55)
2016-12-14 14:52:29,909 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:29,909 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:29,911 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:29,912 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,915 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 55). 2372 bytes result sent to driver
2016-12-14 14:52:29,917 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 55) in 12 ms on localhost (1/2)
2016-12-14 14:52:29,924 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 54). 2372 bytes result sent to driver
2016-12-14 14:52:29,926 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 54) in 22 ms on localhost (2/2)
2016-12-14 14:52:29,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.022 s
2016-12-14 14:52:29,926 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:29,927 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:29,927 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 14:52:29,927 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:29,927 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:29,928 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 2.9 KB, free 523.3 KB)
2016-12-14 14:52:29,930 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 1668.0 B, free 524.9 KB)
2016-12-14 14:52:29,931 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:39109 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:29,931 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,932 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:29,932 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 14:52:29,934 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 56, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,934 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 57, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:29,934 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 56)
2016-12-14 14:52:29,934 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 57)
2016-12-14 14:52:29,936 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,936 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,937 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:29,937 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:29,942 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 57). 1392 bytes result sent to driver
2016-12-14 14:52:29,947 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 57) in 12 ms on localhost (1/2)
2016-12-14 14:52:29,949 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 56). 1392 bytes result sent to driver
2016-12-14 14:52:29,951 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 56) in 18 ms on localhost (2/2)
2016-12-14 14:52:29,951 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:52:29,951 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.018 s
2016-12-14 14:52:29,952 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.055940 s
2016-12-14 14:52:29,953 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 1048.0 B, free 526.0 KB)
2016-12-14 14:52:29,956 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 429.0 B, free 526.4 KB)
2016-12-14 14:52:29,956 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:39109 (size: 429.0 B, free: 529.9 MB)
2016-12-14 14:52:29,957 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at KMeans.scala:276
2016-12-14 14:52:29,969 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:29,970 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 48 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:29,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:29,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 14:52:29,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 14:52:29,972 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:29,974 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 7.3 KB, free 533.7 KB)
2016-12-14 14:52:29,989 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.0 KB, free 537.6 KB)
2016-12-14 14:52:29,990 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:29,990 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:39109 in memory (size: 454.0 B, free: 529.9 MB)
2016-12-14 14:52:29,991 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:29,991 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:29,991 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 14:52:29,991 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 14:52:29,993 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 58, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,994 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 59, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:29,994 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 58)
2016-12-14 14:52:29,994 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 59)
2016-12-14 14:52:29,995 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 14:52:29,996 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:39109 in memory (size: 4.9 KB, free: 529.9 MB)
2016-12-14 14:52:29,997 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:29,997 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:29,997 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:29,997 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:29,997 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:39109 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:52:29,998 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 14:52:29,999 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 14:52:30,000 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 31
2016-12-14 14:52:30,001 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:39109 in memory (size: 1407.0 B, free: 529.9 MB)
2016-12-14 14:52:30,002 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 14:52:30,002 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 59). 2372 bytes result sent to driver
2016-12-14 14:52:30,002 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 27
2016-12-14 14:52:30,003 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:39109 in memory (size: 1652.0 B, free: 529.9 MB)
2016-12-14 14:52:30,004 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 59) in 11 ms on localhost (1/2)
2016-12-14 14:52:30,004 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 58). 2372 bytes result sent to driver
2016-12-14 14:52:30,004 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 14:52:30,005 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 23
2016-12-14 14:52:30,006 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:39109 in memory (size: 1881.0 B, free: 529.9 MB)
2016-12-14 14:52:30,006 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 58) in 13 ms on localhost (2/2)
2016-12-14 14:52:30,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.013 s
2016-12-14 14:52:30,006 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,006 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 14:52:30,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,007 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 14:52:30,007 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,007 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 14:52:30,007 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 14:52:30,007 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 14:52:30,007 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,007 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 14:52:30,008 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 14:52:30,008 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:30,008 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 14:52:30,008 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 14:52:30,008 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 14:52:30,009 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 14:52:30,009 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 2.9 KB, free 478.8 KB)
2016-12-14 14:52:30,009 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:39109 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:52:30,010 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 14:52:30,012 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:39109 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:52:30,012 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 14:52:30,012 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 14:52:30,013 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 14:52:30,013 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 14:52:30,013 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 14:52:30,013 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 14:52:30,014 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:39109 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,014 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 1668.0 B, free 466.0 KB)
2016-12-14 14:52:30,015 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:39109 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,015 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 14:52:30,015 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,016 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:30,016 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,016 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 14:52:30,016 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 14:52:30,017 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 60, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,017 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 14:52:30,018 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 61, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,018 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 60)
2016-12-14 14:52:30,018 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 61)
2016-12-14 14:52:30,018 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:39109 in memory (size: 955.0 B, free: 529.9 MB)
2016-12-14 14:52:30,020 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:39109 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:52:30,020 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,020 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 14:52:30,020 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,021 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,021 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,021 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,022 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 14:52:30,022 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 14:52:30,022 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:39109 in memory (size: 676.0 B, free: 529.9 MB)
2016-12-14 14:52:30,023 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 14:52:30,023 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 14:52:30,023 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 14:52:30,023 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 14:52:30,024 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:39109 in memory (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:52:30,025 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 14:52:30,025 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,026 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 14:52:30,026 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 14:52:30,027 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:39109 in memory (size: 539.0 B, free: 529.9 MB)
2016-12-14 14:52:30,027 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 61). 1392 bytes result sent to driver
2016-12-14 14:52:30,028 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 14:52:30,028 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 14:52:30,028 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 14:52:30,028 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 14:52:30,028 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 14:52:30,029 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 14:52:30,029 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 14:52:30,029 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 14:52:30,030 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:39109 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,030 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 60). 1392 bytes result sent to driver
2016-12-14 14:52:30,030 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 14:52:30,031 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,031 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 61) in 13 ms on localhost (1/2)
2016-12-14 14:52:30,031 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 14:52:30,032 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 14:52:30,032 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 14:52:30,032 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 14:52:30,032 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 14:52:30,032 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 14:52:30,032 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 14:52:30,033 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:39109 in memory (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:52:30,033 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 14:52:30,034 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 60) in 17 ms on localhost (2/2)
2016-12-14 14:52:30,034 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,034 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:52:30,034 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,034 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 14:52:30,035 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: collectAsMap at KMeans.scala:302, took 0.065156 s
2016-12-14 14:52:30,035 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 14:52:30,035 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:39109 in memory (size: 453.0 B, free: 529.9 MB)
2016-12-14 14:52:30,036 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 14:52:30,036 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 7 iterations
2016-12-14 14:52:30,036 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 14:52:30,036 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 14:52:30,037 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 14:52:30,037 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 800.0 B, free 378.5 KB)
2016-12-14 14:52:30,037 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 19
2016-12-14 14:52:30,038 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:39109 in memory (size: 1574.0 B, free: 529.9 MB)
2016-12-14 14:52:30,038 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 14:52:30,039 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 15
2016-12-14 14:52:30,039 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:39109 in memory (size: 432.0 B, free: 529.9 MB)
2016-12-14 14:52:30,040 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:39109 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,040 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 14:52:30,040 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 371.0 B, free 365.5 KB)
2016-12-14 14:52:30,041 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,041 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:39109 (size: 371.0 B, free: 529.9 MB)
2016-12-14 14:52:30,041 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 14:52:30,042 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 14:52:30,042 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at KMeans.scala:276
2016-12-14 14:52:30,043 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:39109 in memory (size: 453.0 B, free: 529.9 MB)
2016-12-14 14:52:30,043 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 14:52:30,044 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 14:52:30,044 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 14:52:30,059 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:30,060 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 50 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:30,060 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:30,060 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:30,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 14:52:30,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 14:52:30,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:30,063 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 7.2 KB, free 360.1 KB)
2016-12-14 14:52:30,065 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 4.0 KB, free 364.0 KB)
2016-12-14 14:52:30,066 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,066 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,066 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:30,066 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 14:52:30,067 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 62, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:30,068 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 63, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:30,068 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 62)
2016-12-14 14:52:30,068 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 63)
2016-12-14 14:52:30,072 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,072 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:30,074 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,074 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:30,080 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 62). 2348 bytes result sent to driver
2016-12-14 14:52:30,082 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 63). 2348 bytes result sent to driver
2016-12-14 14:52:30,083 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 62) in 16 ms on localhost (1/2)
2016-12-14 14:52:30,085 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 63) in 16 ms on localhost (2/2)
2016-12-14 14:52:30,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:52:30,085 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 14:52:30,086 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,086 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:30,087 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 2.9 KB, free 366.9 KB)
2016-12-14 14:52:30,090 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 1668.0 B, free 368.6 KB)
2016-12-14 14:52:30,091 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:39109 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,091 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,092 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:30,092 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 14:52:30,093 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 64, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,094 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 65, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,094 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 64)
2016-12-14 14:52:30,094 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 65)
2016-12-14 14:52:30,097 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,097 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,097 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,097 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,108 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 65). 1352 bytes result sent to driver
2016-12-14 14:52:30,108 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 64). 1314 bytes result sent to driver
2016-12-14 14:52:30,110 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 65) in 17 ms on localhost (1/2)
2016-12-14 14:52:30,111 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 64) in 18 ms on localhost (2/2)
2016-12-14 14:52:30,111 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,111 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 14:52:30,112 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: collectAsMap at KMeans.scala:302, took 0.052308 s
2016-12-14 14:52:30,114 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 8 iterations
2016-12-14 14:52:30,115 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 544.0 B, free 369.1 KB)
2016-12-14 14:52:30,120 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 287.0 B, free 369.4 KB)
2016-12-14 14:52:30,120 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:39109 (size: 287.0 B, free: 529.9 MB)
2016-12-14 14:52:30,121 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at KMeans.scala:276
2016-12-14 14:52:30,138 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:30,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 52 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:30,140 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:30,140 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:30,140 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 34)
2016-12-14 14:52:30,140 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 34)
2016-12-14 14:52:30,142 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:30,143 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 7.2 KB, free 376.6 KB)
2016-12-14 14:52:30,148 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.0 KB, free 380.5 KB)
2016-12-14 14:52:30,149 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,150 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:30,150 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 14:52:30,152 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 66, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:30,153 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 67, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:30,154 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 67)
2016-12-14 14:52:30,154 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 66)
2016-12-14 14:52:30,157 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,157 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,158 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:30,158 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:30,164 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 66). 2324 bytes result sent to driver
2016-12-14 14:52:30,165 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 67). 2324 bytes result sent to driver
2016-12-14 14:52:30,166 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 66) in 15 ms on localhost (1/2)
2016-12-14 14:52:30,167 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 67) in 15 ms on localhost (2/2)
2016-12-14 14:52:30,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 34 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 14:52:30,168 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 35)
2016-12-14 14:52:30,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,169 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:30,170 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 2.9 KB, free 383.5 KB)
2016-12-14 14:52:30,172 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 1668.0 B, free 385.1 KB)
2016-12-14 14:52:30,173 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:39109 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,173 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,173 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:30,173 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 14:52:30,174 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 68, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,175 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 69, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,175 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 68)
2016-12-14 14:52:30,175 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 69)
2016-12-14 14:52:30,177 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,177 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,178 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,178 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,188 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 68). 1277 bytes result sent to driver
2016-12-14 14:52:30,191 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 69). 1277 bytes result sent to driver
2016-12-14 14:52:30,192 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 68) in 18 ms on localhost (1/2)
2016-12-14 14:52:30,194 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 69) in 19 ms on localhost (2/2)
2016-12-14 14:52:30,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 14:52:30,194 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,195 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: collectAsMap at KMeans.scala:302, took 0.056412 s
2016-12-14 14:52:30,197 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 9 iterations
2016-12-14 14:52:30,198 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 296.0 B, free 385.4 KB)
2016-12-14 14:52:30,205 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 200.0 B, free 385.6 KB)
2016-12-14 14:52:30,206 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:39109 (size: 200.0 B, free: 529.9 MB)
2016-12-14 14:52:30,207 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at KMeans.scala:276
2016-12-14 14:52:30,231 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:52:30,232 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 54 (mapPartitions at KMeans.scala:279)
2016-12-14 14:52:30,232 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:52:30,232 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (collectAsMap at KMeans.scala:302)
2016-12-14 14:52:30,233 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 36)
2016-12-14 14:52:30,233 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 36)
2016-12-14 14:52:30,234 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 36 (MapPartitionsRDD[54] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:52:30,236 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 7.1 KB, free 392.7 KB)
2016-12-14 14:52:30,241 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.0 KB, free 396.7 KB)
2016-12-14 14:52:30,242 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:39109 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,243 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,243 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[54] at mapPartitions at KMeans.scala:279)
2016-12-14 14:52:30,243 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 14:52:30,245 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:30,245 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:52:30,245 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 71)
2016-12-14 14:52:30,245 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 70)
2016-12-14 14:52:30,249 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,249 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,249 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:52:30,249 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:52:30,259 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 70). 2300 bytes result sent to driver
2016-12-14 14:52:30,259 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 71). 2300 bytes result sent to driver
2016-12-14 14:52:30,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 71) in 16 ms on localhost (1/2)
2016-12-14 14:52:30,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 70) in 17 ms on localhost (2/2)
2016-12-14 14:52:30,262 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 36 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:52:30,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 37)
2016-12-14 14:52:30,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (ShuffledRDD[55] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:52:30,264 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 2.9 KB, free 399.6 KB)
2016-12-14 14:52:30,268 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 1667.0 B, free 401.2 KB)
2016-12-14 14:52:30,269 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:39109 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:52:30,269 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,270 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 37 (ShuffledRDD[55] at reduceByKey at KMeans.scala:302)
2016-12-14 14:52:30,270 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 2 tasks
2016-12-14 14:52:30,271 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 72, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,272 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 37.0 (TID 73, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,273 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 37.0 (TID 73)
2016-12-14 14:52:30,273 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 72)
2016-12-14 14:52:30,274 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,274 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,275 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,276 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,282 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 72). 1202 bytes result sent to driver
2016-12-14 14:52:30,282 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 37.0 (TID 73). 1240 bytes result sent to driver
2016-12-14 14:52:30,285 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 72) in 14 ms on localhost (1/2)
2016-12-14 14:52:30,285 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 37.0 (TID 73) in 13 ms on localhost (2/2)
2016-12-14 14:52:30,285 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (collectAsMap at KMeans.scala:302) finished in 0.014 s
2016-12-14 14:52:30,285 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,285 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: collectAsMap at KMeans.scala:302, took 0.053988 s
2016-12-14 14:52:30,286 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 10 iterations
2016-12-14 14:52:30,288 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.937 seconds.
2016-12-14 14:52:30,289 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 10 iterations.
2016-12-14 14:52:30,292 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 2367716.0861060848.
2016-12-14 14:52:30,294 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 9 from persistence list
2016-12-14 14:52:30,295 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 14:52:30,299 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:52:30,311 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:108
2016-12-14 14:52:30,311 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (foreach at K_means.scala:108) with 2 output partitions
2016-12-14 14:52:30,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 38 (foreach at K_means.scala:108)
2016-12-14 14:52:30,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 38 (MapPartitionsRDD[8] at map at K_means.scala:102), which has no missing parents
2016-12-14 14:52:30,314 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 4.6 KB, free 400.9 KB)
2016-12-14 14:52:30,318 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.7 KB, free 403.5 KB)
2016-12-14 14:52:30,319 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:39109 (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:52:30,319 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,319 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[8] at map at K_means.scala:102)
2016-12-14 14:52:30,320 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 2 tasks
2016-12-14 14:52:30,321 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 74, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,321 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 38.0 (TID 75, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,322 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 74)
2016-12-14 14:52:30,322 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 38.0 (TID 75)
2016-12-14 14:52:30,325 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,325 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1067.0556874906906,-108.51625428718577] belong to cluster 2
2016-12-14 14:52:30,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-626.0613818015943,-59.52008485465274] belong to cluster 0
2016-12-14 14:52:30,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1051.5901278621598,-81.6594058698266] belong to cluster 2
2016-12-14 14:52:30,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-481.3073749997398,-72.97023346686989] belong to cluster 1
2016-12-14 14:52:30,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1186.553841119994,-80.48681410316806] belong to cluster 2
2016-12-14 14:52:30,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-451.3882935274771,-78.60909193798112] belong to cluster 1
2016-12-14 14:52:30,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1481.7328475535471,-87.21685258436418] belong to cluster 2
2016-12-14 14:52:30,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-496.27882313100343,-71.77255330742169] belong to cluster 1
2016-12-14 14:52:30,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-736.9212797068569,-105.51411816106304] belong to cluster 0
2016-12-14 14:52:30,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-291.4704932605838,-83.32678562606449] belong to cluster 1
2016-12-14 14:52:30,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1451.7238999404728,-86.6919648783193] belong to cluster 2
2016-12-14 14:52:30,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-346.64143411276916,-92.3555237684123] belong to cluster 1
2016-12-14 14:52:30,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1291.4642890693615,-73.50515691121015] belong to cluster 2
2016-12-14 14:52:30,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-939.6761049753039,-145.81788593313698] belong to cluster 0
2016-12-14 14:52:30,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1296.8945680432087,-98.4735559365327] belong to cluster 2
2016-12-14 14:52:30,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-627.2135304490457,-123.44163844253002] belong to cluster 0
2016-12-14 14:52:30,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1046.529571003372,-78.84396571721685] belong to cluster 2
2016-12-14 14:52:30,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-429.40443539808786,-77.83104535743423] belong to cluster 1
2016-12-14 14:52:30,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1046.5422613381963,-79.92258061447627] belong to cluster 2
2016-12-14 14:52:30,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-661.4124156414587,-76.79755086333776] belong to cluster 0
2016-12-14 14:52:30,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1511.5724201440157,-78.68980632657613] belong to cluster 2
2016-12-14 14:52:30,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-407.4518080354334,-81.27355796631441] belong to cluster 1
2016-12-14 14:52:30,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1281.43593593477,-72.73648978239024] belong to cluster 2
2016-12-14 14:52:30,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-711.5610936517796,-84.85370762484945] belong to cluster 0
2016-12-14 14:52:30,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1321.3271185939286,-66.01910922262402] belong to cluster 2
2016-12-14 14:52:30,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-563.4189947087066,-78.50360453438982] belong to cluster 1
2016-12-14 14:52:30,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1151.418066488858,-70.92148833403633] belong to cluster 2
2016-12-14 14:52:30,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-439.61032159027974,-90.775780104985] belong to cluster 1
2016-12-14 14:52:30,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1548.5461020597145,-74.90567636080783] belong to cluster 2
2016-12-14 14:52:30,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-416.4034118198856,-79.14039479951924] belong to cluster 1
2016-12-14 14:52:30,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1311.7382862015543,-89.23895221637811] belong to cluster 2
2016-12-14 14:52:30,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-673.3395704507557,-73.61029560809709] belong to cluster 0
2016-12-14 14:52:30,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1281.8723588386656,-97.82892578627819] belong to cluster 2
2016-12-14 14:52:30,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-316.4829662799191,-84.99117681895092] belong to cluster 1
2016-12-14 14:52:30,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1131.8102992800166,-95.50154336991694] belong to cluster 2
2016-12-14 14:52:30,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-511.2860111155119,-71.46215561971782] belong to cluster 1
2016-12-14 14:52:30,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1681.6110957023343,-78.66964511242995] belong to cluster 2
2016-12-14 14:52:30,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-489.34434046897337,-75.94530720491646] belong to cluster 1
2016-12-14 14:52:30,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-846.8958856787146,-101.41678296587352] belong to cluster 0
2016-12-14 14:52:30,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-313.5349280903914,-86.96459752319261] belong to cluster 1
2016-12-14 14:52:30,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-782.0863022045971,-112.59208005015509] belong to cluster 0
2016-12-14 14:52:30,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-681.5020124326574,-82.4526659126321] belong to cluster 0
2016-12-14 14:52:30,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-771.6391457430324,-88.84159663887723] belong to cluster 0
2016-12-14 14:52:30,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-563.7562696774515,-97.54058671349354] belong to cluster 1
2016-12-14 14:52:30,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1036.5857384201865,-83.06108180337328] belong to cluster 2
2016-12-14 14:52:30,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-326.44983457790494,-82.77920161114395] belong to cluster 1
2016-12-14 14:52:30,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1016.4742207377706,-77.45341953954845] belong to cluster 2
2016-12-14 14:52:30,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-608.6740450414524,-92.75967562698084] belong to cluster 0
2016-12-14 14:52:30,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-846.5125939755575,-81.52827749074356] belong to cluster 0
2016-12-14 14:52:30,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-435.431760039874,-80.85702954164343] belong to cluster 1
2016-12-14 14:52:30,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-831.9914521641198,-109.91574510297418] belong to cluster 0
2016-12-14 14:52:30,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-386.3630750891655,-77.76482815475273] belong to cluster 1
2016-12-14 14:52:30,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1196.4183044251147,-72.22679230208439] belong to cluster 2
2016-12-14 14:52:30,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-408.377701988543,-78.33438912334876] belong to cluster 1
2016-12-14 14:52:30,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1286.4118732241661,-71.63577748814352] belong to cluster 2
2016-12-14 14:52:30,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-496.3832361416917,-77.74825340619208] belong to cluster 1
2016-12-14 14:52:30,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-916.7031758074161,-91.27943451590411] belong to cluster 0
2016-12-14 14:52:30,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-346.79673472101666,-102.4500138206994] belong to cluster 1
2016-12-14 14:52:30,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1036.5009552840324,-78.06439200373835] belong to cluster 2
2016-12-14 14:52:30,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-373.3216158362975,-73.8390732986956] belong to cluster 1
2016-12-14 14:52:30,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1286.5191603049518,-78.81138473173706] belong to cluster 2
2016-12-14 14:52:30,339 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-565.394779020894,-77.470579233764] belong to cluster 1
2016-12-14 14:52:30,339 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1516.5856470581373,-79.6442261779063] belong to cluster 2
2016-12-14 14:52:30,339 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-626.547466854331,-85.4352292747518] belong to cluster 0
2016-12-14 14:52:30,339 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-991.6434591046713,-86.88020862538541] belong to cluster 2
2016-12-14 14:52:30,339 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-466.9581390829936,-111.53238473852751] belong to cluster 1
2016-12-14 14:52:30,340 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1237.0939882479997,-110.58944859610884] belong to cluster 2
2016-12-14 14:52:30,340 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-366.66592996852074,-96.2132333083682] belong to cluster 1
2016-12-14 14:52:30,340 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1096.7237151995973,-91.06220370200253] belong to cluster 2
2016-12-14 14:52:30,340 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-381.40332815678255,-79.83590766250558] belong to cluster 1
2016-12-14 14:52:30,340 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-921.5726656288535,-84.2312019027731] belong to cluster 0
2016-12-14 14:52:30,341 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-381.3355335061613,-75.82780333102973] belong to cluster 1
2016-12-14 14:52:30,341 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-881.7791317493552,-94.79685312806912] belong to cluster 0
2016-12-14 14:52:30,341 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-379.38910723615265,-78.8483186409263] belong to cluster 1
2016-12-14 14:52:30,341 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1106.5112673780438,-78.8661394348228] belong to cluster 2
2016-12-14 14:52:30,341 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-353.41387174581365,-80.34429167898047] belong to cluster 1
2016-12-14 14:52:30,341 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1021.5371397241867,-80.29904924528506] belong to cluster 2
2016-12-14 14:52:30,342 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-467.46233949367235,-84.48826348501314] belong to cluster 1
2016-12-14 14:52:30,342 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-762.1357103161167,-114.87095570030766] belong to cluster 0
2016-12-14 14:52:30,342 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-343.4314203998971,-82.57304988324873] belong to cluster 1
2016-12-14 14:52:30,342 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-796.9223504526663,-103.3460733127563] belong to cluster 0
2016-12-14 14:52:30,342 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-581.2550663851083,-70.29293782784163] belong to cluster 1
2016-12-14 14:52:30,343 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1036.3768003717655,-72.13900501762244] belong to cluster 2
2016-12-14 14:52:30,343 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-632.0197078437067,-111.29014361250229] belong to cluster 0
2016-12-14 14:52:30,343 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1096.5880563832052,-81.98069746416098] belong to cluster 2
2016-12-14 14:52:30,343 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-531.7081682246304,-95.15457310838002] belong to cluster 1
2016-12-14 14:52:30,343 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-681.6780528166574,-91.40895347089466] belong to cluster 0
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-561.5775962371325,-88.73418090773374] belong to cluster 1
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-886.7197180861989,-91.75481191238332] belong to cluster 0
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-601.7231785778847,-95.9444576658962] belong to cluster 0
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1081.7475140319275,-92.3434547109388] belong to cluster 2
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-651.3597346048152,-73.9658397252821] belong to cluster 0
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1066.6045566694045,-83.53717861362811] belong to cluster 2
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-696.5106613355338,-82.21183045491088] belong to cluster 0
2016-12-14 14:52:30,344 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-986.6041932814663,-83.972602551034] belong to cluster 2
2016-12-14 14:52:30,345 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-721.3947774529162,-76.79412732872902] belong to cluster 0
2016-12-14 14:52:30,345 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1061.6126235905847,-84.7187603887732] belong to cluster 2
2016-12-14 14:52:30,345 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-516.5411741321229,-87.55903096203143] belong to cluster 1
2016-12-14 14:52:30,345 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1261.6804562239379,-86.16036431655073] belong to cluster 2
2016-12-14 14:52:30,345 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-581.4164624382113,-78.26740044100536] belong to cluster 1
2016-12-14 14:52:30,345 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1151.431725361706,-71.97082070330555] belong to cluster 2
2016-12-14 14:52:30,346 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-591.6246636598902,-91.18728604037695] belong to cluster 1
2016-12-14 14:52:30,346 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1266.4216714682334,-72.02656866412343] belong to cluster 2
2016-12-14 14:52:30,346 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-601.546218622202,-85.92739458820486] belong to cluster 0
2016-12-14 14:52:30,346 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1191.7591194976694,-90.28462559634369] belong to cluster 2
2016-12-14 14:52:30,346 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-781.3970009516398,-75.71875791682861] belong to cluster 0
2016-12-14 14:52:30,346 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1376.778779187868,-91.06526893344625] belong to cluster 2
2016-12-14 14:52:30,347 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-521.5664985170896,-88.41240191929303] belong to cluster 1
2016-12-14 14:52:30,347 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1061.8903208783827,-99.63303706741986] belong to cluster 2
2016-12-14 14:52:30,347 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-551.4883607087348,-82.79569485687696] belong to cluster 1
2016-12-14 14:52:30,347 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1121.8259994251264,-96.68832217876648] belong to cluster 2
2016-12-14 14:52:30,347 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-856.8053855059657,-97.37545399543913] belong to cluster 0
2016-12-14 14:52:30,347 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-971.9098145606894,-101.24101596404594] belong to cluster 2
2016-12-14 14:52:30,348 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-831.6109708152532,-87.83099324782688] belong to cluster 0
2016-12-14 14:52:30,348 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1271.565559599372,-79.92749829668122] belong to cluster 2
2016-12-14 14:52:30,348 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-416.29686821265284,-73.21082465962817] belong to cluster 1
2016-12-14 14:52:30,348 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1286.674805525687,-85.66734342429967] belong to cluster 2
2016-12-14 14:52:30,348 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-626.3666161148717,-75.55419769185353] belong to cluster 0
2016-12-14 14:52:30,349 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-521.4600177502954,-79.0291555839736] belong to cluster 1
2016-12-14 14:52:30,349 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-651.4733189346213,-81.1176809759916] belong to cluster 0
2016-12-14 14:52:30,349 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-681.6425862055281,-89.34399008912261] belong to cluster 0
2016-12-14 14:52:30,349 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-551.8679015986249,-103.897237475891] belong to cluster 1
2016-12-14 14:52:30,349 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-451.668271311314,-92.4925992499902] belong to cluster 1
2016-12-14 14:52:30,350 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-502.0435089708449,-114.83421893080566] belong to cluster 1
2016-12-14 14:52:30,350 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-631.5222356209091,-83.29774012951259] belong to cluster 0
2016-12-14 14:52:30,350 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-481.86392015294973,-104.17435554810051] belong to cluster 1
2016-12-14 14:52:30,350 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-421.4335826075975,-80.07599274413204] belong to cluster 1
2016-12-14 14:52:30,350 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-426.9219672675265,-109.18846364881536] belong to cluster 1
2016-12-14 14:52:30,350 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-356.7402217667202,-98.19580180895478] belong to cluster 1
2016-12-14 14:52:30,351 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-676.5950494964368,-86.62446715103866] belong to cluster 0
2016-12-14 14:52:30,351 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-679.5869477600613,-86.46550301536936] belong to cluster 0
2016-12-14 14:52:30,351 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-641.6760904014349,-92.23024661669106] belong to cluster 0
2016-12-14 14:52:30,351 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-503.28018422565947,-69.53048425264288] belong to cluster 1
2016-12-14 14:52:30,351 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-726.472451404177,-80.79468429668806] belong to cluster 0
2016-12-14 14:52:30,351 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-511.25129791023176,-69.49309800132089] belong to cluster 1
2016-12-14 14:52:30,351 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-481.4609758971032,-81.10103440698292] belong to cluster 1
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-751.7888641937614,-97.11993515367759] belong to cluster 0
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-881.4925494549075,-82.15641811223844] belong to cluster 0
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-720.5265874722458,-138.6542487392046] belong to cluster 0
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-661.5787096118423,-87.10375932716215] belong to cluster 0
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-871.6228465113504,-88.08395806766858] belong to cluster 0
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-621.4314185514767,-78.73270670911177] belong to cluster 0
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-411.38858571475214,-79.40026843038041] belong to cluster 1
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-521.4238724509677,-79.40549325198108] belong to cluster 1
2016-12-14 14:52:30,352 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-473.3966823230744,-79.2709714207073] belong to cluster 1
2016-12-14 14:52:30,353 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-681.7372770263587,-95.4944134495864] belong to cluster 0
2016-12-14 14:52:30,353 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-987.2094647516482,-122.27595092149959] belong to cluster 2
2016-12-14 14:52:30,353 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-571.7276097776197,-96.49731355415626] belong to cluster 1
2016-12-14 14:52:30,353 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-887.5867648427435,-85.81664735434181] belong to cluster 0
2016-12-14 14:52:30,353 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-676.7243102703435,-94.53476139357936] belong to cluster 0
2016-12-14 14:52:30,353 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-429.61637930042997,-89.8348946848454] belong to cluster 1
2016-12-14 14:52:30,354 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-616.4444598422406,-79.7690932388765] belong to cluster 0
2016-12-14 14:52:30,354 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-393.4324556886084,-79.49342172037888] belong to cluster 1
2016-12-14 14:52:30,354 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-521.4148636494582,-79.4307442478231] belong to cluster 1
2016-12-14 14:52:30,354 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-501.85911075086443,-103.58256020353393] belong to cluster 1
2016-12-14 14:52:30,354 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-696.8032017428163,-99.38220852537219] belong to cluster 0
2016-12-14 14:52:30,354 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-752.2643978583104,-123.05521591611499] belong to cluster 0
2016-12-14 14:52:30,355 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-686.4076970783632,-76.4701082549934] belong to cluster 0
2016-12-14 14:52:30,355 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-464.65046055801395,-93.38598435776416] belong to cluster 1
2016-12-14 14:52:30,355 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-751.6754728561876,-92.41548505295535] belong to cluster 0
2016-12-14 14:52:30,355 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-279.43335789350795,-81.56519957363363] belong to cluster 1
2016-12-14 14:52:30,355 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-631.8178901532403,-101.55749389850901] belong to cluster 0
2016-12-14 14:52:30,355 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-715.3613689566122,-73.83701859545484] belong to cluster 0
2016-12-14 14:52:30,356 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-511.571500260898,-87.4871605496296] belong to cluster 1
2016-12-14 14:52:30,356 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-631.2023161929851,-67.44551108505689] belong to cluster 0
2016-12-14 14:52:30,356 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-471.4091299489527,-78.28379165784487] belong to cluster 1
2016-12-14 14:52:30,356 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-516.3597198186238,-76.49402029257749] belong to cluster 1
2016-12-14 14:52:30,356 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-661.4653055713017,-79.91952780236802] belong to cluster 0
2016-12-14 14:52:30,356 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-521.5394087826562,-85.24806476124215] belong to cluster 1
2016-12-14 14:52:30,357 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-741.5124972446811,-82.48298698245276] belong to cluster 0
2016-12-14 14:52:30,357 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-451.64055646839313,-91.47692664156718] belong to cluster 1
2016-12-14 14:52:30,357 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-751.6243128814715,-89.35931406309254] belong to cluster 0
2016-12-14 14:52:30,357 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-496.44631627434273,-81.81150596481541] belong to cluster 1
2016-12-14 14:52:30,357 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-836.9507818888032,-105.80040810943301] belong to cluster 0
2016-12-14 14:52:30,358 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-563.3838508292906,-78.70554152890688] belong to cluster 1
2016-12-14 14:52:30,358 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-841.9489500567971,-105.69494267477128] belong to cluster 0
2016-12-14 14:52:30,358 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-681.3119563583099,-72.49943333450318] belong to cluster 0
2016-12-14 14:52:30,358 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-561.5495179295699,-86.81079274790021] belong to cluster 1
2016-12-14 14:52:30,360 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 74). 2057 bytes result sent to driver
2016-12-14 14:52:30,360 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 38.0 (TID 75). 2057 bytes result sent to driver
2016-12-14 14:52:30,362 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 74) in 41 ms on localhost (1/2)
2016-12-14 14:52:30,362 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 38.0 (TID 75) in 41 ms on localhost (2/2)
2016-12-14 14:52:30,362 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 38 (foreach at K_means.scala:108) finished in 0.042 s
2016-12-14 14:52:30,362 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,362 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: foreach at K_means.scala:108, took 0.051305 s
2016-12-14 14:52:30,373 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 14:52:30,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (first at PCA.scala:42) with 1 output partitions
2016-12-14 14:52:30,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (first at PCA.scala:42)
2016-12-14 14:52:30,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,375 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (MapPartitionsRDD[56] at map at K_means.scala:113), which has no missing parents
2016-12-14 14:52:30,378 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 3.6 KB, free 407.1 KB)
2016-12-14 14:52:30,383 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.1 KB, free 409.2 KB)
2016-12-14 14:52:30,384 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:39109 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:52:30,385 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,385 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[56] at map at K_means.scala:113)
2016-12-14 14:52:30,386 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 1 tasks
2016-12-14 14:52:30,387 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 76, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,388 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 76)
2016-12-14 14:52:30,390 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,393 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 76). 2248 bytes result sent to driver
2016-12-14 14:52:30,398 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 76) in 10 ms on localhost (1/1)
2016-12-14 14:52:30,398 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (first at PCA.scala:42) finished in 0.012 s
2016-12-14 14:52:30,398 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,398 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: first at PCA.scala:42, took 0.025405 s
2016-12-14 14:52:30,404 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 14:52:30,405 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 14:52:30,406 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 40 (first at RowMatrix.scala:61)
2016-12-14 14:52:30,406 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,406 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,407 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 40 (MapPartitionsRDD[56] at map at K_means.scala:113), which has no missing parents
2016-12-14 14:52:30,408 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 3.6 KB, free 412.8 KB)
2016-12-14 14:52:30,413 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.1 KB, free 414.9 KB)
2016-12-14 14:52:30,413 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:39109 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:52:30,414 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,414 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[56] at map at K_means.scala:113)
2016-12-14 14:52:30,415 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 1 tasks
2016-12-14 14:52:30,415 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 77, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,416 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 77)
2016-12-14 14:52:30,418 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,421 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 77). 2248 bytes result sent to driver
2016-12-14 14:52:30,425 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 77) in 10 ms on localhost (1/1)
2016-12-14 14:52:30,425 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 40 (first at RowMatrix.scala:61) finished in 0.010 s
2016-12-14 14:52:30,426 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,426 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: first at RowMatrix.scala:61, took 0.021295 s
2016-12-14 14:52:30,429 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 14:52:30,430 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 14:52:30,430 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (treeAggregate at RowMatrix.scala:331)
2016-12-14 14:52:30,430 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,431 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,432 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (MapPartitionsRDD[57] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 14:52:30,433 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 4.6 KB, free 419.5 KB)
2016-12-14 14:52:30,437 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KB, free 422.0 KB)
2016-12-14 14:52:30,437 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:39109 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:52:30,438 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,438 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 41 (MapPartitionsRDD[57] at treeAggregate at RowMatrix.scala:331)
2016-12-14 14:52:30,439 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 14:52:30,440 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 78, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,440 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 79, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,440 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 78)
2016-12-14 14:52:30,440 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 79)
2016-12-14 14:52:30,442 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,442 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,445 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 79). 2208 bytes result sent to driver
2016-12-14 14:52:30,448 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 79) in 8 ms on localhost (1/2)
2016-12-14 14:52:30,450 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 78). 2208 bytes result sent to driver
2016-12-14 14:52:30,452 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 78) in 13 ms on localhost (2/2)
2016-12-14 14:52:30,452 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,453 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (treeAggregate at RowMatrix.scala:331) finished in 0.013 s
2016-12-14 14:52:30,453 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: treeAggregate at RowMatrix.scala:331, took 0.023647 s
2016-12-14 14:52:30,457 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 14:52:30,457 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 31 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 14:52:30,457 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 42 (treeAggregate at RowMatrix.scala:121)
2016-12-14 14:52:30,458 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,458 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 42 (MapPartitionsRDD[58] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 14:52:30,460 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 5.2 KB, free 427.2 KB)
2016-12-14 14:52:30,464 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.5 KB, free 429.7 KB)
2016-12-14 14:52:30,464 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:39109 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:52:30,465 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[58] at treeAggregate at RowMatrix.scala:121)
2016-12-14 14:52:30,466 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 14:52:30,467 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 80, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,467 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 81, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,467 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 80)
2016-12-14 14:52:30,467 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 81)
2016-12-14 14:52:30,468 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,469 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,470 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 81). 2831 bytes result sent to driver
2016-12-14 14:52:30,472 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 80). 2831 bytes result sent to driver
2016-12-14 14:52:30,474 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 81) in 7 ms on localhost (1/2)
2016-12-14 14:52:30,475 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 80) in 9 ms on localhost (2/2)
2016-12-14 14:52:30,475 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,475 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 42 (treeAggregate at RowMatrix.scala:121) finished in 0.009 s
2016-12-14 14:52:30,476 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 31 finished: treeAggregate at RowMatrix.scala:121, took 0.018916 s
2016-12-14 14:52:30,487 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:119
2016-12-14 14:52:30,488 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 32 (foreach at K_means.scala:119) with 2 output partitions
2016-12-14 14:52:30,488 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 43 (foreach at K_means.scala:119)
2016-12-14 14:52:30,488 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,489 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,489 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 43 (MapPartitionsRDD[60] at map at K_means.scala:115), which has no missing parents
2016-12-14 14:52:30,491 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 4.5 KB, free 434.2 KB)
2016-12-14 14:52:30,494 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.7 KB, free 436.9 KB)
2016-12-14 14:52:30,495 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:39109 (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:52:30,496 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,496 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[60] at map at K_means.scala:115)
2016-12-14 14:52:30,496 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 14:52:30,497 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 82, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,498 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 83, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,499 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 83)
2016-12-14 14:52:30,499 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 82)
2016-12-14 14:52:30,500 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,501 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,501 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,501 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,501 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,501 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,501 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,501 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,502 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,502 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,502 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,502 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,502 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,502 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,503 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,503 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,503 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,503 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,503 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,503 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,503 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,504 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,504 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,504 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,504 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,504 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,504 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,504 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,505 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,505 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,505 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,505 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,505 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,505 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,506 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,506 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,506 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,506 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,506 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,506 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,507 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,508 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,508 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,508 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,508 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,508 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,508 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,509 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,509 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,509 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,509 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,509 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,509 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,509 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,510 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,510 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,510 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,510 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,510 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,510 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,511 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,511 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,511 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,511 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,511 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,511 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,511 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,512 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,512 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,512 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,512 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,512 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,512 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,513 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,514 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,514 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,514 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,514 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,514 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,514 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 0.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,515 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,516 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,516 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,516 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,516 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,516 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,516 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,517 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,517 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,517 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,517 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,517 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,517 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,517 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,518 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,518 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,518 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,518 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,518 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,518 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,519 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,519 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 14:52:30,519 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,519 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,519 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,520 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,520 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,520 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,520 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,520 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,520 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,521 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,521 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,521 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,521 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,521 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,521 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,522 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,522 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,522 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,522 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,522 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,522 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,523 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,523 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,523 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,523 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,523 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,523 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,524 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,524 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,524 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:52:30,524 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,524 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,525 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,525 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,525 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,525 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,525 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,525 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,526 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,526 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,526 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,526 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,526 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,526 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,527 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,527 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,527 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,527 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,527 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,528 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,528 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:52:30,528 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,528 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 14:52:30,528 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,529 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,529 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 14:52:30,529 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:52:30,531 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 83). 2057 bytes result sent to driver
2016-12-14 14:52:30,531 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 82). 2057 bytes result sent to driver
2016-12-14 14:52:30,533 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 83) in 35 ms on localhost (1/2)
2016-12-14 14:52:30,533 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 82) in 36 ms on localhost (2/2)
2016-12-14 14:52:30,533 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 43 (foreach at K_means.scala:119) finished in 0.036 s
2016-12-14 14:52:30,533 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,534 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 32 finished: foreach at K_means.scala:119, took 0.046622 s
2016-12-14 14:52:30,555 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:13
2016-12-14 14:52:30,556 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 61 (map at Relabel.scala:13)
2016-12-14 14:52:30,557 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 33 (sortBy at Relabel.scala:13) with 2 output partitions
2016-12-14 14:52:30,557 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 45 (sortBy at Relabel.scala:13)
2016-12-14 14:52:30,557 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 44)
2016-12-14 14:52:30,557 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 44)
2016-12-14 14:52:30,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 44 (MapPartitionsRDD[61] at map at Relabel.scala:13), which has no missing parents
2016-12-14 14:52:30,560 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 5.4 KB, free 442.2 KB)
2016-12-14 14:52:30,565 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.1 KB, free 445.3 KB)
2016-12-14 14:52:30,566 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:39109 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:52:30,566 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,567 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[61] at map at Relabel.scala:13)
2016-12-14 14:52:30,567 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 2 tasks
2016-12-14 14:52:30,570 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 84, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:52:30,570 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 44.0 (TID 85, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:52:30,571 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 84)
2016-12-14 14:52:30,571 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 44.0 (TID 85)
2016-12-14 14:52:30,574 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,574 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,584 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 44.0 (TID 85). 2237 bytes result sent to driver
2016-12-14 14:52:30,586 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 44.0 (TID 85) in 16 ms on localhost (1/2)
2016-12-14 14:52:30,587 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 84). 2237 bytes result sent to driver
2016-12-14 14:52:30,588 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 84) in 19 ms on localhost (2/2)
2016-12-14 14:52:30,589 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 44 (map at Relabel.scala:13) finished in 0.020 s
2016-12-14 14:52:30,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 45)
2016-12-14 14:52:30,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,590 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 45 (MapPartitionsRDD[65] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:52:30,592 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 3.5 KB, free 448.9 KB)
2016-12-14 14:52:30,596 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2020.0 B, free 450.9 KB)
2016-12-14 14:52:30,596 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:39109 (size: 2020.0 B, free: 529.9 MB)
2016-12-14 14:52:30,597 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,597 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[65] at sortBy at Relabel.scala:13)
2016-12-14 14:52:30,597 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 45.0 with 2 tasks
2016-12-14 14:52:30,598 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 45.0 (TID 86, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,599 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 45.0 (TID 87, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,600 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 45.0 (TID 87)
2016-12-14 14:52:30,600 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 45.0 (TID 86)
2016-12-14 14:52:30,602 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,602 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,602 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,603 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,611 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 45.0 (TID 87). 1168 bytes result sent to driver
2016-12-14 14:52:30,611 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 45.0 (TID 86). 1160 bytes result sent to driver
2016-12-14 14:52:30,612 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 45.0 (TID 87) in 13 ms on localhost (1/2)
2016-12-14 14:52:30,612 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 45.0 (TID 86) in 14 ms on localhost (2/2)
2016-12-14 14:52:30,613 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 45 (sortBy at Relabel.scala:13) finished in 0.015 s
2016-12-14 14:52:30,613 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,613 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 33 finished: sortBy at Relabel.scala:13, took 0.058045 s
2016-12-14 14:52:30,629 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 14:52:30,632 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 11 is 155 bytes
2016-12-14 14:52:30,635 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 63 (sortBy at Relabel.scala:13)
2016-12-14 14:52:30,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 34 (collect at Relabel.scala:14) with 2 output partitions
2016-12-14 14:52:30,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 48 (collect at Relabel.scala:14)
2016-12-14 14:52:30,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 47)
2016-12-14 14:52:30,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 47)
2016-12-14 14:52:30,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 47 (MapPartitionsRDD[63] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:52:30,641 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 3.6 KB, free 454.4 KB)
2016-12-14 14:52:30,644 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.0 KB, free 456.4 KB)
2016-12-14 14:52:30,645 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:39109 (size: 2.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,646 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,646 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[63] at sortBy at Relabel.scala:13)
2016-12-14 14:52:30,646 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 47.0 with 2 tasks
2016-12-14 14:52:30,647 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 47.0 (TID 88, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 14:52:30,648 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 47.0 (TID 89, localhost, partition 1,NODE_LOCAL, 2132 bytes)
2016-12-14 14:52:30,648 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 47.0 (TID 89)
2016-12-14 14:52:30,648 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 47.0 (TID 88)
2016-12-14 14:52:30,656 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,656 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,657 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,657 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,677 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 47.0 (TID 89). 1303 bytes result sent to driver
2016-12-14 14:52:30,677 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 47.0 (TID 88). 1303 bytes result sent to driver
2016-12-14 14:52:30,679 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 47.0 (TID 88) in 32 ms on localhost (1/2)
2016-12-14 14:52:30,679 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 47.0 (TID 89) in 31 ms on localhost (2/2)
2016-12-14 14:52:30,679 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,679 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 47 (sortBy at Relabel.scala:13) finished in 0.032 s
2016-12-14 14:52:30,679 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 48)
2016-12-14 14:52:30,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 48 (MapPartitionsRDD[67] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:52:30,682 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64 stored as values in memory (estimated size 3.4 KB, free 459.8 KB)
2016-12-14 14:52:30,686 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64_piece0 stored as bytes in memory (estimated size 1948.0 B, free 461.7 KB)
2016-12-14 14:52:30,687 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_64_piece0 in memory on localhost:39109 (size: 1948.0 B, free: 529.9 MB)
2016-12-14 14:52:30,687 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,688 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 48 (MapPartitionsRDD[67] at sortBy at Relabel.scala:13)
2016-12-14 14:52:30,688 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 48.0 with 2 tasks
2016-12-14 14:52:30,689 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 48.0 (TID 90, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,689 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 48.0 (TID 91, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,689 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 48.0 (TID 90)
2016-12-14 14:52:30,689 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 48.0 (TID 91)
2016-12-14 14:52:30,696 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,697 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,697 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,697 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,719 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 48.0 (TID 90). 1211 bytes result sent to driver
2016-12-14 14:52:30,719 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 48.0 (TID 91). 1240 bytes result sent to driver
2016-12-14 14:52:30,721 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 48.0 (TID 90) in 32 ms on localhost (1/2)
2016-12-14 14:52:30,721 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 48.0 (TID 91) in 32 ms on localhost (2/2)
2016-12-14 14:52:30,721 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,722 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 48 (collect at Relabel.scala:14) finished in 0.033 s
2016-12-14 14:52:30,722 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 34 finished: collect at Relabel.scala:14, took 0.093201 s
2016-12-14 14:52:30,731 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:123
2016-12-14 14:52:30,732 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 35 (foreach at K_means.scala:123) with 2 output partitions
2016-12-14 14:52:30,732 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 49 (foreach at K_means.scala:123)
2016-12-14 14:52:30,733 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,733 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,734 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 49 (MapPartitionsRDD[68] at map at Relabel.scala:31), which has no missing parents
2016-12-14 14:52:30,735 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65 stored as values in memory (estimated size 5.0 KB, free 466.7 KB)
2016-12-14 14:52:30,739 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.9 KB, free 469.6 KB)
