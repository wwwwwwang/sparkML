2016-12-14 14:52:30,741 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_65_piece0 in memory on localhost:39109 (size: 2.9 KB, free: 529.9 MB)
2016-12-14 14:52:30,742 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[68] at map at Relabel.scala:31)
2016-12-14 14:52:30,743 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 49.0 with 2 tasks
2016-12-14 14:52:30,744 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 49.0 (TID 92, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,744 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 49.0 (TID 93, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,745 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 49.0 (TID 92)
2016-12-14 14:52:30,745 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 49.0 (TID 93)
2016-12-14 14:52:30,747 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,748 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,748 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,748 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,748 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,748 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,748 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,749 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,749 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,749 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,749 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,749 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,749 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,750 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,750 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,750 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,750 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,750 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,750 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,751 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,751 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,751 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,751 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,751 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,751 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,751 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,752 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,752 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,752 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,752 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,752 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,752 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,752 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,753 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,753 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,753 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,753 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,753 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,753 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,754 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,754 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,754 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,754 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,754 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,754 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,755 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,755 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,755 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,755 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,755 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,755 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,755 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,756 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,756 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,756 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,756 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,756 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,756 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,756 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,757 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,757 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,757 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,757 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,757 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,757 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,758 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,758 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,758 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,758 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,758 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,758 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,759 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,759 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,759 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,759 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,759 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,759 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,759 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,760 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,761 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,761 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 2.0
2016-12-14 14:52:30,761 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,761 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,761 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,761 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,761 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,762 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,763 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,764 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,765 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,766 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,766 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,766 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,766 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,766 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,766 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,766 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,767 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,768 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,769 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,770 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,771 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:52:30,772 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,772 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:52:30,772 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,772 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:52:30,772 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:52:30,773 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 49.0 (TID 92). 2057 bytes result sent to driver
2016-12-14 14:52:30,774 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 49.0 (TID 93). 2057 bytes result sent to driver
2016-12-14 14:52:30,775 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 49.0 (TID 92) in 31 ms on localhost (1/2)
2016-12-14 14:52:30,775 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 49.0 (TID 93) in 31 ms on localhost (2/2)
2016-12-14 14:52:30,776 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 49 (foreach at K_means.scala:123) finished in 0.031 s
2016-12-14 14:52:30,776 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,776 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 35 finished: foreach at K_means.scala:123, took 0.044635 s
2016-12-14 14:52:30,787 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 14:52:30,788 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 69 (map at MulticlassMetrics.scala:46)
2016-12-14 14:52:30,789 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 36 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 14:52:30,789 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 51 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 14:52:30,789 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 50)
2016-12-14 14:52:30,789 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 50)
2016-12-14 14:52:30,790 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 50 (MapPartitionsRDD[69] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 14:52:30,792 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66 stored as values in memory (estimated size 5.9 KB, free 475.4 KB)
2016-12-14 14:52:30,796 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.3 KB, free 478.8 KB)
2016-12-14 14:52:30,797 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_66_piece0 in memory on localhost:39109 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:52:30,797 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[69] at map at MulticlassMetrics.scala:46)
2016-12-14 14:52:30,798 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 50.0 with 2 tasks
2016-12-14 14:52:30,799 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 50.0 (TID 94, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:52:30,799 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 50.0 (TID 95, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:52:30,799 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 50.0 (TID 94)
2016-12-14 14:52:30,799 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 50.0 (TID 95)
2016-12-14 14:52:30,802 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,802 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,822 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 50.0 (TID 94). 2237 bytes result sent to driver
2016-12-14 14:52:30,824 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 81
2016-12-14 14:52:30,825 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 50.0 (TID 95). 2237 bytes result sent to driver
2016-12-14 14:52:30,825 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 14:52:30,826 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 50.0 (TID 94) in 27 ms on localhost (1/2)
2016-12-14 14:52:30,826 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 9
2016-12-14 14:52:30,827 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_65_piece0 on localhost:39109 in memory (size: 2.9 KB, free: 529.9 MB)
2016-12-14 14:52:30,827 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 98
2016-12-14 14:52:30,828 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 50 (map at MulticlassMetrics.scala:46) finished in 0.029 s
2016-12-14 14:52:30,828 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 50.0 (TID 95) in 28 ms on localhost (2/2)
2016-12-14 14:52:30,828 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,828 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 50.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,828 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,828 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_64_piece0 on localhost:39109 in memory (size: 1948.0 B, free: 529.9 MB)
2016-12-14 14:52:30,829 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 51)
2016-12-14 14:52:30,829 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,829 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 97
2016-12-14 14:52:30,829 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 51 (ShuffledRDD[70] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 14:52:30,830 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_63_piece0 on localhost:39109 in memory (size: 2.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,830 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 96
2016-12-14 14:52:30,830 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 12
2016-12-14 14:52:30,830 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67 stored as values in memory (estimated size 2.6 KB, free 462.7 KB)
2016-12-14 14:52:30,831 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_62_piece0 on localhost:39109 in memory (size: 2020.0 B, free: 529.9 MB)
2016-12-14 14:52:30,831 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 14:52:30,831 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 14:52:30,831 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 14:52:30,832 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:39109 in memory (size: 371.0 B, free: 529.9 MB)
2016-12-14 14:52:30,833 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 14:52:30,833 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 14:52:30,833 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 14:52:30,833 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67_piece0 stored as bytes in memory (estimated size 1592.0 B, free 457.6 KB)
2016-12-14 14:52:30,833 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_67_piece0 in memory on localhost:39109 (size: 1592.0 B, free: 529.9 MB)
2016-12-14 14:52:30,834 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:39109 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,834 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,834 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 14:52:30,834 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 51 (ShuffledRDD[70] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 14:52:30,834 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 51.0 with 2 tasks
2016-12-14 14:52:30,835 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,835 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 14:52:30,835 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 51.0 (TID 96, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,835 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 14:52:30,836 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 51.0 (TID 97, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:52:30,836 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:39109 in memory (size: 429.0 B, free: 529.9 MB)
2016-12-14 14:52:30,836 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 51.0 (TID 96)
2016-12-14 14:52:30,836 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 51.0 (TID 97)
2016-12-14 14:52:30,837 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 14:52:30,837 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 84
2016-12-14 14:52:30,837 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,838 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 83
2016-12-14 14:52:30,838 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 14:52:30,838 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,838 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,838 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:39109 in memory (size: 287.0 B, free: 529.9 MB)
2016-12-14 14:52:30,838 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,838 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:52:30,839 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 82
2016-12-14 14:52:30,839 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:39109 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,840 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 14:52:30,840 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,840 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 14:52:30,840 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 14:52:30,841 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 88
2016-12-14 14:52:30,841 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:39109 in memory (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:52:30,841 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 87
2016-12-14 14:52:30,842 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:39109 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:52:30,842 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 86
2016-12-14 14:52:30,842 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 51.0 (TID 97). 1124 bytes result sent to driver
2016-12-14 14:52:30,842 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 14:52:30,842 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 51.0 (TID 96). 1163 bytes result sent to driver
2016-12-14 14:52:30,843 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:39109 in memory (size: 200.0 B, free: 529.9 MB)
2016-12-14 14:52:30,843 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 85
2016-12-14 14:52:30,844 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 51.0 (TID 97) in 7 ms on localhost (1/2)
2016-12-14 14:52:30,844 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 51.0 (TID 96) in 9 ms on localhost (2/2)
2016-12-14 14:52:30,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 51 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.009 s
2016-12-14 14:52:30,844 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 51.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,844 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:39109 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:52:30,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 36 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.057092 s
2016-12-14 14:52:30,845 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 11
2016-12-14 14:52:30,846 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_60_piece0 on localhost:39109 in memory (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:52:30,847 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 93
2016-12-14 14:52:30,848 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_59_piece0 on localhost:39109 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:52:30,848 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 92
2016-12-14 14:52:30,849 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_58_piece0 on localhost:39109 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:52:30,850 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 91
2016-12-14 14:52:30,850 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_57_piece0 on localhost:39109 in memory (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:52:30,851 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 90
2016-12-14 14:52:30,852 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_56_piece0 on localhost:39109 in memory (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:52:30,852 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 89
2016-12-14 14:52:30,853 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_55_piece0 on localhost:39109 in memory (size: 2.7 KB, free: 530.0 MB)
2016-12-14 14:52:30,853 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 95
2016-12-14 14:52:30,854 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_61_piece0 on localhost:39109 in memory (size: 3.1 KB, free: 530.0 MB)
2016-12-14 14:52:30,854 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 94
2016-12-14 14:52:30,860 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 14:52:30,860 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 73 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:52:30,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 37 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 14:52:30,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 53 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:52:30,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 52)
2016-12-14 14:52:30,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 52)
2016-12-14 14:52:30,862 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 52 (MapPartitionsRDD[73] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:52:30,863 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68 stored as values in memory (estimated size 6.4 KB, free 349.3 KB)
2016-12-14 14:52:30,866 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.5 KB, free 352.9 KB)
2016-12-14 14:52:30,866 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_68_piece0 in memory on localhost:39109 (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:52:30,867 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,867 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[73] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:52:30,867 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 52.0 with 2 tasks
2016-12-14 14:52:30,868 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 52.0 (TID 98, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:52:30,869 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 52.0 (TID 99, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:52:30,869 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 52.0 (TID 99)
2016-12-14 14:52:30,869 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 52.0 (TID 98)
2016-12-14 14:52:30,871 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,871 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,876 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 52.0 (TID 98). 2237 bytes result sent to driver
2016-12-14 14:52:30,877 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 52.0 (TID 99). 2237 bytes result sent to driver
2016-12-14 14:52:30,880 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 52.0 (TID 99) in 11 ms on localhost (1/2)
2016-12-14 14:52:30,881 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 52.0 (TID 98) in 13 ms on localhost (2/2)
2016-12-14 14:52:30,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 52 (countByValue at MulticlassMetrics.scala:43) finished in 0.013 s
2016-12-14 14:52:30,881 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 52.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:52:30,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:52:30,882 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 53)
2016-12-14 14:52:30,882 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:52:30,882 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 53 (ShuffledRDD[74] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:52:30,883 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_69 stored as values in memory (estimated size 2.6 KB, free 355.5 KB)
2016-12-14 14:52:30,885 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_69_piece0 stored as bytes in memory (estimated size 1561.0 B, free 357.0 KB)
2016-12-14 14:52:30,885 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_69_piece0 in memory on localhost:39109 (size: 1561.0 B, free: 529.9 MB)
2016-12-14 14:52:30,886 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,886 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 53 (ShuffledRDD[74] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:52:30,886 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 53.0 with 2 tasks
2016-12-14 14:52:30,887 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 53.0 (TID 100, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:52:30,888 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 53.0 (TID 101, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:52:30,888 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 53.0 (TID 100)
2016-12-14 14:52:30,888 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 53.0 (TID 101)
2016-12-14 14:52:30,890 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,890 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,890 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:52:30,891 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:52:30,893 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 53.0 (TID 101). 1124 bytes result sent to driver
2016-12-14 14:52:30,894 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 53.0 (TID 101) in 6 ms on localhost (1/2)
2016-12-14 14:52:30,898 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 53.0 (TID 100). 1164 bytes result sent to driver
2016-12-14 14:52:30,901 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 53.0 (TID 100) in 14 ms on localhost (2/2)
2016-12-14 14:52:30,901 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 53 (countByValue at MulticlassMetrics.scala:43) finished in 0.014 s
2016-12-14 14:52:30,901 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 53.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,901 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 37 finished: countByValue at MulticlassMetrics.scala:43, took 0.041271 s
2016-12-14 14:52:30,902 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.702247191011236
2016-12-14 14:52:30,903 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_70 stored as values in memory (estimated size 296.0 B, free 357.3 KB)
2016-12-14 14:52:30,906 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_70_piece0 stored as bytes in memory (estimated size 247.0 B, free 357.6 KB)
2016-12-14 14:52:30,907 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_70_piece0 in memory on localhost:39109 (size: 247.0 B, free: 529.9 MB)
2016-12-14 14:52:30,908 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 70 from broadcast at KMeansModel.scala:87
2016-12-14 14:52:30,921 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 14:52:30,922 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 38 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 14:52:30,923 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 54 (sum at KMeansModel.scala:88)
2016-12-14 14:52:30,923 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:52:30,923 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:52:30,924 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 54 (MapPartitionsRDD[75] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 14:52:30,926 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_71 stored as values in memory (estimated size 4.8 KB, free 362.4 KB)
2016-12-14 14:52:30,931 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.9 KB, free 365.3 KB)
2016-12-14 14:52:30,931 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_71_piece0 in memory on localhost:39109 (size: 2.9 KB, free: 529.9 MB)
2016-12-14 14:52:30,931 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:52:30,932 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 54 (MapPartitionsRDD[75] at map at KMeansModel.scala:88)
2016-12-14 14:52:30,932 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 54.0 with 2 tasks
2016-12-14 14:52:30,933 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 54.0 (TID 102, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,934 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 54.0 (TID 103, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:52:30,935 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 54.0 (TID 102)
2016-12-14 14:52:30,935 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 54.0 (TID 103)
2016-12-14 14:52:30,937 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:52:30,937 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:52:30,939 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 54.0 (TID 103). 2064 bytes result sent to driver
2016-12-14 14:52:30,940 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 54.0 (TID 102). 2064 bytes result sent to driver
2016-12-14 14:52:30,940 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 54.0 (TID 103) in 6 ms on localhost (1/2)
2016-12-14 14:52:30,944 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 54.0 (TID 102) in 11 ms on localhost (2/2)
2016-12-14 14:52:30,944 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 54 (sum at KMeansModel.scala:88) finished in 0.012 s
2016-12-14 14:52:30,945 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 54.0, whose tasks have all completed, from pool 
2016-12-14 14:52:30,945 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 38 finished: sum at KMeansModel.scala:88, took 0.023188 s
2016-12-14 14:52:30,945 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 2367716.0861060848
2016-12-14 14:52:30,945 INFO  com.datageek.test.K_means$ - main: ==(-_-)~====END====(-_-)~==
2016-12-14 14:52:30,979 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:52:30,979 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:52:30,979 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:52:30,979 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:52:30,979 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:52:30,980 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:52:30,980 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:52:30,980 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:52:30,980 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:52:30,980 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:52:30,980 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:52:30,981 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:52:30,981 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:52:30,981 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:52:30,981 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:52:30,981 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:52:30,981 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:52:30,982 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:52:30,982 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:52:30,982 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:52:30,982 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:52:30,982 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:52:30,982 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:52:30,982 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:52:30,983 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:52:31,040 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 14:52:31,129 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:52:31,143 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 14:52:31,143 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 14:52:31,144 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 14:52:31,147 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 14:52:31,153 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 14:52:31,156 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 14:52:31,158 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 14:52:31,158 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:52:31,159 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-d2522724-891a-4ed6-9297-d5fac4efbe60
2016-12-14 14:52:31,184 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 14:52:31,185 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 15:29:59,941 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 15:30:00,990 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 15:30:00,996 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 15:30:00,998 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 15:30:01,401 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 2794.
2016-12-14 15:30:01,899 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 15:30:01,960 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 15:30:02,170 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:18082]
2016-12-14 15:30:02,173 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:18082]
2016-12-14 15:30:02,184 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 18082.
2016-12-14 15:30:02,215 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 15:30:02,246 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 15:30:02,270 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-28776e66-7d2c-4312-8daf-0704aeb8a3d9
2016-12-14 15:30:02,297 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 15:30:02,408 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 15:30:02,655 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 15:30:02,704 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 15:30:02,704 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 15:30:02,708 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 15:30:02,736 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:2794/jars/mysql-connector-java-5.1.25.jar with timestamp 1481700602735
2016-12-14 15:30:02,736 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:2794/jars/ojdbc6.jar with timestamp 1481700602736
2016-12-14 15:30:02,736 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:2794/jars/orai18n.jar with timestamp 1481700602736
2016-12-14 15:30:02,737 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:2794/jars/machine_learning_2.10-1.0.jar with timestamp 1481700602737
2016-12-14 15:30:02,834 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 15:30:02,869 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57566.
2016-12-14 15:30:02,870 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 57566
2016-12-14 15:30:02,874 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 15:30:02,875 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 15:30:02,880 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:57566 with 530.0 MB RAM, BlockManagerId(driver, localhost, 57566)
2016-12-14 15:30:02,883 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 15:30:04,832 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481700602784
2016-12-14 15:30:04,896 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/glass.txt
2016-12-14 15:30:04,896 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 100
2016-12-14 15:30:04,897 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 6
2016-12-14 15:30:04,897 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 15:30:04,897 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 15:30:04,898 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 15:30:05,587 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 15:30:05,991 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 15:30:05,996 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:57566 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 15:30:06,004 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:88
2016-12-14 15:30:06,117 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 15:30:06,211 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 15:30:06,241 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 15:30:06,283 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 15:30:06,284 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (takeSample at KMeans.scala:378)
2016-12-14 15:30:06,285 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:06,296 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:06,311 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210), which has no missing parents
2016-12-14 15:30:06,397 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 305.3 KB)
2016-12-14 15:30:06,418 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 307.7 KB)
2016-12-14 15:30:06,420 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:57566 (size: 2.4 KB, free: 530.0 MB)
2016-12-14 15:30:06,422 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:06,428 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210)
2016-12-14 15:30:06,430 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 2 tasks
2016-12-14 15:30:06,498 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2564 bytes)
2016-12-14 15:30:06,504 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2564 bytes)
2016-12-14 15:30:06,517 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 15:30:06,517 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 0.0 (TID 1)
2016-12-14 15:30:06,531 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2794/jars/machine_learning_2.10-1.0.jar with timestamp 1481700602737
2016-12-14 15:30:06,532 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 15:30:06,648 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2794/jars/machine_learning_2.10-1.0.jar to /tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/fetchFileTemp7954173241984534468.tmp
2016-12-14 15:30:06,751 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/machine_learning_2.10-1.0.jar to class loader
2016-12-14 15:30:06,751 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2794/jars/mysql-connector-java-5.1.25.jar with timestamp 1481700602735
2016-12-14 15:30:06,752 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2794/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/fetchFileTemp4627371805854112083.tmp
2016-12-14 15:30:06,765 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 15:30:06,766 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2794/jars/orai18n.jar with timestamp 1481700602736
2016-12-14 15:30:06,767 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2794/jars/orai18n.jar to /tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/fetchFileTemp3343522769263006398.tmp
2016-12-14 15:30:06,785 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/orai18n.jar to class loader
2016-12-14 15:30:06,786 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2794/jars/ojdbc6.jar with timestamp 1481700602736
2016-12-14 15:30:06,787 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2794/jars/ojdbc6.jar to /tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/fetchFileTemp7024554205806847385.tmp
2016-12-14 15:30:06,803 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c/userFiles-1996a13e-d932-4a47-8b0e-2699a79a7c8e/ojdbc6.jar to class loader
2016-12-14 15:30:06,839 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 15:30:06,839 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 15:30:06,845 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/glass.txt:0+5116
2016-12-14 15:30:06,845 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/glass.txt:5116+5117
2016-12-14 15:30:06,872 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 15:30:06,872 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 15:30:06,872 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 15:30:06,872 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 15:30:06,873 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 15:30:06,933 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 13.9 KB, free 321.6 KB)
2016-12-14 15:30:06,934 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:57566 (size: 13.9 KB, free: 530.0 MB)
2016-12-14 15:30:06,935 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_1 not found, computing it
2016-12-14 15:30:06,936 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:06,936 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 13.7 KB, free 335.3 KB)
2016-12-14 15:30:06,937 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:57566 (size: 13.7 KB, free: 530.0 MB)
2016-12-14 15:30:06,938 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_0 not found, computing it
2016-12-14 15:30:06,938 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:06,946 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_1 stored as values in memory (estimated size 3.0 KB, free 338.2 KB)
2016-12-14 15:30:06,946 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_0 stored as values in memory (estimated size 2.9 KB, free 341.2 KB)
2016-12-14 15:30:06,946 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_1 in memory on localhost:57566 (size: 3.0 KB, free: 530.0 MB)
2016-12-14 15:30:06,947 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_0 in memory on localhost:57566 (size: 2.9 KB, free: 530.0 MB)
2016-12-14 15:30:07,005 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 0.0 (TID 1). 2638 bytes result sent to driver
2016-12-14 15:30:07,005 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2638 bytes result sent to driver
2016-12-14 15:30:07,033 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 0.0 (TID 1) in 528 ms on localhost (1/2)
2016-12-14 15:30:07,034 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 571 ms on localhost (2/2)
2016-12-14 15:30:07,036 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,039 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (takeSample at KMeans.scala:378) finished in 0.591 s
2016-12-14 15:30:07,049 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: takeSample at KMeans.scala:378, took 0.806480 s
2016-12-14 15:30:07,107 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 15:30:07,111 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 15:30:07,111 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (takeSample at KMeans.scala:378)
2016-12-14 15:30:07,111 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,116 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 15:30:07,123 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 21.3 KB, free 362.4 KB)
2016-12-14 15:30:07,133 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.9 KB, free 371.4 KB)
2016-12-14 15:30:07,134 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:57566 (size: 8.9 KB, free: 529.9 MB)
2016-12-14 15:30:07,136 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,136 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378)
2016-12-14 15:30:07,136 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 2 tasks
2016-12-14 15:30:07,146 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2673 bytes)
2016-12-14 15:30:07,147 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2673 bytes)
2016-12-14 15:30:07,147 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 1.0 (TID 3)
2016-12-14 15:30:07,147 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 2)
2016-12-14 15:30:07,161 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,161 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,161 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,162 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,192 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 2). 3175 bytes result sent to driver
2016-12-14 15:30:07,192 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 1.0 (TID 3). 3530 bytes result sent to driver
2016-12-14 15:30:07,209 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 1.0 (TID 3) in 62 ms on localhost (1/2)
2016-12-14 15:30:07,210 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (2/2)
2016-12-14 15:30:07,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (takeSample at KMeans.scala:378) finished in 0.069 s
2016-12-14 15:30:07,210 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: takeSample at KMeans.scala:378, took 0.102739 s
2016-12-14 15:30:07,217 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 2.3 KB, free 373.7 KB)
2016-12-14 15:30:07,222 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 720.0 B, free 374.4 KB)
2016-12-14 15:30:07,223 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:57566 (size: 720.0 B, free: 529.9 MB)
2016-12-14 15:30:07,224 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at KMeans.scala:396
2016-12-14 15:30:07,244 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:07,246 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:07,246 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (aggregate at KMeans.scala:404)
2016-12-14 15:30:07,246 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,249 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,250 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:07,254 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 380.3 KB)
2016-12-14 15:30:07,262 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.0 KB, free 383.2 KB)
2016-12-14 15:30:07,263 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:57566 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 15:30:07,264 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,265 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398)
2016-12-14 15:30:07,265 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 15:30:07,268 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2596 bytes)
2016-12-14 15:30:07,269 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2596 bytes)
2016-12-14 15:30:07,270 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 4)
2016-12-14 15:30:07,270 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 5)
2016-12-14 15:30:07,275 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_0 not found, computing it
2016-12-14 15:30:07,276 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,276 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,277 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,277 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,281 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_1 not found, computing it
2016-12-14 15:30:07,281 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,283 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,295 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 15:30:07,296 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 15:30:07,323 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_0 stored as values in memory (estimated size 10.4 KB, free 393.6 KB)
2016-12-14 15:30:07,324 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_0 in memory on localhost:57566 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:07,324 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_1 stored as values in memory (estimated size 10.6 KB, free 404.2 KB)
2016-12-14 15:30:07,326 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_1 in memory on localhost:57566 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:07,333 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 4). 2721 bytes result sent to driver
2016-12-14 15:30:07,335 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 5). 2721 bytes result sent to driver
2016-12-14 15:30:07,337 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
2016-12-14 15:30:07,342 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 5) in 74 ms on localhost (2/2)
2016-12-14 15:30:07,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (aggregate at KMeans.scala:404) finished in 0.076 s
2016-12-14 15:30:07,342 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: aggregate at KMeans.scala:404, took 0.098144 s
2016-12-14 15:30:07,348 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 7 from persistence list
2016-12-14 15:30:07,356 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 7
2016-12-14 15:30:07,370 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:07,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:07,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (collect at KMeans.scala:436)
2016-12-14 15:30:07,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,375 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:07,380 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 6.0 KB, free 410.2 KB)
2016-12-14 15:30:07,388 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 413.3 KB)
2016-12-14 15:30:07,389 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:57566 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:07,390 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:07,391 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 15:30:07,393 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2628 bytes)
2016-12-14 15:30:07,394 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2628 bytes)
2016-12-14 15:30:07,395 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 6)
2016-12-14 15:30:07,395 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 7)
2016-12-14 15:30:07,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 15:30:07,403 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,403 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 15:30:07,420 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 7). 5724 bytes result sent to driver
2016-12-14 15:30:07,422 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 6). 5973 bytes result sent to driver
2016-12-14 15:30:07,434 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 6) in 42 ms on localhost (1/2)
2016-12-14 15:30:07,435 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 7) in 41 ms on localhost (2/2)
2016-12-14 15:30:07,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (collect at KMeans.scala:436) finished in 0.043 s
2016-12-14 15:30:07,435 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,436 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: collect at KMeans.scala:436, took 0.065602 s
2016-12-14 15:30:07,440 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 11.7 KB, free 425.1 KB)
2016-12-14 15:30:07,451 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.0 KB, free 429.1 KB)
2016-12-14 15:30:07,452 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:57566 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:07,454 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at KMeans.scala:396
2016-12-14 15:30:07,475 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:07,476 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:07,476 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (aggregate at KMeans.scala:404)
2016-12-14 15:30:07,476 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,479 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:07,483 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 6.1 KB, free 435.2 KB)
2016-12-14 15:30:07,491 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.1 KB, free 438.3 KB)
2016-12-14 15:30:07,492 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:57566 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 15:30:07,493 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398)
2016-12-14 15:30:07,494 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 15:30:07,496 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2628 bytes)
2016-12-14 15:30:07,496 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2628 bytes)
2016-12-14 15:30:07,497 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 9)
2016-12-14 15:30:07,497 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 8)
2016-12-14 15:30:07,502 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_1 not found, computing it
2016-12-14 15:30:07,502 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,502 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,502 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 15:30:07,503 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_0 not found, computing it
2016-12-14 15:30:07,504 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,504 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,505 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 15:30:07,524 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_0 stored as values in memory (estimated size 10.4 KB, free 448.6 KB)
2016-12-14 15:30:07,525 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_0 in memory on localhost:57566 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:07,525 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_1 stored as values in memory (estimated size 10.6 KB, free 459.2 KB)
2016-12-14 15:30:07,527 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_1 in memory on localhost:57566 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:07,530 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 8). 2721 bytes result sent to driver
2016-12-14 15:30:07,533 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 9). 2721 bytes result sent to driver
2016-12-14 15:30:07,535 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 8) in 40 ms on localhost (1/2)
2016-12-14 15:30:07,540 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 9) in 44 ms on localhost (2/2)
2016-12-14 15:30:07,540 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (aggregate at KMeans.scala:404) finished in 0.046 s
2016-12-14 15:30:07,540 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: aggregate at KMeans.scala:404, took 0.065885 s
2016-12-14 15:30:07,543 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 10 from persistence list
2016-12-14 15:30:07,547 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 15:30:07,567 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:07,569 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:07,569 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (collect at KMeans.scala:436)
2016-12-14 15:30:07,569 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,573 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:07,576 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.2 KB, free 444.5 KB)
2016-12-14 15:30:07,584 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.2 KB, free 447.7 KB)
2016-12-14 15:30:07,585 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:57566 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:07,586 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,587 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:07,587 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 15:30:07,589 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2660 bytes)
2016-12-14 15:30:07,590 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2660 bytes)
2016-12-14 15:30:07,591 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 10)
2016-12-14 15:30:07,591 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 11)
2016-12-14 15:30:07,597 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,597 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,597 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,597 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,598 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 15:30:07,598 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 15:30:07,604 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 10). 3972 bytes result sent to driver
2016-12-14 15:30:07,610 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 11). 6628 bytes result sent to driver
2016-12-14 15:30:07,615 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 10) in 27 ms on localhost (1/2)
2016-12-14 15:30:07,620 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 11) in 31 ms on localhost (2/2)
2016-12-14 15:30:07,621 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (collect at KMeans.scala:436) finished in 0.032 s
2016-12-14 15:30:07,621 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,621 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: collect at KMeans.scala:436, took 0.053624 s
2016-12-14 15:30:07,623 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 11.2 KB, free 458.9 KB)
2016-12-14 15:30:07,630 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.6 KB, free 462.5 KB)
2016-12-14 15:30:07,631 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:07,632 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at KMeans.scala:396
2016-12-14 15:30:07,643 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:07,645 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:07,645 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 15:30:07,646 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,647 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:07,650 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 468.8 KB)
2016-12-14 15:30:07,655 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.1 KB, free 472.0 KB)
2016-12-14 15:30:07,656 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:57566 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 15:30:07,656 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,656 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398)
2016-12-14 15:30:07,656 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 15:30:07,658 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2660 bytes)
2016-12-14 15:30:07,659 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2660 bytes)
2016-12-14 15:30:07,660 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 13)
2016-12-14 15:30:07,660 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 12)
2016-12-14 15:30:07,663 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_1 not found, computing it
2016-12-14 15:30:07,663 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,663 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,664 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 15:30:07,666 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_0 not found, computing it
2016-12-14 15:30:07,666 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,667 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,667 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 15:30:07,671 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_1 stored as values in memory (estimated size 10.6 KB, free 482.5 KB)
2016-12-14 15:30:07,672 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_0 stored as values in memory (estimated size 10.4 KB, free 492.9 KB)
2016-12-14 15:30:07,672 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_1 in memory on localhost:57566 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:07,674 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_0 in memory on localhost:57566 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:07,679 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 13). 2721 bytes result sent to driver
2016-12-14 15:30:07,681 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 12). 2721 bytes result sent to driver
2016-12-14 15:30:07,686 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 13) in 27 ms on localhost (1/2)
2016-12-14 15:30:07,687 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 12) in 30 ms on localhost (2/2)
2016-12-14 15:30:07,687 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.030 s
2016-12-14 15:30:07,687 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,687 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.043976 s
2016-12-14 15:30:07,689 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 14 from persistence list
2016-12-14 15:30:07,690 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 15:30:07,711 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:07,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:07,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 15:30:07,713 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,714 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,714 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:07,718 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.5 KB, free 478.4 KB)
2016-12-14 15:30:07,742 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 478.6 KB)
2016-12-14 15:30:07,742 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:57566 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 15:30:07,743 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:57566 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 15:30:07,743 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,744 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:07,744 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 15:30:07,746 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 15:30:07,747 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 15:30:07,747 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2692 bytes)
2016-12-14 15:30:07,749 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:57566 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:07,750 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 15:30:07,750 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2692 bytes)
2016-12-14 15:30:07,751 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 14)
2016-12-14 15:30:07,751 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 15)
2016-12-14 15:30:07,751 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:57566 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 15:30:07,752 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 15:30:07,754 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:57566 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:07,755 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 15:30:07,756 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,756 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:57566 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 15:30:07,757 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,757 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 15:30:07,757 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 15:30:07,758 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,758 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,758 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 15:30:07,758 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:57566 in memory (size: 8.9 KB, free: 529.9 MB)
2016-12-14 15:30:07,759 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 15:30:07,759 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:57566 in memory (size: 2.4 KB, free: 529.9 MB)
2016-12-14 15:30:07,764 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 15). 6525 bytes result sent to driver
2016-12-14 15:30:07,766 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 14). 4352 bytes result sent to driver
2016-12-14 15:30:07,769 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 15) in 21 ms on localhost (1/2)
2016-12-14 15:30:07,773 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 14) in 27 ms on localhost (2/2)
2016-12-14 15:30:07,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 15:30:07,774 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.062591 s
2016-12-14 15:30:07,776 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 11.4 KB, free 410.2 KB)
2016-12-14 15:30:07,782 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.9 KB)
2016-12-14 15:30:07,783 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:57566 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 15:30:07,784 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at KMeans.scala:396
2016-12-14 15:30:07,795 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:07,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:07,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 15:30:07,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,798 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,798 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:07,801 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 6.5 KB, free 420.5 KB)
2016-12-14 15:30:07,809 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.2 KB, free 423.7 KB)
2016-12-14 15:30:07,810 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:57566 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:07,811 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,812 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398)
2016-12-14 15:30:07,812 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 15:30:07,814 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2692 bytes)
2016-12-14 15:30:07,815 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2692 bytes)
2016-12-14 15:30:07,816 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 17)
2016-12-14 15:30:07,816 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 16)
2016-12-14 15:30:07,821 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_1 not found, computing it
2016-12-14 15:30:07,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 15:30:07,822 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_0 not found, computing it
2016-12-14 15:30:07,823 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,823 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,823 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 15:30:07,829 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_1 stored as values in memory (estimated size 10.6 KB, free 434.2 KB)
2016-12-14 15:30:07,830 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_0 stored as values in memory (estimated size 10.4 KB, free 444.6 KB)
2016-12-14 15:30:07,830 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_1 in memory on localhost:57566 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:07,830 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_0 in memory on localhost:57566 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:07,835 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 16). 2721 bytes result sent to driver
2016-12-14 15:30:07,836 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 17). 2721 bytes result sent to driver
2016-12-14 15:30:07,840 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 16) in 27 ms on localhost (1/2)
2016-12-14 15:30:07,840 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 17) in 26 ms on localhost (2/2)
2016-12-14 15:30:07,840 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.027 s
2016-12-14 15:30:07,840 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,841 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.045550 s
2016-12-14 15:30:07,843 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 18 from persistence list
2016-12-14 15:30:07,843 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 15:30:07,859 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:07,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:07,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 15:30:07,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,863 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,864 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:07,866 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.7 KB, free 430.4 KB)
2016-12-14 15:30:07,873 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 433.7 KB)
2016-12-14 15:30:07,873 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:57566 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 15:30:07,874 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:07,874 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 15:30:07,876 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2724 bytes)
2016-12-14 15:30:07,876 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2724 bytes)
2016-12-14 15:30:07,877 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 18)
2016-12-14 15:30:07,877 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 19)
2016-12-14 15:30:07,880 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,881 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,881 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 15:30:07,882 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,882 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,882 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 15:30:07,885 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 18). 5993 bytes result sent to driver
2016-12-14 15:30:07,888 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 19). 5633 bytes result sent to driver
2016-12-14 15:30:07,895 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 18) in 20 ms on localhost (1/2)
2016-12-14 15:30:07,896 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 19) in 20 ms on localhost (2/2)
2016-12-14 15:30:07,896 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,896 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.021 s
2016-12-14 15:30:07,896 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.036855 s
2016-12-14 15:30:07,898 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 12.2 KB, free 445.9 KB)
2016-12-14 15:30:07,906 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.1 KB, free 450.0 KB)
2016-12-14 15:30:07,907 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:57566 (size: 4.1 KB, free: 529.9 MB)
2016-12-14 15:30:07,908 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at KMeans.scala:396
2016-12-14 15:30:07,927 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:07,928 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:07,928 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 15:30:07,929 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,931 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,931 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:07,933 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 6.8 KB, free 456.8 KB)
2016-12-14 15:30:07,941 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.3 KB, free 460.0 KB)
2016-12-14 15:30:07,941 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:57566 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 15:30:07,942 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:07,942 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398)
2016-12-14 15:30:07,942 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 15:30:07,944 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2724 bytes)
2016-12-14 15:30:07,945 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2724 bytes)
2016-12-14 15:30:07,946 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 20)
2016-12-14 15:30:07,946 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 21)
2016-12-14 15:30:07,951 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_0 not found, computing it
2016-12-14 15:30:07,951 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:07,951 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:07,951 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 15:30:07,953 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_1 not found, computing it
2016-12-14 15:30:07,953 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:07,954 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:07,954 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 15:30:07,957 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_0 stored as values in memory (estimated size 10.4 KB, free 470.4 KB)
2016-12-14 15:30:07,958 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_0 in memory on localhost:57566 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:07,962 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_1 stored as values in memory (estimated size 10.6 KB, free 481.0 KB)
2016-12-14 15:30:07,963 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 20). 2721 bytes result sent to driver
2016-12-14 15:30:07,963 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_1 in memory on localhost:57566 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:07,968 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 20) in 24 ms on localhost (1/2)
2016-12-14 15:30:07,970 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 21). 2721 bytes result sent to driver
2016-12-14 15:30:07,974 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 21) in 30 ms on localhost (2/2)
2016-12-14 15:30:07,975 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.031 s
2016-12-14 15:30:07,975 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 15:30:07,975 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.047932 s
2016-12-14 15:30:07,977 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 22 from persistence list
2016-12-14 15:30:07,979 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 15:30:07,995 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:07,997 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:07,997 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 15:30:07,997 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:07,999 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:07,999 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:08,002 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 6.9 KB, free 467.0 KB)
2016-12-14 15:30:08,009 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.4 KB, free 470.4 KB)
2016-12-14 15:30:08,010 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:57566 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 15:30:08,010 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:08,011 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 15:30:08,013 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2756 bytes)
2016-12-14 15:30:08,014 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2756 bytes)
2016-12-14 15:30:08,015 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 22)
2016-12-14 15:30:08,015 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 23)
2016-12-14 15:30:08,020 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:08,021 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:08,021 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_1 locally
2016-12-14 15:30:08,023 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,023 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:08,024 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_0 locally
2016-12-14 15:30:08,027 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 23). 7354 bytes result sent to driver
2016-12-14 15:30:08,033 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 22). 5801 bytes result sent to driver
2016-12-14 15:30:08,037 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 23) in 22 ms on localhost (1/2)
2016-12-14 15:30:08,042 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 22) in 29 ms on localhost (2/2)
2016-12-14 15:30:08,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.030 s
2016-12-14 15:30:08,042 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.047094 s
2016-12-14 15:30:08,043 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 26 from persistence list
2016-12-14 15:30:08,044 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 15:30:08,046 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 60.0 KB, free 509.4 KB)
2016-12-14 15:30:08,056 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 12.7 KB, free 522.1 KB)
2016-12-14 15:30:08,057 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:57566 (size: 12.7 KB, free: 529.9 MB)
2016-12-14 15:30:08,058 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at KMeans.scala:450
2016-12-14 15:30:08,105 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 15:30:08,121 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 29 (flatMap at KMeans.scala:451)
2016-12-14 15:30:08,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 15:30:08,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collectAsMap at KMeans.scala:455)
2016-12-14 15:30:08,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 12)
2016-12-14 15:30:08,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 12)
2016-12-14 15:30:08,125 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 15:30:08,133 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 5.9 KB, free 528.0 KB)
2016-12-14 15:30:08,140 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.2 KB, free 531.2 KB)
2016-12-14 15:30:08,141 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:57566 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:08,141 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451)
2016-12-14 15:30:08,145 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 15:30:08,148 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,149 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,149 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 24)
2016-12-14 15:30:08,149 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 25)
2016-12-14 15:30:08,155 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:08,155 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,155 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:08,156 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:08,256 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 24). 2237 bytes result sent to driver
2016-12-14 15:30:08,256 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 25). 2237 bytes result sent to driver
2016-12-14 15:30:08,266 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 24) in 120 ms on localhost (1/2)
2016-12-14 15:30:08,267 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 25) in 118 ms on localhost (2/2)
2016-12-14 15:30:08,267 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,269 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 12 (flatMap at KMeans.scala:451) finished in 0.123 s
2016-12-14 15:30:08,269 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:08,270 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:08,271 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 13)
2016-12-14 15:30:08,272 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:08,274 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 15:30:08,281 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 2.6 KB, free 533.8 KB)
2016-12-14 15:30:08,289 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1555.0 B, free 535.3 KB)
2016-12-14 15:30:08,290 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:57566 (size: 1555.0 B, free: 529.9 MB)
2016-12-14 15:30:08,291 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,291 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455)
2016-12-14 15:30:08,292 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 15:30:08,295 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 26, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,296 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 27, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,296 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 26)
2016-12-14 15:30:08,296 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 27)
2016-12-14 15:30:08,306 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,306 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,308 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 15:30:08,308 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 15:30:08,354 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 26). 7413 bytes result sent to driver
2016-12-14 15:30:08,354 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 27). 7201 bytes result sent to driver
2016-12-14 15:30:08,358 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 27) in 62 ms on localhost (1/2)
2016-12-14 15:30:08,358 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 26) in 64 ms on localhost (2/2)
2016-12-14 15:30:08,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collectAsMap at KMeans.scala:455) finished in 0.065 s
2016-12-14 15:30:08,358 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: collectAsMap at KMeans.scala:455, took 0.253636 s
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 15:30:08,493 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:08,495 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 12 iterations.
2016-12-14 15:30:08,511 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 2.364 seconds.
2016-12-14 15:30:08,514 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 8.0 KB, free 543.3 KB)
2016-12-14 15:30:08,518 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.3 KB, free 547.6 KB)
2016-12-14 15:30:08,519 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:57566 (size: 4.3 KB, free: 529.9 MB)
2016-12-14 15:30:08,520 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at KMeans.scala:276
2016-12-14 15:30:08,539 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:08,540 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 31 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,540 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:08,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:08,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 14)
2016-12-14 15:30:08,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 14)
2016-12-14 15:30:08,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:08,546 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 6.9 KB, free 554.5 KB)
2016-12-14 15:30:08,555 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.6 KB, free 558.1 KB)
2016-12-14 15:30:08,556 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,557 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,558 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 15:30:08,560 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,561 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,561 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 28)
2016-12-14 15:30:08,561 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 29)
2016-12-14 15:30:08,564 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:08,564 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:08,565 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,565 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:08,582 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 29). 2516 bytes result sent to driver
2016-12-14 15:30:08,582 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 28). 2516 bytes result sent to driver
2016-12-14 15:30:08,586 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 28) in 26 ms on localhost (1/2)
2016-12-14 15:30:08,586 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 29) in 26 ms on localhost (2/2)
2016-12-14 15:30:08,587 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,587 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 14 (mapPartitions at KMeans.scala:279) finished in 0.028 s
2016-12-14 15:30:08,587 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:08,588 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:08,588 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 15)
2016-12-14 15:30:08,588 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:08,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:08,591 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 2.9 KB, free 561.0 KB)
2016-12-14 15:30:08,597 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1662.0 B, free 562.6 KB)
2016-12-14 15:30:08,598 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:57566 (size: 1662.0 B, free: 529.9 MB)
2016-12-14 15:30:08,598 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,599 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:08,599 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 15:30:08,600 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 30, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,601 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 31, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,601 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 30)
2016-12-14 15:30:08,601 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 31)
2016-12-14 15:30:08,603 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,603 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,603 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:08,603 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:08,614 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 30). 3788 bytes result sent to driver
2016-12-14 15:30:08,615 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 31). 4157 bytes result sent to driver
2016-12-14 15:30:08,617 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 30) in 17 ms on localhost (1/2)
2016-12-14 15:30:08,619 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 31) in 18 ms on localhost (2/2)
2016-12-14 15:30:08,620 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,620 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 15:30:08,620 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collectAsMap at KMeans.scala:302, took 0.081579 s
2016-12-14 15:30:08,625 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 8.0 KB, free 570.5 KB)
2016-12-14 15:30:08,629 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.0 KB, free 574.6 KB)
2016-12-14 15:30:08,630 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:57566 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:08,631 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at KMeans.scala:276
2016-12-14 15:30:08,648 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:08,650 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 33 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,651 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:08,651 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:08,651 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 15:30:08,651 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 15:30:08,653 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:08,654 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 6.9 KB, free 581.4 KB)
2016-12-14 15:30:08,659 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.6 KB, free 585.0 KB)
2016-12-14 15:30:08,660 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,661 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,661 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,661 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 15:30:08,663 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,663 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 33, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,664 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 33)
2016-12-14 15:30:08,664 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 32)
2016-12-14 15:30:08,667 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:08,667 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,668 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:08,668 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:08,677 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 32). 2516 bytes result sent to driver
2016-12-14 15:30:08,679 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 32) in 16 ms on localhost (1/2)
2016-12-14 15:30:08,679 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 33). 2516 bytes result sent to driver
2016-12-14 15:30:08,683 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 33) in 20 ms on localhost (2/2)
2016-12-14 15:30:08,683 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,683 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (mapPartitions at KMeans.scala:279) finished in 0.021 s
2016-12-14 15:30:08,683 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:08,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:08,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 15:30:08,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:08,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:08,685 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 2.9 KB, free 587.9 KB)
2016-12-14 15:30:08,687 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1658.0 B, free 589.5 KB)
2016-12-14 15:30:08,688 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:57566 (size: 1658.0 B, free: 529.9 MB)
2016-12-14 15:30:08,688 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,689 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:08,689 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 15:30:08,689 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 34, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,690 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 35, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,690 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 34)
2016-12-14 15:30:08,690 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 35)
2016-12-14 15:30:08,691 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,692 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:08,692 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,693 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:08,699 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 34). 3788 bytes result sent to driver
2016-12-14 15:30:08,703 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 34) in 14 ms on localhost (1/2)
2016-12-14 15:30:08,706 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 35). 4157 bytes result sent to driver
2016-12-14 15:30:08,711 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 35) in 20 ms on localhost (2/2)
2016-12-14 15:30:08,711 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 15:30:08,711 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,711 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: collectAsMap at KMeans.scala:302, took 0.062412 s
2016-12-14 15:30:08,714 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 2 iterations
2016-12-14 15:30:08,716 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 7.2 KB, free 596.7 KB)
2016-12-14 15:30:08,723 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KB, free 600.3 KB)
2016-12-14 15:30:08,724 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,724 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at KMeans.scala:276
2016-12-14 15:30:08,733 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:08,734 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 35 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,735 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:08,735 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:08,735 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 15:30:08,735 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 15:30:08,737 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:08,739 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 6.8 KB, free 607.2 KB)
2016-12-14 15:30:08,743 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.6 KB, free 610.8 KB)
2016-12-14 15:30:08,744 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,745 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,745 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,745 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 15:30:08,747 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 36, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,748 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 37, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,749 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 36)
2016-12-14 15:30:08,749 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 37)
2016-12-14 15:30:08,752 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:08,752 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:08,753 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,753 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:08,760 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 37). 2492 bytes result sent to driver
2016-12-14 15:30:08,763 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 37) in 15 ms on localhost (1/2)
2016-12-14 15:30:08,766 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 36). 2492 bytes result sent to driver
2016-12-14 15:30:08,769 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 36) in 23 ms on localhost (2/2)
2016-12-14 15:30:08,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.023 s
2016-12-14 15:30:08,770 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:08,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:08,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 15:30:08,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:08,771 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:08,772 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 2.9 KB, free 613.7 KB)
2016-12-14 15:30:08,776 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1661.0 B, free 615.3 KB)
2016-12-14 15:30:08,777 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:57566 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:08,777 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,778 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:08,778 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 15:30:08,779 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 38, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,779 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 39, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,780 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 39)
2016-12-14 15:30:08,780 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 38)
2016-12-14 15:30:08,783 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,783 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,783 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:08,783 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:08,796 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 38). 3507 bytes result sent to driver
2016-12-14 15:30:08,799 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 39). 3879 bytes result sent to driver
2016-12-14 15:30:08,802 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 38) in 23 ms on localhost (1/2)
2016-12-14 15:30:08,803 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 39) in 24 ms on localhost (2/2)
2016-12-14 15:30:08,803 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,803 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.024 s
2016-12-14 15:30:08,803 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collectAsMap at KMeans.scala:302, took 0.070436 s
2016-12-14 15:30:08,805 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 3 iterations
2016-12-14 15:30:08,805 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 3 iterations
2016-12-14 15:30:08,806 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 5.6 KB, free 620.9 KB)
2016-12-14 15:30:08,821 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:57566 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:08,823 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 15:30:08,824 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,824 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.9 KB, free 615.7 KB)
2016-12-14 15:30:08,825 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 15:30:08,825 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:57566 (size: 2.9 KB, free: 529.9 MB)
2016-12-14 15:30:08,826 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at KMeans.scala:276
2016-12-14 15:30:08,829 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 15:30:08,830 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,831 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 15:30:08,831 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 15:30:08,831 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 15:30:08,831 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 15:30:08,832 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 15:30:08,832 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 15:30:08,832 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 15:30:08,832 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 15:30:08,832 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 15:30:08,833 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:57566 in memory (size: 1658.0 B, free: 529.9 MB)
2016-12-14 15:30:08,834 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 15:30:08,835 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:57566 in memory (size: 4.1 KB, free: 529.9 MB)
2016-12-14 15:30:08,836 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:57566 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 15:30:08,837 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 15:30:08,837 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:57566 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:08,838 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 15:30:08,839 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 15:30:08,841 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 22
2016-12-14 15:30:08,842 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:08,842 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:57566 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 15:30:08,843 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 37 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,844 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:57566 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 15:30:08,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:08,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:08,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 15:30:08,844 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 15:30:08,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 15:30:08,845 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 15:30:08,846 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 18
2016-12-14 15:30:08,846 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:08,846 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,847 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 15:30:08,847 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 14
2016-12-14 15:30:08,848 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 6.8 KB, free 524.5 KB)
2016-12-14 15:30:08,849 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:57566 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:08,850 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 15:30:08,851 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 10
2016-12-14 15:30:08,851 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:57566 in memory (size: 720.0 B, free: 529.9 MB)
2016-12-14 15:30:08,852 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 15:30:08,852 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 15:30:08,852 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 15:30:08,852 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 15:30:08,853 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.6 KB, free 509.3 KB)
2016-12-14 15:30:08,853 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,854 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:57566 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 15:30:08,854 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,855 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,855 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 15:30:08,855 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 15:30:08,856 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:57566 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 15:30:08,856 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 15:30:08,856 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 15:30:08,856 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,857 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:57566 in memory (size: 12.7 KB, free: 529.9 MB)
2016-12-14 15:30:08,857 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 41, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,858 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 40)
2016-12-14 15:30:08,858 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 41)
2016-12-14 15:30:08,858 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:57566 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 15:30:08,858 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 15:30:08,860 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:57566 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 15:30:08,860 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 15:30:08,861 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 15:30:08,861 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,861 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 26
2016-12-14 15:30:08,861 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:08,861 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 15:30:08,861 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 15:30:08,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 15:30:08,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 15:30:08,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 15:30:08,862 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:08,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 15:30:08,862 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:08,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 15:30:08,862 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 15:30:08,863 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 15:30:08,863 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 15:30:08,863 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:57566 in memory (size: 1662.0 B, free: 529.9 MB)
2016-12-14 15:30:08,864 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 15:30:08,864 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,865 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 15:30:08,865 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 15:30:08,865 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:57566 in memory (size: 4.3 KB, free: 529.9 MB)
2016-12-14 15:30:08,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 15:30:08,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 15:30:08,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 15:30:08,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 15:30:08,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 15:30:08,866 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 15:30:08,867 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,867 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 40). 2444 bytes result sent to driver
2016-12-14 15:30:08,867 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 15:30:08,868 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 15:30:08,869 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:57566 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:08,871 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 40) in 15 ms on localhost (1/2)
2016-12-14 15:30:08,871 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 41). 2444 bytes result sent to driver
2016-12-14 15:30:08,873 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 41) in 16 ms on localhost (2/2)
2016-12-14 15:30:08,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 15:30:08,873 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:08,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:08,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 15:30:08,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:08,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:08,876 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 2.9 KB, free 356.2 KB)
2016-12-14 15:30:08,880 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1659.0 B, free 357.8 KB)
2016-12-14 15:30:08,880 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:57566 (size: 1659.0 B, free: 529.9 MB)
2016-12-14 15:30:08,881 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:08,881 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 15:30:08,882 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 42, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,882 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 43, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,883 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 42)
2016-12-14 15:30:08,883 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 43)
2016-12-14 15:30:08,884 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,884 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,884 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:08,884 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:08,891 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 43). 3410 bytes result sent to driver
2016-12-14 15:30:08,893 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 42). 2850 bytes result sent to driver
2016-12-14 15:30:08,893 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 43) in 11 ms on localhost (1/2)
2016-12-14 15:30:08,897 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 42) in 15 ms on localhost (2/2)
2016-12-14 15:30:08,897 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.015 s
2016-12-14 15:30:08,897 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,898 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:302, took 0.055661 s
2016-12-14 15:30:08,899 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 4 iterations
2016-12-14 15:30:08,899 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 4 iterations
2016-12-14 15:30:08,900 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 4.0 KB, free 361.8 KB)
2016-12-14 15:30:08,902 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.1 KB, free 363.9 KB)
2016-12-14 15:30:08,903 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:57566 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 15:30:08,903 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at KMeans.scala:276
2016-12-14 15:30:08,911 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:08,912 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 39 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:08,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:08,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 15:30:08,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 15:30:08,914 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:08,916 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 6.7 KB, free 370.6 KB)
2016-12-14 15:30:08,920 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.6 KB, free 374.2 KB)
2016-12-14 15:30:08,921 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,921 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,921 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,921 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 15:30:08,922 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 44, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,923 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 45, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,923 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 45)
2016-12-14 15:30:08,923 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 44)
2016-12-14 15:30:08,925 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:08,925 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:08,926 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,926 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:08,930 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 45). 2396 bytes result sent to driver
2016-12-14 15:30:08,932 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 45) in 10 ms on localhost (1/2)
2016-12-14 15:30:08,935 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 44). 2396 bytes result sent to driver
2016-12-14 15:30:08,937 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 44) in 15 ms on localhost (2/2)
2016-12-14 15:30:08,937 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,937 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.015 s
2016-12-14 15:30:08,938 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:08,938 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:08,938 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 15:30:08,938 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:08,939 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:08,941 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 2.9 KB, free 377.1 KB)
2016-12-14 15:30:08,947 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1657.0 B, free 378.7 KB)
2016-12-14 15:30:08,948 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:57566 (size: 1657.0 B, free: 529.9 MB)
2016-12-14 15:30:08,949 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,949 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:08,950 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 15:30:08,951 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 46, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,951 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 47, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:08,951 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 47)
2016-12-14 15:30:08,951 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 46)
2016-12-14 15:30:08,954 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,954 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:08,954 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:08,955 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:08,966 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 47). 2849 bytes result sent to driver
2016-12-14 15:30:08,966 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 46). 2289 bytes result sent to driver
2016-12-14 15:30:08,969 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 46) in 18 ms on localhost (1/2)
2016-12-14 15:30:08,969 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 47) in 18 ms on localhost (2/2)
2016-12-14 15:30:08,969 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 15:30:08,969 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 15:30:08,970 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.058202 s
2016-12-14 15:30:08,971 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 5 iterations
2016-12-14 15:30:08,971 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 3.2 KB, free 381.9 KB)
2016-12-14 15:30:08,973 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1791.0 B, free 383.7 KB)
2016-12-14 15:30:08,974 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:57566 (size: 1791.0 B, free: 529.9 MB)
2016-12-14 15:30:08,974 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at KMeans.scala:276
2016-12-14 15:30:08,982 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:08,983 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 41 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:08,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:08,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 15:30:08,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 15:30:08,986 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:08,988 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 6.6 KB, free 390.3 KB)
2016-12-14 15:30:08,992 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.6 KB, free 393.9 KB)
2016-12-14 15:30:08,993 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:08,993 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:08,994 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:08,994 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 15:30:08,995 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 48, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,996 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 49, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:08,996 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 48)
2016-12-14 15:30:08,996 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 49)
2016-12-14 15:30:08,998 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:08,998 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:09,000 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,000 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:09,006 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 48). 2372 bytes result sent to driver
2016-12-14 15:30:09,008 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 48) in 13 ms on localhost (1/2)
2016-12-14 15:30:09,009 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 49). 2372 bytes result sent to driver
2016-12-14 15:30:09,011 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 49) in 15 ms on localhost (2/2)
2016-12-14 15:30:09,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 15:30:09,011 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,012 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,012 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 15:30:09,012 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,013 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:09,014 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 2.9 KB, free 396.8 KB)
2016-12-14 15:30:09,018 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1660.0 B, free 398.4 KB)
2016-12-14 15:30:09,019 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:57566 (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:09,020 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:09,021 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 15:30:09,022 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 50, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,023 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 51, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,024 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 50)
2016-12-14 15:30:09,024 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 51)
2016-12-14 15:30:09,026 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,026 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,026 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,026 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,035 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 50). 2196 bytes result sent to driver
2016-12-14 15:30:09,037 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 51). 2380 bytes result sent to driver
2016-12-14 15:30:09,039 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 50) in 17 ms on localhost (1/2)
2016-12-14 15:30:09,040 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 51) in 17 ms on localhost (2/2)
2016-12-14 15:30:09,040 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 15:30:09,040 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,040 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.057766 s
2016-12-14 15:30:09,041 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 6 iterations
2016-12-14 15:30:09,042 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 2.4 KB, free 400.8 KB)
2016-12-14 15:30:09,044 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 1195.0 B, free 402.0 KB)
2016-12-14 15:30:09,045 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:57566 (size: 1195.0 B, free: 529.9 MB)
2016-12-14 15:30:09,045 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at KMeans.scala:276
2016-12-14 15:30:09,053 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:09,056 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 43 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,057 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:09,057 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:09,057 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 15:30:09,057 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 15:30:09,058 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:09,060 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 6.6 KB, free 408.6 KB)
2016-12-14 15:30:09,064 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.6 KB, free 412.1 KB)
2016-12-14 15:30:09,065 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:57566 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,065 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,065 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,066 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 15:30:09,067 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 52, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,068 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 53, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,068 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 53)
2016-12-14 15:30:09,068 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 52)
2016-12-14 15:30:09,072 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,073 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:09,073 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,074 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:09,082 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 53). 2348 bytes result sent to driver
2016-12-14 15:30:09,083 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 52). 2348 bytes result sent to driver
2016-12-14 15:30:09,084 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 53) in 17 ms on localhost (1/2)
2016-12-14 15:30:09,084 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 52) in 17 ms on localhost (2/2)
2016-12-14 15:30:09,085 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.019 s
2016-12-14 15:30:09,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,085 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,086 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 15:30:09,086 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,087 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:09,088 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 2.9 KB, free 415.0 KB)
2016-12-14 15:30:09,092 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1661.0 B, free 416.7 KB)
2016-12-14 15:30:09,093 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:57566 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:09,094 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:09,095 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 15:30:09,096 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 54, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,096 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 55, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,096 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 55)
2016-12-14 15:30:09,096 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 54)
2016-12-14 15:30:09,099 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,099 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,099 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,099 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,110 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 55). 2006 bytes result sent to driver
2016-12-14 15:30:09,111 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 54). 2007 bytes result sent to driver
2016-12-14 15:30:09,113 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 55) in 17 ms on localhost (1/2)
2016-12-14 15:30:09,113 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 54) in 18 ms on localhost (2/2)
2016-12-14 15:30:09,114 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 15:30:09,114 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,114 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.060617 s
2016-12-14 15:30:09,115 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 7 iterations
2016-12-14 15:30:09,116 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 1664.0 B, free 418.3 KB)
2016-12-14 15:30:09,120 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 858.0 B, free 419.1 KB)
2016-12-14 15:30:09,121 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:57566 (size: 858.0 B, free: 529.9 MB)
2016-12-14 15:30:09,121 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at KMeans.scala:276
2016-12-14 15:30:09,137 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:09,138 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 45 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:09,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:09,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 15:30:09,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 15:30:09,141 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:09,143 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 6.6 KB, free 425.7 KB)
2016-12-14 15:30:09,147 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.5 KB, free 429.2 KB)
2016-12-14 15:30:09,147 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:57566 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:09,148 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,148 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,149 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 15:30:09,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 56, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,151 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 57, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,151 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 56)
2016-12-14 15:30:09,151 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 57)
2016-12-14 15:30:09,155 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,155 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:09,156 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,156 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:09,163 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 56). 2324 bytes result sent to driver
2016-12-14 15:30:09,165 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 57). 2324 bytes result sent to driver
2016-12-14 15:30:09,166 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 56) in 16 ms on localhost (1/2)
2016-12-14 15:30:09,167 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 57) in 16 ms on localhost (2/2)
2016-12-14 15:30:09,167 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 15:30:09,167 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,167 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,167 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 15:30:09,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:09,170 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 2.9 KB, free 432.1 KB)
2016-12-14 15:30:09,174 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1661.0 B, free 433.7 KB)
2016-12-14 15:30:09,175 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:57566 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:09,175 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,176 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:09,176 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 15:30:09,177 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 58, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,178 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 59, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,179 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 58)
2016-12-14 15:30:09,179 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 59)
2016-12-14 15:30:09,181 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,181 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,181 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,182 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:09,192 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 59). 1634 bytes result sent to driver
2016-12-14 15:30:09,193 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 58). 1820 bytes result sent to driver
2016-12-14 15:30:09,196 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 59) in 18 ms on localhost (1/2)
2016-12-14 15:30:09,197 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 58) in 20 ms on localhost (2/2)
2016-12-14 15:30:09,197 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 15:30:09,197 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.059923 s
2016-12-14 15:30:09,199 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 8 iterations
2016-12-14 15:30:09,200 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 856.0 B, free 434.6 KB)
2016-12-14 15:30:09,204 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 597.0 B, free 435.2 KB)
2016-12-14 15:30:09,204 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:57566 (size: 597.0 B, free: 529.9 MB)
2016-12-14 15:30:09,205 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at KMeans.scala:276
2016-12-14 15:30:09,221 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:09,222 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 47 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,223 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:09,223 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:09,223 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 15:30:09,223 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 15:30:09,225 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:09,226 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 6.5 KB, free 441.7 KB)
2016-12-14 15:30:09,230 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.5 KB, free 445.2 KB)
2016-12-14 15:30:09,231 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:57566 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:09,232 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,232 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,232 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 15:30:09,234 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 60, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,235 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 61, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,235 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 60)
2016-12-14 15:30:09,235 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 61)
2016-12-14 15:30:09,238 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,239 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:09,239 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,239 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:09,243 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 60). 2300 bytes result sent to driver
2016-12-14 15:30:09,245 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 61). 2300 bytes result sent to driver
2016-12-14 15:30:09,245 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 60) in 12 ms on localhost (1/2)
2016-12-14 15:30:09,247 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 61) in 13 ms on localhost (2/2)
2016-12-14 15:30:09,247 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,247 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 15:30:09,248 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,248 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,248 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 15:30:09,248 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,249 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:09,251 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 2.9 KB, free 448.1 KB)
2016-12-14 15:30:09,254 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1661.0 B, free 449.7 KB)
2016-12-14 15:30:09,255 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:57566 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:09,255 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,256 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:09,256 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 15:30:09,257 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 62, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,257 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 63, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,258 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 62)
2016-12-14 15:30:09,258 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 63)
2016-12-14 15:30:09,260 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,260 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:09,260 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,260 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,267 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 63). 1352 bytes result sent to driver
2016-12-14 15:30:09,269 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 62). 1540 bytes result sent to driver
2016-12-14 15:30:09,270 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 63) in 13 ms on localhost (1/2)
2016-12-14 15:30:09,274 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 62) in 17 ms on localhost (2/2)
2016-12-14 15:30:09,274 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 15:30:09,274 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,275 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.054311 s
2016-12-14 15:30:09,277 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 856.0 B, free 450.6 KB)
2016-12-14 15:30:09,281 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 595.0 B, free 451.2 KB)
2016-12-14 15:30:09,281 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:57566 (size: 595.0 B, free: 529.9 MB)
2016-12-14 15:30:09,282 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at KMeans.scala:276
2016-12-14 15:30:09,297 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:09,298 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 49 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,299 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:09,299 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:09,299 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 15:30:09,299 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 15:30:09,301 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:09,302 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 6.5 KB, free 457.7 KB)
2016-12-14 15:30:09,304 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.5 KB, free 461.2 KB)
2016-12-14 15:30:09,305 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:57566 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:09,305 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,306 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[49] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,306 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 15:30:09,308 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 64, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,309 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 65, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,310 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 64)
2016-12-14 15:30:09,310 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 65)
2016-12-14 15:30:09,313 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,313 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:09,313 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,314 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:09,320 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 64). 2300 bytes result sent to driver
2016-12-14 15:30:09,322 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 65). 2300 bytes result sent to driver
2016-12-14 15:30:09,322 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 64) in 15 ms on localhost (1/2)
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 65) in 16 ms on localhost (2/2)
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:09,325 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 2.9 KB, free 464.1 KB)
2016-12-14 15:30:09,328 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1660.0 B, free 465.7 KB)
2016-12-14 15:30:09,329 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:57566 (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:09,330 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,330 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[50] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:09,330 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 15:30:09,332 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 66, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,332 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 67, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,333 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 67)
2016-12-14 15:30:09,333 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 66)
2016-12-14 15:30:09,335 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,335 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,336 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,336 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,343 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 67). 1352 bytes result sent to driver
2016-12-14 15:30:09,347 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 66). 1540 bytes result sent to driver
2016-12-14 15:30:09,349 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 67) in 16 ms on localhost (1/2)
2016-12-14 15:30:09,350 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 66) in 19 ms on localhost (2/2)
2016-12-14 15:30:09,350 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 15:30:09,350 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,350 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.053078 s
2016-12-14 15:30:09,352 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 856.0 B, free 466.6 KB)
2016-12-14 15:30:09,358 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 599.0 B, free 467.1 KB)
2016-12-14 15:30:09,359 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:57566 (size: 599.0 B, free: 529.9 MB)
2016-12-14 15:30:09,360 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at KMeans.scala:276
2016-12-14 15:30:09,377 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:09,378 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 51 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,378 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:09,379 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:09,379 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 34)
2016-12-14 15:30:09,379 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 34)
2016-12-14 15:30:09,380 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 34 (MapPartitionsRDD[51] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:09,382 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 6.5 KB, free 473.7 KB)
2016-12-14 15:30:09,387 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.5 KB, free 477.2 KB)
2016-12-14 15:30:09,388 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:57566 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:09,388 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[51] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:09,389 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 15:30:09,390 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 68, localhost, partition 0,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,391 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 69, localhost, partition 1,PROCESS_LOCAL, 2553 bytes)
2016-12-14 15:30:09,391 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 68)
2016-12-14 15:30:09,391 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 69)
2016-12-14 15:30:09,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 15:30:09,394 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,395 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 15:30:09,397 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 68). 2300 bytes result sent to driver
2016-12-14 15:30:09,399 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 68) in 9 ms on localhost (1/2)
2016-12-14 15:30:09,401 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 69). 2300 bytes result sent to driver
2016-12-14 15:30:09,403 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 69) in 13 ms on localhost (2/2)
2016-12-14 15:30:09,404 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 34 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 15:30:09,404 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,404 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,404 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,404 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 35)
2016-12-14 15:30:09,404 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,405 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (ShuffledRDD[52] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:09,406 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 2.9 KB, free 480.1 KB)
2016-12-14 15:30:09,410 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 1661.0 B, free 481.7 KB)
2016-12-14 15:30:09,411 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:57566 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:09,411 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,412 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (ShuffledRDD[52] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:09,412 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 15:30:09,413 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 70, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,414 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 71, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,415 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 71)
2016-12-14 15:30:09,415 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 70)
2016-12-14 15:30:09,417 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,417 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:09,417 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,417 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,426 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 71). 1352 bytes result sent to driver
2016-12-14 15:30:09,430 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 70). 1540 bytes result sent to driver
2016-12-14 15:30:09,432 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 71) in 18 ms on localhost (1/2)
2016-12-14 15:30:09,433 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 70) in 20 ms on localhost (2/2)
2016-12-14 15:30:09,433 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 15:30:09,433 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,433 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: collectAsMap at KMeans.scala:302, took 0.056266 s
2016-12-14 15:30:09,435 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 11 iterations
2016-12-14 15:30:09,436 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.923 seconds.
2016-12-14 15:30:09,438 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 11 iterations.
2016-12-14 15:30:09,442 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 336.2131430295502.
2016-12-14 15:30:09,445 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 4 from persistence list
2016-12-14 15:30:09,446 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 15:30:09,447 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 15:30:09,462 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:108
2016-12-14 15:30:09,463 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (foreach at K_means.scala:108) with 2 output partitions
2016-12-14 15:30:09,463 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 36 (foreach at K_means.scala:108)
2016-12-14 15:30:09,463 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:09,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:09,465 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 36 (MapPartitionsRDD[3] at map at K_means.scala:98), which has no missing parents
2016-12-14 15:30:09,467 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 4.4 KB, free 480.2 KB)
2016-12-14 15:30:09,471 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.6 KB, free 482.9 KB)
2016-12-14 15:30:09,472 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:57566 (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,472 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 36 (MapPartitionsRDD[3] at map at K_means.scala:98)
2016-12-14 15:30:09,473 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 15:30:09,474 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 72, localhost, partition 0,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:09,474 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 73, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:09,474 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 73)
2016-12-14 15:30:09,474 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 72)
2016-12-14 15:30:09,477 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,477 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,480 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,480 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.53125,10.73,0.0,2.1,69.81,0.58,13.3,3.15,0.28] belong to cluster 4
2016-12-14 15:30:09,480 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51761,13.89,3.6,1.36,72.73,0.48,7.83,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,481 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.53393,12.3,0.0,1.0,70.16,0.12,16.19,0.0,0.24] belong to cluster 4
2016-12-14 15:30:09,481 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51618,13.53,3.55,1.54,72.99,0.39,7.78,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,481 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52222,14.43,0.0,1.0,72.67,0.1,11.52,0.0,0.08] belong to cluster 2
2016-12-14 15:30:09,481 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51766,13.21,3.69,1.29,72.61,0.57,8.22,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,481 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51818,13.72,0.0,0.56,74.45,0.0,10.99,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,481 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51742,13.27,3.62,1.24,73.08,0.55,8.07,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,482 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52664,11.23,0.0,0.77,73.21,0.0,14.68,0.0,0.0] belong to cluster 4
2016-12-14 15:30:09,482 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51596,12.79,3.61,1.62,72.97,0.64,8.07,0.0,0.26] belong to cluster 1
2016-12-14 15:30:09,482 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52739,11.02,0.0,0.75,73.08,0.0,14.96,0.0,0.0] belong to cluster 4
2016-12-14 15:30:09,482 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51743,13.3,3.6,1.14,73.09,0.58,8.17,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,482 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52777,12.64,0.0,0.67,72.02,0.06,14.4,0.0,0.0] belong to cluster 4
2016-12-14 15:30:09,483 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51756,13.15,3.61,1.05,73.24,0.57,8.24,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,483 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51892,13.46,3.83,1.26,72.55,0.57,8.21,0.0,0.14] belong to cluster 1
2016-12-14 15:30:09,483 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51918,14.04,3.58,1.37,72.08,0.56,8.3,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,483 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51847,13.1,3.97,1.19,72.44,0.6,8.43,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,484 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51755,13.0,3.6,1.36,72.99,0.57,8.4,0.0,0.11] belong to cluster 1
2016-12-14 15:30:09,484 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51846,13.41,3.89,1.33,72.38,0.51,8.28,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,484 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51571,12.72,3.46,1.56,73.2,0.67,8.09,0.0,0.24] belong to cluster 1
2016-12-14 15:30:09,484 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51829,13.24,3.9,1.41,72.33,0.55,8.31,0.0,0.1] belong to cluster 1
2016-12-14 15:30:09,484 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51763,12.8,3.66,1.27,73.01,0.6,8.56,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,484 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51708,13.72,3.68,1.81,72.06,0.64,7.88,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,485 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51589,12.88,3.43,1.4,73.28,0.69,8.05,0.0,0.24] belong to cluster 1
2016-12-14 15:30:09,485 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51673,13.3,3.64,1.53,72.53,0.65,8.03,0.0,0.29] belong to cluster 1
2016-12-14 15:30:09,485 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51748,12.86,3.56,1.27,73.21,0.54,8.38,0.0,0.17] belong to cluster 1
2016-12-14 15:30:09,485 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51652,13.56,3.57,1.47,72.45,0.64,7.96,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,486 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51763,12.61,3.59,1.31,73.29,0.58,8.5,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,486 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51844,13.25,3.76,1.32,72.4,0.58,8.42,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,486 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51761,12.81,3.54,1.23,73.24,0.58,8.39,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,486 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51663,12.93,3.54,1.62,72.96,0.64,8.03,0.0,0.21] belong to cluster 1
2016-12-14 15:30:09,486 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51784,12.68,3.67,1.16,73.11,0.61,8.7,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,487 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51687,13.23,3.54,1.48,72.84,0.56,8.1,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,487 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52196,14.36,3.85,0.89,71.36,0.15,9.15,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,487 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51707,13.48,3.48,1.71,72.52,0.62,7.99,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,487 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51911,13.9,3.73,1.18,72.12,0.06,8.89,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,487 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52177,13.2,3.68,1.15,72.75,0.54,8.52,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,488 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51735,13.02,3.54,1.69,72.73,0.54,8.44,0.0,0.07] belong to cluster 1
2016-12-14 15:30:09,488 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51872,12.93,3.66,1.56,72.51,0.58,8.55,0.0,0.12] belong to cluster 1
2016-12-14 15:30:09,488 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5175,12.82,3.55,1.49,72.75,0.54,8.52,0.0,0.19] belong to cluster 1
2016-12-14 15:30:09,488 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51667,12.94,3.61,1.26,72.75,0.56,8.6,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,488 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51966,14.77,3.75,0.29,72.02,0.03,9.0,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,489 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52081,13.78,2.28,1.43,71.99,0.49,9.85,0.0,0.17] belong to cluster 3
2016-12-14 15:30:09,489 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51736,12.78,3.62,1.29,72.79,0.59,8.7,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,489 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52068,13.55,2.09,1.67,72.18,0.53,9.57,0.27,0.17] belong to cluster 3
2016-12-14 15:30:09,489 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51751,12.81,3.57,1.35,73.02,0.62,8.59,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,489 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5202,13.98,1.35,1.63,71.76,0.39,10.56,0.0,0.18] belong to cluster 2
2016-12-14 15:30:09,489 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5172,13.38,3.5,1.15,72.85,0.5,8.43,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,490 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52177,13.75,1.01,1.36,72.19,0.33,11.14,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,490 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51764,12.98,3.54,1.21,73.0,0.65,8.53,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,490 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52614,13.7,0.0,1.36,71.24,0.19,13.44,0.0,0.1] belong to cluster 4
2016-12-14 15:30:09,490 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51793,13.21,3.48,1.41,72.64,0.59,8.43,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,490 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51813,13.43,3.98,1.18,72.49,0.58,8.15,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,491 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51721,12.87,3.48,1.33,73.04,0.56,8.43,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,491 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.518,13.71,3.93,1.54,71.81,0.54,8.21,0.0,0.15] belong to cluster 1
2016-12-14 15:30:09,491 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51768,12.56,3.52,1.43,73.15,0.57,8.54,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,491 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51811,13.33,3.85,1.25,72.78,0.52,8.12,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,491 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51784,13.08,3.49,1.28,72.86,0.6,8.49,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,492 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51789,13.19,3.9,1.3,72.33,0.55,8.44,0.0,0.28] belong to cluster 1
2016-12-14 15:30:09,492 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51768,12.65,3.56,1.3,73.08,0.61,8.69,0.0,0.14] belong to cluster 1
2016-12-14 15:30:09,492 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51806,13.0,3.8,1.08,73.07,0.56,8.38,0.0,0.12] belong to cluster 1
2016-12-14 15:30:09,492 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51747,12.84,3.5,1.14,73.27,0.56,8.55,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,492 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51711,12.89,3.62,1.57,72.96,0.61,8.11,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,493 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51775,12.85,3.48,1.23,72.97,0.61,8.56,0.09,0.22] belong to cluster 1
2016-12-14 15:30:09,493 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51674,12.79,3.52,1.54,73.36,0.66,7.9,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,493 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51753,12.57,3.47,1.38,73.39,0.6,8.55,0.0,0.06] belong to cluster 1
2016-12-14 15:30:09,493 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51674,12.87,3.56,1.64,73.14,0.65,7.99,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,493 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51783,12.69,3.54,1.34,72.95,0.57,8.75,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,493 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5169,13.33,3.54,1.61,72.54,0.68,8.11,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,494 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51567,13.29,3.45,1.21,72.74,0.56,8.57,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,494 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51851,13.2,3.63,1.07,72.83,0.57,8.41,0.09,0.17] belong to cluster 1
2016-12-14 15:30:09,494 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51909,13.89,3.53,1.32,71.81,0.51,8.78,0.11,0.0] belong to cluster 3
2016-12-14 15:30:09,494 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51662,12.85,3.51,1.44,73.01,0.68,8.23,0.06,0.25] belong to cluster 1
2016-12-14 15:30:09,494 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51797,12.74,3.48,1.35,72.96,0.64,8.68,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,495 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51709,13.0,3.47,1.79,72.72,0.66,8.18,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,495 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52213,14.21,3.82,0.47,71.77,0.11,9.57,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,495 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5166,12.99,3.18,1.23,72.97,0.58,8.81,0.0,0.24] belong to cluster 1
2016-12-14 15:30:09,495 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52213,14.21,3.82,0.47,71.77,0.11,9.57,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,495 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51839,12.85,3.67,1.24,72.57,0.62,8.68,0.0,0.35] belong to cluster 1
2016-12-14 15:30:09,495 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51793,12.79,3.5,1.12,73.03,0.64,8.77,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,496 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51769,13.65,3.66,1.11,72.77,0.11,8.6,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,496 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51755,12.71,3.42,1.2,73.2,0.59,8.64,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,496 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5161,13.33,3.53,1.34,72.67,0.56,8.33,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,496 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51779,13.21,3.39,1.33,72.76,0.59,8.59,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,496 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5167,13.24,3.57,1.38,72.7,0.56,8.44,0.0,0.1] belong to cluster 1
2016-12-14 15:30:09,497 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5221,13.73,3.84,0.72,71.76,0.17,9.74,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,497 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51643,12.16,3.52,1.35,72.89,0.57,8.53,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,497 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51786,12.73,3.43,1.19,72.95,0.62,8.76,0.0,0.3] belong to cluster 1
2016-12-14 15:30:09,497 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51665,13.14,3.45,1.76,72.48,0.6,8.38,0.0,0.17] belong to cluster 1
2016-12-14 15:30:09,497 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.519,13.49,3.48,1.35,71.95,0.55,9.0,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,498 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52127,14.32,3.9,0.83,71.5,0.0,9.49,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,498 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51869,13.19,3.37,1.18,72.72,0.57,8.83,0.0,0.16] belong to cluster 1
2016-12-14 15:30:09,498 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51779,13.64,3.65,0.65,73.0,0.06,8.93,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,498 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52667,13.99,3.7,0.71,71.57,0.02,9.82,0.0,0.1] belong to cluster 3
2016-12-14 15:30:09,498 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5161,13.42,3.4,1.22,72.69,0.59,8.32,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,498 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52223,13.21,3.77,0.79,71.99,0.13,10.02,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,499 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51694,12.86,3.58,1.31,72.61,0.61,8.79,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,499 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51898,13.58,3.35,1.23,72.08,0.59,8.91,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,499 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51646,13.04,3.4,1.26,73.01,0.52,8.58,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,499 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5232,13.72,3.72,0.51,71.75,0.09,10.06,0.0,0.16] belong to cluster 3
2016-12-14 15:30:09,499 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51655,13.41,3.39,1.28,72.64,0.52,8.65,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,500 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51926,13.2,3.33,1.28,72.36,0.6,9.14,0.0,0.11] belong to cluster 1
2016-12-14 15:30:09,500 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52121,14.03,3.76,0.58,71.79,0.11,9.65,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,500 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51808,13.43,2.87,1.19,72.84,0.55,9.03,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,500 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51776,13.53,3.41,1.52,72.04,0.58,8.79,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,500 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51837,13.14,2.84,1.28,72.85,0.55,9.07,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,500 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51796,13.5,3.36,1.63,71.94,0.57,8.81,0.0,0.09] belong to cluster 3
2016-12-14 15:30:09,501 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51778,13.21,2.81,1.29,72.98,0.51,9.02,0.0,0.09] belong to cluster 1
2016-12-14 15:30:09,501 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51832,13.33,3.34,1.54,72.14,0.56,8.99,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,501 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51769,12.45,2.71,1.29,73.7,0.56,9.06,0.0,0.24] belong to cluster 1
2016-12-14 15:30:09,501 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51934,13.64,3.54,0.75,72.65,0.16,8.89,0.15,0.24] belong to cluster 1
2016-12-14 15:30:09,501 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51215,12.99,3.47,1.12,72.98,0.62,8.35,0.0,0.31] belong to cluster 1
2016-12-14 15:30:09,501 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52211,14.19,3.78,0.91,71.36,0.23,9.14,0.0,0.37] belong to cluster 3
2016-12-14 15:30:09,502 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51824,12.87,3.48,1.29,72.95,0.6,8.43,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,502 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51514,14.01,2.68,3.5,69.89,1.68,5.87,2.2,0.0] belong to cluster 5
2016-12-14 15:30:09,502 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51754,13.48,3.74,1.17,72.99,0.59,8.03,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,502 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51915,12.73,1.85,1.86,72.69,0.6,10.09,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,502 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51754,13.39,3.66,1.19,72.79,0.57,8.27,0.0,0.11] belong to cluster 1
2016-12-14 15:30:09,503 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52171,11.56,1.88,1.56,72.86,0.47,11.41,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,503 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51905,13.6,3.62,1.11,72.64,0.14,8.76,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,503 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52151,11.03,1.71,1.56,73.44,0.58,11.62,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,503 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51977,13.81,3.58,1.32,71.72,0.12,8.67,0.69,0.0] belong to cluster 3
2016-12-14 15:30:09,503 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51969,12.64,0.0,1.65,73.75,0.38,11.53,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,503 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52172,13.51,3.86,0.88,71.79,0.23,9.54,0.0,0.11] belong to cluster 3
2016-12-14 15:30:09,504 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51666,12.86,0.0,1.83,73.88,0.97,10.17,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,504 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52227,14.17,3.81,0.78,71.35,0.0,9.69,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,504 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51994,13.27,0.0,1.76,73.03,0.47,11.32,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,504 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52172,13.48,3.74,0.9,72.01,0.18,9.61,0.0,0.07] belong to cluster 3
2016-12-14 15:30:09,504 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52369,13.44,0.0,1.58,72.22,0.32,12.24,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,505 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52099,13.69,3.59,1.12,71.96,0.09,9.4,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,505 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51316,13.02,0.0,3.04,70.48,6.21,6.96,0.0,0.0] belong to cluster 5
2016-12-14 15:30:09,505 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52152,13.05,3.65,0.87,72.22,0.19,9.85,0.0,0.17] belong to cluster 3
2016-12-14 15:30:09,505 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51321,13.0,0.0,3.02,70.7,6.21,6.93,0.0,0.0] belong to cluster 5
2016-12-14 15:30:09,505 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52152,13.05,3.65,0.87,72.32,0.19,9.85,0.0,0.17] belong to cluster 3
2016-12-14 15:30:09,505 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52043,13.38,0.0,1.4,72.25,0.33,12.5,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,506 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52152,13.12,3.58,0.9,72.2,0.23,9.82,0.0,0.16] belong to cluster 3
2016-12-14 15:30:09,506 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52058,12.85,1.61,2.17,72.18,0.76,9.7,0.24,0.51] belong to cluster 2
2016-12-14 15:30:09,506 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.523,13.31,3.58,0.82,71.99,0.12,10.17,0.0,0.03] belong to cluster 3
2016-12-14 15:30:09,506 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52119,12.97,0.33,1.51,73.39,0.13,11.27,0.0,0.28] belong to cluster 2
2016-12-14 15:30:09,506 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51574,14.86,3.67,1.74,71.87,0.16,7.36,0.0,0.12] belong to cluster 1
2016-12-14 15:30:09,507 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51905,14.0,2.39,1.56,72.37,0.0,9.57,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,507 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51848,13.64,3.87,1.27,71.96,0.54,8.32,0.0,0.32] belong to cluster 1
2016-12-14 15:30:09,507 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51937,13.79,2.41,1.19,72.76,0.0,9.77,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,507 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51593,13.09,3.59,1.52,73.1,0.67,7.83,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,507 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51829,14.46,2.24,1.62,72.38,0.0,9.26,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,507 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51631,13.34,3.57,1.57,72.87,0.61,7.89,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,508 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51852,14.09,2.19,1.66,72.67,0.0,9.32,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,508 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51596,13.02,3.56,1.54,73.11,0.72,7.9,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,508 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51299,14.4,1.74,1.54,74.55,0.0,7.59,0.0,0.0] belong to cluster 0
2016-12-14 15:30:09,508 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5159,13.02,3.58,1.51,73.12,0.69,7.96,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,508 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51888,14.99,0.78,1.74,72.5,0.0,9.95,0.0,0.0] belong to cluster 0
2016-12-14 15:30:09,509 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51645,13.44,3.61,1.54,72.39,0.66,8.03,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,509 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51916,14.15,0.0,2.09,72.74,0.0,10.88,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,509 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51627,13.0,3.58,1.54,72.83,0.61,8.04,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,509 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51969,14.56,0.0,0.56,73.48,0.0,11.22,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,509 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51613,13.92,3.52,1.25,72.88,0.37,7.94,0.0,0.14] belong to cluster 1
2016-12-14 15:30:09,510 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51115,17.38,0.0,0.34,75.41,0.0,6.65,0.0,0.0] belong to cluster 0
2016-12-14 15:30:09,510 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5159,12.82,3.52,1.9,72.86,0.69,7.97,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,510 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51131,13.69,3.2,1.81,72.81,1.76,5.43,1.19,0.0] belong to cluster 1
2016-12-14 15:30:09,510 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51592,12.86,3.52,2.12,72.66,0.69,7.97,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,510 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51838,14.32,3.26,2.22,71.25,1.46,5.79,1.63,0.0] belong to cluster 1
2016-12-14 15:30:09,510 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51593,13.25,3.45,1.43,73.17,0.61,7.86,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,511 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52315,13.44,3.34,1.23,72.38,0.6,8.83,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,511 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51646,13.41,3.55,1.25,72.81,0.68,8.1,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,511 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52247,14.86,2.2,2.06,70.26,0.76,9.76,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,511 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51594,13.09,3.52,1.55,72.87,0.68,8.05,0.0,0.09] belong to cluster 1
2016-12-14 15:30:09,511 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52365,15.79,1.83,1.31,70.43,0.31,8.61,1.68,0.0] belong to cluster 3
2016-12-14 15:30:09,512 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51409,14.25,3.09,2.08,72.28,1.1,7.08,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,512 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51613,13.88,1.78,1.79,73.1,0.0,8.67,0.76,0.0] belong to cluster 0
2016-12-14 15:30:09,512 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51625,13.36,3.58,1.49,72.72,0.45,8.21,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,512 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51602,14.85,0.0,2.38,73.28,0.0,8.76,0.64,0.09] belong to cluster 0
2016-12-14 15:30:09,512 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51569,13.24,3.49,1.47,73.25,0.38,8.03,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,512 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51623,14.2,0.0,2.79,73.46,0.04,9.04,0.4,0.09] belong to cluster 0
2016-12-14 15:30:09,512 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51645,13.4,3.49,1.52,72.65,0.67,8.08,0.0,0.1] belong to cluster 1
2016-12-14 15:30:09,513 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51719,14.75,0.0,2.0,73.02,0.0,8.53,1.59,0.08] belong to cluster 0
2016-12-14 15:30:09,513 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51618,13.01,3.5,1.48,72.89,0.6,8.12,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,513 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51683,14.56,0.0,1.98,73.29,0.0,8.52,1.57,0.07] belong to cluster 0
2016-12-14 15:30:09,513 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5164,12.55,3.48,1.87,73.23,0.63,8.08,0.0,0.09] belong to cluster 1
2016-12-14 15:30:09,513 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51545,14.14,0.0,2.68,73.39,0.08,9.07,0.61,0.05] belong to cluster 0
2016-12-14 15:30:09,514 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51841,12.93,3.74,1.11,72.28,0.64,8.96,0.0,0.22] belong to cluster 1
2016-12-14 15:30:09,514 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51556,13.87,0.0,2.54,73.23,0.14,9.41,0.81,0.01] belong to cluster 0
2016-12-14 15:30:09,514 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51605,12.9,3.44,1.45,73.06,0.44,8.27,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,514 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51727,14.7,0.0,2.34,73.28,0.0,8.95,0.66,0.0] belong to cluster 0
2016-12-14 15:30:09,514 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51588,13.12,3.41,1.58,73.26,0.07,8.39,0.0,0.19] belong to cluster 1
2016-12-14 15:30:09,514 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51531,14.38,0.0,2.66,73.1,0.04,9.08,0.64,0.0] belong to cluster 0
2016-12-14 15:30:09,515 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5159,13.24,3.34,1.47,73.1,0.39,8.22,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,515 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51609,15.01,0.0,2.51,73.05,0.05,8.83,0.53,0.0] belong to cluster 0
2016-12-14 15:30:09,515 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51629,12.71,3.33,1.49,73.28,0.67,8.24,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,515 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51508,15.15,0.0,2.25,73.5,0.0,8.34,0.63,0.0] belong to cluster 0
2016-12-14 15:30:09,515 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5186,13.36,3.43,1.43,72.26,0.51,8.6,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,516 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51653,11.95,0.0,1.19,75.18,2.7,8.93,0.0,0.0] belong to cluster 2
2016-12-14 15:30:09,516 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51841,13.02,3.62,1.06,72.34,0.64,9.13,0.0,0.15] belong to cluster 1
2016-12-14 15:30:09,516 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51514,14.85,0.0,2.42,73.72,0.0,8.39,0.56,0.0] belong to cluster 0
2016-12-14 15:30:09,516 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51743,12.2,3.25,1.16,73.55,0.62,8.9,0.0,0.24] belong to cluster 1
2016-12-14 15:30:09,516 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51658,14.8,0.0,1.99,73.11,0.0,8.28,1.71,0.0] belong to cluster 0
2016-12-14 15:30:09,517 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51689,12.67,2.88,1.71,73.21,0.73,8.54,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,517 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51617,14.95,0.0,2.27,73.3,0.0,8.71,0.67,0.0] belong to cluster 0
2016-12-14 15:30:09,517 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51811,12.96,2.96,1.43,72.92,0.6,8.79,0.14,0.0] belong to cluster 1
2016-12-14 15:30:09,517 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51732,14.95,0.0,1.8,72.99,0.0,8.61,1.55,0.0] belong to cluster 0
2016-12-14 15:30:09,517 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51655,12.75,2.85,1.44,73.27,0.57,8.79,0.11,0.22] belong to cluster 1
2016-12-14 15:30:09,517 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51645,14.94,0.0,1.87,73.11,0.0,8.67,1.38,0.0] belong to cluster 0
2016-12-14 15:30:09,518 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5173,12.35,2.72,1.63,72.87,0.7,9.23,0.0,0.0] belong to cluster 1
2016-12-14 15:30:09,518 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51831,14.39,0.0,1.82,72.86,1.41,6.47,2.88,0.0] belong to cluster 0
2016-12-14 15:30:09,518 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5182,12.62,2.76,0.83,73.81,0.35,9.42,0.0,0.2] belong to cluster 1
2016-12-14 15:30:09,518 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5164,14.37,0.0,2.74,72.85,0.0,9.45,0.54,0.0] belong to cluster 0
2016-12-14 15:30:09,518 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52725,13.8,3.15,0.66,70.57,0.08,11.64,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,518 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51623,14.14,0.0,2.88,72.61,0.08,9.18,1.06,0.0] belong to cluster 0
2016-12-14 15:30:09,519 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.5241,13.83,2.9,1.17,71.15,0.08,10.79,0.0,0.0] belong to cluster 3
2016-12-14 15:30:09,519 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51685,14.92,0.0,1.99,73.06,0.0,8.4,1.59,0.0] belong to cluster 0
2016-12-14 15:30:09,519 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52475,11.45,0.0,1.88,72.19,0.81,13.24,0.0,0.34] belong to cluster 4
2016-12-14 15:30:09,519 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.52065,14.36,0.0,2.02,73.42,0.0,8.44,1.64,0.0] belong to cluster 0
2016-12-14 15:30:09,519 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51651,14.38,0.0,1.94,73.61,0.0,8.48,1.57,0.0] belong to cluster 0
2016-12-14 15:30:09,519 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[1.51711,14.23,0.0,2.08,73.36,0.0,8.62,1.67,0.0] belong to cluster 0
2016-12-14 15:30:09,521 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 73). 2057 bytes result sent to driver
2016-12-14 15:30:09,522 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 72). 2057 bytes result sent to driver
2016-12-14 15:30:09,523 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 72) in 50 ms on localhost (1/2)
2016-12-14 15:30:09,523 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 73) in 49 ms on localhost (2/2)
2016-12-14 15:30:09,523 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 36 (foreach at K_means.scala:108) finished in 0.050 s
2016-12-14 15:30:09,524 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,524 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: foreach at K_means.scala:108, took 0.061648 s
2016-12-14 15:30:09,536 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:119
2016-12-14 15:30:09,537 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (foreach at K_means.scala:119) with 2 output partitions
2016-12-14 15:30:09,537 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (foreach at K_means.scala:119)
2016-12-14 15:30:09,537 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:09,538 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:09,538 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (MapPartitionsRDD[53] at map at K_means.scala:117), which has no missing parents
2016-12-14 15:30:09,540 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 4.3 KB, free 487.2 KB)
2016-12-14 15:30:09,544 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.6 KB, free 489.8 KB)
2016-12-14 15:30:09,544 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:57566 (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,545 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,545 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[53] at map at K_means.scala:117)
2016-12-14 15:30:09,546 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 2 tasks
2016-12-14 15:30:09,547 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 74, localhost, partition 0,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:09,548 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 37.0 (TID 75, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:09,548 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 74)
2016-12-14 15:30:09,548 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 37.0 (TID 75)
2016-12-14 15:30:09,550 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,550 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,551 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:09,551 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,551 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:09,551 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,551 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:09,551 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:09,552 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,553 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,553 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,553 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,553 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,553 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,553 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,553 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,554 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,554 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,554 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,554 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,554 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,554 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,554 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,555 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:09,556 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:09,557 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,558 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,558 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,558 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,558 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,558 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,558 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,559 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,559 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,559 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,559 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,559 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,559 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,559 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,560 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,560 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,560 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,560 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,560 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,561 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,561 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,561 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,561 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,561 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,562 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,562 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,562 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,562 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,562 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,562 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,563 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,563 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,563 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,563 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,563 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,563 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,564 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,564 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,564 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,564 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:09,564 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,565 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,565 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,565 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,565 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,565 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,566 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,566 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,566 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:09,566 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:09,566 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:09,567 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:09,567 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 1.0
2016-12-14 15:30:09,565 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,567 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:09,567 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,567 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 5.0
2016-12-14 15:30:09,568 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,568 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,568 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,568 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,568 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,569 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,569 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,569 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,569 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,569 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,569 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,570 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,570 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,570 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,570 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,570 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 5.0
2016-12-14 15:30:09,570 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,571 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 5.0
2016-12-14 15:30:09,571 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,571 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,571 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 15:30:09,571 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,572 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,572 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:09,572 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,572 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 3.0
2016-12-14 15:30:09,572 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,572 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 3.0
2016-12-14 15:30:09,573 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,573 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 3.0
2016-12-14 15:30:09,573 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,573 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 3.0
2016-12-14 15:30:09,573 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,573 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 0.0
2016-12-14 15:30:09,574 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,574 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 0.0
2016-12-14 15:30:09,574 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,574 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 2.0
2016-12-14 15:30:09,574 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:09,575 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 2.0
2016-12-14 15:30:09,575 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,575 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 0.0
2016-12-14 15:30:09,575 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,575 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 1.0
2016-12-14 15:30:09,575 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,576 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 1.0
2016-12-14 15:30:09,576 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,576 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 1.0
2016-12-14 15:30:09,576 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,576 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 3.0
2016-12-14 15:30:09,576 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,577 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 3.0
2016-12-14 15:30:09,577 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,577 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,577 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,577 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,577 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,578 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,578 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,578 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,578 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,578 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,579 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,579 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,579 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,579 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,579 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,579 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,580 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,580 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,580 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,580 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,580 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,581 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,580 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,581 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,581 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 2.0
2016-12-14 15:30:09,581 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,581 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,581 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,581 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,582 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,582 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,582 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,582 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,582 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,582 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,583 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,583 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,583 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,583 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,583 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,584 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,584 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,584 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,584 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,584 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,584 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,585 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,585 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,585 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:09,585 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,585 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:09,586 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:09,586 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:09,586 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:09,588 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 37.0 (TID 75). 2057 bytes result sent to driver
2016-12-14 15:30:09,589 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 74). 2057 bytes result sent to driver
2016-12-14 15:30:09,590 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 74) in 43 ms on localhost (1/2)
2016-12-14 15:30:09,590 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 37.0 (TID 75) in 43 ms on localhost (2/2)
2016-12-14 15:30:09,590 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (foreach at K_means.scala:119) finished in 0.044 s
2016-12-14 15:30:09,590 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,591 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: foreach at K_means.scala:119, took 0.054461 s
2016-12-14 15:30:09,634 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:57566 in memory (size: 2.1 KB, free: 529.9 MB)
2016-12-14 15:30:09,636 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_55_piece0 on localhost:57566 in memory (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,637 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 91
2016-12-14 15:30:09,638 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:57566 in memory (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,638 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 90
2016-12-14 15:30:09,639 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:57566 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:09,639 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 89
2016-12-14 15:30:09,641 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:57566 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:09,641 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 88
2016-12-14 15:30:09,642 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 11
2016-12-14 15:30:09,643 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:57566 in memory (size: 599.0 B, free: 529.9 MB)
2016-12-14 15:30:09,644 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 87
2016-12-14 15:30:09,645 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:57566 in memory (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:09,645 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 86
2016-12-14 15:30:09,645 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:13
2016-12-14 15:30:09,646 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:57566 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:09,647 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 85
2016-12-14 15:30:09,647 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 54 (map at Relabel.scala:13)
2016-12-14 15:30:09,647 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 15:30:09,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (sortBy at Relabel.scala:13) with 2 output partitions
2016-12-14 15:30:09,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (sortBy at Relabel.scala:13)
2016-12-14 15:30:09,648 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:57566 in memory (size: 595.0 B, free: 529.9 MB)
2016-12-14 15:30:09,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 38)
2016-12-14 15:30:09,649 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 38)
2016-12-14 15:30:09,649 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 84
2016-12-14 15:30:09,650 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 38 (MapPartitionsRDD[54] at map at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:09,650 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:57566 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:09,651 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 83
2016-12-14 15:30:09,651 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:57566 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:09,652 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 5.2 KB, free 434.9 KB)
2016-12-14 15:30:09,653 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 82
2016-12-14 15:30:09,653 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 15:30:09,654 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:57566 in memory (size: 597.0 B, free: 529.9 MB)
2016-12-14 15:30:09,655 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 81
2016-12-14 15:30:09,656 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:57566 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:09,656 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 15:30:09,656 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 15:30:09,656 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 15:30:09,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 15:30:09,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 15:30:09,658 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:57566 in memory (size: 1659.0 B, free: 529.9 MB)
2016-12-14 15:30:09,658 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.1 KB, free 421.0 KB)
2016-12-14 15:30:09,658 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 15:30:09,659 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:57566 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 15:30:09,659 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,659 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,660 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[54] at map at Relabel.scala:13)
2016-12-14 15:30:09,660 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 2 tasks
2016-12-14 15:30:09,660 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 15:30:09,661 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 15:30:09,661 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 76, localhost, partition 0,PROCESS_LOCAL, 2379 bytes)
2016-12-14 15:30:09,662 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 38.0 (TID 77, localhost, partition 1,PROCESS_LOCAL, 2379 bytes)
2016-12-14 15:30:09,662 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:57566 in memory (size: 2.9 KB, free: 529.9 MB)
2016-12-14 15:30:09,662 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 76)
2016-12-14 15:30:09,662 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 38.0 (TID 77)
2016-12-14 15:30:09,663 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 15:30:09,663 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 15:30:09,663 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 15:30:09,663 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 15:30:09,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 15:30:09,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 15:30:09,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 15:30:09,664 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:09,665 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 15:30:09,665 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 4
2016-12-14 15:30:09,665 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:09,666 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,666 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 15:30:09,667 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 15:30:09,667 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 15:30:09,668 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,668 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 15:30:09,668 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 15:30:09,669 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:57566 in memory (size: 1195.0 B, free: 529.9 MB)
2016-12-14 15:30:09,670 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 15:30:09,670 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 15:30:09,670 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 15:30:09,670 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:57566 in memory (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:09,671 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 15:30:09,672 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:57566 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:09,672 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 15:30:09,673 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 15:30:09,673 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:57566 in memory (size: 1791.0 B, free: 529.9 MB)
2016-12-14 15:30:09,674 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 15:30:09,674 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 15:30:09,675 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 15:30:09,675 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 15:30:09,675 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 76). 2237 bytes result sent to driver
2016-12-14 15:30:09,676 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:57566 in memory (size: 1657.0 B, free: 530.0 MB)
2016-12-14 15:30:09,676 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 15:30:09,676 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 15:30:09,678 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:57566 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 15:30:09,678 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 38.0 (TID 77). 2237 bytes result sent to driver
2016-12-14 15:30:09,678 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 15:30:09,679 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 76) in 17 ms on localhost (1/2)
2016-12-14 15:30:09,679 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 15:30:09,679 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:57566 in memory (size: 858.0 B, free: 530.0 MB)
2016-12-14 15:30:09,680 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 15:30:09,680 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 15:30:09,681 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:57566 in memory (size: 1661.0 B, free: 530.0 MB)
2016-12-14 15:30:09,682 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 38.0 (TID 77) in 19 ms on localhost (2/2)
2016-12-14 15:30:09,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 38 (map at Relabel.scala:13) finished in 0.021 s
2016-12-14 15:30:09,682 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,683 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 39)
2016-12-14 15:30:09,683 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,683 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:09,685 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 3.5 KB, free 340.4 KB)
2016-12-14 15:30:09,689 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2022.0 B, free 342.4 KB)
2016-12-14 15:30:09,689 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:57566 (size: 2022.0 B, free: 530.0 MB)
2016-12-14 15:30:09,690 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,690 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[58] at sortBy at Relabel.scala:13)
2016-12-14 15:30:09,690 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 2 tasks
2016-12-14 15:30:09,691 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 78, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,692 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 39.0 (TID 79, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,692 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 78)
2016-12-14 15:30:09,692 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 39.0 (TID 79)
2016-12-14 15:30:09,694 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,694 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,694 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,694 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,703 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 39.0 (TID 79). 1200 bytes result sent to driver
2016-12-14 15:30:09,703 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 78). 1208 bytes result sent to driver
2016-12-14 15:30:09,705 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 39.0 (TID 79) in 13 ms on localhost (1/2)
2016-12-14 15:30:09,705 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 78) in 14 ms on localhost (2/2)
2016-12-14 15:30:09,705 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (sortBy at Relabel.scala:13) finished in 0.014 s
2016-12-14 15:30:09,705 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,705 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: sortBy at Relabel.scala:13, took 0.059339 s
2016-12-14 15:30:09,889 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_57_piece0 on localhost:57566 in memory (size: 2022.0 B, free: 530.0 MB)
2016-12-14 15:30:09,890 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 93
2016-12-14 15:30:09,891 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_56_piece0 on localhost:57566 in memory (size: 3.1 KB, free: 530.0 MB)
2016-12-14 15:30:09,892 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 92
2016-12-14 15:30:09,912 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 15:30:09,919 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 12 is 155 bytes
2016-12-14 15:30:09,924 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 56 (sortBy at Relabel.scala:13)
2016-12-14 15:30:09,925 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (collect at Relabel.scala:14) with 2 output partitions
2016-12-14 15:30:09,925 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 42 (collect at Relabel.scala:14)
2016-12-14 15:30:09,925 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 41)
2016-12-14 15:30:09,925 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 41)
2016-12-14 15:30:09,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 41 (MapPartitionsRDD[56] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:09,932 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 3.6 KB, free 332.2 KB)
2016-12-14 15:30:09,936 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.0 KB, free 334.2 KB)
2016-12-14 15:30:09,937 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:57566 (size: 2.0 KB, free: 530.0 MB)
2016-12-14 15:30:09,937 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,938 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[56] at sortBy at Relabel.scala:13)
2016-12-14 15:30:09,938 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 15:30:09,940 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 80, localhost, partition 0,NODE_LOCAL, 2128 bytes)
2016-12-14 15:30:09,940 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 81, localhost, partition 1,NODE_LOCAL, 2128 bytes)
2016-12-14 15:30:09,941 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 80)
2016-12-14 15:30:09,941 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 81)
2016-12-14 15:30:09,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,962 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 80). 1303 bytes result sent to driver
2016-12-14 15:30:09,965 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 81). 1303 bytes result sent to driver
2016-12-14 15:30:09,965 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 80) in 26 ms on localhost (1/2)
2016-12-14 15:30:09,968 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 81) in 27 ms on localhost (2/2)
2016-12-14 15:30:09,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 41 (sortBy at Relabel.scala:13) finished in 0.029 s
2016-12-14 15:30:09,968 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 15:30:09,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:09,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:09,969 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 42)
2016-12-14 15:30:09,969 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:09,969 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 42 (MapPartitionsRDD[60] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:09,974 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 3.4 KB, free 337.6 KB)
2016-12-14 15:30:09,978 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 1946.0 B, free 339.5 KB)
2016-12-14 15:30:09,978 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:57566 (size: 1946.0 B, free: 530.0 MB)
2016-12-14 15:30:09,979 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:09,979 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[60] at sortBy at Relabel.scala:13)
2016-12-14 15:30:09,979 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 15:30:09,981 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 82, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,981 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 83, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:09,982 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 82)
2016-12-14 15:30:09,982 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 83)
2016-12-14 15:30:09,989 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,989 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:09,990 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:09,990 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:10,013 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 83). 1388 bytes result sent to driver
2016-12-14 15:30:10,013 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 82). 1356 bytes result sent to driver
2016-12-14 15:30:10,015 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 83) in 34 ms on localhost (1/2)
2016-12-14 15:30:10,015 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 82) in 35 ms on localhost (2/2)
2016-12-14 15:30:10,015 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 42 (collect at Relabel.scala:14) finished in 0.035 s
2016-12-14 15:30:10,016 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 15:30:10,016 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: collect at Relabel.scala:14, took 0.104169 s
2016-12-14 15:30:10,025 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:123
2016-12-14 15:30:10,026 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (foreach at K_means.scala:123) with 2 output partitions
2016-12-14 15:30:10,027 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 43 (foreach at K_means.scala:123)
2016-12-14 15:30:10,027 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:10,028 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:10,028 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 43 (MapPartitionsRDD[61] at map at Relabel.scala:31), which has no missing parents
2016-12-14 15:30:10,030 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 4.8 KB, free 344.3 KB)
2016-12-14 15:30:10,034 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.9 KB, free 347.2 KB)
2016-12-14 15:30:10,035 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:57566 (size: 2.9 KB, free: 530.0 MB)
2016-12-14 15:30:10,035 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:10,035 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[61] at map at Relabel.scala:31)
2016-12-14 15:30:10,036 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 15:30:10,038 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 84, localhost, partition 0,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:10,038 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 85, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:10,039 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 84)
2016-12-14 15:30:10,039 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 85)
2016-12-14 15:30:10,042 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:10,042 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:10,044 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,044 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,045 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,045 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,045 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,045 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:10,045 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,045 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:10,046 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,046 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,046 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,046 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,046 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,047 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,047 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,046 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,047 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,047 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,047 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,048 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,048 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,048 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,048 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,048 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,048 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,049 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,049 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,049 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,049 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,049 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,049 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,049 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,050 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,050 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,050 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,050 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,050 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,050 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,051 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,051 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,051 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,051 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,051 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,051 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,052 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,052 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,052 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,052 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,052 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,052 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:10,053 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,053 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:10,053 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,053 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,053 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,053 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,053 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,054 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,054 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,054 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,054 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,054 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,054 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,055 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,055 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,055 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,055 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,055 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,055 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,056 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,056 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,056 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,056 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,056 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,056 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,056 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,057 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,057 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,057 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,057 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,057 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,057 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,058 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,058 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,058 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,058 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,058 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,058 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,059 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,059 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,059 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,059 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,059 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,059 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:10,059 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,060 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,060 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,060 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,060 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,060 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,060 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,061 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,061 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,061 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,061 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,061 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:10,061 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,062 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:10,062 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,062 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:10,062 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,062 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:10,062 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,063 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:10,063 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,063 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:10,063 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,063 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 0.0
2016-12-14 15:30:10,063 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:10,064 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,064 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,064 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,064 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,064 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,064 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,064 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,065 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,065 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,065 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,065 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,065 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,065 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,066 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,066 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 0.0
2016-12-14 15:30:10,066 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,066 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 0.0
2016-12-14 15:30:10,066 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:10,066 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,067 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,067 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,067 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,067 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:10,067 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,067 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:10,067 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,068 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:10,068 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,068 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:10,068 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,068 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:10,068 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,069 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 5.0
2016-12-14 15:30:10,069 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,069 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 5.0
2016-12-14 15:30:10,069 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,069 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 3.0
2016-12-14 15:30:10,069 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,070 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 3.0
2016-12-14 15:30:10,070 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,070 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 5.0
2016-12-14 15:30:10,070 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,070 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 1.0
2016-12-14 15:30:10,070 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,070 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 1.0
2016-12-14 15:30:10,071 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,071 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 1.0
2016-12-14 15:30:10,071 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,071 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 0.0
2016-12-14 15:30:10,071 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,071 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 0.0
2016-12-14 15:30:10,072 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,072 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,072 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,072 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,072 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,072 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,073 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,073 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,073 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,073 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,073 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,073 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,074 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,074 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,074 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,074 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,074 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,074 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,074 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,075 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,075 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,075 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,075 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,075 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 3.0
2016-12-14 15:30:10,075 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,076 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,076 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,076 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,076 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,076 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,076 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,076 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,077 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:10,077 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,077 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,077 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,077 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,077 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,078 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:10,078 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,078 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,078 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,078 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,079 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:10,080 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 84). 2057 bytes result sent to driver
2016-12-14 15:30:10,081 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 85). 2057 bytes result sent to driver
2016-12-14 15:30:10,083 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 85) in 45 ms on localhost (1/2)
2016-12-14 15:30:10,083 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 84) in 46 ms on localhost (2/2)
2016-12-14 15:30:10,083 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 43 (foreach at K_means.scala:123) finished in 0.046 s
2016-12-14 15:30:10,084 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 15:30:10,084 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: foreach at K_means.scala:123, took 0.058234 s
2016-12-14 15:30:10,094 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 15:30:10,095 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 62 (map at MulticlassMetrics.scala:46)
2016-12-14 15:30:10,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 15:30:10,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 45 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 15:30:10,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 44)
2016-12-14 15:30:10,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 44)
2016-12-14 15:30:10,097 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 44 (MapPartitionsRDD[62] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 15:30:10,099 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 5.7 KB, free 352.9 KB)
2016-12-14 15:30:10,103 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.4 KB, free 356.3 KB)
2016-12-14 15:30:10,104 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:57566 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 15:30:10,105 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:10,105 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[62] at map at MulticlassMetrics.scala:46)
2016-12-14 15:30:10,105 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 2 tasks
2016-12-14 15:30:10,107 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 86, localhost, partition 0,PROCESS_LOCAL, 2379 bytes)
2016-12-14 15:30:10,108 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 44.0 (TID 87, localhost, partition 1,PROCESS_LOCAL, 2379 bytes)
2016-12-14 15:30:10,108 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 86)
2016-12-14 15:30:10,108 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 44.0 (TID 87)
2016-12-14 15:30:10,112 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:10,112 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:10,120 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 44.0 (TID 87). 2237 bytes result sent to driver
2016-12-14 15:30:10,121 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 86). 2237 bytes result sent to driver
2016-12-14 15:30:10,122 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 44.0 (TID 87) in 15 ms on localhost (1/2)
2016-12-14 15:30:10,122 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 86) in 15 ms on localhost (2/2)
2016-12-14 15:30:10,123 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 15:30:10,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 44 (map at MulticlassMetrics.scala:46) finished in 0.017 s
2016-12-14 15:30:10,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:10,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:10,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 45)
2016-12-14 15:30:10,123 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:10,124 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 45 (ShuffledRDD[63] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 15:30:10,125 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 2.6 KB, free 358.9 KB)
2016-12-14 15:30:10,129 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 1592.0 B, free 360.5 KB)
2016-12-14 15:30:10,130 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:57566 (size: 1592.0 B, free: 529.9 MB)
2016-12-14 15:30:10,131 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:10,131 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 45 (ShuffledRDD[63] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 15:30:10,131 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 45.0 with 2 tasks
2016-12-14 15:30:10,133 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 45.0 (TID 88, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:10,135 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 45.0 (TID 89, localhost, partition 1,PROCESS_LOCAL, 2139 bytes)
2016-12-14 15:30:10,135 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 45.0 (TID 88)
2016-12-14 15:30:10,135 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 45.0 (TID 89)
2016-12-14 15:30:10,136 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 15:30:10,136 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:10,136 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:10,136 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:10,143 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 45.0 (TID 89). 1124 bytes result sent to driver
2016-12-14 15:30:10,143 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 45.0 (TID 88). 1176 bytes result sent to driver
2016-12-14 15:30:10,144 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 45.0 (TID 89) in 9 ms on localhost (1/2)
2016-12-14 15:30:10,145 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 45.0 (TID 88) in 12 ms on localhost (2/2)
2016-12-14 15:30:10,145 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 45 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.013 s
2016-12-14 15:30:10,145 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 15:30:10,145 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.050641 s
2016-12-14 15:30:10,158 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 15:30:10,159 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 66 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:10,160 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 15:30:10,160 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 47 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:10,160 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 46)
2016-12-14 15:30:10,161 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 46)
2016-12-14 15:30:10,162 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 46 (MapPartitionsRDD[66] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 15:30:10,164 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 6.3 KB, free 366.7 KB)
2016-12-14 15:30:10,168 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.5 KB, free 370.3 KB)
2016-12-14 15:30:10,169 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:57566 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:10,170 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:10,170 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[66] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:10,170 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 46.0 with 2 tasks
2016-12-14 15:30:10,172 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 46.0 (TID 90, localhost, partition 0,PROCESS_LOCAL, 2379 bytes)
2016-12-14 15:30:10,172 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 46.0 (TID 91, localhost, partition 1,PROCESS_LOCAL, 2379 bytes)
2016-12-14 15:30:10,172 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 46.0 (TID 91)
2016-12-14 15:30:10,172 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 46.0 (TID 90)
2016-12-14 15:30:10,175 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:10,175 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:10,185 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 46.0 (TID 91). 2237 bytes result sent to driver
2016-12-14 15:30:10,185 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 46.0 (TID 90). 2237 bytes result sent to driver
2016-12-14 15:30:10,187 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 46.0 (TID 91) in 15 ms on localhost (1/2)
2016-12-14 15:30:10,187 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 46.0 (TID 90) in 16 ms on localhost (2/2)
2016-12-14 15:30:10,187 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 15:30:10,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 46 (countByValue at MulticlassMetrics.scala:43) finished in 0.017 s
2016-12-14 15:30:10,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:10,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:10,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 47)
2016-12-14 15:30:10,189 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:10,189 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 47 (ShuffledRDD[67] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 15:30:10,191 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64 stored as values in memory (estimated size 2.6 KB, free 372.9 KB)
2016-12-14 15:30:10,194 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64_piece0 stored as bytes in memory (estimated size 1562.0 B, free 374.4 KB)
2016-12-14 15:30:10,195 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_64_piece0 in memory on localhost:57566 (size: 1562.0 B, free: 529.9 MB)
2016-12-14 15:30:10,195 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:10,196 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 47 (ShuffledRDD[67] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:10,196 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 47.0 with 2 tasks
2016-12-14 15:30:10,197 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 47.0 (TID 92, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 15:30:10,197 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 47.0 (TID 93, localhost, partition 1,PROCESS_LOCAL, 2139 bytes)
2016-12-14 15:30:10,198 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 47.0 (TID 92)
2016-12-14 15:30:10,198 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 47.0 (TID 93)
2016-12-14 15:30:10,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 15:30:10,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:10,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:10,199 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:10,202 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 47.0 (TID 93). 1124 bytes result sent to driver
2016-12-14 15:30:10,203 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 47.0 (TID 92). 1177 bytes result sent to driver
2016-12-14 15:30:10,203 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 47.0 (TID 93) in 6 ms on localhost (1/2)
2016-12-14 15:30:10,204 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 47.0 (TID 92) in 8 ms on localhost (2/2)
2016-12-14 15:30:10,204 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 47 (countByValue at MulticlassMetrics.scala:43) finished in 0.008 s
2016-12-14 15:30:10,204 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 15:30:10,204 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: countByValue at MulticlassMetrics.scala:43, took 0.045561 s
2016-12-14 15:30:10,205 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.5420560747663551
2016-12-14 15:30:10,206 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65 stored as values in memory (estimated size 856.0 B, free 375.3 KB)
2016-12-14 15:30:10,208 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65_piece0 stored as bytes in memory (estimated size 652.0 B, free 375.9 KB)
2016-12-14 15:30:10,208 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_65_piece0 in memory on localhost:57566 (size: 652.0 B, free: 529.9 MB)
2016-12-14 15:30:10,209 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 65 from broadcast at KMeansModel.scala:87
2016-12-14 15:30:10,221 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 15:30:10,222 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 31 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 15:30:10,222 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 48 (sum at KMeansModel.scala:88)
2016-12-14 15:30:10,222 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:10,223 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:10,223 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 48 (MapPartitionsRDD[68] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 15:30:10,225 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66 stored as values in memory (estimated size 4.2 KB, free 380.1 KB)
2016-12-14 15:30:10,229 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.4 KB, free 382.6 KB)
2016-12-14 15:30:10,229 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_66_piece0 in memory on localhost:57566 (size: 2.4 KB, free: 529.9 MB)
2016-12-14 15:30:10,230 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:10,230 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 48 (MapPartitionsRDD[68] at map at KMeansModel.scala:88)
2016-12-14 15:30:10,230 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 48.0 with 2 tasks
2016-12-14 15:30:10,232 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 48.0 (TID 94, localhost, partition 0,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:10,232 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 48.0 (TID 95, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
2016-12-14 15:30:10,233 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 48.0 (TID 94)
2016-12-14 15:30:10,233 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 48.0 (TID 95)
2016-12-14 15:30:10,236 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:10,236 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:10,241 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 48.0 (TID 95). 2064 bytes result sent to driver
2016-12-14 15:30:10,241 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 48.0 (TID 94). 2064 bytes result sent to driver
2016-12-14 15:30:10,242 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 48.0 (TID 94) in 11 ms on localhost (1/2)
2016-12-14 15:30:10,243 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 48.0 (TID 95) in 11 ms on localhost (2/2)
2016-12-14 15:30:10,243 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 48 (sum at KMeansModel.scala:88) finished in 0.012 s
2016-12-14 15:30:10,243 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 15:30:10,243 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 31 finished: sum at KMeansModel.scala:88, took 0.022043 s
2016-12-14 15:30:10,244 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 336.2131430295502
2016-12-14 15:30:10,244 INFO  com.datageek.test.K_means$ - main: ==(-_-)~====END====(-_-)~==
2016-12-14 15:30:10,332 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 15:30:10,332 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 15:30:10,333 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 15:30:10,333 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 15:30:10,334 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 15:30:10,334 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 15:30:10,334 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 15:30:10,335 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 15:30:10,335 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 15:30:10,335 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 15:30:10,336 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 15:30:10,336 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 15:30:10,336 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 15:30:10,337 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 15:30:10,337 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 15:30:10,337 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 15:30:10,337 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 15:30:10,338 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 15:30:10,338 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 15:30:10,338 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 15:30:10,339 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 15:30:10,339 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 15:30:10,339 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 15:30:10,340 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 15:30:10,340 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 15:30:10,398 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 15:30:10,491 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 15:30:10,511 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 15:30:10,512 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 15:30:10,513 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 15:30:10,516 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 15:30:10,523 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 15:30:10,526 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 15:30:10,527 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 15:30:10,532 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 15:30:10,533 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-c370e270-e9ae-4031-86ba-92890f49701c
2016-12-14 15:30:10,576 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 15:30:10,577 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 15:30:42,865 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 15:30:44,006 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 15:30:44,012 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 15:30:44,013 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 15:30:44,407 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 20257.
2016-12-14 15:30:44,998 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 15:30:45,069 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 15:30:45,307 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:26484]
2016-12-14 15:30:45,310 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:26484]
2016-12-14 15:30:45,319 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 26484.
2016-12-14 15:30:45,350 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 15:30:45,379 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 15:30:45,403 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-4bc0f985-7f88-4534-9e6c-88b750408ed8
2016-12-14 15:30:45,430 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 15:30:45,542 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 15:30:45,827 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 15:30:45,918 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 15:30:45,922 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 15:30:45,925 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 15:30:45,970 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:20257/jars/mysql-connector-java-5.1.25.jar with timestamp 1481700645969
2016-12-14 15:30:45,970 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:20257/jars/ojdbc6.jar with timestamp 1481700645970
2016-12-14 15:30:45,971 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:20257/jars/orai18n.jar with timestamp 1481700645971
2016-12-14 15:30:45,971 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:20257/jars/machine_learning_2.10-1.0.jar with timestamp 1481700645971
2016-12-14 15:30:46,059 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 15:30:46,078 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 23995.
2016-12-14 15:30:46,079 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 23995
2016-12-14 15:30:46,081 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 15:30:46,082 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 15:30:46,086 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:23995 with 530.0 MB RAM, BlockManagerId(driver, localhost, 23995)
2016-12-14 15:30:46,090 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 15:30:47,986 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481700646030
2016-12-14 15:30:48,044 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/glass.txt
2016-12-14 15:30:48,046 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 100
2016-12-14 15:30:48,047 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 6
2016-12-14 15:30:48,048 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 15:30:48,050 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 15:30:48,050 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 15:30:48,728 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 15:30:49,130 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 15:30:49,135 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:23995 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 15:30:49,142 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:88
2016-12-14 15:30:49,314 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 15:30:49,411 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 15:30:49,443 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (first at PCA.scala:42) with 1 output partitions
2016-12-14 15:30:49,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (first at PCA.scala:42)
2016-12-14 15:30:49,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:49,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:49,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:100), which has no missing parents
2016-12-14 15:30:49,480 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 304.6 KB)
2016-12-14 15:30:49,505 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 306.7 KB)
2016-12-14 15:30:49,506 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:23995 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 15:30:49,507 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:49,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:100)
2016-12-14 15:30:49,516 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 1 tasks
2016-12-14 15:30:49,586 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:49,602 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 15:30:49,614 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20257/jars/mysql-connector-java-5.1.25.jar with timestamp 1481700645969
2016-12-14 15:30:49,615 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 15:30:49,727 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20257/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/fetchFileTemp4954906818196596445.tmp
2016-12-14 15:30:49,831 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 15:30:49,831 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20257/jars/orai18n.jar with timestamp 1481700645971
2016-12-14 15:30:49,832 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20257/jars/orai18n.jar to /tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/fetchFileTemp327025245984190021.tmp
2016-12-14 15:30:49,850 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/orai18n.jar to class loader
2016-12-14 15:30:49,851 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20257/jars/machine_learning_2.10-1.0.jar with timestamp 1481700645971
2016-12-14 15:30:49,852 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20257/jars/machine_learning_2.10-1.0.jar to /tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/fetchFileTemp7278153121898997358.tmp
2016-12-14 15:30:49,860 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/machine_learning_2.10-1.0.jar to class loader
2016-12-14 15:30:49,861 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:20257/jars/ojdbc6.jar with timestamp 1481700645970
2016-12-14 15:30:49,861 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:20257/jars/ojdbc6.jar to /tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/fetchFileTemp8497629662253605524.tmp
2016-12-14 15:30:49,875 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793/userFiles-11afc2ac-43b3-4e53-9f1c-a92ae34e82f0/ojdbc6.jar to class loader
2016-12-14 15:30:49,892 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 15:30:49,896 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/glass.txt:0+5116
2016-12-14 15:30:49,909 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 15:30:49,909 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 15:30:49,909 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 15:30:49,909 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 15:30:49,909 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 15:30:49,949 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 13.7 KB, free 320.4 KB)
2016-12-14 15:30:49,950 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:23995 (size: 13.7 KB, free: 530.0 MB)
2016-12-14 15:30:50,035 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2741 bytes result sent to driver
2016-12-14 15:30:50,075 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 515 ms on localhost (1/1)
2016-12-14 15:30:50,079 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 15:30:50,080 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (first at PCA.scala:42) finished in 0.545 s
2016-12-14 15:30:50,087 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: first at PCA.scala:42, took 0.675220 s
2016-12-14 15:30:50,140 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 15:30:50,141 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 15:30:50,141 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (first at RowMatrix.scala:61)
2016-12-14 15:30:50,142 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:50,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:50,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:100), which has no missing parents
2016-12-14 15:30:50,147 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 3.6 KB, free 324.0 KB)
2016-12-14 15:30:50,155 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 326.1 KB)
2016-12-14 15:30:50,155 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:23995 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 15:30:50,156 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:50,157 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:100)
2016-12-14 15:30:50,157 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 1 tasks
2016-12-14 15:30:50,166 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:50,168 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 15:30:50,178 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:50,189 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 1). 2216 bytes result sent to driver
2016-12-14 15:30:50,208 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 1) in 46 ms on localhost (1/1)
2016-12-14 15:30:50,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (first at RowMatrix.scala:61) finished in 0.046 s
2016-12-14 15:30:50,209 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 15:30:50,209 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: first at RowMatrix.scala:61, took 0.069202 s
2016-12-14 15:30:50,774 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 15:30:50,776 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 15:30:50,777 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:331)
2016-12-14 15:30:50,777 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:50,778 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:50,779 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 15:30:50,782 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 4.6 KB, free 330.6 KB)
2016-12-14 15:30:50,790 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 333.1 KB)
2016-12-14 15:30:50,791 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:23995 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 15:30:50,793 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:50,793 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331)
2016-12-14 15:30:50,793 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 15:30:50,796 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:50,799 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:50,800 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 2)
2016-12-14 15:30:50,801 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 3)
2016-12-14 15:30:50,809 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 15:30:50,809 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/glass.txt:5116+5117
2016-12-14 15:30:50,810 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:50,829 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 13.9 KB, free 347.0 KB)
2016-12-14 15:30:50,830 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:23995 (size: 13.9 KB, free: 530.0 MB)
2016-12-14 15:30:50,838 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 2). 2176 bytes result sent to driver
2016-12-14 15:30:50,839 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 3). 2756 bytes result sent to driver
2016-12-14 15:30:50,849 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 2) in 53 ms on localhost (1/2)
2016-12-14 15:30:50,849 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 3) in 51 ms on localhost (2/2)
2016-12-14 15:30:50,850 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (treeAggregate at RowMatrix.scala:331) finished in 0.054 s
2016-12-14 15:30:50,850 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 15:30:50,853 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 15:30:50,853 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 15:30:50,862 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: treeAggregate at RowMatrix.scala:331, took 0.086681 s
2016-12-14 15:30:50,878 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 15:30:50,879 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 15:30:50,879 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (treeAggregate at RowMatrix.scala:121)
2016-12-14 15:30:50,880 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:50,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:50,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 15:30:50,884 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 4.9 KB, free 351.9 KB)
2016-12-14 15:30:50,890 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.5 KB, free 354.4 KB)
2016-12-14 15:30:50,891 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:23995 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 15:30:50,892 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:50,892 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121)
2016-12-14 15:30:50,893 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 15:30:50,895 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:50,896 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:50,897 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 5)
2016-12-14 15:30:50,897 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 4)
2016-12-14 15:30:50,902 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:50,902 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:50,913 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 4). 2462 bytes result sent to driver
2016-12-14 15:30:50,913 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 5). 2462 bytes result sent to driver
2016-12-14 15:30:50,921 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 4) in 26 ms on localhost (1/2)
2016-12-14 15:30:50,924 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 5) in 29 ms on localhost (2/2)
2016-12-14 15:30:50,925 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (treeAggregate at RowMatrix.scala:121) finished in 0.030 s
2016-12-14 15:30:50,925 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 15:30:50,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: treeAggregate at RowMatrix.scala:121, took 0.047581 s
2016-12-14 15:30:51,121 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:23995 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 15:30:51,126 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 15:30:51,128 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:23995 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 15:30:51,129 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 15:30:51,130 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:23995 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 15:30:51,131 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 15:30:51,132 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:23995 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 15:30:51,133 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 15:30:51,323 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2016-12-14 15:30:51,324 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2016-12-14 15:30:51,403 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 15:30:51,427 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 15:30:51,428 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 15:30:51,428 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (takeSample at KMeans.scala:378)
2016-12-14 15:30:51,428 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:51,430 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:51,430 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210), which has no missing parents
2016-12-14 15:30:51,442 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 4.8 KB, free 333.5 KB)
2016-12-14 15:30:51,451 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.8 KB, free 336.2 KB)
2016-12-14 15:30:51,452 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:23995 (size: 2.8 KB, free: 530.0 MB)
2016-12-14 15:30:51,453 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:51,453 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210)
2016-12-14 15:30:51,454 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 15:30:51,459 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2568 bytes)
2016-12-14 15:30:51,460 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2568 bytes)
2016-12-14 15:30:51,461 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 6)
2016-12-14 15:30:51,461 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 7)
2016-12-14 15:30:51,468 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,468 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,469 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_1 not found, computing it
2016-12-14 15:30:51,469 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_0 not found, computing it
2016-12-14 15:30:51,469 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,469 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,478 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_0 stored as values in memory (estimated size 2.9 KB, free 339.1 KB)
2016-12-14 15:30:51,479 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_0 in memory on localhost:23995 (size: 2.9 KB, free: 530.0 MB)
2016-12-14 15:30:51,481 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_1 stored as values in memory (estimated size 3.0 KB, free 342.1 KB)
2016-12-14 15:30:51,483 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_1 in memory on localhost:23995 (size: 3.0 KB, free: 530.0 MB)
2016-12-14 15:30:51,486 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 6). 2638 bytes result sent to driver
2016-12-14 15:30:51,494 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 7). 2638 bytes result sent to driver
2016-12-14 15:30:51,495 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 6) in 39 ms on localhost (1/2)
2016-12-14 15:30:51,500 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 7) in 41 ms on localhost (2/2)
2016-12-14 15:30:51,500 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 15:30:51,500 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (takeSample at KMeans.scala:378) finished in 0.045 s
2016-12-14 15:30:51,501 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: takeSample at KMeans.scala:378, took 0.074076 s
2016-12-14 15:30:51,593 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 15:30:51,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 15:30:51,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (takeSample at KMeans.scala:378)
2016-12-14 15:30:51,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:51,597 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:51,598 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 15:30:51,603 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 21.8 KB, free 363.9 KB)
2016-12-14 15:30:51,611 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.3 KB, free 373.2 KB)
2016-12-14 15:30:51,612 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:23995 (size: 9.3 KB, free: 529.9 MB)
2016-12-14 15:30:51,613 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:51,614 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378)
2016-12-14 15:30:51,614 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 15:30:51,617 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2677 bytes)
2016-12-14 15:30:51,618 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2677 bytes)
2016-12-14 15:30:51,619 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 9)
2016-12-14 15:30:51,619 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 8)
2016-12-14 15:30:51,628 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,628 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,629 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:51,629 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:51,642 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 9). 2717 bytes result sent to driver
2016-12-14 15:30:51,642 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 8). 2685 bytes result sent to driver
2016-12-14 15:30:51,652 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 9) in 34 ms on localhost (1/2)
2016-12-14 15:30:51,656 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 8) in 40 ms on localhost (2/2)
2016-12-14 15:30:51,656 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (takeSample at KMeans.scala:378) finished in 0.041 s
2016-12-14 15:30:51,656 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 15:30:51,657 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: takeSample at KMeans.scala:378, took 0.063243 s
2016-12-14 15:30:51,663 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 1840.0 B, free 375.0 KB)
2016-12-14 15:30:51,673 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 435.0 B, free 375.4 KB)
2016-12-14 15:30:51,674 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:23995 (size: 435.0 B, free: 529.9 MB)
2016-12-14 15:30:51,675 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at KMeans.scala:396
2016-12-14 15:30:51,707 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:51,709 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:51,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 15:30:51,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:51,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:51,713 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:51,717 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.4 KB, free 381.8 KB)
2016-12-14 15:30:51,726 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.3 KB, free 385.2 KB)
2016-12-14 15:30:51,727 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:23995 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 15:30:51,727 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:51,728 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398)
2016-12-14 15:30:51,728 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 15:30:51,731 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2600 bytes)
2016-12-14 15:30:51,732 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2600 bytes)
2016-12-14 15:30:51,732 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 11)
2016-12-14 15:30:51,732 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 10)
2016-12-14 15:30:51,736 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_0 not found, computing it
2016-12-14 15:30:51,736 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_1 not found, computing it
2016-12-14 15:30:51,736 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,736 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,736 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:51,737 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:51,737 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,737 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,737 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:51,737 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:51,754 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_1 stored as values in memory (estimated size 10.6 KB, free 395.7 KB)
2016-12-14 15:30:51,754 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_1 in memory on localhost:23995 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:51,755 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_0 stored as values in memory (estimated size 10.4 KB, free 406.1 KB)
2016-12-14 15:30:51,756 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_0 in memory on localhost:23995 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:51,759 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 11). 2721 bytes result sent to driver
2016-12-14 15:30:51,760 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 10). 2721 bytes result sent to driver
2016-12-14 15:30:51,764 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 11) in 33 ms on localhost (1/2)
2016-12-14 15:30:51,765 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 10) in 35 ms on localhost (2/2)
2016-12-14 15:30:51,765 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.036 s
2016-12-14 15:30:51,766 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 15:30:51,766 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.057861 s
2016-12-14 15:30:51,769 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 12 from persistence list
2016-12-14 15:30:51,775 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 12
2016-12-14 15:30:51,799 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:51,800 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:51,800 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 15:30:51,800 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:51,801 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:51,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:51,804 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 6.6 KB, free 412.7 KB)
2016-12-14 15:30:51,809 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.5 KB, free 416.2 KB)
2016-12-14 15:30:51,810 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:23995 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:51,811 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:51,811 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:51,811 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 15:30:51,812 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2632 bytes)
2016-12-14 15:30:51,813 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2632 bytes)
2016-12-14 15:30:51,813 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 12)
2016-12-14 15:30:51,813 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 13)
2016-12-14 15:30:51,816 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,816 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,816 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:51,817 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:51,817 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 15:30:51,817 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 15:30:51,832 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 12). 3341 bytes result sent to driver
2016-12-14 15:30:51,833 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 13). 4216 bytes result sent to driver
2016-12-14 15:30:51,841 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 12) in 29 ms on localhost (1/2)
2016-12-14 15:30:51,845 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 13) in 33 ms on localhost (2/2)
2016-12-14 15:30:51,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.034 s
2016-12-14 15:30:51,845 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 15:30:51,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.045987 s
2016-12-14 15:30:51,850 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 8.5 KB, free 424.7 KB)
2016-12-14 15:30:51,857 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.6 KB, free 427.2 KB)
2016-12-14 15:30:51,857 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:23995 (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:51,858 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at KMeans.scala:396
2016-12-14 15:30:51,869 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:51,870 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:51,870 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 15:30:51,871 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:51,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:51,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:51,876 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.6 KB, free 433.9 KB)
2016-12-14 15:30:51,881 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.4 KB, free 437.3 KB)
2016-12-14 15:30:51,881 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:23995 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 15:30:51,881 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:51,882 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398)
2016-12-14 15:30:51,882 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 15:30:51,884 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2632 bytes)
2016-12-14 15:30:51,885 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2632 bytes)
2016-12-14 15:30:51,885 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 14)
2016-12-14 15:30:51,885 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 15)
2016-12-14 15:30:51,888 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_0 not found, computing it
2016-12-14 15:30:51,888 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,888 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:51,889 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_1 not found, computing it
2016-12-14 15:30:51,889 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 15:30:51,889 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,889 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:51,889 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 15:30:51,897 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_0 stored as values in memory (estimated size 10.4 KB, free 447.7 KB)
2016-12-14 15:30:51,897 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_1 stored as values in memory (estimated size 10.6 KB, free 458.2 KB)
2016-12-14 15:30:51,898 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_0 in memory on localhost:23995 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:51,898 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_1 in memory on localhost:23995 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:51,903 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 14). 2721 bytes result sent to driver
2016-12-14 15:30:51,903 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 15). 2721 bytes result sent to driver
2016-12-14 15:30:51,908 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 15) in 24 ms on localhost (1/2)
2016-12-14 15:30:51,908 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 14) in 25 ms on localhost (2/2)
2016-12-14 15:30:51,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.026 s
2016-12-14 15:30:51,909 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 15:30:51,909 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.039796 s
2016-12-14 15:30:51,911 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 15 from persistence list
2016-12-14 15:30:51,914 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 15:30:51,934 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:51,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:51,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 15:30:51,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:51,937 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:51,938 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:51,944 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 6.8 KB, free 444.1 KB)
2016-12-14 15:30:51,951 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.6 KB, free 447.7 KB)
2016-12-14 15:30:51,952 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:23995 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:51,953 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:51,954 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:51,954 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 15:30:51,956 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2664 bytes)
2016-12-14 15:30:51,957 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2664 bytes)
2016-12-14 15:30:51,958 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 16)
2016-12-14 15:30:51,958 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 17)
2016-12-14 15:30:51,965 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:51,965 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:51,965 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:51,965 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:51,965 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 15:30:51,965 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 15:30:51,973 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 17). 3759 bytes result sent to driver
2016-12-14 15:30:51,973 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 16). 3229 bytes result sent to driver
2016-12-14 15:30:51,983 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 17) in 27 ms on localhost (1/2)
2016-12-14 15:30:51,985 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 16) in 30 ms on localhost (2/2)
2016-12-14 15:30:51,985 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.030 s
2016-12-14 15:30:51,985 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 15:30:51,985 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.050625 s
2016-12-14 15:30:51,987 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 8.6 KB, free 456.2 KB)
2016-12-14 15:30:51,996 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.3 KB, free 458.5 KB)
2016-12-14 15:30:51,997 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:23995 (size: 2.3 KB, free: 529.9 MB)
2016-12-14 15:30:51,998 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at KMeans.scala:396
2016-12-14 15:30:52,018 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:52,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:52,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 15:30:52,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:52,021 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:52,022 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:52,025 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.9 KB, free 465.4 KB)
2016-12-14 15:30:52,030 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.5 KB, free 468.8 KB)
2016-12-14 15:30:52,031 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:23995 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:52,032 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,032 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398)
2016-12-14 15:30:52,032 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 15:30:52,033 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2664 bytes)
2016-12-14 15:30:52,034 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2664 bytes)
2016-12-14 15:30:52,034 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 18)
2016-12-14 15:30:52,035 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 19)
2016-12-14 15:30:52,037 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_0 not found, computing it
2016-12-14 15:30:52,037 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_1 not found, computing it
2016-12-14 15:30:52,038 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,038 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,038 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,038 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,038 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 15:30:52,038 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 15:30:52,042 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_0 stored as values in memory (estimated size 10.4 KB, free 479.2 KB)
2016-12-14 15:30:52,042 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_1 stored as values in memory (estimated size 10.6 KB, free 489.8 KB)
2016-12-14 15:30:52,042 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_0 in memory on localhost:23995 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:52,043 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_1 in memory on localhost:23995 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,047 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 19). 2721 bytes result sent to driver
2016-12-14 15:30:52,047 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 18). 2721 bytes result sent to driver
2016-12-14 15:30:52,051 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 19) in 17 ms on localhost (1/2)
2016-12-14 15:30:52,051 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 18) in 18 ms on localhost (2/2)
2016-12-14 15:30:52,051 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.018 s
2016-12-14 15:30:52,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.032510 s
2016-12-14 15:30:52,053 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 19 from persistence list
2016-12-14 15:30:52,053 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 15:30:52,074 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:52,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:52,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 15:30:52,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:52,077 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:52,078 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:52,083 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 475.9 KB)
2016-12-14 15:30:52,092 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.6 KB, free 479.5 KB)
2016-12-14 15:30:52,093 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:23995 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,094 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:52,095 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 15:30:52,097 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2696 bytes)
2016-12-14 15:30:52,098 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2696 bytes)
2016-12-14 15:30:52,099 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 20)
2016-12-14 15:30:52,099 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 21)
2016-12-14 15:30:52,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 15:30:52,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,107 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 15:30:52,116 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 21). 3757 bytes result sent to driver
2016-12-14 15:30:52,116 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 20). 3406 bytes result sent to driver
2016-12-14 15:30:52,128 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 20) in 32 ms on localhost (1/2)
2016-12-14 15:30:52,130 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 21) in 32 ms on localhost (2/2)
2016-12-14 15:30:52,130 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.034 s
2016-12-14 15:30:52,131 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,131 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.057037 s
2016-12-14 15:30:52,134 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 7.9 KB, free 487.3 KB)
2016-12-14 15:30:52,141 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 489.7 KB)
2016-12-14 15:30:52,142 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:23995 (size: 2.3 KB, free: 529.9 MB)
2016-12-14 15:30:52,143 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at KMeans.scala:396
2016-12-14 15:30:52,161 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:52,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:52,164 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 12 (aggregate at KMeans.scala:404)
2016-12-14 15:30:52,164 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:52,165 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:52,166 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:52,167 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 496.8 KB)
2016-12-14 15:30:52,171 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 500.3 KB)
2016-12-14 15:30:52,172 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:23995 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:52,173 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,173 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398)
2016-12-14 15:30:52,173 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 15:30:52,175 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2696 bytes)
2016-12-14 15:30:52,176 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2696 bytes)
2016-12-14 15:30:52,177 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 23)
2016-12-14 15:30:52,177 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 22)
2016-12-14 15:30:52,180 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_0 not found, computing it
2016-12-14 15:30:52,180 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_1 not found, computing it
2016-12-14 15:30:52,180 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,180 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,181 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,181 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,181 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 15:30:52,181 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 15:30:52,184 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_0 stored as values in memory (estimated size 10.4 KB, free 510.7 KB)
2016-12-14 15:30:52,185 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_1 stored as values in memory (estimated size 10.6 KB, free 521.2 KB)
2016-12-14 15:30:52,185 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_0 in memory on localhost:23995 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:52,185 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_1 in memory on localhost:23995 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,188 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 23). 2721 bytes result sent to driver
2016-12-14 15:30:52,188 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 22). 2721 bytes result sent to driver
2016-12-14 15:30:52,191 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 23) in 16 ms on localhost (1/2)
2016-12-14 15:30:52,192 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 22) in 18 ms on localhost (2/2)
2016-12-14 15:30:52,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 12 (aggregate at KMeans.scala:404) finished in 0.018 s
2016-12-14 15:30:52,192 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: aggregate at KMeans.scala:404, took 0.030359 s
2016-12-14 15:30:52,193 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 23 from persistence list
2016-12-14 15:30:52,194 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 15:30:52,209 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:52,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:52,213 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collect at KMeans.scala:436)
2016-12-14 15:30:52,213 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:52,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:52,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:52,221 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 7.3 KB, free 507.6 KB)
2016-12-14 15:30:52,229 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 511.2 KB)
2016-12-14 15:30:52,230 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:23995 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 15:30:52,231 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:52,232 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 15:30:52,235 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2728 bytes)
2016-12-14 15:30:52,236 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2728 bytes)
2016-12-14 15:30:52,237 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 24)
2016-12-14 15:30:52,237 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 25)
2016-12-14 15:30:52,240 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,240 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,240 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,240 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,240 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 15:30:52,240 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 15:30:52,245 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 25). 4255 bytes result sent to driver
2016-12-14 15:30:52,245 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 24). 3297 bytes result sent to driver
2016-12-14 15:30:52,257 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 25) in 22 ms on localhost (1/2)
2016-12-14 15:30:52,258 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collect at KMeans.scala:436) finished in 0.023 s
2016-12-14 15:30:52,258 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 24) in 23 ms on localhost (2/2)
2016-12-14 15:30:52,258 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,258 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collect at KMeans.scala:436, took 0.048412 s
2016-12-14 15:30:52,261 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 8.6 KB, free 519.9 KB)
2016-12-14 15:30:52,269 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.6 KB, free 522.4 KB)
2016-12-14 15:30:52,270 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:23995 (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,271 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at KMeans.scala:396
2016-12-14 15:30:52,291 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 15:30:52,293 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 15:30:52,293 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 14 (aggregate at KMeans.scala:404)
2016-12-14 15:30:52,293 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:52,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:52,295 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398), which has no missing parents
2016-12-14 15:30:52,297 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 7.3 KB, free 529.8 KB)
2016-12-14 15:30:52,302 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.6 KB, free 533.4 KB)
2016-12-14 15:30:52,304 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:23995 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,304 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,305 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398)
2016-12-14 15:30:52,305 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 15:30:52,306 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 26, localhost, partition 0,PROCESS_LOCAL, 2728 bytes)
2016-12-14 15:30:52,307 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 27, localhost, partition 1,PROCESS_LOCAL, 2728 bytes)
2016-12-14 15:30:52,308 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 26)
2016-12-14 15:30:52,308 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 27)
2016-12-14 15:30:52,311 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_0 not found, computing it
2016-12-14 15:30:52,311 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_1 not found, computing it
2016-12-14 15:30:52,311 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,311 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,311 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,311 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,312 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 15:30:52,312 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 15:30:52,314 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_0 stored as values in memory (estimated size 10.4 KB, free 543.7 KB)
2016-12-14 15:30:52,315 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_1 stored as values in memory (estimated size 10.6 KB, free 554.3 KB)
2016-12-14 15:30:52,315 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_0 in memory on localhost:23995 (size: 10.4 KB, free: 529.9 MB)
2016-12-14 15:30:52,316 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_1 in memory on localhost:23995 (size: 10.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,319 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 26). 2721 bytes result sent to driver
2016-12-14 15:30:52,319 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 27). 2721 bytes result sent to driver
2016-12-14 15:30:52,323 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 27) in 16 ms on localhost (1/2)
2016-12-14 15:30:52,323 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 26) in 18 ms on localhost (2/2)
2016-12-14 15:30:52,323 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 14 (aggregate at KMeans.scala:404) finished in 0.018 s
2016-12-14 15:30:52,323 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: aggregate at KMeans.scala:404, took 0.032418 s
2016-12-14 15:30:52,326 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 27 from persistence list
2016-12-14 15:30:52,327 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 15:30:52,342 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 15:30:52,345 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:23995 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:52,346 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 15:30:52,347 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:23995 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 15:30:52,348 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 15:30:52,350 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:23995 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:52,350 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 15:30:52,352 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:23995 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,353 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 15:30:52,354 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:23995 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 15:30:52,354 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 15:30:52,356 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:23995 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:52,357 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 15:30:52,357 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 15:30:52,357 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collect at KMeans.scala:436)
2016-12-14 15:30:52,358 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:23995 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:52,358 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 15:30:52,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:52,359 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:23995 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 15:30:52,360 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 15:30:52,360 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 15:30:52,361 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:23995 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 15:30:52,361 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 15:30:52,362 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:23995 in memory (size: 9.3 KB, free: 529.9 MB)
2016-12-14 15:30:52,363 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 7.5 KB, free 437.8 KB)
2016-12-14 15:30:52,364 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 15:30:52,365 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:23995 in memory (size: 2.8 KB, free: 529.9 MB)
2016-12-14 15:30:52,366 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 15:30:52,372 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.2 KB)
2016-12-14 15:30:52,373 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:23995 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 15:30:52,374 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 15:30:52,375 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 15:30:52,377 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2760 bytes)
2016-12-14 15:30:52,377 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2760 bytes)
2016-12-14 15:30:52,378 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 28)
2016-12-14 15:30:52,378 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 29)
2016-12-14 15:30:52,382 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,382 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,382 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,383 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,383 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_1 locally
2016-12-14 15:30:52,383 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_0 locally
2016-12-14 15:30:52,390 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 28). 3386 bytes result sent to driver
2016-12-14 15:30:52,390 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 29). 4153 bytes result sent to driver
2016-12-14 15:30:52,396 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 28) in 20 ms on localhost (1/2)
2016-12-14 15:30:52,400 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 29) in 23 ms on localhost (2/2)
2016-12-14 15:30:52,400 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collect at KMeans.scala:436) finished in 0.024 s
2016-12-14 15:30:52,400 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,401 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collect at KMeans.scala:436, took 0.045990 s
2016-12-14 15:30:52,402 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 31 from persistence list
2016-12-14 15:30:52,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 15:30:52,404 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 40.7 KB, free 432.0 KB)
2016-12-14 15:30:52,410 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 7.1 KB, free 439.1 KB)
2016-12-14 15:30:52,410 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:23995 (size: 7.1 KB, free: 529.9 MB)
2016-12-14 15:30:52,411 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at KMeans.scala:450
2016-12-14 15:30:52,438 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 15:30:52,457 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 34 (flatMap at KMeans.scala:451)
2016-12-14 15:30:52,458 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 15:30:52,458 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:455)
2016-12-14 15:30:52,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 15:30:52,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 15:30:52,461 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 15:30:52,470 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 6.5 KB, free 445.5 KB)
2016-12-14 15:30:52,477 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.5 KB, free 449.1 KB)
2016-12-14 15:30:52,477 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:23995 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:52,478 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451)
2016-12-14 15:30:52,480 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 15:30:52,482 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:52,483 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:52,483 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 30)
2016-12-14 15:30:52,483 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 31)
2016-12-14 15:30:52,488 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,488 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,489 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,489 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,622 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 31). 2237 bytes result sent to driver
2016-12-14 15:30:52,622 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 30). 2237 bytes result sent to driver
2016-12-14 15:30:52,633 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 30) in 152 ms on localhost (1/2)
2016-12-14 15:30:52,634 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 31) in 151 ms on localhost (2/2)
2016-12-14 15:30:52,634 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,635 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (flatMap at KMeans.scala:451) finished in 0.154 s
2016-12-14 15:30:52,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:52,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:52,637 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 15:30:52,637 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:52,638 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 15:30:52,643 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 2.6 KB, free 451.6 KB)
2016-12-14 15:30:52,648 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1555.0 B, free 453.2 KB)
2016-12-14 15:30:52,649 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:23995 (size: 1555.0 B, free: 529.9 MB)
2016-12-14 15:30:52,649 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,649 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455)
2016-12-14 15:30:52,650 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 15:30:52,653 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 32, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:52,653 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 33, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:52,654 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 32)
2016-12-14 15:30:52,654 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 33)
2016-12-14 15:30:52,669 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:52,669 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:52,671 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 15:30:52,671 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 5 ms
2016-12-14 15:30:52,718 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 33). 7605 bytes result sent to driver
2016-12-14 15:30:52,718 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 32). 7794 bytes result sent to driver
2016-12-14 15:30:52,723 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 32) in 72 ms on localhost (1/2)
2016-12-14 15:30:52,724 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 33) in 71 ms on localhost (2/2)
2016-12-14 15:30:52,724 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:455) finished in 0.073 s
2016-12-14 15:30:52,724 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 15:30:52,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:455, took 0.286775 s
2016-12-14 15:30:52,881 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 15:30:52,882 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:52,881 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 15:30:52,883 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:52,883 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 15:30:52,883 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 15:30:52,883 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 7 iterations.
2016-12-14 15:30:52,884 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 7 iterations.
2016-12-14 15:30:52,884 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 10 iterations.
2016-12-14 15:30:52,885 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 12 iterations.
2016-12-14 15:30:52,908 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 1.492 seconds.
2016-12-14 15:30:52,913 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 4.7 KB, free 457.9 KB)
2016-12-14 15:30:52,921 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 1746.0 B, free 459.6 KB)
2016-12-14 15:30:52,922 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:23995 (size: 1746.0 B, free: 529.9 MB)
2016-12-14 15:30:52,923 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at KMeans.scala:276
2016-12-14 15:30:52,956 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:52,958 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 36 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:52,958 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:52,959 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:52,959 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 15:30:52,959 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 15:30:52,961 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:52,963 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 7.4 KB, free 467.0 KB)
2016-12-14 15:30:52,969 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 4.0 KB, free 471.0 KB)
2016-12-14 15:30:52,970 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:23995 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:52,971 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:52,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:52,971 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 15:30:52,973 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 34, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:52,974 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 35, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:52,974 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 35)
2016-12-14 15:30:52,974 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 34)
2016-12-14 15:30:52,978 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:52,978 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:52,978 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:52,978 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:52,996 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 34). 2516 bytes result sent to driver
2016-12-14 15:30:52,996 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 35). 2516 bytes result sent to driver
2016-12-14 15:30:53,001 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 35) in 28 ms on localhost (1/2)
2016-12-14 15:30:53,002 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 34) in 28 ms on localhost (2/2)
2016-12-14 15:30:53,002 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,003 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.030 s
2016-12-14 15:30:53,003 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,003 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,004 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 15:30:53,004 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,005 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,007 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 2.9 KB, free 473.9 KB)
2016-12-14 15:30:53,013 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 1661.0 B, free 475.5 KB)
2016-12-14 15:30:53,014 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,015 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,015 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,015 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 15:30:53,017 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 36, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,017 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 37, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,018 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 37)
2016-12-14 15:30:53,018 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 36)
2016-12-14 15:30:53,021 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,022 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,022 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,022 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,039 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 37). 2359 bytes result sent to driver
2016-12-14 15:30:53,039 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 36). 2211 bytes result sent to driver
2016-12-14 15:30:53,044 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 36) in 27 ms on localhost (1/2)
2016-12-14 15:30:53,046 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 37) in 29 ms on localhost (2/2)
2016-12-14 15:30:53,046 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.030 s
2016-12-14 15:30:53,046 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,047 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.090148 s
2016-12-14 15:30:53,053 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 4.7 KB, free 480.2 KB)
2016-12-14 15:30:53,061 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 1523.0 B, free 481.7 KB)
2016-12-14 15:30:53,062 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:23995 (size: 1523.0 B, free: 529.9 MB)
2016-12-14 15:30:53,063 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,087 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,089 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 38 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,090 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,090 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,090 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 15:30:53,090 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 15:30:53,092 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,093 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 7.4 KB, free 489.1 KB)
2016-12-14 15:30:53,100 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 4.0 KB, free 493.1 KB)
2016-12-14 15:30:53,100 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:23995 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:53,101 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,101 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,102 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 15:30:53,104 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 38, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,104 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 39, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,105 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 38)
2016-12-14 15:30:53,105 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 39)
2016-12-14 15:30:53,108 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,108 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,108 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,109 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,118 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 39). 2516 bytes result sent to driver
2016-12-14 15:30:53,120 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 38). 2516 bytes result sent to driver
2016-12-14 15:30:53,124 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 39) in 20 ms on localhost (1/2)
2016-12-14 15:30:53,124 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 38) in 21 ms on localhost (2/2)
2016-12-14 15:30:53,125 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,125 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.022 s
2016-12-14 15:30:53,125 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 15:30:53,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,127 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,129 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 2.9 KB, free 496.0 KB)
2016-12-14 15:30:53,134 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 1658.0 B, free 497.6 KB)
2016-12-14 15:30:53,135 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:23995 (size: 1658.0 B, free: 529.9 MB)
2016-12-14 15:30:53,136 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,136 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,137 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 15:30:53,138 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,139 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,139 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 40)
2016-12-14 15:30:53,139 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 41)
2016-12-14 15:30:53,141 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,141 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,141 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,141 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,148 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 40). 2211 bytes result sent to driver
2016-12-14 15:30:53,148 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 41). 2359 bytes result sent to driver
2016-12-14 15:30:53,151 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 40) in 13 ms on localhost (1/2)
2016-12-14 15:30:53,154 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 41) in 15 ms on localhost (2/2)
2016-12-14 15:30:53,155 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 15:30:53,155 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,155 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.068279 s
2016-12-14 15:30:53,158 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 2 iterations
2016-12-14 15:30:53,158 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 2 iterations
2016-12-14 15:30:53,159 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 2 iterations
2016-12-14 15:30:53,160 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 3.3 KB, free 500.9 KB)
2016-12-14 15:30:53,165 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 1096.0 B, free 501.9 KB)
2016-12-14 15:30:53,166 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:23995 (size: 1096.0 B, free: 529.9 MB)
2016-12-14 15:30:53,167 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,184 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,187 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 40 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 15:30:53,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 15:30:53,189 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,190 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 7.3 KB, free 509.3 KB)
2016-12-14 15:30:53,193 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KB, free 513.2 KB)
2016-12-14 15:30:53,193 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,194 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,194 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 15:30:53,196 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 42, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,196 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 43, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,196 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 43)
2016-12-14 15:30:53,196 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 42)
2016-12-14 15:30:53,198 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,198 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,199 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,199 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,205 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 43). 2444 bytes result sent to driver
2016-12-14 15:30:53,205 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 42). 2444 bytes result sent to driver
2016-12-14 15:30:53,207 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 43) in 11 ms on localhost (1/2)
2016-12-14 15:30:53,207 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 42) in 12 ms on localhost (2/2)
2016-12-14 15:30:53,208 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.013 s
2016-12-14 15:30:53,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 15:30:53,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,209 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,210 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 2.9 KB, free 516.1 KB)
2016-12-14 15:30:53,214 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 1661.0 B, free 517.7 KB)
2016-12-14 15:30:53,215 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,215 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,216 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 15:30:53,217 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 44, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,217 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 45, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,218 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 44)
2016-12-14 15:30:53,218 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 45)
2016-12-14 15:30:53,219 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,219 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,219 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,219 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,226 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 44). 1837 bytes result sent to driver
2016-12-14 15:30:53,226 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 45). 2060 bytes result sent to driver
2016-12-14 15:30:53,231 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 44) in 14 ms on localhost (1/2)
2016-12-14 15:30:53,233 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 45) in 15 ms on localhost (2/2)
2016-12-14 15:30:53,233 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 15:30:53,233 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,234 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.049095 s
2016-12-14 15:30:53,236 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 3.3 KB, free 521.0 KB)
2016-12-14 15:30:53,241 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 1050.0 B, free 522.1 KB)
2016-12-14 15:30:53,241 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:23995 (size: 1050.0 B, free: 529.9 MB)
2016-12-14 15:30:53,242 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,259 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 42 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 15:30:53,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 15:30:53,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,264 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 7.3 KB, free 529.4 KB)
2016-12-14 15:30:53,269 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.9 KB, free 533.3 KB)
2016-12-14 15:30:53,270 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,271 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,271 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,272 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 15:30:53,274 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 46, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,274 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 47, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,275 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 46)
2016-12-14 15:30:53,275 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 47)
2016-12-14 15:30:53,277 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,277 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,277 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,278 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,284 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 47). 2444 bytes result sent to driver
2016-12-14 15:30:53,285 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 46). 2444 bytes result sent to driver
2016-12-14 15:30:53,287 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 47) in 13 ms on localhost (1/2)
2016-12-14 15:30:53,287 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 46) in 14 ms on localhost (2/2)
2016-12-14 15:30:53,287 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 15:30:53,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 15:30:53,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,291 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 2.9 KB, free 536.2 KB)
2016-12-14 15:30:53,294 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1661.0 B, free 537.9 KB)
2016-12-14 15:30:53,295 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,295 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,296 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,296 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 15:30:53,297 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 48, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,297 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 49, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,298 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 48)
2016-12-14 15:30:53,298 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 49)
2016-12-14 15:30:53,299 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,299 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,299 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,299 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,306 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 49). 2060 bytes result sent to driver
2016-12-14 15:30:53,307 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 48). 1837 bytes result sent to driver
2016-12-14 15:30:53,308 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 49) in 11 ms on localhost (1/2)
2016-12-14 15:30:53,310 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 48) in 14 ms on localhost (2/2)
2016-12-14 15:30:53,310 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.014 s
2016-12-14 15:30:53,311 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,311 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.051640 s
2016-12-14 15:30:53,313 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 3.3 KB, free 541.2 KB)
2016-12-14 15:30:53,316 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 1045.0 B, free 542.2 KB)
2016-12-14 15:30:53,317 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:23995 (size: 1045.0 B, free: 529.9 MB)
2016-12-14 15:30:53,317 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,325 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,327 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 44 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,327 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,327 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,328 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 15:30:53,328 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 15:30:53,329 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,332 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 7.3 KB, free 549.5 KB)
2016-12-14 15:30:53,337 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.9 KB, free 553.4 KB)
2016-12-14 15:30:53,338 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,339 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,339 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,339 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 15:30:53,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 50, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 51, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,342 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 50)
2016-12-14 15:30:53,342 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 51)
2016-12-14 15:30:53,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,346 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,346 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,355 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 50). 2444 bytes result sent to driver
2016-12-14 15:30:53,355 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 51). 2444 bytes result sent to driver
2016-12-14 15:30:53,357 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 50) in 17 ms on localhost (1/2)
2016-12-14 15:30:53,358 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 51) in 17 ms on localhost (2/2)
2016-12-14 15:30:53,358 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 15:30:53,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 15:30:53,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,360 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,362 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 2.9 KB, free 556.4 KB)
2016-12-14 15:30:53,367 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 1657.0 B, free 558.0 KB)
2016-12-14 15:30:53,368 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:23995 (size: 1657.0 B, free: 529.9 MB)
2016-12-14 15:30:53,368 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,369 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,369 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 15:30:53,371 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 52, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,371 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 53, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,372 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 53)
2016-12-14 15:30:53,372 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 52)
2016-12-14 15:30:53,374 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,374 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,375 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,375 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,386 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 52). 1837 bytes result sent to driver
2016-12-14 15:30:53,386 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 53). 2060 bytes result sent to driver
2016-12-14 15:30:53,391 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 52) in 21 ms on localhost (1/2)
2016-12-14 15:30:53,393 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 53) in 22 ms on localhost (2/2)
2016-12-14 15:30:53,393 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.023 s
2016-12-14 15:30:53,394 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.068326 s
2016-12-14 15:30:53,397 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 3.3 KB, free 561.3 KB)
2016-12-14 15:30:53,403 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 1027.0 B, free 562.3 KB)
2016-12-14 15:30:53,404 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:23995 (size: 1027.0 B, free: 529.9 MB)
2016-12-14 15:30:53,404 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,420 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,422 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 46 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,422 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,423 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,423 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 15:30:53,423 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 15:30:53,424 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,427 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 7.3 KB, free 569.6 KB)
2016-12-14 15:30:53,430 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.9 KB, free 573.5 KB)
2016-12-14 15:30:53,431 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,431 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,432 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,432 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 15:30:53,434 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 54, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,435 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 55, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,435 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 54)
2016-12-14 15:30:53,435 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 55)
2016-12-14 15:30:53,438 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,438 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,438 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,439 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,448 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 55). 2444 bytes result sent to driver
2016-12-14 15:30:53,448 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 54). 2444 bytes result sent to driver
2016-12-14 15:30:53,450 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 55) in 15 ms on localhost (1/2)
2016-12-14 15:30:53,450 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 54) in 16 ms on localhost (2/2)
2016-12-14 15:30:53,450 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,450 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 15:30:53,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 15:30:53,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,452 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 2.9 KB, free 576.4 KB)
2016-12-14 15:30:53,457 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 1660.0 B, free 578.1 KB)
2016-12-14 15:30:53,457 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:23995 (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:53,458 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,459 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 15:30:53,460 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 56, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,461 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 57, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,461 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 56)
2016-12-14 15:30:53,461 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 57)
2016-12-14 15:30:53,463 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,463 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,463 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,463 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,472 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 56). 1837 bytes result sent to driver
2016-12-14 15:30:53,472 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 57). 2060 bytes result sent to driver
2016-12-14 15:30:53,474 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 56) in 14 ms on localhost (1/2)
2016-12-14 15:30:53,475 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 57) in 14 ms on localhost (2/2)
2016-12-14 15:30:53,475 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.015 s
2016-12-14 15:30:53,476 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,476 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.055428 s
2016-12-14 15:30:53,478 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 6 iterations
2016-12-14 15:30:53,478 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 6 iterations
2016-12-14 15:30:53,479 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 2.4 KB, free 580.4 KB)
2016-12-14 15:30:53,489 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 15:30:53,491 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:23995 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 15:30:53,492 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 15:30:53,494 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 15:30:53,495 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 709.0 B, free 569.9 KB)
2016-12-14 15:30:53,495 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 31
2016-12-14 15:30:53,495 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:23995 (size: 709.0 B, free: 529.9 MB)
2016-12-14 15:30:53,496 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,496 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:23995 in memory (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:53,497 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 15:30:53,498 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 27
2016-12-14 15:30:53,499 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:23995 in memory (size: 2.3 KB, free: 529.9 MB)
2016-12-14 15:30:53,500 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 15:30:53,501 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 23
2016-12-14 15:30:53,502 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:23995 in memory (size: 2.3 KB, free: 529.9 MB)
2016-12-14 15:30:53,502 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 15:30:53,503 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:23995 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 15:30:53,504 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 15:30:53,505 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:23995 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:53,506 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 15:30:53,510 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 15:30:53,511 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:23995 in memory (size: 7.1 KB, free: 529.9 MB)
2016-12-14 15:30:53,512 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,513 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 15:30:53,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 48 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,514 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 15:30:53,514 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,514 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,514 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 15:30:53,514 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 15:30:53,514 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:23995 in memory (size: 1746.0 B, free: 529.9 MB)
2016-12-14 15:30:53,515 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 15:30:53,515 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 15:30:53,515 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 15:30:53,515 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 15:30:53,515 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,515 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 15:30:53,516 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 15:30:53,516 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 15:30:53,516 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 15:30:53,516 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 15:30:53,517 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 15:30:53,517 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 15:30:53,517 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 15:30:53,517 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 15:30:53,517 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 15:30:53,517 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 7.2 KB, free 476.6 KB)
2016-12-14 15:30:53,518 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 15:30:53,518 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 15:30:53,518 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 15:30:53,519 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 15:30:53,519 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 15:30:53,520 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,520 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 15:30:53,521 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:23995 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:53,522 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 15:30:53,522 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 15:30:53,522 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 15:30:53,522 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 15:30:53,522 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.9 KB, free 464.6 KB)
2016-12-14 15:30:53,523 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,524 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:23995 in memory (size: 1658.0 B, free: 529.9 MB)
2016-12-14 15:30:53,524 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,524 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,524 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 15:30:53,524 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 15:30:53,525 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:23995 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 15:30:53,526 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 15:30:53,526 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 58, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,526 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 15:30:53,526 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 59, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,527 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:23995 in memory (size: 1523.0 B, free: 529.9 MB)
2016-12-14 15:30:53,527 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 58)
2016-12-14 15:30:53,527 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 59)
2016-12-14 15:30:53,527 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 15:30:53,528 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,529 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 15:30:53,530 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,531 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,531 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 15:30:53,531 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,531 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,531 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 15:30:53,531 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,532 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:23995 in memory (size: 1096.0 B, free: 529.9 MB)
2016-12-14 15:30:53,532 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 15:30:53,532 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 15:30:53,533 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 15:30:53,533 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,533 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 15:30:53,534 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,535 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 15:30:53,535 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 15:30:53,535 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:23995 in memory (size: 1050.0 B, free: 529.9 MB)
2016-12-14 15:30:53,536 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 15:30:53,536 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 15:30:53,536 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 15:30:53,536 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 15:30:53,536 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 15:30:53,537 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:23995 in memory (size: 1657.0 B, free: 529.9 MB)
2016-12-14 15:30:53,537 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 15:30:53,538 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 58). 2396 bytes result sent to driver
2016-12-14 15:30:53,538 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 59). 2396 bytes result sent to driver
2016-12-14 15:30:53,538 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,539 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 15:30:53,539 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 15:30:53,540 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:23995 in memory (size: 1045.0 B, free: 529.9 MB)
2016-12-14 15:30:53,540 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 15:30:53,540 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 58) in 15 ms on localhost (1/2)
2016-12-14 15:30:53,540 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 15:30:53,541 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 15:30:53,541 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 59) in 15 ms on localhost (2/2)
2016-12-14 15:30:53,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 15:30:53,541 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 15:30:53,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,541 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,541 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 15:30:53,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 15:30:53,541 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 15:30:53,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,542 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 15:30:53,542 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 15:30:53,542 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,542 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 15:30:53,543 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:23995 in memory (size: 1027.0 B, free: 529.9 MB)
2016-12-14 15:30:53,543 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 2.9 KB, free 380.7 KB)
2016-12-14 15:30:53,543 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 15:30:53,543 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 15:30:53,544 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 15:30:53,544 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 15:30:53,544 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 15:30:53,545 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 15:30:53,545 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 15:30:53,545 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 15:30:53,546 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 19
2016-12-14 15:30:53,547 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:23995 in memory (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:53,547 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 1661.0 B, free 371.3 KB)
2016-12-14 15:30:53,547 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 15:30:53,548 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,548 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 15
2016-12-14 15:30:53,548 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,548 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,548 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:23995 in memory (size: 435.0 B, free: 529.9 MB)
2016-12-14 15:30:53,548 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 15:30:53,549 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:23995 in memory (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:53,550 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 60, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,550 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 15:30:53,550 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 61, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,550 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 60)
2016-12-14 15:30:53,550 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,550 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 61)
2016-12-14 15:30:53,552 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,552 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,552 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,552 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,559 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 61). 1837 bytes result sent to driver
2016-12-14 15:30:53,559 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 60). 1614 bytes result sent to driver
2016-12-14 15:30:53,562 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 61) in 11 ms on localhost (1/2)
2016-12-14 15:30:53,564 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 60) in 15 ms on localhost (2/2)
2016-12-14 15:30:53,564 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.015 s
2016-12-14 15:30:53,564 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,564 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: collectAsMap at KMeans.scala:302, took 0.052105 s
2016-12-14 15:30:53,565 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 7 iterations
2016-12-14 15:30:53,566 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 1944.0 B, free 355.2 KB)
2016-12-14 15:30:53,568 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 643.0 B, free 355.8 KB)
2016-12-14 15:30:53,569 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:23995 (size: 643.0 B, free: 529.9 MB)
2016-12-14 15:30:53,569 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,578 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,579 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 50 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,579 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,579 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,580 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 15:30:53,580 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 15:30:53,581 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,583 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 7.2 KB, free 363.0 KB)
2016-12-14 15:30:53,587 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 3.9 KB, free 366.9 KB)
2016-12-14 15:30:53,588 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,588 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,589 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 15:30:53,590 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 62, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,591 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 63, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,592 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 63)
2016-12-14 15:30:53,592 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 62)
2016-12-14 15:30:53,594 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,594 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,594 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,594 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,599 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 62). 2372 bytes result sent to driver
2016-12-14 15:30:53,599 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 63). 2372 bytes result sent to driver
2016-12-14 15:30:53,602 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 63) in 11 ms on localhost (1/2)
2016-12-14 15:30:53,603 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 62) in 12 ms on localhost (2/2)
2016-12-14 15:30:53,603 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,603 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.013 s
2016-12-14 15:30:53,603 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,604 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,604 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 15:30:53,604 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,605 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,607 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 2.9 KB, free 369.8 KB)
2016-12-14 15:30:53,612 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 1661.0 B, free 371.5 KB)
2016-12-14 15:30:53,613 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,614 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,614 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,614 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 15:30:53,616 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 64, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,616 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 65, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,617 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 65)
2016-12-14 15:30:53,617 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 64)
2016-12-14 15:30:53,618 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,618 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,618 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,619 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,624 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 65). 1652 bytes result sent to driver
2016-12-14 15:30:53,625 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 64). 1576 bytes result sent to driver
2016-12-14 15:30:53,627 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 65) in 11 ms on localhost (1/2)
2016-12-14 15:30:53,632 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 64) in 17 ms on localhost (2/2)
2016-12-14 15:30:53,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 15:30:53,632 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: collectAsMap at KMeans.scala:302, took 0.054879 s
2016-12-14 15:30:53,634 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 1944.0 B, free 373.4 KB)
2016-12-14 15:30:53,637 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 642.0 B, free 374.0 KB)
2016-12-14 15:30:53,637 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:23995 (size: 642.0 B, free: 529.9 MB)
2016-12-14 15:30:53,638 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,647 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 52 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,649 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,649 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 34)
2016-12-14 15:30:53,649 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 34)
2016-12-14 15:30:53,650 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,651 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 7.2 KB, free 381.2 KB)
2016-12-14 15:30:53,656 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.9 KB, free 385.1 KB)
2016-12-14 15:30:53,657 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,657 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,658 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,658 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 15:30:53,659 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 66, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,660 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 67, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,660 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 66)
2016-12-14 15:30:53,660 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 67)
2016-12-14 15:30:53,663 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,663 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,663 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,663 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,668 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 66). 2372 bytes result sent to driver
2016-12-14 15:30:53,668 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 67). 2372 bytes result sent to driver
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 67) in 9 ms on localhost (1/2)
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 66) in 11 ms on localhost (2/2)
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 34 (mapPartitions at KMeans.scala:279) finished in 0.011 s
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 35)
2016-12-14 15:30:53,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,671 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,672 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 2.9 KB, free 388.0 KB)
2016-12-14 15:30:53,676 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 1661.0 B, free 389.6 KB)
2016-12-14 15:30:53,677 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,677 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,678 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,678 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 15:30:53,679 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 68, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,679 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 69, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,679 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 69)
2016-12-14 15:30:53,679 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 68)
2016-12-14 15:30:53,681 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,681 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,681 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,681 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:53,687 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 69). 1652 bytes result sent to driver
2016-12-14 15:30:53,687 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 68). 1576 bytes result sent to driver
2016-12-14 15:30:53,689 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 69) in 10 ms on localhost (1/2)
2016-12-14 15:30:53,693 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 68) in 14 ms on localhost (2/2)
2016-12-14 15:30:53,693 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (collectAsMap at KMeans.scala:302) finished in 0.015 s
2016-12-14 15:30:53,693 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,693 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: collectAsMap at KMeans.scala:302, took 0.046514 s
2016-12-14 15:30:53,695 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 9 iterations
2016-12-14 15:30:53,695 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 1472.0 B, free 391.1 KB)
2016-12-14 15:30:53,699 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 571.0 B, free 391.6 KB)
2016-12-14 15:30:53,700 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:23995 (size: 571.0 B, free: 529.9 MB)
2016-12-14 15:30:53,701 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,711 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 54 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 36)
2016-12-14 15:30:53,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 36)
2016-12-14 15:30:53,713 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 36 (MapPartitionsRDD[54] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,715 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 7.2 KB, free 398.8 KB)
2016-12-14 15:30:53,718 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.9 KB, free 402.7 KB)
2016-12-14 15:30:53,718 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,719 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,719 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[54] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,719 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 15:30:53,720 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,720 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,721 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 70)
2016-12-14 15:30:53,721 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 71)
2016-12-14 15:30:53,723 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,723 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,723 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,723 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,728 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 71). 2348 bytes result sent to driver
2016-12-14 15:30:53,728 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 70). 2348 bytes result sent to driver
2016-12-14 15:30:53,730 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 71) in 10 ms on localhost (1/2)
2016-12-14 15:30:53,730 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 70) in 11 ms on localhost (2/2)
2016-12-14 15:30:53,730 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 36 (mapPartitions at KMeans.scala:279) finished in 0.011 s
2016-12-14 15:30:53,730 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,730 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,731 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,731 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 37)
2016-12-14 15:30:53,731 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,731 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (ShuffledRDD[55] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,732 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 2.9 KB, free 405.6 KB)
2016-12-14 15:30:53,734 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 1660.0 B, free 407.3 KB)
2016-12-14 15:30:53,734 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:23995 (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:53,735 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,735 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 37 (ShuffledRDD[55] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,735 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 2 tasks
2016-12-14 15:30:53,736 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 72, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,736 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 37.0 (TID 73, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,736 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 72)
2016-12-14 15:30:53,736 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 37.0 (TID 73)
2016-12-14 15:30:53,738 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,738 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,738 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,738 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,743 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 72). 1502 bytes result sent to driver
2016-12-14 15:30:53,743 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 37.0 (TID 73). 1503 bytes result sent to driver
2016-12-14 15:30:53,746 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 72) in 10 ms on localhost (1/2)
2016-12-14 15:30:53,746 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 37.0 (TID 73) in 10 ms on localhost (2/2)
2016-12-14 15:30:53,746 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (collectAsMap at KMeans.scala:302) finished in 0.011 s
2016-12-14 15:30:53,746 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,747 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: collectAsMap at KMeans.scala:302, took 0.035378 s
2016-12-14 15:30:53,747 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 10 iterations
2016-12-14 15:30:53,748 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 992.0 B, free 408.2 KB)
2016-12-14 15:30:53,750 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 427.0 B, free 408.6 KB)
2016-12-14 15:30:53,751 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:23995 (size: 427.0 B, free: 529.9 MB)
2016-12-14 15:30:53,751 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,759 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,760 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 56 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,761 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,761 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,761 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 38)
2016-12-14 15:30:53,761 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 38)
2016-12-14 15:30:53,762 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 38 (MapPartitionsRDD[56] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,764 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 7.1 KB, free 415.8 KB)
2016-12-14 15:30:53,768 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.9 KB, free 419.7 KB)
2016-12-14 15:30:53,769 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,769 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,770 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[56] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,770 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 2 tasks
2016-12-14 15:30:53,771 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 74, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,772 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 38.0 (TID 75, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,773 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 38.0 (TID 75)
2016-12-14 15:30:53,773 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 74)
2016-12-14 15:30:53,774 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,775 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,775 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,775 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,779 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 38.0 (TID 75). 2324 bytes result sent to driver
2016-12-14 15:30:53,779 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 74). 2324 bytes result sent to driver
2016-12-14 15:30:53,781 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 38.0 (TID 75) in 9 ms on localhost (1/2)
2016-12-14 15:30:53,782 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 74) in 10 ms on localhost (2/2)
2016-12-14 15:30:53,782 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,782 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 38 (mapPartitions at KMeans.scala:279) finished in 0.011 s
2016-12-14 15:30:53,782 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,782 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,782 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 39)
2016-12-14 15:30:53,782 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,783 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (ShuffledRDD[57] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,784 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 2.9 KB, free 422.6 KB)
2016-12-14 15:30:53,786 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 1661.0 B, free 424.2 KB)
2016-12-14 15:30:53,786 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,787 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,787 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 39 (ShuffledRDD[57] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,787 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 2 tasks
2016-12-14 15:30:53,788 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 76, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,788 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 39.0 (TID 77, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,789 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 39.0 (TID 77)
2016-12-14 15:30:53,789 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 76)
2016-12-14 15:30:53,790 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,790 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,793 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,793 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,801 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 39.0 (TID 77). 1351 bytes result sent to driver
2016-12-14 15:30:53,802 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 76). 1428 bytes result sent to driver
2016-12-14 15:30:53,804 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 39.0 (TID 77) in 16 ms on localhost (1/2)
2016-12-14 15:30:53,806 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 76) in 19 ms on localhost (2/2)
2016-12-14 15:30:53,806 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 15:30:53,806 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,807 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: collectAsMap at KMeans.scala:302, took 0.047614 s
2016-12-14 15:30:53,809 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 992.0 B, free 425.2 KB)
2016-12-14 15:30:53,812 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 427.0 B, free 425.6 KB)
2016-12-14 15:30:53,813 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:23995 (size: 427.0 B, free: 529.9 MB)
2016-12-14 15:30:53,814 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at KMeans.scala:276
2016-12-14 15:30:53,830 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 15:30:53,830 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 58 (mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 15:30:53,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (collectAsMap at KMeans.scala:302)
2016-12-14 15:30:53,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 40)
2016-12-14 15:30:53,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 40)
2016-12-14 15:30:53,832 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 40 (MapPartitionsRDD[58] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 15:30:53,833 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 7.1 KB, free 432.7 KB)
2016-12-14 15:30:53,835 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.9 KB, free 436.6 KB)
2016-12-14 15:30:53,835 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:23995 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:53,835 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,836 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[58] at mapPartitions at KMeans.scala:279)
2016-12-14 15:30:53,836 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 2 tasks
2016-12-14 15:30:53,836 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 78, localhost, partition 0,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,837 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 40.0 (TID 79, localhost, partition 1,PROCESS_LOCAL, 2557 bytes)
2016-12-14 15:30:53,837 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 78)
2016-12-14 15:30:53,837 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 40.0 (TID 79)
2016-12-14 15:30:53,839 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,839 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,839 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 15:30:53,839 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 15:30:53,843 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 40.0 (TID 79). 2324 bytes result sent to driver
2016-12-14 15:30:53,843 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 78). 2324 bytes result sent to driver
2016-12-14 15:30:53,844 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 40.0 (TID 79) in 7 ms on localhost (1/2)
2016-12-14 15:30:53,845 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 78) in 9 ms on localhost (2/2)
2016-12-14 15:30:53,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 40 (mapPartitions at KMeans.scala:279) finished in 0.009 s
2016-12-14 15:30:53,845 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:53,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:53,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 41)
2016-12-14 15:30:53,845 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:53,846 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (ShuffledRDD[59] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 15:30:53,847 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 2.9 KB, free 439.5 KB)
2016-12-14 15:30:53,849 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 1661.0 B, free 441.2 KB)
2016-12-14 15:30:53,849 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:23995 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:53,850 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,850 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 41 (ShuffledRDD[59] at reduceByKey at KMeans.scala:302)
2016-12-14 15:30:53,850 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 15:30:53,851 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 80, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,851 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 81, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:53,851 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 80)
2016-12-14 15:30:53,851 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 81)
2016-12-14 15:30:53,852 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,852 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:53,852 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,852 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:53,857 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 80). 1428 bytes result sent to driver
2016-12-14 15:30:53,857 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 81). 1351 bytes result sent to driver
2016-12-14 15:30:53,860 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 81) in 9 ms on localhost (1/2)
2016-12-14 15:30:53,861 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 80) in 10 ms on localhost (2/2)
2016-12-14 15:30:53,861 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (collectAsMap at KMeans.scala:302) finished in 0.011 s
2016-12-14 15:30:53,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: collectAsMap at KMeans.scala:302, took 0.031503 s
2016-12-14 15:30:53,863 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 12 iterations
2016-12-14 15:30:53,863 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 12 iterations
2016-12-14 15:30:53,865 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.954 seconds.
2016-12-14 15:30:53,866 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 12 iterations.
2016-12-14 15:30:53,869 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 106.0579582015615.
2016-12-14 15:30:53,871 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 9 from persistence list
2016-12-14 15:30:53,871 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 15:30:53,872 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 15:30:53,884 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:108
2016-12-14 15:30:53,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (foreach at K_means.scala:108) with 2 output partitions
2016-12-14 15:30:53,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 42 (foreach at K_means.scala:108)
2016-12-14 15:30:53,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:53,886 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:53,886 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 42 (MapPartitionsRDD[8] at map at K_means.scala:102), which has no missing parents
2016-12-14 15:30:53,887 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 4.6 KB, free 439.9 KB)
2016-12-14 15:30:53,890 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.7 KB, free 442.5 KB)
2016-12-14 15:30:53,890 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:23995 (size: 2.7 KB, free: 529.9 MB)
2016-12-14 15:30:53,890 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,890 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[8] at map at K_means.scala:102)
2016-12-14 15:30:53,891 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 15:30:53,891 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 82, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,892 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 83, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,892 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 83)
2016-12-14 15:30:53,892 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 82)
2016-12-14 15:30:53,893 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,893 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.981982686667498,-10.927177477682065] belong to cluster 1
2016-12-14 15:30:53,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4292111107700873,-11.825556141018845] belong to cluster 3
2016-12-14 15:30:53,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-10.715250140415055,-8.802902843937433] belong to cluster 1
2016-12-14 15:30:53,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4239290147681047,-13.271256403953856] belong to cluster 3
2016-12-14 15:30:53,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.559762413255225,-13.020244625297904] belong to cluster 4
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.433313987213723,-13.273391228922565] belong to cluster 3
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.160964613010732,-13.286523356486173] belong to cluster 4
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6028109906390355,-12.678611240861468] belong to cluster 3
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.645508346905558,-9.831472521232158] belong to cluster 1
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5481694135275594,-12.909266625052062] belong to cluster 3
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.832286023308608,-9.544632155659988] belong to cluster 1
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.558768286976784,-12.805266332162981] belong to cluster 3
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.479293566910183,-10.315833706842508] belong to cluster 1
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6240659570218763,-12.849590741733206] belong to cluster 3
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4982246820799396,-12.686688248971492] belong to cluster 3
2016-12-14 15:30:53,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6572869801117665,-12.745949616383268] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5353900606117317,-12.297410826554685] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.759643779863749,-12.936808505149626] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.510659968536911,-12.572238615354056] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7870802820823837,-12.622755806377887] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5219336506192347,-12.493988315737061] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.672766956356051,-12.879035352455327] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.410564368573261,-13.132229945850522] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8422021814121226,-12.397284423524944] belong to cluster 3
2016-12-14 15:30:53,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.517117183672048,-12.90886774210546] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6604432456330023,-12.959992614388357] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5230194964256323,-13.066511045563258] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.796559461988575,-12.616263613741713] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6910183387798687,-12.501247523885311] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8500611255416914,-12.459152930744523] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.584670810807885,-12.922677812192513] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.811591844280215,-12.603492846960158] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.637937132906813,-12.934835748463152] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.92141010027821,-12.249631471530915] belong to cluster 3
2016-12-14 15:30:53,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.619301638525208,-13.138610974580766] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1630075563448874,-12.087020704075655] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8085810091550534,-12.482850569541913] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0798256106930726,-12.342322407307794] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8566061445094966,-12.429220618374584] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.877632275973137,-12.671156106132932] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9126513957312206,-12.398395586034287] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9120172059623006,-12.486727475000174] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.758438087074931,-12.571102687078229] belong to cluster 2
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.116993037568896,-12.357682396712054] belong to cluster 3
2016-12-14 15:30:53,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.728766304710531,-12.918751639024194] belong to cluster 2
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9693625691512695,-12.286127674433079] belong to cluster 3
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.936254991805165,-12.714602423297109] belong to cluster 4
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9299457584953936,-12.45637014916407] belong to cluster 3
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.56125473292351,-12.460177980157845] belong to cluster 4
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8831057999695933,-12.723151667623636] belong to cluster 3
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.8728927415172,-11.369644256343168] belong to cluster 1
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.905111956790263,-12.540455787775837] belong to cluster 3
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.3442379298056553,-12.601306609597096] belong to cluster 3
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9012554274352804,-12.70209956058848] belong to cluster 3
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.451205016000374,-12.657648263190007] belong to cluster 3
2016-12-14 15:30:53,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8909661007242953,-12.620324426809734] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4218999790845253,-12.718701328901592] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.93445744983364,-12.45540723525496] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6045013722704518,-12.362381194539779] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9240635133559167,-12.617911344974758] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6159831690702235,-12.468325205620365] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0005294221963674,-12.331635776695112] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.580321985296648,-12.801410987896052] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9469716449830234,-12.518953658872029] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.499824325159915,-13.020412175083024] belong to cluster 3
2016-12-14 15:30:53,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.978041593616158,-12.514320757173808] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5405456316054047,-12.957234182539123] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9711424090665903,-12.516128646085134] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6453800211975076,-12.956428958214573] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.062335239881501,-12.304763329331871] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7703376188319337,-12.593048469656472] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0118134183743663,-12.628483187320047] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7336987283708987,-12.763728318379467] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1315809450509926,-12.562165355319339] belong to cluster 3
2016-12-14 15:30:53,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.746447161590052,-12.899119771336984] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0539266444163835,-12.412253974926669] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.3629396981774513,-12.55531875654245] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.448132006083614,-11.751179735888101] belong to cluster 2
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.91813892469424,-12.240821799043939] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.448132006083614,-11.751179735888101] belong to cluster 2
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9168829970933094,-12.572721494973653] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0902959943737978,-12.319880778736174] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7980501318865447,-12.769067091343171] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0647563477457163,-12.460107486643219] belong to cluster 3
2016-12-14 15:30:53,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8440410691600473,-12.658110626302808] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0704980519885368,-12.65488225985779] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9190627624315444,-12.23088605706732] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.5479017026135296,-11.513051608588846] belong to cluster 2
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9045869721830937,-12.77903784725416] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.138811480399861,-12.33561348874941] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.365148284105376,-11.830299434267545] belong to cluster 2
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.299182739711413,-12.308620872679029] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.129089168918961,-12.291027943675672] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2428275868796548,-12.458400217990668] belong to cluster 3
2016-12-14 15:30:53,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.878796506017711,-12.857658505377] belong to cluster 3
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.720906317510698,-11.586702776709185] belong to cluster 2
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0615995798701685,-12.256565639718504] belong to cluster 3
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.7845231173419047,-11.229614413740837] belong to cluster 2
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0538574595043393,-12.61096184362446] belong to cluster 3
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.323921388851797,-12.468938728629624] belong to cluster 3
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1188196723353045,-12.654139179318577] belong to cluster 3
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.8488278360518113,-11.30958709705065] belong to cluster 2
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.5477631191678065,-11.694996997910613] belong to cluster 2
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.4876598508324554,-12.252889517567997] belong to cluster 2
2016-12-14 15:30:53,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2126099141894673,-12.556686456841765] belong to cluster 3
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.7456350660831546,-12.728781582375872] belong to cluster 2
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2685962478676727,-12.566054665296914] belong to cluster 3
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.7936280848730908,-12.629988986956857] belong to cluster 2
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.397481679772522,-12.414104266459288] belong to cluster 3
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.7852343233268013,-12.727190257604711] belong to cluster 2
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1926477734330265,-12.373268090955538] belong to cluster 3
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.8623616232143125,-12.596160654338] belong to cluster 2
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1989192187102247,-12.070678475709066] belong to cluster 3
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.832194130097416,-12.657980689968445] belong to cluster 3
2016-12-14 15:30:53,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1.9543111883474376,-15.646590859144833] belong to cluster 0
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.886669919701069,-12.596653969735645] belong to cluster 3
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.2203625518408545,-12.499306318004145] belong to cluster 2
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.432086684643232,-12.921082684135621] belong to cluster 3
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.0707160424976,-11.144187267503556] belong to cluster 4
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6556844541494753,-12.743056585298037] belong to cluster 3
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.31424127439543,-11.019625938794094] belong to cluster 4
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.052367169466071,-12.453708419045615] belong to cluster 3
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.53550770086492,-12.70851418992607] belong to cluster 4
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.094815757072997,-12.642643140097903] belong to cluster 3
2016-12-14 15:30:53,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.57596112060248,-13.76808084955549] belong to cluster 4
2016-12-14 15:30:53,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.396276019026096,-11.589421257281721] belong to cluster 2
2016-12-14 15:30:53,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.407199085415481,-12.987338727287426] belong to cluster 4
2016-12-14 15:30:53,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.562464300390877,-11.653952028958075] belong to cluster 2
2016-12-14 15:30:53,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.045122535636896,-12.268361684936574] belong to cluster 4
2016-12-14 15:30:53,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.5332816912294382,-11.642809926303894] belong to cluster 2
2016-12-14 15:30:53,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.068209053598304,-16.008914304043472] belong to cluster 5
2016-12-14 15:30:53,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.5202593645470506,-11.976599187141492] belong to cluster 2
2016-12-14 15:30:53,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.044853755651904,-16.056963549065067] belong to cluster 5
2016-12-14 15:30:53,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.7504257702354797,-11.404542000021513] belong to cluster 2
2016-12-14 15:30:53,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.211457190394174,-12.044360097195554] belong to cluster 4
2016-12-14 15:30:53,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.7496563887558634,-11.423951249113342] belong to cluster 2
2016-12-14 15:30:53,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.155520592644309,-12.960971273627592] belong to cluster 2
2016-12-14 15:30:53,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.7802861531106253,-11.497177417894259] belong to cluster 2
2016-12-14 15:30:53,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.141837907013722,-12.684489421857752] belong to cluster 4
2016-12-14 15:30:53,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.027876739121971,-11.286387416624247] belong to cluster 2
2016-12-14 15:30:53,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.533680433619558,-12.831170833873962] belong to cluster 2
2016-12-14 15:30:53,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.119943147893192,-13.806141193212861] belong to cluster 0
2016-12-14 15:30:53,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.631391557084434,-12.593141908205933] belong to cluster 2
2016-12-14 15:30:53,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5546700517439955,-12.550848599660895] belong to cluster 3
2016-12-14 15:30:53,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.44212435592164,-13.304732521200403] belong to cluster 2
2016-12-14 15:30:53,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4070530480001366,-13.090607233474838] belong to cluster 3
2016-12-14 15:30:53,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.51233333734111,-13.213966600119264] belong to cluster 2
2016-12-14 15:30:53,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4754039108784065,-13.1262347503201] belong to cluster 3
2016-12-14 15:30:53,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.647323952665134,-14.982741825580447] belong to cluster 0
2016-12-14 15:30:53,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4720631129016004,-13.048121235990909] belong to cluster 3
2016-12-14 15:30:53,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.98125659888637,-13.937760757884167] belong to cluster 5
2016-12-14 15:30:53,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.4992605006445467,-12.991317732585758] belong to cluster 3
2016-12-14 15:30:53,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.177652666935285,-13.589972705244545] belong to cluster 4
2016-12-14 15:30:53,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5417282396628753,-12.962312517315075] belong to cluster 3
2016-12-14 15:30:53,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.339232738572981,-13.291394617578408] belong to cluster 4
2016-12-14 15:30:53,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5631872971413583,-12.877175515877255] belong to cluster 3
2016-12-14 15:30:53,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.256450257542725,-17.55210185974539] belong to cluster 5
2016-12-14 15:30:53,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5595963491398983,-13.245697617415384] belong to cluster 3
2016-12-14 15:30:53,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1.0893157407625003,-15.419788558723683] belong to cluster 0
2016-12-14 15:30:53,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.566095925482854,-12.988457878910314] belong to cluster 3
2016-12-14 15:30:53,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-1.3895785034387875,-15.28696860771236] belong to cluster 0
2016-12-14 15:30:53,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5785174493232734,-13.022536216717665] belong to cluster 3
2016-12-14 15:30:53,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.271279600384682,-12.527135215447668] belong to cluster 3
2016-12-14 15:30:53,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.531490933192657,-13.196001449894084] belong to cluster 3
2016-12-14 15:30:53,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.794929093368296,-12.95892699089] belong to cluster 2
2016-12-14 15:30:53,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.613967072191732,-12.948292472522295] belong to cluster 3
2016-12-14 15:30:53,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.424486903797332,-14.407668116852964] belong to cluster 5
2016-12-14 15:30:53,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.609695300859607,-12.955592999184429] belong to cluster 3
2016-12-14 15:30:53,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.4242946260755955,-14.040748044179411] belong to cluster 5
2016-12-14 15:30:53,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.277554813966565,-14.317724600242347] belong to cluster 0
2016-12-14 15:30:53,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.806940715599709,-15.498024070102236] belong to cluster 5
2016-12-14 15:30:53,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6960143185849312,-12.864995002831982] belong to cluster 3
2016-12-14 15:30:53,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.982215933271323,-15.157686031013702] belong to cluster 5
2016-12-14 15:30:53,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.637199810845693,-13.067449513811288] belong to cluster 3
2016-12-14 15:30:53,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.70580851522967,-15.663701387869567] belong to cluster 5
2016-12-14 15:30:53,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.658228706256127,-13.025337574693518] belong to cluster 3
2016-12-14 15:30:53,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.691198043176966,-15.637022745199657] belong to cluster 5
2016-12-14 15:30:53,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6731618995508035,-12.870346574777546] belong to cluster 3
2016-12-14 15:30:53,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.0098776989779426,-15.12496758428173] belong to cluster 5
2016-12-14 15:30:53,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.6657049305797673,-12.890972924823892] belong to cluster 3
2016-12-14 15:30:53,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.241606004365653,-14.791923193247683] belong to cluster 5
2016-12-14 15:30:53,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0537119910501938,-11.97635147246123] belong to cluster 3
2016-12-14 15:30:53,916 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.933096581392932,-15.316652708987457] belong to cluster 5
2016-12-14 15:30:53,916 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.826483342410367,-12.775171644342803] belong to cluster 3
2016-12-14 15:30:53,916 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.02749482583102,-15.15644082791539] belong to cluster 5
2016-12-14 15:30:53,916 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9672111949556306,-12.836054866121158] belong to cluster 3
2016-12-14 15:30:53,916 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.852668978112287,-15.48978082245438] belong to cluster 5
2016-12-14 15:30:53,916 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.875246463970942,-13.00365355389711] belong to cluster 3
2016-12-14 15:30:53,917 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.518064926516987,-15.885015298640347] belong to cluster 5
2016-12-14 15:30:53,917 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8645359673224036,-12.854571196973843] belong to cluster 3
2016-12-14 15:30:53,917 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.5421416549721165,-14.436196073448684] belong to cluster 5
2016-12-14 15:30:53,917 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.065691072719999,-12.607343071217539] belong to cluster 3
2016-12-14 15:30:53,917 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.547722660028116,-15.805594825421764] belong to cluster 5
2016-12-14 15:30:53,917 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2547964828201463,-11.972444592972504] belong to cluster 2
2016-12-14 15:30:53,918 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.544674701062994,-15.880871427901416] belong to cluster 5
2016-12-14 15:30:53,918 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.3490178687164875,-12.245356497779897] belong to cluster 3
2016-12-14 15:30:53,918 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.771635975144535,-15.552366134219806] belong to cluster 5
2016-12-14 15:30:53,918 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.3993813405121487,-12.94756202327762] belong to cluster 3
2016-12-14 15:30:53,918 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.751467940313826,-15.628932740890377] belong to cluster 5
2016-12-14 15:30:53,918 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.5265641038441524,-12.754622840660867] belong to cluster 3
2016-12-14 15:30:53,918 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.781417238384184,-15.591349890511339] belong to cluster 5
2016-12-14 15:30:53,919 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.6005654396779483,-12.787620427221489] belong to cluster 3
2016-12-14 15:30:53,919 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.280162014747167,-17.14905071075182] belong to cluster 5
2016-12-14 15:30:53,919 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.9799011598468628,-12.391480834277322] belong to cluster 2
2016-12-14 15:30:53,919 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.279949446722892,-14.869939634367684] belong to cluster 5
2016-12-14 15:30:53,919 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.068079770374716,-12.295933248804893] belong to cluster 2
2016-12-14 15:30:53,919 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.134231311184982,-15.058937216038851] belong to cluster 5
2016-12-14 15:30:53,920 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.3532451415649565,-10.488043057633863] belong to cluster 2
2016-12-14 15:30:53,920 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.619529676960462,-15.818189725792427] belong to cluster 5
2016-12-14 15:30:53,920 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.976051962823787,-11.404572896981628] belong to cluster 2
2016-12-14 15:30:53,920 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.639514153132639,-15.65900409991586] belong to cluster 5
2016-12-14 15:30:53,920 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.666584118457827,-10.975026156911047] belong to cluster 1
2016-12-14 15:30:53,920 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.6565297759165265,-15.642839524423112] belong to cluster 5
2016-12-14 15:30:53,921 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.765153145709253,-15.506746623748661] belong to cluster 5
2016-12-14 15:30:53,923 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 83). 2057 bytes result sent to driver
2016-12-14 15:30:53,923 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 82). 2057 bytes result sent to driver
2016-12-14 15:30:53,925 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 82) in 34 ms on localhost (1/2)
2016-12-14 15:30:53,926 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 83) in 33 ms on localhost (2/2)
2016-12-14 15:30:53,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 42 (foreach at K_means.scala:108) finished in 0.035 s
2016-12-14 15:30:53,926 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: foreach at K_means.scala:108, took 0.041608 s
2016-12-14 15:30:53,932 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 15:30:53,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (first at PCA.scala:42) with 1 output partitions
2016-12-14 15:30:53,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 43 (first at PCA.scala:42)
2016-12-14 15:30:53,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:53,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:53,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 43 (MapPartitionsRDD[60] at map at K_means.scala:113), which has no missing parents
2016-12-14 15:30:53,934 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 3.6 KB, free 446.1 KB)
2016-12-14 15:30:53,937 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.1 KB, free 448.2 KB)
2016-12-14 15:30:53,937 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:23995 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 15:30:53,937 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,937 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[60] at map at K_means.scala:113)
2016-12-14 15:30:53,938 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 1 tasks
2016-12-14 15:30:53,938 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 84, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,939 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 84)
2016-12-14 15:30:53,941 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,943 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 84). 2216 bytes result sent to driver
2016-12-14 15:30:53,946 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 84) in 8 ms on localhost (1/1)
2016-12-14 15:30:53,946 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 43 (first at PCA.scala:42) finished in 0.008 s
2016-12-14 15:30:53,947 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,947 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: first at PCA.scala:42, took 0.014382 s
2016-12-14 15:30:53,950 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 15:30:53,950 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 31 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 15:30:53,950 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 44 (first at RowMatrix.scala:61)
2016-12-14 15:30:53,950 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:53,950 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:53,951 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 44 (MapPartitionsRDD[60] at map at K_means.scala:113), which has no missing parents
2016-12-14 15:30:53,951 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 3.6 KB, free 451.8 KB)
2016-12-14 15:30:53,954 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.1 KB, free 453.9 KB)
2016-12-14 15:30:53,954 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:23995 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 15:30:53,954 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,954 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[60] at map at K_means.scala:113)
2016-12-14 15:30:53,955 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 1 tasks
2016-12-14 15:30:53,955 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 85, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,956 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 85)
2016-12-14 15:30:53,957 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,960 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 85). 2216 bytes result sent to driver
2016-12-14 15:30:53,964 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 85) in 9 ms on localhost (1/1)
2016-12-14 15:30:53,964 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 44 (first at RowMatrix.scala:61) finished in 0.009 s
2016-12-14 15:30:53,964 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,964 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 31 finished: first at RowMatrix.scala:61, took 0.014494 s
2016-12-14 15:30:53,968 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 15:30:53,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 32 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 15:30:53,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 45 (treeAggregate at RowMatrix.scala:331)
2016-12-14 15:30:53,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:53,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:53,969 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 45 (MapPartitionsRDD[61] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 15:30:53,969 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64 stored as values in memory (estimated size 4.6 KB, free 458.5 KB)
2016-12-14 15:30:53,972 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.5 KB, free 460.9 KB)
2016-12-14 15:30:53,972 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_64_piece0 in memory on localhost:23995 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 15:30:53,972 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,973 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[61] at treeAggregate at RowMatrix.scala:331)
2016-12-14 15:30:53,973 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 45.0 with 2 tasks
2016-12-14 15:30:53,973 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 45.0 (TID 86, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,974 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 45.0 (TID 87, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,974 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 45.0 (TID 87)
2016-12-14 15:30:53,974 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 45.0 (TID 86)
2016-12-14 15:30:53,976 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:53,976 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:53,984 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 45.0 (TID 87). 2176 bytes result sent to driver
2016-12-14 15:30:53,984 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 45.0 (TID 86). 2176 bytes result sent to driver
2016-12-14 15:30:53,986 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 45.0 (TID 87) in 13 ms on localhost (1/2)
2016-12-14 15:30:53,987 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 45.0 (TID 86) in 14 ms on localhost (2/2)
2016-12-14 15:30:53,987 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 45 (treeAggregate at RowMatrix.scala:331) finished in 0.014 s
2016-12-14 15:30:53,987 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 15:30:53,987 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 32 finished: treeAggregate at RowMatrix.scala:331, took 0.019614 s
2016-12-14 15:30:53,991 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 15:30:53,991 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 33 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 15:30:53,991 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 46 (treeAggregate at RowMatrix.scala:121)
2016-12-14 15:30:53,991 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:53,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:53,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 46 (MapPartitionsRDD[62] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 15:30:53,993 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65 stored as values in memory (estimated size 4.9 KB, free 465.8 KB)
2016-12-14 15:30:53,995 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.5 KB, free 468.3 KB)
2016-12-14 15:30:53,995 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_65_piece0 in memory on localhost:23995 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 15:30:53,996 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:53,996 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[62] at treeAggregate at RowMatrix.scala:121)
2016-12-14 15:30:53,996 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 46.0 with 2 tasks
2016-12-14 15:30:53,997 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 46.0 (TID 88, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,997 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 46.0 (TID 89, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:53,997 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 46.0 (TID 89)
2016-12-14 15:30:53,997 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 46.0 (TID 88)
2016-12-14 15:30:53,999 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:54,000 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:54,002 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 46.0 (TID 88). 2462 bytes result sent to driver
2016-12-14 15:30:54,003 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 46.0 (TID 89). 2462 bytes result sent to driver
2016-12-14 15:30:54,005 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 46.0 (TID 88) in 9 ms on localhost (1/2)
2016-12-14 15:30:54,007 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 46.0 (TID 89) in 10 ms on localhost (2/2)
2016-12-14 15:30:54,007 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 46 (treeAggregate at RowMatrix.scala:121) finished in 0.011 s
2016-12-14 15:30:54,007 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,008 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 33 finished: treeAggregate at RowMatrix.scala:121, took 0.016744 s
2016-12-14 15:30:54,017 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:119
2016-12-14 15:30:54,017 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 34 (foreach at K_means.scala:119) with 2 output partitions
2016-12-14 15:30:54,017 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 47 (foreach at K_means.scala:119)
2016-12-14 15:30:54,018 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:54,018 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:54,018 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 47 (MapPartitionsRDD[64] at map at K_means.scala:115), which has no missing parents
2016-12-14 15:30:54,019 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66 stored as values in memory (estimated size 4.5 KB, free 472.8 KB)
2016-12-14 15:30:54,021 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.6 KB, free 475.5 KB)
2016-12-14 15:30:54,022 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_66_piece0 in memory on localhost:23995 (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:54,022 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,022 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[64] at map at K_means.scala:115)
2016-12-14 15:30:54,022 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 47.0 with 2 tasks
2016-12-14 15:30:54,023 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 47.0 (TID 90, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:54,024 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 47.0 (TID 91, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:54,024 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 47.0 (TID 90)
2016-12-14 15:30:54,024 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 47.0 (TID 91)
2016-12-14 15:30:54,026 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:54,026 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:54,028 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,028 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:54,028 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,028 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:54,028 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,028 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:54,029 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,029 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:54,029 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,029 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:54,029 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,029 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:54,030 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,030 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:54,030 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,030 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,030 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,030 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,030 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,031 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,031 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,031 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,031 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,031 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,031 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,031 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,032 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,032 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,032 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,032 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,032 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,032 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,033 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,033 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,033 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,033 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,033 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,033 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,033 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,034 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,034 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,034 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,034 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,034 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:54,034 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,035 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:54,035 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,035 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:54,035 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,035 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 4.0
2016-12-14 15:30:54,035 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,035 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:54,036 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,036 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,036 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,036 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,036 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,036 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,036 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,037 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,037 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,037 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,037 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,037 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,037 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,038 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,038 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,038 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,038 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,038 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,038 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,039 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,039 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,039 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,039 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,039 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,039 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,039 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,040 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,040 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,040 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,040 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,040 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,040 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,041 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,041 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,041 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,041 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,041 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,041 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,041 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,042 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 15:30:54,042 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,042 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,042 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,042 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,042 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,043 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,043 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,043 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,043 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,043 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,043 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,043 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 15:30:54,044 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,044 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,044 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,044 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,044 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,044 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,044 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,045 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,045 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,045 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 3.0
2016-12-14 15:30:54,045 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,045 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 0.0
2016-12-14 15:30:54,045 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,046 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:54,046 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,046 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,046 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,046 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,046 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 3.0
2016-12-14 15:30:54,046 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,047 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,047 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,047 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,047 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,047 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,047 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,047 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,048 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 5.0
2016-12-14 15:30:54,048 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,048 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 5.0
2016-12-14 15:30:54,048 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,048 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,048 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,049 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 2.0
2016-12-14 15:30:54,049 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 2.0
2016-12-14 15:30:54,049 INFO  com.datageek.test.K_means$ - apply: old label pair: 3.0 --- 4.0
2016-12-14 15:30:54,049 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 15:30:54,049 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 2.0
2016-12-14 15:30:54,049 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,049 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 2.0
2016-12-14 15:30:54,050 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,050 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 2.0
2016-12-14 15:30:54,050 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,050 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 2.0
2016-12-14 15:30:54,050 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,050 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 0.0
2016-12-14 15:30:54,050 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,051 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 5.0
2016-12-14 15:30:54,051 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,051 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 4.0
2016-12-14 15:30:54,051 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,051 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 4.0
2016-12-14 15:30:54,051 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,052 INFO  com.datageek.test.K_means$ - apply: old label pair: 4.0 --- 5.0
2016-12-14 15:30:54,052 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,052 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:54,052 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,052 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 0.0
2016-12-14 15:30:54,052 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,052 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 3.0
2016-12-14 15:30:54,053 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,053 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 2.0
2016-12-14 15:30:54,053 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,053 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,053 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 15:30:54,053 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,054 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,054 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,054 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,054 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,054 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,054 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,054 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,055 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,055 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,055 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,055 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,055 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,055 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,056 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,056 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,056 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,056 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,056 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,056 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,056 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,057 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,057 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,057 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:54,057 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,057 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,057 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,058 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,058 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,058 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,058 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,058 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 3.0
2016-12-14 15:30:54,058 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,058 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:54,059 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,059 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:54,059 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,059 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:54,059 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,059 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 15:30:54,059 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,060 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 1.0
2016-12-14 15:30:54,060 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,060 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,060 INFO  com.datageek.test.K_means$ - apply: old label pair: 5.0 --- 5.0
2016-12-14 15:30:54,062 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 47.0 (TID 90). 2057 bytes result sent to driver
2016-12-14 15:30:54,062 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 47.0 (TID 91). 2057 bytes result sent to driver
2016-12-14 15:30:54,064 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 47.0 (TID 90) in 41 ms on localhost (1/2)
2016-12-14 15:30:54,064 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 47.0 (TID 91) in 40 ms on localhost (2/2)
2016-12-14 15:30:54,064 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 47 (foreach at K_means.scala:119) finished in 0.041 s
2016-12-14 15:30:54,064 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,065 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 34 finished: foreach at K_means.scala:119, took 0.047533 s
2016-12-14 15:30:54,101 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:13
2016-12-14 15:30:54,102 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 65 (map at Relabel.scala:13)
2016-12-14 15:30:54,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 35 (sortBy at Relabel.scala:13) with 2 output partitions
2016-12-14 15:30:54,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 49 (sortBy at Relabel.scala:13)
2016-12-14 15:30:54,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 48)
2016-12-14 15:30:54,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 48)
2016-12-14 15:30:54,104 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 48 (MapPartitionsRDD[65] at map at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:54,105 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67 stored as values in memory (estimated size 5.4 KB, free 480.9 KB)
2016-12-14 15:30:54,114 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 102
2016-12-14 15:30:54,115 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:23995 in memory (size: 709.0 B, free: 529.9 MB)
2016-12-14 15:30:54,115 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 83
2016-12-14 15:30:54,116 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 82
2016-12-14 15:30:54,116 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 81
2016-12-14 15:30:54,116 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 15:30:54,116 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 15:30:54,116 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 90
2016-12-14 15:30:54,116 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 15:30:54,117 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:23995 in memory (size: 643.0 B, free: 529.9 MB)
2016-12-14 15:30:54,117 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 89
2016-12-14 15:30:54,117 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 88
2016-12-14 15:30:54,117 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.1 KB, free 478.4 KB)
2016-12-14 15:30:54,117 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 87
2016-12-14 15:30:54,118 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 86
2016-12-14 15:30:54,118 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_67_piece0 in memory on localhost:23995 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 15:30:54,119 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,119 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:54,119 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[65] at map at Relabel.scala:13)
2016-12-14 15:30:54,119 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 85
2016-12-14 15:30:54,119 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 48.0 with 2 tasks
2016-12-14 15:30:54,120 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:54,120 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 84
2016-12-14 15:30:54,120 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 15:30:54,120 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 48.0 (TID 92, localhost, partition 0,PROCESS_LOCAL, 2383 bytes)
2016-12-14 15:30:54,121 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 48.0 (TID 93, localhost, partition 1,PROCESS_LOCAL, 2383 bytes)
2016-12-14 15:30:54,121 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:23995 in memory (size: 642.0 B, free: 529.9 MB)
2016-12-14 15:30:54,121 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 48.0 (TID 93)
2016-12-14 15:30:54,121 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 48.0 (TID 92)
2016-12-14 15:30:54,121 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 95
2016-12-14 15:30:54,122 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 94
2016-12-14 15:30:54,122 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 93
2016-12-14 15:30:54,122 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 92
2016-12-14 15:30:54,123 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:54,123 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:54,123 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:54,123 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 91
2016-12-14 15:30:54,124 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:54,124 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 98
2016-12-14 15:30:54,125 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:54,125 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 97
2016-12-14 15:30:54,126 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:54,126 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 96
2016-12-14 15:30:54,133 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 48.0 (TID 92). 2237 bytes result sent to driver
2016-12-14 15:30:54,131 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 48.0 (TID 93). 2237 bytes result sent to driver
2016-12-14 15:30:54,147 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 15:30:54,147 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 11
2016-12-14 15:30:54,148 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_55_piece0 on localhost:23995 in memory (size: 427.0 B, free: 529.9 MB)
2016-12-14 15:30:54,148 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 104
2016-12-14 15:30:54,149 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 103
2016-12-14 15:30:54,149 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 48.0 (TID 92) in 29 ms on localhost (1/2)
2016-12-14 15:30:54,149 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:23995 in memory (size: 1660.0 B, free: 529.9 MB)
2016-12-14 15:30:54,149 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 48.0 (TID 93) in 28 ms on localhost (2/2)
2016-12-14 15:30:54,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 48 (map at Relabel.scala:13) finished in 0.030 s
2016-12-14 15:30:54,150 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:54,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:54,150 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:54,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 49)
2016-12-14 15:30:54,150 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:54,151 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 101
2016-12-14 15:30:54,151 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 49 (MapPartitionsRDD[69] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:54,151 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 15:30:54,152 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:23995 in memory (size: 571.0 B, free: 529.9 MB)
2016-12-14 15:30:54,152 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 100
2016-12-14 15:30:54,152 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 99
2016-12-14 15:30:54,153 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68 stored as values in memory (estimated size 3.5 KB, free 413.4 KB)
2016-12-14 15:30:54,153 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_60_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:54,153 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 110
2016-12-14 15:30:54,154 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_59_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:54,154 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 109
2016-12-14 15:30:54,154 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 12
2016-12-14 15:30:54,155 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_58_piece0 on localhost:23995 in memory (size: 427.0 B, free: 529.9 MB)
2016-12-14 15:30:54,155 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 108
2016-12-14 15:30:54,156 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 107
2016-12-14 15:30:54,156 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68_piece0 stored as bytes in memory (estimated size 2017.0 B, free 398.4 KB)
2016-12-14 15:30:54,156 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_57_piece0 on localhost:23995 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 15:30:54,156 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_68_piece0 in memory on localhost:23995 (size: 2017.0 B, free: 529.9 MB)
2016-12-14 15:30:54,156 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 106
2016-12-14 15:30:54,157 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,157 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_56_piece0 on localhost:23995 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 15:30:54,157 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[69] at sortBy at Relabel.scala:13)
2016-12-14 15:30:54,157 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 105
2016-12-14 15:30:54,157 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 49.0 with 2 tasks
2016-12-14 15:30:54,158 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_66_piece0 on localhost:23995 in memory (size: 2.6 KB, free: 529.9 MB)
2016-12-14 15:30:54,158 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 116
2016-12-14 15:30:54,159 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_65_piece0 on localhost:23995 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 15:30:54,159 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 49.0 (TID 94, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:54,159 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 115
2016-12-14 15:30:54,159 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 49.0 (TID 95, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:54,159 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_64_piece0 on localhost:23995 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 15:30:54,159 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 49.0 (TID 94)
2016-12-14 15:30:54,159 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 49.0 (TID 95)
2016-12-14 15:30:54,160 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 114
2016-12-14 15:30:54,160 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_63_piece0 on localhost:23995 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 15:30:54,160 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 113
2016-12-14 15:30:54,161 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_62_piece0 on localhost:23995 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 15:30:54,161 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,161 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 112
2016-12-14 15:30:54,161 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,162 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:54,162 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_61_piece0 on localhost:23995 in memory (size: 2.7 KB, free: 530.0 MB)
2016-12-14 15:30:54,162 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:54,162 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 111
2016-12-14 15:30:54,163 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 15:30:54,163 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 9
2016-12-14 15:30:54,166 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 49.0 (TID 94). 1208 bytes result sent to driver
2016-12-14 15:30:54,167 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 49.0 (TID 94) in 9 ms on localhost (1/2)
2016-12-14 15:30:54,167 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 49.0 (TID 95). 1232 bytes result sent to driver
2016-12-14 15:30:54,169 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 49.0 (TID 95) in 10 ms on localhost (2/2)
2016-12-14 15:30:54,169 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 49 (sortBy at Relabel.scala:13) finished in 0.011 s
2016-12-14 15:30:54,169 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,170 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 35 finished: sortBy at Relabel.scala:13, took 0.067749 s
2016-12-14 15:30:54,199 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 15:30:54,206 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 13 is 155 bytes
2016-12-14 15:30:54,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 67 (sortBy at Relabel.scala:13)
2016-12-14 15:30:54,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 36 (collect at Relabel.scala:14) with 2 output partitions
2016-12-14 15:30:54,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 52 (collect at Relabel.scala:14)
2016-12-14 15:30:54,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 51)
2016-12-14 15:30:54,211 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 51)
2016-12-14 15:30:54,212 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 51 (MapPartitionsRDD[67] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:54,217 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_69 stored as values in memory (estimated size 3.6 KB, free 346.2 KB)
2016-12-14 15:30:54,220 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.0 KB, free 348.2 KB)
2016-12-14 15:30:54,221 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_69_piece0 in memory on localhost:23995 (size: 2.0 KB, free: 530.0 MB)
2016-12-14 15:30:54,222 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,222 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[67] at sortBy at Relabel.scala:13)
2016-12-14 15:30:54,222 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 51.0 with 2 tasks
2016-12-14 15:30:54,223 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 51.0 (TID 96, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 15:30:54,224 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 51.0 (TID 97, localhost, partition 1,NODE_LOCAL, 2132 bytes)
2016-12-14 15:30:54,224 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 51.0 (TID 97)
2016-12-14 15:30:54,224 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 51.0 (TID 96)
2016-12-14 15:30:54,233 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,234 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:54,234 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,234 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:54,246 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 51.0 (TID 97). 1303 bytes result sent to driver
2016-12-14 15:30:54,248 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 51.0 (TID 97) in 23 ms on localhost (1/2)
2016-12-14 15:30:54,248 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 51.0 (TID 96). 1303 bytes result sent to driver
2016-12-14 15:30:54,251 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 51.0 (TID 96) in 28 ms on localhost (2/2)
2016-12-14 15:30:54,251 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 51 (sortBy at Relabel.scala:13) finished in 0.028 s
2016-12-14 15:30:54,251 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 51.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,251 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:54,252 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:54,252 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 52)
2016-12-14 15:30:54,252 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:54,252 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 52 (MapPartitionsRDD[71] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 15:30:54,257 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_70 stored as values in memory (estimated size 3.4 KB, free 351.6 KB)
2016-12-14 15:30:54,260 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_70_piece0 stored as bytes in memory (estimated size 1949.0 B, free 353.5 KB)
2016-12-14 15:30:54,261 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_70_piece0 in memory on localhost:23995 (size: 1949.0 B, free: 530.0 MB)
2016-12-14 15:30:54,262 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 52 (MapPartitionsRDD[71] at sortBy at Relabel.scala:13)
2016-12-14 15:30:54,262 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 52.0 with 2 tasks
2016-12-14 15:30:54,263 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 52.0 (TID 98, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:54,264 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 52.0 (TID 99, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:54,264 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 52.0 (TID 98)
2016-12-14 15:30:54,264 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 52.0 (TID 99)
2016-12-14 15:30:54,267 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,268 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 15:30:54,268 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,268 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:54,279 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 52.0 (TID 98). 1417 bytes result sent to driver
2016-12-14 15:30:54,279 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 52.0 (TID 99). 1446 bytes result sent to driver
2016-12-14 15:30:54,281 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 52.0 (TID 98) in 17 ms on localhost (1/2)
2016-12-14 15:30:54,281 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 52.0 (TID 99) in 17 ms on localhost (2/2)
2016-12-14 15:30:54,281 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 52 (collect at Relabel.scala:14) finished in 0.018 s
2016-12-14 15:30:54,281 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 52.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,282 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 36 finished: collect at Relabel.scala:14, took 0.082322 s
2016-12-14 15:30:54,306 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:123
2016-12-14 15:30:54,307 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 37 (foreach at K_means.scala:123) with 2 output partitions
2016-12-14 15:30:54,307 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 53 (foreach at K_means.scala:123)
2016-12-14 15:30:54,307 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:54,308 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:54,308 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 53 (MapPartitionsRDD[72] at map at Relabel.scala:31), which has no missing parents
2016-12-14 15:30:54,310 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_71 stored as values in memory (estimated size 5.0 KB, free 358.5 KB)
2016-12-14 15:30:54,313 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.9 KB, free 361.3 KB)
2016-12-14 15:30:54,314 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_71_piece0 in memory on localhost:23995 (size: 2.9 KB, free: 529.9 MB)
2016-12-14 15:30:54,315 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[72] at map at Relabel.scala:31)
2016-12-14 15:30:54,315 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 53.0 with 2 tasks
2016-12-14 15:30:54,316 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 53.0 (TID 100, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:54,317 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 53.0 (TID 101, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:54,317 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 53.0 (TID 101)
2016-12-14 15:30:54,318 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 53.0 (TID 100)
2016-12-14 15:30:54,320 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:54,320 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:54,321 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,321 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,321 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,322 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,323 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,324 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,325 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 3.0
2016-12-14 15:30:54,326 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,327 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,328 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,329 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,329 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,329 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,329 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,329 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,329 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,329 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,330 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 0.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 4.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 0.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 1.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 5.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 5.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 0.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 3.0 --- 3.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 15:30:54,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 4.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 0.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 4.0
2016-12-14 15:30:54,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 5.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 3.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 3.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 4.0 --- 5.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 4.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 4.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 1.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 0.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 4.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 0.0
2016-12-14 15:30:54,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 5.0 --- 5.0
2016-12-14 15:30:54,346 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 53.0 (TID 100). 2057 bytes result sent to driver
2016-12-14 15:30:54,347 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 53.0 (TID 101). 2057 bytes result sent to driver
2016-12-14 15:30:54,348 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 53.0 (TID 100) in 32 ms on localhost (1/2)
2016-12-14 15:30:54,349 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 53.0 (TID 101) in 32 ms on localhost (2/2)
2016-12-14 15:30:54,349 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 53 (foreach at K_means.scala:123) finished in 0.033 s
2016-12-14 15:30:54,349 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 53.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,349 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 37 finished: foreach at K_means.scala:123, took 0.043343 s
2016-12-14 15:30:54,370 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 15:30:54,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 73 (map at MulticlassMetrics.scala:46)
2016-12-14 15:30:54,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 38 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 15:30:54,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 55 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 15:30:54,373 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 54)
2016-12-14 15:30:54,373 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 54)
2016-12-14 15:30:54,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 54 (MapPartitionsRDD[73] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 15:30:54,375 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_72 stored as values in memory (estimated size 5.9 KB, free 367.2 KB)
2016-12-14 15:30:54,378 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.3 KB, free 370.6 KB)
2016-12-14 15:30:54,378 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_72_piece0 in memory on localhost:23995 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 15:30:54,379 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,379 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[73] at map at MulticlassMetrics.scala:46)
2016-12-14 15:30:54,379 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 54.0 with 2 tasks
2016-12-14 15:30:54,380 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 54.0 (TID 102, localhost, partition 0,PROCESS_LOCAL, 2383 bytes)
2016-12-14 15:30:54,380 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 54.0 (TID 103, localhost, partition 1,PROCESS_LOCAL, 2383 bytes)
2016-12-14 15:30:54,381 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 54.0 (TID 103)
2016-12-14 15:30:54,381 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 54.0 (TID 102)
2016-12-14 15:30:54,383 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:54,383 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:54,389 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 54.0 (TID 103). 2237 bytes result sent to driver
2016-12-14 15:30:54,391 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 54.0 (TID 102). 2237 bytes result sent to driver
2016-12-14 15:30:54,391 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 54.0 (TID 103) in 11 ms on localhost (1/2)
2016-12-14 15:30:54,393 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 54.0 (TID 102) in 13 ms on localhost (2/2)
2016-12-14 15:30:54,393 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 54 (map at MulticlassMetrics.scala:46) finished in 0.014 s
2016-12-14 15:30:54,393 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 54.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,393 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:54,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:54,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 55)
2016-12-14 15:30:54,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:54,394 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 55 (ShuffledRDD[74] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 15:30:54,396 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_73 stored as values in memory (estimated size 2.6 KB, free 373.2 KB)
2016-12-14 15:30:54,399 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_73_piece0 stored as bytes in memory (estimated size 1593.0 B, free 374.7 KB)
2016-12-14 15:30:54,400 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_73_piece0 in memory on localhost:23995 (size: 1593.0 B, free: 529.9 MB)
2016-12-14 15:30:54,401 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,401 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 55 (ShuffledRDD[74] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 15:30:54,401 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 55.0 with 2 tasks
2016-12-14 15:30:54,403 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 55.0 (TID 104, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:54,403 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 55.0 (TID 105, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 15:30:54,403 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 55.0 (TID 105)
2016-12-14 15:30:54,404 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 55.0 (TID 104)
2016-12-14 15:30:54,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:54,405 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:54,408 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 55.0 (TID 105). 1124 bytes result sent to driver
2016-12-14 15:30:54,409 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 55.0 (TID 104). 1189 bytes result sent to driver
2016-12-14 15:30:54,410 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 55.0 (TID 105) in 7 ms on localhost (1/2)
2016-12-14 15:30:54,410 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 55.0 (TID 104) in 7 ms on localhost (2/2)
2016-12-14 15:30:54,410 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 55 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.008 s
2016-12-14 15:30:54,410 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 55.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,411 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 38 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.039648 s
2016-12-14 15:30:54,435 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 15:30:54,438 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 77 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:54,438 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 39 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 15:30:54,438 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 57 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:54,438 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 56)
2016-12-14 15:30:54,438 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 56)
2016-12-14 15:30:54,439 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 56 (MapPartitionsRDD[77] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 15:30:54,441 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_74 stored as values in memory (estimated size 6.4 KB, free 381.2 KB)
2016-12-14 15:30:54,443 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.5 KB, free 384.7 KB)
2016-12-14 15:30:54,443 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_74_piece0 in memory on localhost:23995 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 15:30:54,444 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[77] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:54,444 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 56.0 with 2 tasks
2016-12-14 15:30:54,445 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 56.0 (TID 106, localhost, partition 0,PROCESS_LOCAL, 2383 bytes)
2016-12-14 15:30:54,445 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 56.0 (TID 107, localhost, partition 1,PROCESS_LOCAL, 2383 bytes)
2016-12-14 15:30:54,446 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 56.0 (TID 107)
2016-12-14 15:30:54,446 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 56.0 (TID 106)
2016-12-14 15:30:54,448 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:54,448 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:54,454 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 56.0 (TID 107). 2237 bytes result sent to driver
2016-12-14 15:30:54,455 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 56.0 (TID 106). 2237 bytes result sent to driver
2016-12-14 15:30:54,456 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 56.0 (TID 107) in 11 ms on localhost (1/2)
2016-12-14 15:30:54,458 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 56.0 (TID 106) in 13 ms on localhost (2/2)
2016-12-14 15:30:54,458 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 56 (countByValue at MulticlassMetrics.scala:43) finished in 0.014 s
2016-12-14 15:30:54,458 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 56.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,458 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 15:30:54,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 15:30:54,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 57)
2016-12-14 15:30:54,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 15:30:54,459 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 57 (ShuffledRDD[78] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 15:30:54,461 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_75 stored as values in memory (estimated size 2.6 KB, free 387.3 KB)
2016-12-14 15:30:54,465 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_75_piece0 stored as bytes in memory (estimated size 1562.0 B, free 388.8 KB)
2016-12-14 15:30:54,466 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_75_piece0 in memory on localhost:23995 (size: 1562.0 B, free: 529.9 MB)
2016-12-14 15:30:54,466 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 57 (ShuffledRDD[78] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 15:30:54,467 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 57.0 with 2 tasks
2016-12-14 15:30:54,468 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 57.0 (TID 108, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 15:30:54,468 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 57.0 (TID 109, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 15:30:54,468 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 57.0 (TID 109)
2016-12-14 15:30:54,468 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 57.0 (TID 108)
2016-12-14 15:30:54,470 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,470 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:54,471 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 15:30:54,471 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 15:30:54,473 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 57.0 (TID 109). 1124 bytes result sent to driver
2016-12-14 15:30:54,475 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 57.0 (TID 109) in 7 ms on localhost (1/2)
2016-12-14 15:30:54,478 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 57.0 (TID 108). 1190 bytes result sent to driver
2016-12-14 15:30:54,479 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 57.0 (TID 108) in 12 ms on localhost (2/2)
2016-12-14 15:30:54,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 57 (countByValue at MulticlassMetrics.scala:43) finished in 0.013 s
2016-12-14 15:30:54,480 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 57.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 39 finished: countByValue at MulticlassMetrics.scala:43, took 0.044442 s
2016-12-14 15:30:54,481 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.5093457943925234
2016-12-14 15:30:54,482 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_76 stored as values in memory (estimated size 520.0 B, free 389.3 KB)
2016-12-14 15:30:54,486 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_76_piece0 stored as bytes in memory (estimated size 330.0 B, free 389.7 KB)
2016-12-14 15:30:54,487 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_76_piece0 in memory on localhost:23995 (size: 330.0 B, free: 529.9 MB)
2016-12-14 15:30:54,487 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 76 from broadcast at KMeansModel.scala:87
2016-12-14 15:30:54,500 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 15:30:54,501 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 40 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 15:30:54,501 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 58 (sum at KMeansModel.scala:88)
2016-12-14 15:30:54,501 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 15:30:54,502 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 15:30:54,502 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 58 (MapPartitionsRDD[79] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 15:30:54,503 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_77 stored as values in memory (estimated size 4.8 KB, free 394.4 KB)
2016-12-14 15:30:54,505 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.8 KB, free 397.3 KB)
2016-12-14 15:30:54,505 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_77_piece0 in memory on localhost:23995 (size: 2.8 KB, free: 529.9 MB)
2016-12-14 15:30:54,505 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
2016-12-14 15:30:54,506 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 58 (MapPartitionsRDD[79] at map at KMeansModel.scala:88)
2016-12-14 15:30:54,506 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 58.0 with 2 tasks
2016-12-14 15:30:54,507 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 58.0 (TID 110, localhost, partition 0,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:54,507 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 58.0 (TID 111, localhost, partition 1,PROCESS_LOCAL, 2394 bytes)
2016-12-14 15:30:54,507 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 58.0 (TID 111)
2016-12-14 15:30:54,507 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 58.0 (TID 110)
2016-12-14 15:30:54,509 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 15:30:54,509 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 15:30:54,511 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 58.0 (TID 111). 2064 bytes result sent to driver
2016-12-14 15:30:54,512 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 58.0 (TID 110). 2064 bytes result sent to driver
2016-12-14 15:30:54,513 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 58.0 (TID 111) in 6 ms on localhost (1/2)
2016-12-14 15:30:54,513 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 58.0 (TID 110) in 7 ms on localhost (2/2)
2016-12-14 15:30:54,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 58 (sum at KMeansModel.scala:88) finished in 0.007 s
2016-12-14 15:30:54,514 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 58.0, whose tasks have all completed, from pool 
2016-12-14 15:30:54,514 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 40 finished: sum at KMeansModel.scala:88, took 0.013708 s
2016-12-14 15:30:54,514 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 106.0579582015615
2016-12-14 15:30:54,514 INFO  com.datageek.test.K_means$ - main: ==(-_-)~====END====(-_-)~==
2016-12-14 15:30:54,614 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 15:30:54,615 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 15:30:54,615 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 15:30:54,615 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 15:30:54,616 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 15:30:54,616 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 15:30:54,616 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 15:30:54,617 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 15:30:54,617 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 15:30:54,617 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 15:30:54,617 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 15:30:54,618 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 15:30:54,618 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 15:30:54,618 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 15:30:54,619 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 15:30:54,619 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 15:30:54,619 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 15:30:54,620 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 15:30:54,620 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 15:30:54,620 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 15:30:54,621 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 15:30:54,621 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 15:30:54,621 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 15:30:54,622 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 15:30:54,776 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 15:30:54,833 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 15:30:54,902 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 15:30:54,914 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 15:30:54,914 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 15:30:54,915 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 15:30:54,917 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 15:30:54,925 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 15:30:54,926 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 15:30:54,930 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 15:30:54,931 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 15:30:54,933 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-27fc725d-1a97-48b7-a39a-a72ffb4ff793
2016-12-14 15:30:54,964 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 15:30:54,965 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 17:17:35,834 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 17:17:36,979 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 17:17:36,985 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 17:17:36,986 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 17:17:37,393 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 56677.
2016-12-14 17:17:37,992 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 17:17:38,062 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 17:17:38,301 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:36987]
2016-12-14 17:17:38,304 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:36987]
2016-12-14 17:17:38,315 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 36987.
2016-12-14 17:17:38,345 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 17:17:38,373 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 17:17:38,397 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-328b12b9-265d-4f0d-b7da-a6f2173542ea
2016-12-14 17:17:38,424 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 17:17:38,533 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 17:17:38,807 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 17:17:38,893 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 17:17:38,894 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 17:17:38,898 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 17:17:38,945 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:56677/jars/mysql-connector-java-5.1.25.jar with timestamp 1481707058944
2016-12-14 17:17:38,945 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:56677/jars/ojdbc6.jar with timestamp 1481707058945
2016-12-14 17:17:38,946 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:56677/jars/orai18n.jar with timestamp 1481707058946
2016-12-14 17:17:38,946 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:56677/jars/machine_learning_2.10-1.0.jar with timestamp 1481707058946
2016-12-14 17:17:39,059 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 17:17:39,094 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50986.
2016-12-14 17:17:39,095 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 50986
2016-12-14 17:17:39,100 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 17:17:39,101 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 17:17:39,106 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:50986 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50986)
2016-12-14 17:17:39,110 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 17:17:40,483 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481707059008
2016-12-14 17:17:40,517 INFO  com.datageek.test.K_means$ - main: #####################path = 
2016-12-14 17:17:40,518 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 17:17:40,518 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 17:17:40,518 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 17:17:40,518 INFO  com.datageek.test.K_means$ - main: #####################sql = select
2016-12-14 17:17:40,518 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 17:17:40,518 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 17:17:40,518 INFO  com.datageek.test.K_means$ - main: #####################dimensionReduction = false
2016-12-14 17:17:42,007 INFO  org.apache.spark.sql.hive.HiveContext - logInfo: Initializing execution hive, version 1.1.0
2016-12-14 17:17:42,113 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Inspected Hadoop version: 2.6.0-cdh5.7.2
2016-12-14 17:17:42,114 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0-cdh5.7.2
2016-12-14 17:17:42,636 INFO  hive.metastore - open: Trying to connect to metastore with URI thrift://hadoop101.dategeek.com.cn:9083
2016-12-14 17:17:42,679 INFO  hive.metastore - open: Opened a connection to metastore, current connections: 1
2016-12-14 17:17:42,728 INFO  hive.metastore - open: Connected to metastore.
2016-12-14 17:17:42,891 INFO  hive.ql.metadata.Hive - reloadFunctions: Registering function changetime ingeekdata.hiveudf.HiveUDF
2016-12-14 17:17:43,725 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-50f4c4f3-f54c-481a-b0b3-7571bed1a507/scratch/root
2016-12-14 17:17:43,727 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/5a4c69cb-5a01-4963-8285-6e46d5201dc9_resources
2016-12-14 17:17:43,728 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-50f4c4f3-f54c-481a-b0b3-7571bed1a507/scratch/root/5a4c69cb-5a01-4963-8285-6e46d5201dc9
2016-12-14 17:17:43,729 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/root/5a4c69cb-5a01-4963-8285-6e46d5201dc9
2016-12-14 17:17:43,730 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-50f4c4f3-f54c-481a-b0b3-7571bed1a507/scratch/root/5a4c69cb-5a01-4963-8285-6e46d5201dc9/_tmp_space.db
2016-12-14 17:17:43,740 INFO  org.apache.hadoop.hive.ql.session.SessionState - start: No Tez session required at this point. hive.execution.engine=mr.
2016-12-14 17:17:45,061 INFO  org.apache.spark.SparkContext - logInfo: Invoking stop() from shutdown hook
2016-12-14 17:17:45,150 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
2016-12-14 17:17:45,151 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
2016-12-14 17:17:45,152 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
2016-12-14 17:17:45,153 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
2016-12-14 17:17:45,153 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL,null}
2016-12-14 17:17:45,154 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 17:17:45,154 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 17:17:45,155 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 17:17:45,155 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 17:17:45,156 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 17:17:45,156 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 17:17:45,157 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 17:17:45,157 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 17:17:45,158 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 17:17:45,159 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 17:17:45,159 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 17:17:45,160 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 17:17:45,160 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 17:17:45,161 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 17:17:45,161 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 17:17:45,161 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 17:17:45,162 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 17:17:45,162 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 17:17:45,163 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 17:17:45,163 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 17:17:45,164 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 17:17:45,164 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 17:17:45,165 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 17:17:45,165 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 17:17:45,165 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 17:17:45,221 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 17:17:45,310 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 17:17:45,323 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 17:17:45,323 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 17:17:45,330 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 17:17:45,338 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 17:17:45,346 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 17:17:45,347 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 17:17:45,347 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 17:17:45,348 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-50f4c4f3-f54c-481a-b0b3-7571bed1a507
2016-12-14 17:17:45,350 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-4064a59e-1078-4983-9df2-97c86d970d4f
2016-12-14 17:17:45,353 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 17:17:45,385 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 17:17:45,386 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 17:19:52,856 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 17:19:53,979 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 17:19:53,984 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 17:19:53,985 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 17:19:54,368 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 30415.
2016-12-14 17:19:54,946 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 17:19:55,024 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 17:19:55,263 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:19530]
2016-12-14 17:19:55,266 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:19530]
2016-12-14 17:19:55,277 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 19530.
2016-12-14 17:19:55,307 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 17:19:55,337 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 17:19:55,362 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-70fd188a-a8b6-4fea-b1ab-edd7885786b8
2016-12-14 17:19:55,389 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 17:19:55,488 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 17:19:55,738 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 17:19:55,791 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 17:19:55,792 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 17:19:55,795 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 17:19:55,827 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:30415/jars/mysql-connector-java-5.1.25.jar with timestamp 1481707195827
2016-12-14 17:19:55,828 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:30415/jars/ojdbc6.jar with timestamp 1481707195828
2016-12-14 17:19:55,828 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:30415/jars/orai18n.jar with timestamp 1481707195828
2016-12-14 17:19:55,829 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:30415/jars/machine_learning_2.10-1.0.jar with timestamp 1481707195828
2016-12-14 17:19:55,896 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 17:19:55,918 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 3359.
2016-12-14 17:19:55,919 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 3359
2016-12-14 17:19:55,921 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 17:19:55,922 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 17:19:55,926 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:3359 with 530.0 MB RAM, BlockManagerId(driver, localhost, 3359)
2016-12-14 17:19:55,928 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 17:19:57,299 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481707195866
2016-12-14 17:19:57,358 INFO  com.datageek.test.K_means$ - main: #####################path = 
2016-12-14 17:19:57,359 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 17:19:57,359 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 17:19:57,359 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 17:19:57,360 INFO  com.datageek.test.K_means$ - main: #####################sql = select cluster_no, sepal_length, sepal_width, petal_length, petal_width from jiangyin.iris
2016-12-14 17:19:57,360 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 17:19:57,360 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 17:19:57,360 INFO  com.datageek.test.K_means$ - main: #####################dimensionReduction = false
2016-12-14 17:19:58,685 INFO  org.apache.spark.sql.hive.HiveContext - logInfo: Initializing execution hive, version 1.1.0
2016-12-14 17:19:58,784 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Inspected Hadoop version: 2.6.0-cdh5.7.2
2016-12-14 17:19:58,785 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0-cdh5.7.2
2016-12-14 17:19:59,234 INFO  hive.metastore - open: Trying to connect to metastore with URI thrift://hadoop101.dategeek.com.cn:9083
2016-12-14 17:19:59,277 INFO  hive.metastore - open: Opened a connection to metastore, current connections: 1
2016-12-14 17:19:59,315 INFO  hive.metastore - open: Connected to metastore.
2016-12-14 17:19:59,404 INFO  hive.ql.metadata.Hive - reloadFunctions: Registering function changetime ingeekdata.hiveudf.HiveUDF
2016-12-14 17:20:00,262 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-7a728db0-bdbb-4f88-af5b-02d9c7b5267d/scratch/root
2016-12-14 17:20:00,264 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/37bad69a-abea-49e6-a4c6-c6b99543069b_resources
2016-12-14 17:20:00,264 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-7a728db0-bdbb-4f88-af5b-02d9c7b5267d/scratch/root/37bad69a-abea-49e6-a4c6-c6b99543069b
2016-12-14 17:20:00,265 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/root/37bad69a-abea-49e6-a4c6-c6b99543069b
2016-12-14 17:20:00,266 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-7a728db0-bdbb-4f88-af5b-02d9c7b5267d/scratch/root/37bad69a-abea-49e6-a4c6-c6b99543069b/_tmp_space.db
2016-12-14 17:20:00,271 INFO  org.apache.hadoop.hive.ql.session.SessionState - start: No Tez session required at this point. hive.execution.engine=mr.
2016-12-14 17:20:01,801 INFO  org.apache.spark.sql.hive.HiveContext - logInfo: default warehouse location is /user/hive/warehouse
2016-12-14 17:20:01,814 INFO  org.apache.spark.sql.hive.HiveContext - logInfo: Initializing metastore client version 1.1.0 using Spark classes.
2016-12-14 17:20:01,842 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Inspected Hadoop version: 2.6.0-cdh5.7.2
2016-12-14 17:20:01,890 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0-cdh5.7.2
2016-12-14 17:20:02,819 INFO  hive.metastore - open: Trying to connect to metastore with URI thrift://hadoop101.dategeek.com.cn:9083
2016-12-14 17:20:02,857 INFO  hive.metastore - open: Opened a connection to metastore, current connections: 1
2016-12-14 17:20:02,879 INFO  hive.metastore - open: Connected to metastore.
2016-12-14 17:20:03,047 INFO  hive.ql.metadata.Hive - reloadFunctions: Registering function changetime ingeekdata.hiveudf.HiveUDF
2016-12-14 17:20:03,796 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/f7de48bf-1f73-4f7e-bfed-3884109cd5a3_resources
2016-12-14 17:20:03,832 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: /tmp/hive/root/f7de48bf-1f73-4f7e-bfed-3884109cd5a3
2016-12-14 17:20:03,835 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/root/f7de48bf-1f73-4f7e-bfed-3884109cd5a3
2016-12-14 17:20:03,845 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: /tmp/hive/root/f7de48bf-1f73-4f7e-bfed-3884109cd5a3/_tmp_space.db
2016-12-14 17:20:03,858 INFO  org.apache.hadoop.hive.ql.session.SessionState - start: No Tez session required at this point. hive.execution.engine=mr.
2016-12-14 17:20:05,023 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 634.9 KB, free 634.9 KB)
2016-12-14 17:20:05,531 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 46.1 KB, free 681.0 KB)
2016-12-14 17:20:05,536 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:3359 (size: 46.1 KB, free: 530.0 MB)
2016-12-14 17:20:05,544 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from rdd at K_means.scala:101
2016-12-14 17:20:05,989 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 17:20:06,080 INFO  org.apache.hadoop.hive.ql.log.PerfLogger - PerfLogBegin: <PERFLOG method=OrcGetSplits from=org.apache.hadoop.hive.ql.io.orc.ReaderImpl>
2016-12-14 17:20:06,085 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
2016-12-14 17:20:06,134 INFO  org.apache.hadoop.hive.ql.io.orc.OrcInputFormat - generateSplitsInfo: FooterCacheHitRatio: 0/1
2016-12-14 17:20:06,135 INFO  org.apache.hadoop.hive.ql.log.PerfLogger - PerfLogEnd: </PERFLOG method=OrcGetSplits start=1481707206080 end=1481707206135 duration=55 from=org.apache.hadoop.hive.ql.io.orc.ReaderImpl>
2016-12-14 17:20:06,144 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 17:20:06,169 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (takeSample at KMeans.scala:378) with 1 output partitions
2016-12-14 17:20:06,170 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (takeSample at KMeans.scala:378)
2016-12-14 17:20:06,171 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:20:06,179 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:20:06,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[9] at map at KMeans.scala:210), which has no missing parents
2016-12-14 17:20:06,268 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 8.5 KB, free 689.5 KB)
2016-12-14 17:20:06,288 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 694.0 KB)
2016-12-14 17:20:06,289 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:3359 (size: 4.5 KB, free: 530.0 MB)
2016-12-14 17:20:06,290 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:20:06,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at map at KMeans.scala:210)
2016-12-14 17:20:06,297 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 1 tasks
2016-12-14 17:20:06,372 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,ANY, 2609 bytes)
2016-12-14 17:20:06,385 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 17:20:06,398 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:30415/jars/orai18n.jar with timestamp 1481707195828
2016-12-14 17:20:06,403 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 17:20:06,489 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:30415/jars/orai18n.jar to /tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/fetchFileTemp5511845530826748613.tmp
2016-12-14 17:20:06,589 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/orai18n.jar to class loader
2016-12-14 17:20:06,590 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:30415/jars/mysql-connector-java-5.1.25.jar with timestamp 1481707195827
2016-12-14 17:20:06,591 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:30415/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/fetchFileTemp5570130384582490441.tmp
2016-12-14 17:20:06,606 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 17:20:06,607 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:30415/jars/machine_learning_2.10-1.0.jar with timestamp 1481707195828
2016-12-14 17:20:06,608 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:30415/jars/machine_learning_2.10-1.0.jar to /tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/fetchFileTemp169056415265413620.tmp
2016-12-14 17:20:06,616 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/machine_learning_2.10-1.0.jar to class loader
2016-12-14 17:20:06,616 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:30415/jars/ojdbc6.jar with timestamp 1481707195828
2016-12-14 17:20:06,617 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:30415/jars/ojdbc6.jar to /tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/fetchFileTemp9222999298675768512.tmp
2016-12-14 17:20:06,631 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47/userFiles-41620865-2c38-4bed-8db0-d7589cd0e586/ojdbc6.jar to class loader
2016-12-14 17:20:06,661 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_5_0 not found, computing it
2016-12-14 17:20:06,665 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: hdfs://nameservice1/user/hive/warehouse/jiangyin.db/iris/000000_0:0+1771
2016-12-14 17:20:06,675 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 17:20:06,675 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 17:20:06,675 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 17:20:06,676 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 17:20:06,676 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 17:20:06,769 INFO  org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger - <init>: min key = null, max key = null
2016-12-14 17:20:06,769 INFO  org.apache.hadoop.hive.ql.io.orc.ReaderImpl - rowsOptions: Reading ORC rows from hdfs://nameservice1/user/hive/warehouse/jiangyin.db/iris/000000_0 with {include: [true, true, true, true, true, true], offset: 0, length: 9223372036854775807}
2016-12-14 17:20:06,820 ERROR org.apache.spark.executor.Executor - logError: Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "1 6.6 3.0 4.4 1.4"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:232)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:31)
	at com.datageek.test.K_means$$anonfun$1.apply(K_means.scala:111)
	at com.datageek.test.K_means$$anonfun$1.apply(K_means.scala:109)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-12-14 17:20:06,861 WARN  org.apache.spark.scheduler.TaskSetManager - logWarning: Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.NumberFormatException: For input string: "1 6.6 3.0 4.4 1.4"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:232)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:31)
	at com.datageek.test.K_means$$anonfun$1.apply(K_means.scala:111)
	at com.datageek.test.K_means$$anonfun$1.apply(K_means.scala:109)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-12-14 17:20:06,866 ERROR org.apache.spark.scheduler.TaskSetManager - logError: Task 0 in stage 0.0 failed 1 times; aborting job
2016-12-14 17:20:06,869 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 17:20:06,875 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Cancelling stage 0
2016-12-14 17:20:06,878 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (takeSample at KMeans.scala:378) failed in 0.559 s
2016-12-14 17:20:06,880 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 failed: takeSample at KMeans.scala:378, took 0.736316 s
2016-12-14 17:20:06,901 INFO  org.apache.spark.SparkContext - logInfo: Invoking stop() from shutdown hook
2016-12-14 17:20:06,998 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
2016-12-14 17:20:06,999 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
2016-12-14 17:20:06,999 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
2016-12-14 17:20:07,000 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
2016-12-14 17:20:07,001 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL,null}
2016-12-14 17:20:07,001 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 17:20:07,002 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 17:20:07,002 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 17:20:07,002 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 17:20:07,003 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 17:20:07,003 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 17:20:07,003 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 17:20:07,004 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 17:20:07,004 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 17:20:07,004 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 17:20:07,005 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 17:20:07,005 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 17:20:07,005 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 17:20:07,005 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 17:20:07,005 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 17:20:07,006 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 17:20:07,006 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 17:20:07,006 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 17:20:07,006 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 17:20:07,007 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 17:20:07,007 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 17:20:07,008 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 17:20:07,008 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 17:20:07,008 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 17:20:07,009 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 17:20:07,065 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 17:20:07,143 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 17:20:07,181 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 17:20:07,183 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 17:20:07,184 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 17:20:07,189 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 17:20:07,200 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 17:20:07,200 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 17:20:07,201 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 17:20:07,203 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-7e21ca61-ab3f-4b95-b001-57587e3e5b47
2016-12-14 17:20:07,204 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-7a728db0-bdbb-4f88-af5b-02d9c7b5267d
2016-12-14 17:20:07,207 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 17:20:07,254 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 17:20:07,255 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 17:26:30,646 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 17:26:31,758 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 17:26:31,764 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 17:26:31,765 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 17:26:32,168 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 35090.
2016-12-14 17:26:32,760 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 17:26:32,833 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 17:26:33,075 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:25891]
2016-12-14 17:26:33,078 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:25891]
2016-12-14 17:26:33,090 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 25891.
2016-12-14 17:26:33,122 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 17:26:33,152 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 17:26:33,176 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-02c04e2d-075f-47d1-8c8b-d20319223454
2016-12-14 17:26:33,203 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 17:26:33,304 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 17:26:33,537 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 17:26:33,591 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 17:26:33,591 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 17:26:33,593 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 17:26:33,619 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:35090/jars/mysql-connector-java-5.1.25.jar with timestamp 1481707593618
2016-12-14 17:26:33,619 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:35090/jars/ojdbc6.jar with timestamp 1481707593619
2016-12-14 17:26:33,619 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:35090/jars/orai18n.jar with timestamp 1481707593619
2016-12-14 17:26:33,619 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:35090/jars/machine_learning_2.10-1.0.jar with timestamp 1481707593619
2016-12-14 17:26:33,675 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 17:26:33,696 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 27689.
2016-12-14 17:26:33,697 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 27689
2016-12-14 17:26:33,699 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 17:26:33,700 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 17:26:33,704 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:27689 with 530.0 MB RAM, BlockManagerId(driver, localhost, 27689)
2016-12-14 17:26:33,708 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 17:26:35,562 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481707593650
2016-12-14 17:26:35,621 INFO  com.datageek.test.K_means$ - main: #####################path = 
2016-12-14 17:26:35,621 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 17:26:35,621 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 17:26:35,622 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 17:26:35,622 INFO  com.datageek.test.K_means$ - main: #####################sql = select cluster_no, sepal_length, sepal_width, petal_length, petal_width from jiangyin.iris
2016-12-14 17:26:35,622 INFO  com.datageek.test.K_means$ - main: #####################savePath = 
2016-12-14 17:26:35,622 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 17:26:35,623 INFO  com.datageek.test.K_means$ - main: #####################dimensionReduction = false
2016-12-14 17:26:37,043 INFO  org.apache.spark.sql.hive.HiveContext - logInfo: Initializing execution hive, version 1.1.0
2016-12-14 17:26:37,149 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Inspected Hadoop version: 2.6.0-cdh5.7.2
2016-12-14 17:26:37,150 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0-cdh5.7.2
2016-12-14 17:26:37,689 INFO  hive.metastore - open: Trying to connect to metastore with URI thrift://hadoop101.dategeek.com.cn:9083
2016-12-14 17:26:37,732 INFO  hive.metastore - open: Opened a connection to metastore, current connections: 1
2016-12-14 17:26:37,769 INFO  hive.metastore - open: Connected to metastore.
2016-12-14 17:26:37,905 INFO  hive.ql.metadata.Hive - reloadFunctions: Registering function changetime ingeekdata.hiveudf.HiveUDF
2016-12-14 17:26:38,752 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-e479e051-5a61-4c56-bd6c-88e047cf59c4/scratch/root
2016-12-14 17:26:38,753 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/55854ee8-5050-4a11-8d23-d6ff7f2896aa_resources
2016-12-14 17:26:38,753 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-e479e051-5a61-4c56-bd6c-88e047cf59c4/scratch/root/55854ee8-5050-4a11-8d23-d6ff7f2896aa
2016-12-14 17:26:38,754 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/root/55854ee8-5050-4a11-8d23-d6ff7f2896aa
2016-12-14 17:26:38,755 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: file:/tmp/spark-e479e051-5a61-4c56-bd6c-88e047cf59c4/scratch/root/55854ee8-5050-4a11-8d23-d6ff7f2896aa/_tmp_space.db
2016-12-14 17:26:38,760 INFO  org.apache.hadoop.hive.ql.session.SessionState - start: No Tez session required at this point. hive.execution.engine=mr.
2016-12-14 17:26:39,618 INFO  org.apache.spark.sql.hive.HiveContext - logInfo: default warehouse location is /user/hive/warehouse
2016-12-14 17:26:39,626 INFO  org.apache.spark.sql.hive.HiveContext - logInfo: Initializing metastore client version 1.1.0 using Spark classes.
2016-12-14 17:26:39,640 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Inspected Hadoop version: 2.6.0-cdh5.7.2
2016-12-14 17:26:39,671 INFO  org.apache.spark.sql.hive.client.ClientWrapper - logInfo: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0-cdh5.7.2
2016-12-14 17:26:40,163 INFO  hive.metastore - open: Trying to connect to metastore with URI thrift://hadoop101.dategeek.com.cn:9083
2016-12-14 17:26:40,181 INFO  hive.metastore - open: Opened a connection to metastore, current connections: 1
2016-12-14 17:26:40,206 INFO  hive.metastore - open: Connected to metastore.
2016-12-14 17:26:40,371 INFO  hive.ql.metadata.Hive - reloadFunctions: Registering function changetime ingeekdata.hiveudf.HiveUDF
2016-12-14 17:26:41,092 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/a645a5bf-da47-479d-ba11-c5e7dc39183d_resources
2016-12-14 17:26:41,123 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: /tmp/hive/root/a645a5bf-da47-479d-ba11-c5e7dc39183d
2016-12-14 17:26:41,125 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created local directory: /tmp/root/a645a5bf-da47-479d-ba11-c5e7dc39183d
2016-12-14 17:26:41,143 INFO  org.apache.hadoop.hive.ql.session.SessionState - createPath: Created HDFS directory: /tmp/hive/root/a645a5bf-da47-479d-ba11-c5e7dc39183d/_tmp_space.db
2016-12-14 17:26:41,154 INFO  org.apache.hadoop.hive.ql.session.SessionState - start: No Tez session required at this point. hive.execution.engine=mr.
2016-12-14 17:26:42,311 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 634.9 KB, free 634.9 KB)
2016-12-14 17:26:42,795 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 46.1 KB, free 681.0 KB)
2016-12-14 17:26:42,800 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:27689 (size: 46.1 KB, free: 530.0 MB)
2016-12-14 17:26:42,806 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from rdd at K_means.scala:101
2016-12-14 17:26:43,247 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 17:26:43,329 INFO  org.apache.hadoop.hive.ql.log.PerfLogger - PerfLogBegin: <PERFLOG method=OrcGetSplits from=org.apache.hadoop.hive.ql.io.orc.ReaderImpl>
2016-12-14 17:26:43,333 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
2016-12-14 17:26:43,385 INFO  org.apache.hadoop.hive.ql.io.orc.OrcInputFormat - generateSplitsInfo: FooterCacheHitRatio: 0/1
2016-12-14 17:26:43,386 INFO  org.apache.hadoop.hive.ql.log.PerfLogger - PerfLogEnd: </PERFLOG method=OrcGetSplits start=1481707603329 end=1481707603386 duration=57 from=org.apache.hadoop.hive.ql.io.orc.ReaderImpl>
2016-12-14 17:26:43,404 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 17:26:43,433 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (takeSample at KMeans.scala:378) with 1 output partitions
2016-12-14 17:26:43,434 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (takeSample at KMeans.scala:378)
2016-12-14 17:26:43,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:43,443 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:43,456 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[9] at map at KMeans.scala:210), which has no missing parents
2016-12-14 17:26:43,498 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 8.5 KB, free 689.5 KB)
2016-12-14 17:26:43,519 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 693.9 KB)
2016-12-14 17:26:43,520 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:27689 (size: 4.4 KB, free: 530.0 MB)
2016-12-14 17:26:43,521 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:43,528 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at map at KMeans.scala:210)
2016-12-14 17:26:43,531 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 1 tasks
2016-12-14 17:26:43,607 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,ANY, 2609 bytes)
2016-12-14 17:26:43,617 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 17:26:43,629 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:35090/jars/mysql-connector-java-5.1.25.jar with timestamp 1481707593618
2016-12-14 17:26:43,633 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 17:26:43,711 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:35090/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/fetchFileTemp2311882200351492934.tmp
2016-12-14 17:26:43,782 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 17:26:43,782 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:35090/jars/ojdbc6.jar with timestamp 1481707593619
2016-12-14 17:26:43,783 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:35090/jars/ojdbc6.jar to /tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/fetchFileTemp7993855868874974465.tmp
2016-12-14 17:26:43,809 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/ojdbc6.jar to class loader
2016-12-14 17:26:43,810 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:35090/jars/orai18n.jar with timestamp 1481707593619
2016-12-14 17:26:43,811 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:35090/jars/orai18n.jar to /tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/fetchFileTemp1458017971759371671.tmp
2016-12-14 17:26:43,822 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/orai18n.jar to class loader
2016-12-14 17:26:43,823 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:35090/jars/machine_learning_2.10-1.0.jar with timestamp 1481707593619
2016-12-14 17:26:43,824 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:35090/jars/machine_learning_2.10-1.0.jar to /tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/fetchFileTemp727623494797761753.tmp
2016-12-14 17:26:43,832 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30/userFiles-132cbd81-c09c-4b92-941f-aee94cf1013f/machine_learning_2.10-1.0.jar to class loader
2016-12-14 17:26:43,872 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_5_0 not found, computing it
2016-12-14 17:26:43,878 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: hdfs://nameservice1/user/hive/warehouse/jiangyin.db/iris/000000_0:0+1771
2016-12-14 17:26:43,897 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 17:26:43,898 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 17:26:43,898 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 17:26:43,898 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 17:26:43,899 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 17:26:44,095 INFO  org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger - <init>: min key = null, max key = null
2016-12-14 17:26:44,096 INFO  org.apache.hadoop.hive.ql.io.orc.ReaderImpl - rowsOptions: Reading ORC rows from hdfs://nameservice1/user/hive/warehouse/jiangyin.db/iris/000000_0 with {include: [true, true, true, true, true, true], offset: 0, length: 9223372036854775807}
2016-12-14 17:26:44,267 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_5_0 stored as values in memory (estimated size 13.5 KB, free 707.4 KB)
2016-12-14 17:26:44,268 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_5_0 in memory on localhost:27689 (size: 13.5 KB, free: 529.9 MB)
2016-12-14 17:26:44,269 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_7_0 not found, computing it
2016-12-14 17:26:44,270 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:44,284 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_7_0 stored as values in memory (estimated size 4.1 KB, free 711.5 KB)
2016-12-14 17:26:44,285 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_7_0 in memory on localhost:27689 (size: 4.1 KB, free: 529.9 MB)
2016-12-14 17:26:44,326 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2638 bytes result sent to driver
2016-12-14 17:26:44,353 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 781 ms on localhost (1/1)
2016-12-14 17:26:44,356 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 17:26:44,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (takeSample at KMeans.scala:378) finished in 0.806 s
2016-12-14 17:26:44,370 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: takeSample at KMeans.scala:378, took 0.964926 s
2016-12-14 17:26:44,477 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 17:26:44,479 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (takeSample at KMeans.scala:378) with 1 output partitions
2016-12-14 17:26:44,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (takeSample at KMeans.scala:378)
2016-12-14 17:26:44,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:44,483 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:44,484 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (PartitionwiseSampledRDD[11] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 17:26:44,489 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 25.4 KB, free 736.9 KB)
2016-12-14 17:26:44,527 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KB, free 747.9 KB)
2016-12-14 17:26:44,530 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:27689 (size: 11.0 KB, free: 529.9 MB)
2016-12-14 17:26:44,531 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:44,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[11] at takeSample at KMeans.scala:378)
2016-12-14 17:26:44,532 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 1 tasks
2016-12-14 17:26:44,539 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2718 bytes)
2016-12-14 17:26:44,541 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 17:26:44,543 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:27689 in memory (size: 4.4 KB, free: 529.9 MB)
2016-12-14 17:26:44,549 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 17:26:44,556 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:44,556 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:44,569 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 1). 3761 bytes result sent to driver
2016-12-14 17:26:44,593 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 1) in 56 ms on localhost (1/1)
2016-12-14 17:26:44,593 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 17:26:44,593 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (takeSample at KMeans.scala:378) finished in 0.056 s
2016-12-14 17:26:44,594 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: takeSample at KMeans.scala:378, took 0.116911 s
2016-12-14 17:26:44,599 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 2000.0 B, free 737.0 KB)
2016-12-14 17:26:44,612 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 468.0 B, free 737.4 KB)
2016-12-14 17:26:44,614 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:27689 (size: 468.0 B, free: 529.9 MB)
2016-12-14 17:26:44,615 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at KMeans.scala:396
2016-12-14 17:26:44,653 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 17:26:44,655 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (aggregate at KMeans.scala:404) with 1 output partitions
2016-12-14 17:26:44,655 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (aggregate at KMeans.scala:404)
2016-12-14 17:26:44,655 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:44,656 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:44,657 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[13] at map at KMeans.scala:398), which has no missing parents
2016-12-14 17:26:44,663 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 10.0 KB, free 747.4 KB)
2016-12-14 17:26:44,672 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KB, free 752.5 KB)
2016-12-14 17:26:44,673 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:27689 (size: 5.0 KB, free: 529.9 MB)
2016-12-14 17:26:44,674 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:44,674 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at map at KMeans.scala:398)
2016-12-14 17:26:44,675 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 1 tasks
2016-12-14 17:26:44,677 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2641 bytes)
2016-12-14 17:26:44,678 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 2)
2016-12-14 17:26:44,684 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_13_0 not found, computing it
2016-12-14 17:26:44,684 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:44,684 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:44,685 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:44,685 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:44,695 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 17:26:44,696 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 17:26:44,709 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_13_0 stored as values in memory (estimated size 14.7 KB, free 767.1 KB)
2016-12-14 17:26:44,710 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_13_0 in memory on localhost:27689 (size: 14.7 KB, free: 529.9 MB)
2016-12-14 17:26:44,715 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 2). 2721 bytes result sent to driver
2016-12-14 17:26:44,722 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 2) in 46 ms on localhost (1/1)
2016-12-14 17:26:44,722 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (aggregate at KMeans.scala:404) finished in 0.046 s
2016-12-14 17:26:44,722 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 17:26:44,723 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: aggregate at KMeans.scala:404, took 0.069346 s
2016-12-14 17:26:44,726 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 10 from persistence list
2016-12-14 17:26:44,732 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 17:26:44,758 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 17:26:44,761 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (collect at KMeans.scala:436) with 1 output partitions
2016-12-14 17:26:44,761 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (collect at KMeans.scala:436)
2016-12-14 17:26:44,761 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:44,763 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:44,764 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[15] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 17:26:44,768 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 10.2 KB, free 777.3 KB)
2016-12-14 17:26:44,775 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.2 KB, free 782.5 KB)
2016-12-14 17:26:44,776 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:27689 (size: 5.2 KB, free: 529.9 MB)
2016-12-14 17:26:44,776 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:44,777 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 17:26:44,777 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 1 tasks
2016-12-14 17:26:44,780 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0,PROCESS_LOCAL, 2673 bytes)
2016-12-14 17:26:44,780 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 3)
2016-12-14 17:26:44,785 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:44,786 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:44,786 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_13_0 locally
2016-12-14 17:26:44,799 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 3). 4932 bytes result sent to driver
2016-12-14 17:26:44,814 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 3) in 36 ms on localhost (1/1)
2016-12-14 17:26:44,814 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 17:26:44,815 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (collect at KMeans.scala:436) finished in 0.036 s
2016-12-14 17:26:44,815 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: collect at KMeans.scala:436, took 0.056606 s
2016-12-14 17:26:44,818 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 5.8 KB, free 788.3 KB)
2016-12-14 17:26:44,829 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1362.0 B, free 789.7 KB)
2016-12-14 17:26:44,830 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:27689 (size: 1362.0 B, free: 529.9 MB)
2016-12-14 17:26:44,831 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at KMeans.scala:396
2016-12-14 17:26:44,853 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 17:26:44,855 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (aggregate at KMeans.scala:404) with 1 output partitions
2016-12-14 17:26:44,855 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (aggregate at KMeans.scala:404)
2016-12-14 17:26:44,855 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:44,857 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:44,858 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[17] at map at KMeans.scala:398), which has no missing parents
2016-12-14 17:26:44,864 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 10.3 KB, free 799.9 KB)
2016-12-14 17:26:44,872 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.1 KB, free 805.1 KB)
2016-12-14 17:26:44,873 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:27689 (size: 5.1 KB, free: 529.9 MB)
2016-12-14 17:26:44,874 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:44,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at map at KMeans.scala:398)
2016-12-14 17:26:44,875 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 1 tasks
2016-12-14 17:26:44,878 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2673 bytes)
2016-12-14 17:26:44,879 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 4)
2016-12-14 17:26:44,883 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_17_0 not found, computing it
2016-12-14 17:26:44,884 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:44,884 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:44,884 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_13_0 locally
2016-12-14 17:26:44,893 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_17_0 stored as values in memory (estimated size 14.7 KB, free 819.7 KB)
2016-12-14 17:26:44,894 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_17_0 in memory on localhost:27689 (size: 14.7 KB, free: 529.9 MB)
2016-12-14 17:26:44,899 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 4). 2721 bytes result sent to driver
2016-12-14 17:26:44,903 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 4) in 27 ms on localhost (1/1)
2016-12-14 17:26:44,903 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 17:26:44,903 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (aggregate at KMeans.scala:404) finished in 0.027 s
2016-12-14 17:26:44,904 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: aggregate at KMeans.scala:404, took 0.050485 s
2016-12-14 17:26:44,905 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 13 from persistence list
2016-12-14 17:26:44,908 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 13
2016-12-14 17:26:44,932 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 17:26:44,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (collect at KMeans.scala:436) with 1 output partitions
2016-12-14 17:26:44,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (collect at KMeans.scala:436)
2016-12-14 17:26:44,934 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:44,935 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:44,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (MapPartitionsRDD[19] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 17:26:44,938 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 10.4 KB, free 815.5 KB)
2016-12-14 17:26:44,944 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.3 KB, free 820.7 KB)
2016-12-14 17:26:44,945 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:27689 (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:44,946 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:44,946 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 17:26:44,946 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 1 tasks
2016-12-14 17:26:44,949 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2705 bytes)
2016-12-14 17:26:44,949 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 5)
2016-12-14 17:26:44,954 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:44,954 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:44,954 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_17_0 locally
2016-12-14 17:26:44,961 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 5). 4769 bytes result sent to driver
2016-12-14 17:26:44,974 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 5) in 27 ms on localhost (1/1)
2016-12-14 17:26:44,974 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 17:26:44,975 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 17:26:44,975 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: collect at KMeans.scala:436, took 0.043040 s
2016-12-14 17:26:44,978 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 5.6 KB, free 826.3 KB)
2016-12-14 17:26:44,984 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1337.0 B, free 827.7 KB)
2016-12-14 17:26:44,985 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:27689 (size: 1337.0 B, free: 529.9 MB)
2016-12-14 17:26:44,986 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at KMeans.scala:396
2016-12-14 17:26:45,004 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 17:26:45,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 1 output partitions
2016-12-14 17:26:45,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 17:26:45,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:45,008 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:45,008 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[21] at map at KMeans.scala:398), which has no missing parents
2016-12-14 17:26:45,012 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 10.5 KB, free 838.1 KB)
2016-12-14 17:26:45,016 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KB, free 843.3 KB)
2016-12-14 17:26:45,017 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:27689 (size: 5.2 KB, free: 529.9 MB)
2016-12-14 17:26:45,018 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,018 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at map at KMeans.scala:398)
2016-12-14 17:26:45,018 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 1 tasks
2016-12-14 17:26:45,020 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2705 bytes)
2016-12-14 17:26:45,021 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 6)
2016-12-14 17:26:45,028 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_21_0 not found, computing it
2016-12-14 17:26:45,029 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,029 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,029 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_17_0 locally
2016-12-14 17:26:45,033 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_21_0 stored as values in memory (estimated size 14.7 KB, free 858.0 KB)
2016-12-14 17:26:45,034 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_21_0 in memory on localhost:27689 (size: 14.7 KB, free: 529.9 MB)
2016-12-14 17:26:45,039 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 6). 2721 bytes result sent to driver
2016-12-14 17:26:45,046 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 6) in 27 ms on localhost (1/1)
2016-12-14 17:26:45,047 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.028 s
2016-12-14 17:26:45,047 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,048 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.042872 s
2016-12-14 17:26:45,049 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 17 from persistence list
2016-12-14 17:26:45,050 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 17
2016-12-14 17:26:45,071 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 17:26:45,073 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 1 output partitions
2016-12-14 17:26:45,074 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 17:26:45,074 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:45,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:45,076 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[23] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 17:26:45,080 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 10.6 KB, free 854.0 KB)
2016-12-14 17:26:45,084 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.3 KB, free 859.3 KB)
2016-12-14 17:26:45,085 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:27689 (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:45,086 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,086 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 17:26:45,086 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 1 tasks
2016-12-14 17:26:45,088 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0,PROCESS_LOCAL, 2737 bytes)
2016-12-14 17:26:45,089 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 7)
2016-12-14 17:26:45,095 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,095 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,095 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_21_0 locally
2016-12-14 17:26:45,104 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 7). 4370 bytes result sent to driver
2016-12-14 17:26:45,114 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 7) in 26 ms on localhost (1/1)
2016-12-14 17:26:45,114 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 17:26:45,114 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,114 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.043194 s
2016-12-14 17:26:45,117 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 4.7 KB, free 864.0 KB)
2016-12-14 17:26:45,124 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1163.0 B, free 865.2 KB)
2016-12-14 17:26:45,125 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:27689 (size: 1163.0 B, free: 529.9 MB)
2016-12-14 17:26:45,125 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at KMeans.scala:396
2016-12-14 17:26:45,145 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 17:26:45,147 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 1 output partitions
2016-12-14 17:26:45,147 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 17:26:45,147 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:45,148 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:45,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[25] at map at KMeans.scala:398), which has no missing parents
2016-12-14 17:26:45,151 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 10.7 KB, free 875.9 KB)
2016-12-14 17:26:45,156 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.3 KB, free 881.1 KB)
2016-12-14 17:26:45,156 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:27689 (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:45,157 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,157 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[25] at map at KMeans.scala:398)
2016-12-14 17:26:45,157 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 1 tasks
2016-12-14 17:26:45,159 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2737 bytes)
2016-12-14 17:26:45,159 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 8)
2016-12-14 17:26:45,163 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_25_0 not found, computing it
2016-12-14 17:26:45,163 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,163 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,163 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_21_0 locally
2016-12-14 17:26:45,167 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_25_0 stored as values in memory (estimated size 14.7 KB, free 895.8 KB)
2016-12-14 17:26:45,168 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_25_0 in memory on localhost:27689 (size: 14.7 KB, free: 529.9 MB)
2016-12-14 17:26:45,171 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 8). 2721 bytes result sent to driver
2016-12-14 17:26:45,177 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 8) in 19 ms on localhost (1/1)
2016-12-14 17:26:45,177 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.019 s
2016-12-14 17:26:45,177 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,178 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.032228 s
2016-12-14 17:26:45,178 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 21 from persistence list
2016-12-14 17:26:45,179 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 21
2016-12-14 17:26:45,196 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 17:26:45,197 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 1 output partitions
2016-12-14 17:26:45,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 17:26:45,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:45,199 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:45,199 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[27] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 17:26:45,201 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 10.9 KB, free 892.0 KB)
2016-12-14 17:26:45,206 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.4 KB, free 897.4 KB)
2016-12-14 17:26:45,207 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:45,207 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[27] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 17:26:45,208 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 1 tasks
2016-12-14 17:26:45,209 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0,PROCESS_LOCAL, 2769 bytes)
2016-12-14 17:26:45,210 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 9)
2016-12-14 17:26:45,214 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,214 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,214 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_25_0 locally
2016-12-14 17:26:45,219 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 9). 4881 bytes result sent to driver
2016-12-14 17:26:45,230 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 9) in 21 ms on localhost (1/1)
2016-12-14 17:26:45,230 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.021 s
2016-12-14 17:26:45,231 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.034958 s
2016-12-14 17:26:45,234 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 5.8 KB, free 903.2 KB)
2016-12-14 17:26:45,243 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 1365.0 B, free 904.5 KB)
2016-12-14 17:26:45,243 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:27689 (size: 1365.0 B, free: 529.9 MB)
2016-12-14 17:26:45,244 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at KMeans.scala:396
2016-12-14 17:26:45,262 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 17:26:45,264 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 1 output partitions
2016-12-14 17:26:45,264 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 17:26:45,264 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:45,266 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:45,266 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[29] at map at KMeans.scala:398), which has no missing parents
2016-12-14 17:26:45,268 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 10.9 KB, free 915.5 KB)
2016-12-14 17:26:45,273 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.3 KB, free 920.8 KB)
2016-12-14 17:26:45,274 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:27689 (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:45,274 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,274 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[29] at map at KMeans.scala:398)
2016-12-14 17:26:45,275 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 1 tasks
2016-12-14 17:26:45,276 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2769 bytes)
2016-12-14 17:26:45,276 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 10)
2016-12-14 17:26:45,280 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_29_0 not found, computing it
2016-12-14 17:26:45,280 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,280 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,280 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_25_0 locally
2016-12-14 17:26:45,283 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_29_0 stored as values in memory (estimated size 14.7 KB, free 935.5 KB)
2016-12-14 17:26:45,284 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_29_0 in memory on localhost:27689 (size: 14.7 KB, free: 529.9 MB)
2016-12-14 17:26:45,287 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 10). 2721 bytes result sent to driver
2016-12-14 17:26:45,293 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 10) in 18 ms on localhost (1/1)
2016-12-14 17:26:45,293 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.018 s
2016-12-14 17:26:45,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.031441 s
2016-12-14 17:26:45,295 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 25 from persistence list
2016-12-14 17:26:45,295 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 25
2016-12-14 17:26:45,311 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 17:26:45,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 1 output partitions
2016-12-14 17:26:45,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 17:26:45,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:45,313 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:45,313 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[31] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 17:26:45,315 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 11.1 KB, free 931.9 KB)
2016-12-14 17:26:45,319 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KB, free 937.3 KB)
2016-12-14 17:26:45,320 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:45,321 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,321 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[31] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 17:26:45,321 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 1 tasks
2016-12-14 17:26:45,322 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0,PROCESS_LOCAL, 2801 bytes)
2016-12-14 17:26:45,323 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 11)
2016-12-14 17:26:45,328 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,328 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,328 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_29_0 locally
2016-12-14 17:26:45,335 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 11). 5048 bytes result sent to driver
2016-12-14 17:26:45,342 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 11) in 19 ms on localhost (1/1)
2016-12-14 17:26:45,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.021 s
2016-12-14 17:26:45,342 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.031307 s
2016-12-14 17:26:45,343 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 29 from persistence list
2016-12-14 17:26:45,344 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 29
2016-12-14 17:26:45,345 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 25.8 KB, free 948.5 KB)
2016-12-14 17:26:45,353 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 952.2 KB)
2016-12-14 17:26:45,354 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:27689 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 17:26:45,355 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at KMeans.scala:450
2016-12-14 17:26:45,405 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 17:26:45,416 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 32 (flatMap at KMeans.scala:451)
2016-12-14 17:26:45,416 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (collectAsMap at KMeans.scala:455) with 1 output partitions
2016-12-14 17:26:45,416 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collectAsMap at KMeans.scala:455)
2016-12-14 17:26:45,417 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 12)
2016-12-14 17:26:45,417 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 12)
2016-12-14 17:26:45,419 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 12 (MapPartitionsRDD[32] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 17:26:45,424 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 10.1 KB, free 962.3 KB)
2016-12-14 17:26:45,439 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 17:26:45,440 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:27689 in memory (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:45,441 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 17:26:45,441 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:27689 in memory (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:45,442 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 17:26:45,442 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.2 KB, free 935.0 KB)
2016-12-14 17:26:45,443 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:27689 (size: 5.2 KB, free: 529.9 MB)
2016-12-14 17:26:45,443 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:27689 in memory (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:45,443 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,443 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 17:26:45,444 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:27689 in memory (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:45,445 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 17:26:45,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[32] at flatMap at KMeans.scala:451)
2016-12-14 17:26:45,445 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 1 tasks
2016-12-14 17:26:45,446 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:27689 in memory (size: 5.2 KB, free: 529.9 MB)
2016-12-14 17:26:45,446 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 17:26:45,447 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:27689 in memory (size: 5.3 KB, free: 529.9 MB)
2016-12-14 17:26:45,447 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 17:26:45,448 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:45,448 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 12)
2016-12-14 17:26:45,448 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:27689 in memory (size: 5.1 KB, free: 529.9 MB)
2016-12-14 17:26:45,449 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 17:26:45,449 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:27689 in memory (size: 5.2 KB, free: 529.9 MB)
2016-12-14 17:26:45,450 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 17:26:45,451 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:27689 in memory (size: 5.0 KB, free: 529.9 MB)
2016-12-14 17:26:45,451 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 17:26:45,452 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:27689 in memory (size: 11.0 KB, free: 529.9 MB)
2016-12-14 17:26:45,452 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 17:26:45,453 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:27689 in memory (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:45,456 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,457 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,605 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 12). 2236 bytes result sent to driver
2016-12-14 17:26:45,616 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 12) in 170 ms on localhost (1/1)
2016-12-14 17:26:45,616 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,617 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 12 (flatMap at KMeans.scala:451) finished in 0.171 s
2016-12-14 17:26:45,618 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:45,618 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:45,619 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 13)
2016-12-14 17:26:45,619 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:45,621 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (ShuffledRDD[33] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 17:26:45,624 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 2.6 KB, free 775.4 KB)
2016-12-14 17:26:45,627 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1554.0 B, free 777.0 KB)
2016-12-14 17:26:45,628 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:27689 (size: 1554.0 B, free: 529.9 MB)
2016-12-14 17:26:45,629 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[33] at reduceByKey at KMeans.scala:455)
2016-12-14 17:26:45,629 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 1 tasks
2016-12-14 17:26:45,632 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:45,632 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 13)
2016-12-14 17:26:45,651 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:45,653 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 7 ms
2016-12-14 17:26:45,731 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 13). 7518 bytes result sent to driver
2016-12-14 17:26:45,742 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 13) in 111 ms on localhost (1/1)
2016-12-14 17:26:45,742 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collectAsMap at KMeans.scala:455) finished in 0.113 s
2016-12-14 17:26:45,742 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,743 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: collectAsMap at KMeans.scala:455, took 0.337422 s
2016-12-14 17:26:45,861 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 17:26:45,861 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 17:26:45,861 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 17:26:45,861 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 17:26:45,861 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 17:26:45,861 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 17:26:45,862 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 17:26:45,863 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 17:26:45,862 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 17:26:45,862 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 17:26:45,886 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 2.618 seconds.
2016-12-14 17:26:45,890 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 3.0 KB, free 779.9 KB)
2016-12-14 17:26:45,897 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1367.0 B, free 781.3 KB)
2016-12-14 17:26:45,898 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:27689 (size: 1367.0 B, free: 529.9 MB)
2016-12-14 17:26:45,899 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at KMeans.scala:276
2016-12-14 17:26:45,921 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:45,922 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 34 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:45,922 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:45,922 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:45,922 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 14)
2016-12-14 17:26:45,922 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 14)
2016-12-14 17:26:45,924 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 14 (MapPartitionsRDD[34] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:45,925 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 10.8 KB, free 792.1 KB)
2016-12-14 17:26:45,931 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.5 KB, free 797.5 KB)
2016-12-14 17:26:45,931 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:27689 (size: 5.5 KB, free: 529.9 MB)
2016-12-14 17:26:45,932 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[34] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:45,933 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 1 tasks
2016-12-14 17:26:45,935 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:45,935 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 14)
2016-12-14 17:26:45,941 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:45,941 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:45,959 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 14). 2515 bytes result sent to driver
2016-12-14 17:26:45,966 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 14) in 32 ms on localhost (1/1)
2016-12-14 17:26:45,967 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 14 (mapPartitions at KMeans.scala:279) finished in 0.032 s
2016-12-14 17:26:45,967 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 17:26:45,967 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:45,967 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:45,967 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 15)
2016-12-14 17:26:45,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:45,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (ShuffledRDD[35] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:45,970 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 2.9 KB, free 800.4 KB)
2016-12-14 17:26:45,974 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1665.0 B, free 802.0 KB)
2016-12-14 17:26:45,975 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:27689 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:45,975 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:45,975 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 15 (ShuffledRDD[35] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:45,975 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 1 tasks
2016-12-14 17:26:45,976 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:45,977 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 15)
2016-12-14 17:26:45,978 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:45,979 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 17:26:45,993 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 15). 2764 bytes result sent to driver
2016-12-14 17:26:46,001 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 15) in 24 ms on localhost (1/1)
2016-12-14 17:26:46,001 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collectAsMap at KMeans.scala:302) finished in 0.025 s
2016-12-14 17:26:46,001 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,001 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collectAsMap at KMeans.scala:302, took 0.080267 s
2016-12-14 17:26:46,005 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 3.0 KB, free 805.0 KB)
2016-12-14 17:26:46,009 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 935.0 B, free 805.9 KB)
2016-12-14 17:26:46,009 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:27689 (size: 935.0 B, free: 529.9 MB)
2016-12-14 17:26:46,010 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,019 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 36 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 17:26:46,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 17:26:46,021 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,022 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 10.8 KB, free 816.7 KB)
2016-12-14 17:26:46,026 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.5 KB, free 822.2 KB)
2016-12-14 17:26:46,026 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:27689 (size: 5.5 KB, free: 529.9 MB)
2016-12-14 17:26:46,026 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,027 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,027 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 1 tasks
2016-12-14 17:26:46,028 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,028 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 16)
2016-12-14 17:26:46,034 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,034 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,048 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 16). 2515 bytes result sent to driver
2016-12-14 17:26:46,052 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 16) in 24 ms on localhost (1/1)
2016-12-14 17:26:46,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (mapPartitions at KMeans.scala:279) finished in 0.025 s
2016-12-14 17:26:46,052 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 17:26:46,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,054 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 2.9 KB, free 825.1 KB)
2016-12-14 17:26:46,059 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1666.0 B, free 826.7 KB)
2016-12-14 17:26:46,060 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:27689 (size: 1666.0 B, free: 529.9 MB)
2016-12-14 17:26:46,061 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 17 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,061 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 1 tasks
2016-12-14 17:26:46,063 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 17, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,063 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 17)
2016-12-14 17:26:46,066 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,066 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:46,082 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 17). 2764 bytes result sent to driver
2016-12-14 17:26:46,086 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 17) in 24 ms on localhost (1/1)
2016-12-14 17:26:46,086 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:302) finished in 0.024 s
2016-12-14 17:26:46,087 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,088 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: collectAsMap at KMeans.scala:302, took 0.067916 s
2016-12-14 17:26:46,089 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 2 iterations
2016-12-14 17:26:46,089 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 2 iterations
2016-12-14 17:26:46,089 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 2 iterations
2016-12-14 17:26:46,090 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 2.1 KB, free 828.8 KB)
2016-12-14 17:26:46,094 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 847.0 B, free 829.6 KB)
2016-12-14 17:26:46,095 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:27689 (size: 847.0 B, free: 529.9 MB)
2016-12-14 17:26:46,095 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,105 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,106 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 38 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,106 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 17:26:46,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 17:26:46,108 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,109 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 10.7 KB, free 840.3 KB)
2016-12-14 17:26:46,112 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.4 KB, free 845.7 KB)
2016-12-14 17:26:46,113 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,114 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,114 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,114 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 1 tasks
2016-12-14 17:26:46,116 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,117 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 18)
2016-12-14 17:26:46,126 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,126 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,139 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 18). 2443 bytes result sent to driver
2016-12-14 17:26:46,143 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 18) in 29 ms on localhost (1/1)
2016-12-14 17:26:46,143 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.029 s
2016-12-14 17:26:46,143 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,143 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 17:26:46,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,145 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 2.9 KB, free 848.6 KB)
2016-12-14 17:26:46,148 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1664.0 B, free 850.3 KB)
2016-12-14 17:26:46,149 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:27689 (size: 1664.0 B, free: 529.9 MB)
2016-12-14 17:26:46,149 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,149 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 1 tasks
2016-12-14 17:26:46,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 19, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,151 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 19)
2016-12-14 17:26:46,153 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,154 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 17:26:46,171 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 19). 2284 bytes result sent to driver
2016-12-14 17:26:46,177 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 19) in 27 ms on localhost (1/1)
2016-12-14 17:26:46,177 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.027 s
2016-12-14 17:26:46,177 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,178 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collectAsMap at KMeans.scala:302, took 0.072221 s
2016-12-14 17:26:46,180 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 2.1 KB, free 852.4 KB)
2016-12-14 17:26:46,183 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 764.0 B, free 853.1 KB)
2016-12-14 17:26:46,184 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:27689 (size: 764.0 B, free: 529.9 MB)
2016-12-14 17:26:46,185 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,193 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 40 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 17:26:46,195 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 17:26:46,195 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,197 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 10.7 KB, free 863.8 KB)
2016-12-14 17:26:46,200 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.4 KB, free 869.2 KB)
2016-12-14 17:26:46,200 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,201 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,201 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,201 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 1 tasks
2016-12-14 17:26:46,203 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,203 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 20)
2016-12-14 17:26:46,209 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,210 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,221 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 20). 2443 bytes result sent to driver
2016-12-14 17:26:46,225 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 20) in 23 ms on localhost (1/1)
2016-12-14 17:26:46,225 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.023 s
2016-12-14 17:26:46,225 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,225 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,226 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,226 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 17:26:46,226 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,226 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,227 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 2.9 KB, free 872.1 KB)
2016-12-14 17:26:46,230 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1665.0 B, free 873.8 KB)
2016-12-14 17:26:46,230 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:27689 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,231 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 21 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,231 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 1 tasks
2016-12-14 17:26:46,232 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 21, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,232 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 21)
2016-12-14 17:26:46,234 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,234 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:46,246 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 21). 2284 bytes result sent to driver
2016-12-14 17:26:46,254 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 21) in 22 ms on localhost (1/1)
2016-12-14 17:26:46,254 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.022 s
2016-12-14 17:26:46,255 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,255 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:302, took 0.061538 s
2016-12-14 17:26:46,257 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 4 iterations
2016-12-14 17:26:46,258 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 1840.0 B, free 875.6 KB)
2016-12-14 17:26:46,264 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 593.0 B, free 876.1 KB)
2016-12-14 17:26:46,265 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:27689 (size: 593.0 B, free: 529.9 MB)
2016-12-14 17:26:46,266 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,282 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,283 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 42 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,283 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,283 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,283 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 17:26:46,284 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 17:26:46,285 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,287 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 10.6 KB, free 886.8 KB)
2016-12-14 17:26:46,293 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.4 KB, free 892.2 KB)
2016-12-14 17:26:46,294 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,294 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,295 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,295 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 1 tasks
2016-12-14 17:26:46,296 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,296 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 22)
2016-12-14 17:26:46,303 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,303 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,313 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 22). 2419 bytes result sent to driver
2016-12-14 17:26:46,316 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 22) in 21 ms on localhost (1/1)
2016-12-14 17:26:46,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.021 s
2016-12-14 17:26:46,316 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,317 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 17:26:46,317 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,317 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,318 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 2.9 KB, free 895.1 KB)
2016-12-14 17:26:46,320 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1661.0 B, free 896.7 KB)
2016-12-14 17:26:46,321 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:27689 (size: 1661.0 B, free: 529.9 MB)
2016-12-14 17:26:46,321 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,321 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 23 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,321 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 1 tasks
2016-12-14 17:26:46,323 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 23, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,323 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 23)
2016-12-14 17:26:46,326 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,327 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 17:26:46,339 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 23). 2123 bytes result sent to driver
2016-12-14 17:26:46,344 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 23) in 21 ms on localhost (1/1)
2016-12-14 17:26:46,344 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.022 s
2016-12-14 17:26:46,344 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,344 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.061925 s
2016-12-14 17:26:46,345 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 5 iterations
2016-12-14 17:26:46,346 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 1544.0 B, free 898.2 KB)
2016-12-14 17:26:46,348 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 471.0 B, free 898.7 KB)
2016-12-14 17:26:46,349 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:27689 (size: 471.0 B, free: 529.9 MB)
2016-12-14 17:26:46,349 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,357 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 44 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 17:26:46,358 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 17:26:46,359 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,360 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 10.6 KB, free 909.3 KB)
2016-12-14 17:26:46,363 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.4 KB, free 914.7 KB)
2016-12-14 17:26:46,364 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,364 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,365 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,365 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 1 tasks
2016-12-14 17:26:46,366 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,367 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 24)
2016-12-14 17:26:46,373 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,373 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,384 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 24). 2395 bytes result sent to driver
2016-12-14 17:26:46,386 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 24) in 20 ms on localhost (1/1)
2016-12-14 17:26:46,386 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,386 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.020 s
2016-12-14 17:26:46,386 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,386 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,387 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 17:26:46,387 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,387 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,388 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 2.9 KB, free 917.6 KB)
2016-12-14 17:26:46,390 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1665.0 B, free 919.3 KB)
2016-12-14 17:26:46,391 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:27689 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,391 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 25 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,392 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 1 tasks
2016-12-14 17:26:46,393 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 25, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,393 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 25)
2016-12-14 17:26:46,396 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,396 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:46,408 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 25). 1963 bytes result sent to driver
2016-12-14 17:26:46,415 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 25) in 23 ms on localhost (1/1)
2016-12-14 17:26:46,415 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.023 s
2016-12-14 17:26:46,415 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,415 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.058062 s
2016-12-14 17:26:46,417 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 6 iterations
2016-12-14 17:26:46,418 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 1240.0 B, free 920.5 KB)
2016-12-14 17:26:46,423 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 377.0 B, free 920.8 KB)
2016-12-14 17:26:46,423 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:27689 (size: 377.0 B, free: 529.9 MB)
2016-12-14 17:26:46,424 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,440 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 46 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 17:26:46,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 17:26:46,446 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,447 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 10.6 KB, free 931.4 KB)
2016-12-14 17:26:46,450 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.4 KB, free 936.8 KB)
2016-12-14 17:26:46,450 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,451 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,451 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 1 tasks
2016-12-14 17:26:46,452 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 26, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,453 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 26)
2016-12-14 17:26:46,457 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,457 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,462 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 26). 2371 bytes result sent to driver
2016-12-14 17:26:46,466 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 26) in 14 ms on localhost (1/1)
2016-12-14 17:26:46,466 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 17:26:46,466 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,466 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 17:26:46,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,468 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 2.9 KB, free 939.7 KB)
2016-12-14 17:26:46,470 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1665.0 B, free 941.4 KB)
2016-12-14 17:26:46,471 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:27689 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,471 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,472 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 27 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,472 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 1 tasks
2016-12-14 17:26:46,473 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 27, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,474 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 27)
2016-12-14 17:26:46,476 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,476 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:46,488 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 27). 1804 bytes result sent to driver
2016-12-14 17:26:46,494 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 27) in 22 ms on localhost (1/1)
2016-12-14 17:26:46,494 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.022 s
2016-12-14 17:26:46,495 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,495 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.054840 s
2016-12-14 17:26:46,497 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 1240.0 B, free 942.6 KB)
2016-12-14 17:26:46,501 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 366.0 B, free 942.9 KB)
2016-12-14 17:26:46,502 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:27689 (size: 366.0 B, free: 529.9 MB)
2016-12-14 17:26:46,503 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,518 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,519 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 48 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 17:26:46,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 17:26:46,521 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,522 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 10.6 KB, free 953.5 KB)
2016-12-14 17:26:46,525 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.4 KB, free 958.9 KB)
2016-12-14 17:26:46,525 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,526 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,526 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,526 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 1 tasks
2016-12-14 17:26:46,527 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,528 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 28)
2016-12-14 17:26:46,533 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,534 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,542 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 28). 2371 bytes result sent to driver
2016-12-14 17:26:46,544 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 28) in 17 ms on localhost (1/1)
2016-12-14 17:26:46,544 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.017 s
2016-12-14 17:26:46,544 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,544 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,545 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,545 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 17:26:46,545 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,545 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,546 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 2.9 KB, free 961.8 KB)
2016-12-14 17:26:46,565 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 17:26:46,566 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1665.0 B, free 963.4 KB)
2016-12-14 17:26:46,566 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 13
2016-12-14 17:26:46,567 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:27689 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,567 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,568 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 29 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,568 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 1 tasks
2016-12-14 17:26:46,568 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 13
2016-12-14 17:26:46,569 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:27689 in memory (size: 1337.0 B, free: 529.9 MB)
2016-12-14 17:26:46,569 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 29, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,569 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 29)
2016-12-14 17:26:46,570 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:27689 in memory (size: 1554.0 B, free: 529.9 MB)
2016-12-14 17:26:46,571 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 17:26:46,572 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,572 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:46,572 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:27689 in memory (size: 5.2 KB, free: 529.9 MB)
2016-12-14 17:26:46,573 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 17:26:46,577 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 17:26:46,578 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:27689 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 17:26:46,579 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 29
2016-12-14 17:26:46,580 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 29
2016-12-14 17:26:46,581 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:27689 in memory (size: 1365.0 B, free: 529.9 MB)
2016-12-14 17:26:46,582 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 17
2016-12-14 17:26:46,583 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 29). 1804 bytes result sent to driver
2016-12-14 17:26:46,583 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 17
2016-12-14 17:26:46,583 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 17:26:46,583 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 17:26:46,583 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 17:26:46,584 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 17:26:46,584 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 17:26:46,585 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:27689 in memory (size: 1666.0 B, free: 529.9 MB)
2016-12-14 17:26:46,586 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 17:26:46,587 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:27689 in memory (size: 5.5 KB, free: 529.9 MB)
2016-12-14 17:26:46,588 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 17:26:46,588 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 17:26:46,588 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 29) in 20 ms on localhost (1/1)
2016-12-14 17:26:46,588 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 17:26:46,589 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,589 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:27689 in memory (size: 935.0 B, free: 529.9 MB)
2016-12-14 17:26:46,589 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.070400 s
2016-12-14 17:26:46,590 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 17:26:46,590 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 17:26:46,590 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 17:26:46,590 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 17:26:46,590 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 17:26:46,591 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 8 iterations
2016-12-14 17:26:46,591 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 17:26:46,591 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 8 iterations
2016-12-14 17:26:46,591 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 17:26:46,591 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 17:26:46,592 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 17:26:46,592 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 640.0 B, free 876.5 KB)
2016-12-14 17:26:46,593 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:27689 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,594 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 17:26:46,594 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:27689 in memory (size: 5.5 KB, free: 529.9 MB)
2016-12-14 17:26:46,595 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 17:26:46,595 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 17:26:46,596 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 273.0 B, free 856.0 KB)
2016-12-14 17:26:46,596 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:27689 (size: 273.0 B, free: 529.9 MB)
2016-12-14 17:26:46,597 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at KMeans.scala:276
2016-12-14 17:26:46,597 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:27689 in memory (size: 1367.0 B, free: 529.9 MB)
2016-12-14 17:26:46,597 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 17:26:46,598 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 17:26:46,598 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 17:26:46,598 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 17:26:46,598 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 17:26:46,599 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 17:26:46,599 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 17:26:46,599 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 17:26:46,599 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 17:26:46,599 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 17:26:46,599 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 17:26:46,600 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 17:26:46,600 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 17:26:46,600 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 17:26:46,600 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 17:26:46,601 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:27689 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,602 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 17:26:46,603 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:27689 in memory (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,604 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 17:26:46,605 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 17:26:46,605 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:27689 in memory (size: 764.0 B, free: 529.9 MB)
2016-12-14 17:26:46,606 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 17:26:46,606 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 17:26:46,607 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 17:26:46,607 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 17:26:46,607 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 17:26:46,607 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 17:26:46,607 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 17:26:46,608 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:27689 in memory (size: 1664.0 B, free: 529.9 MB)
2016-12-14 17:26:46,609 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 17:26:46,610 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:27689 in memory (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,610 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 17:26:46,611 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 17:26:46,611 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 17:26:46,612 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 50 (mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,612 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:27689 in memory (size: 847.0 B, free: 529.9 MB)
2016-12-14 17:26:46,612 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 1 output partitions
2016-12-14 17:26:46,612 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 17:26:46,612 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 17:26:46,612 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 17:26:46,613 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 17:26:46,613 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 17:26:46,614 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:27689 in memory (size: 1362.0 B, free: 529.9 MB)
2016-12-14 17:26:46,614 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 17:26:46,614 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 25
2016-12-14 17:26:46,615 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 25
2016-12-14 17:26:46,615 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:27689 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,616 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 10.5 KB, free 803.4 KB)
2016-12-14 17:26:46,616 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 17:26:46,616 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:27689 in memory (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,617 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 17:26:46,617 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 17:26:46,618 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:27689 in memory (size: 377.0 B, free: 529.9 MB)
2016-12-14 17:26:46,618 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 17:26:46,618 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 17:26:46,618 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 17:26:46,618 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 17:26:46,618 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.4 KB, free 791.3 KB)
2016-12-14 17:26:46,619 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:27689 (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,619 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:27689 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,619 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,619 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279)
2016-12-14 17:26:46,620 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 17:26:46,620 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 1 tasks
2016-12-14 17:26:46,620 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:27689 in memory (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,621 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2598 bytes)
2016-12-14 17:26:46,621 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 17:26:46,621 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 30)
2016-12-14 17:26:46,622 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 17:26:46,622 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:27689 in memory (size: 471.0 B, free: 529.9 MB)
2016-12-14 17:26:46,623 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 17:26:46,623 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 17:26:46,623 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 17:26:46,624 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 17:26:46,624 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 17:26:46,625 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:27689 in memory (size: 1661.0 B, free: 529.9 MB)
2016-12-14 17:26:46,625 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 17:26:46,626 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:27689 in memory (size: 5.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,627 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 17:26:46,627 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,627 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 17:26:46,627 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_7_0 locally
2016-12-14 17:26:46,628 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:27689 in memory (size: 593.0 B, free: 529.9 MB)
2016-12-14 17:26:46,629 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 17:26:46,629 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 21
2016-12-14 17:26:46,630 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 21
2016-12-14 17:26:46,631 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:27689 in memory (size: 1163.0 B, free: 529.9 MB)
2016-12-14 17:26:46,632 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:27689 in memory (size: 468.0 B, free: 529.9 MB)
2016-12-14 17:26:46,635 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 30). 2323 bytes result sent to driver
2016-12-14 17:26:46,639 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 30) in 19 ms on localhost (1/1)
2016-12-14 17:26:46,639 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.019 s
2016-12-14 17:26:46,639 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,639 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,640 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,640 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 17:26:46,640 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,641 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 17:26:46,642 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 2.9 KB, free 740.4 KB)
2016-12-14 17:26:46,646 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1665.0 B, free 742.0 KB)
2016-12-14 17:26:46,647 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:27689 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 17:26:46,648 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,648 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 31 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302)
2016-12-14 17:26:46,648 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 1 tasks
2016-12-14 17:26:46,649 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 31, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,650 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 31)
2016-12-14 17:26:46,652 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,653 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 17:26:46,663 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 31). 1486 bytes result sent to driver
2016-12-14 17:26:46,669 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 31) in 20 ms on localhost (1/1)
2016-12-14 17:26:46,669 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 17:26:46,669 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.059869 s
2016-12-14 17:26:46,672 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 9 iterations
2016-12-14 17:26:46,672 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 9 iterations
2016-12-14 17:26:46,673 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.785 seconds.
2016-12-14 17:26:46,674 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 9 iterations.
2016-12-14 17:26:46,677 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 78.94084142614625.
2016-12-14 17:26:46,679 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 7 from persistence list
2016-12-14 17:26:46,680 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 7
2016-12-14 17:26:46,680 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 17:26:46,692 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:130
2016-12-14 17:26:46,693 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (foreach at K_means.scala:130) with 1 output partitions
2016-12-14 17:26:46,693 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 32 (foreach at K_means.scala:130)
2016-12-14 17:26:46,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:46,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:46,695 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 32 (MapPartitionsRDD[6] at map at K_means.scala:120), which has no missing parents
2016-12-14 17:26:46,697 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 8.2 KB, free 746.1 KB)
2016-12-14 17:26:46,701 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 4.3 KB, free 750.4 KB)
2016-12-14 17:26:46,701 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:27689 (size: 4.3 KB, free: 529.9 MB)
2016-12-14 17:26:46,702 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,703 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[6] at map at K_means.scala:120)
2016-12-14 17:26:46,703 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 1 tasks
2016-12-14 17:26:46,704 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2435 bytes)
2016-12-14 17:26:46,705 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 32)
2016-12-14 17:26:46,709 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,710 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.6,3.0,4.4,1.4] belong to cluster 0
2016-12-14 17:26:46,711 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.5,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,711 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,2.8,4.8,1.4] belong to cluster 0
2016-12-14 17:26:46,711 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.0,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,711 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.0,5.0,1.7] belong to cluster 1
2016-12-14 17:26:46,712 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.7,3.2,1.3,0.2] belong to cluster 2
2016-12-14 17:26:46,712 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.9,4.5,1.5] belong to cluster 0
2016-12-14 17:26:46,712 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.1,1.5,0.2] belong to cluster 2
2016-12-14 17:26:46,712 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.6,3.5,1.0] belong to cluster 0
2016-12-14 17:26:46,713 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.6,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,713 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.4,3.8,1.1] belong to cluster 0
2016-12-14 17:26:46,713 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.9,1.7,0.4] belong to cluster 2
2016-12-14 17:26:46,713 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.4,3.7,1.0] belong to cluster 0
2016-12-14 17:26:46,713 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.4,1.4,0.3] belong to cluster 2
2016-12-14 17:26:46,714 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,3.9,1.2] belong to cluster 0
2016-12-14 17:26:46,714 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.4,1.5,0.2] belong to cluster 2
2016-12-14 17:26:46,714 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.7,5.1,1.6] belong to cluster 0
2016-12-14 17:26:46,714 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,2.9,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,715 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.0,4.5,1.5] belong to cluster 0
2016-12-14 17:26:46,715 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 2
2016-12-14 17:26:46,715 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,3.4,4.5,1.6] belong to cluster 0
2016-12-14 17:26:46,715 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.7,1.5,0.2] belong to cluster 2
2016-12-14 17:26:46,715 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,4.7,1.5] belong to cluster 0
2016-12-14 17:26:46,716 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.4,1.6,0.2] belong to cluster 2
2016-12-14 17:26:46,716 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.3,4.4,1.3] belong to cluster 0
2016-12-14 17:26:46,716 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.0,1.4,0.1] belong to cluster 2
2016-12-14 17:26:46,716 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,3.0,4.1,1.3] belong to cluster 0
2016-12-14 17:26:46,717 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.3,3.0,1.1,0.1] belong to cluster 2
2016-12-14 17:26:46,717 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.5,4.0,1.3] belong to cluster 0
2016-12-14 17:26:46,717 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,4.0,1.2,0.2] belong to cluster 2
2016-12-14 17:26:46,717 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.6,4.4,1.2] belong to cluster 0
2016-12-14 17:26:46,717 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,4.4,1.5,0.4] belong to cluster 2
2016-12-14 17:26:46,718 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,3.0,4.6,1.4] belong to cluster 0
2016-12-14 17:26:46,718 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.9,1.3,0.4] belong to cluster 2
2016-12-14 17:26:46,718 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.6,4.0,1.2] belong to cluster 0
2016-12-14 17:26:46,718 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.5,1.4,0.3] belong to cluster 2
2016-12-14 17:26:46,718 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,2.3,3.3,1.0] belong to cluster 0
2016-12-14 17:26:46,719 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,3.8,1.7,0.3] belong to cluster 2
2016-12-14 17:26:46,719 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.7,4.2,1.3] belong to cluster 0
2016-12-14 17:26:46,719 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.5,0.3] belong to cluster 2
2016-12-14 17:26:46,719 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,3.0,4.2,1.2] belong to cluster 0
2016-12-14 17:26:46,720 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.4,1.7,0.2] belong to cluster 2
2016-12-14 17:26:46,720 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.9,4.2,1.3] belong to cluster 0
2016-12-14 17:26:46,720 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.7,1.5,0.4] belong to cluster 2
2016-12-14 17:26:46,720 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.9,4.3,1.3] belong to cluster 0
2016-12-14 17:26:46,720 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.6,1.0,0.2] belong to cluster 2
2016-12-14 17:26:46,721 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,2.5,3.0,1.1] belong to cluster 0
2016-12-14 17:26:46,721 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.3,1.7,0.5] belong to cluster 2
2016-12-14 17:26:46,721 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.8,4.1,1.3] belong to cluster 0
2016-12-14 17:26:46,721 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.4,1.9,0.2] belong to cluster 2
2016-12-14 17:26:46,722 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.3,6.0,2.5] belong to cluster 1
2016-12-14 17:26:46,722 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.0,1.6,0.2] belong to cluster 2
2016-12-14 17:26:46,722 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,5.1,1.9] belong to cluster 0
2016-12-14 17:26:46,722 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.4,1.6,0.4] belong to cluster 2
2016-12-14 17:26:46,722 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.1,3.0,5.9,2.1] belong to cluster 1
2016-12-14 17:26:46,723 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,3.5,1.5,0.2] belong to cluster 2
2016-12-14 17:26:46,723 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.9,5.6,1.8] belong to cluster 1
2016-12-14 17:26:46,723 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,3.4,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,723 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.8,2.2] belong to cluster 1
2016-12-14 17:26:46,724 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.7,3.2,1.6,0.2] belong to cluster 2
2016-12-14 17:26:46,724 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.6,3.0,6.6,2.1] belong to cluster 1
2016-12-14 17:26:46,724 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.1,1.6,0.2] belong to cluster 2
2016-12-14 17:26:46,724 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,2.5,4.5,1.7] belong to cluster 0
2016-12-14 17:26:46,724 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.4,1.5,0.4] belong to cluster 2
2016-12-14 17:26:46,725 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.3,2.9,6.3,1.8] belong to cluster 1
2016-12-14 17:26:46,725 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,4.1,1.5,0.1] belong to cluster 2
2016-12-14 17:26:46,725 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,2.5,5.8,1.8] belong to cluster 1
2016-12-14 17:26:46,725 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,4.2,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,726 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.6,6.1,2.5] belong to cluster 1
2016-12-14 17:26:46,726 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 2
2016-12-14 17:26:46,726 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.2,5.1,2.0] belong to cluster 1
2016-12-14 17:26:46,726 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.2,1.2,0.2] belong to cluster 2
2016-12-14 17:26:46,726 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.7,5.3,1.9] belong to cluster 1
2016-12-14 17:26:46,727 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,3.5,1.3,0.2] belong to cluster 2
2016-12-14 17:26:46,727 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,3.0,5.5,2.1] belong to cluster 1
2016-12-14 17:26:46,727 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 2
2016-12-14 17:26:46,727 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.5,5.0,2.0] belong to cluster 0
2016-12-14 17:26:46,728 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,3.0,1.3,0.2] belong to cluster 2
2016-12-14 17:26:46,728 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.8,5.1,2.4] belong to cluster 0
2016-12-14 17:26:46,728 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.4,1.5,0.2] belong to cluster 2
2016-12-14 17:26:46,728 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.2,5.3,2.3] belong to cluster 1
2016-12-14 17:26:46,728 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.5,1.3,0.3] belong to cluster 2
2016-12-14 17:26:46,729 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.5,1.8] belong to cluster 1
2016-12-14 17:26:46,729 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.5,2.3,1.3,0.3] belong to cluster 2
2016-12-14 17:26:46,729 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,3.8,6.7,2.2] belong to cluster 1
2016-12-14 17:26:46,729 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,3.2,1.3,0.2] belong to cluster 2
2016-12-14 17:26:46,730 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,2.6,6.9,2.3] belong to cluster 1
2016-12-14 17:26:46,730 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.5,1.6,0.6] belong to cluster 2
2016-12-14 17:26:46,730 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.2,5.0,1.5] belong to cluster 0
2016-12-14 17:26:46,730 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.9,0.4] belong to cluster 2
2016-12-14 17:26:46,730 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.2,5.7,2.3] belong to cluster 1
2016-12-14 17:26:46,731 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.0,1.4,0.3] belong to cluster 2
2016-12-14 17:26:46,731 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.8,4.9,2.0] belong to cluster 0
2016-12-14 17:26:46,731 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.6,0.2] belong to cluster 2
2016-12-14 17:26:46,731 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,2.8,6.7,2.0] belong to cluster 1
2016-12-14 17:26:46,732 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.2,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,732 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.7,4.9,1.8] belong to cluster 0
2016-12-14 17:26:46,732 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.3,3.7,1.5,0.2] belong to cluster 2
2016-12-14 17:26:46,732 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.3,5.7,2.1] belong to cluster 1
2016-12-14 17:26:46,732 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.3,1.4,0.2] belong to cluster 2
2016-12-14 17:26:46,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.2,6.0,1.8] belong to cluster 1
2016-12-14 17:26:46,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.0,3.2,4.7,1.4] belong to cluster 0
2016-12-14 17:26:46,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.8,4.8,1.8] belong to cluster 0
2016-12-14 17:26:46,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.2,4.5,1.5] belong to cluster 0
2016-12-14 17:26:46,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,3.0,4.9,1.8] belong to cluster 0
2016-12-14 17:26:46,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,4.9,1.5] belong to cluster 1
2016-12-14 17:26:46,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.8,5.6,2.1] belong to cluster 1
2016-12-14 17:26:46,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.3,4.0,1.3] belong to cluster 0
2016-12-14 17:26:46,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.0,5.8,1.6] belong to cluster 1
2016-12-14 17:26:46,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,2.8,4.6,1.5] belong to cluster 0
2016-12-14 17:26:46,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.4,2.8,6.1,1.9] belong to cluster 1
2016-12-14 17:26:46,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.8,4.5,1.3] belong to cluster 0
2016-12-14 17:26:46,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.9,3.8,6.4,2.0] belong to cluster 1
2016-12-14 17:26:46,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.3,4.7,1.6] belong to cluster 0
2016-12-14 17:26:46,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.8,5.6,2.2] belong to cluster 1
2016-12-14 17:26:46,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,2.4,3.3,1.0] belong to cluster 0
2016-12-14 17:26:46,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.8,5.1,1.5] belong to cluster 0
2016-12-14 17:26:46,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.6,2.9,4.6,1.3] belong to cluster 0
2016-12-14 17:26:46,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.6,5.6,1.4] belong to cluster 1
2016-12-14 17:26:46,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,2.7,3.9,1.4] belong to cluster 0
2016-12-14 17:26:46,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,2.0,3.5,1.0] belong to cluster 0
2016-12-14 17:26:46,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,3.0,6.1,2.3] belong to cluster 1
2016-12-14 17:26:46,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.0,4.2,1.5] belong to cluster 0
2016-12-14 17:26:46,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.4,5.6,2.4] belong to cluster 1
2016-12-14 17:26:46,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.2,4.0,1.0] belong to cluster 0
2016-12-14 17:26:46,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.1,5.5,1.8] belong to cluster 1
2016-12-14 17:26:46,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.9,4.7,1.4] belong to cluster 0
2016-12-14 17:26:46,739 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,3.0,4.8,1.8] belong to cluster 0
2016-12-14 17:26:46,739 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.9,3.6,1.3] belong to cluster 0
2016-12-14 17:26:46,739 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,5.4,2.1] belong to cluster 1
2016-12-14 17:26:46,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,4.4,1.4] belong to cluster 0
2016-12-14 17:26:46,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,5.6,2.4] belong to cluster 1
2016-12-14 17:26:46,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,3.0,4.5,1.5] belong to cluster 0
2016-12-14 17:26:46,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,5.1,2.3] belong to cluster 1
2016-12-14 17:26:46,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,4.1,1.0] belong to cluster 0
2016-12-14 17:26:46,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,5.1,1.9] belong to cluster 0
2016-12-14 17:26:46,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.2,4.5,1.5] belong to cluster 0
2016-12-14 17:26:46,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,3.2,5.9,2.3] belong to cluster 1
2016-12-14 17:26:46,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.5,3.9,1.1] belong to cluster 0
2016-12-14 17:26:46,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.3,5.7,2.5] belong to cluster 1
2016-12-14 17:26:46,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.2,4.8,1.8] belong to cluster 0
2016-12-14 17:26:46,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.0,5.2,2.3] belong to cluster 1
2016-12-14 17:26:46,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.8,4.0,1.3] belong to cluster 0
2016-12-14 17:26:46,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.5,5.0,1.9] belong to cluster 0
2016-12-14 17:26:46,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.5,4.9,1.5] belong to cluster 0
2016-12-14 17:26:46,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.2,2.0] belong to cluster 1
2016-12-14 17:26:46,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.8,4.7,1.2] belong to cluster 0
2016-12-14 17:26:46,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,3.4,5.4,2.3] belong to cluster 1
2016-12-14 17:26:46,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.9,4.3,1.3] belong to cluster 0
2016-12-14 17:26:46,744 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.0,5.1,1.8] belong to cluster 0
2016-12-14 17:26:46,747 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 32). 2057 bytes result sent to driver
2016-12-14 17:26:46,749 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 32) in 45 ms on localhost (1/1)
2016-12-14 17:26:46,749 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 32 (foreach at K_means.scala:130) finished in 0.045 s
2016-12-14 17:26:46,749 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,749 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: foreach at K_means.scala:130, took 0.057244 s
2016-12-14 17:26:46,755 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:141
2016-12-14 17:26:46,756 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (foreach at K_means.scala:141) with 1 output partitions
2016-12-14 17:26:46,756 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (foreach at K_means.scala:141)
2016-12-14 17:26:46,756 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:46,757 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:46,757 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (MapPartitionsRDD[52] at map at K_means.scala:139), which has no missing parents
2016-12-14 17:26:46,759 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 8.1 KB, free 758.5 KB)
2016-12-14 17:26:46,763 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.4 KB, free 762.9 KB)
2016-12-14 17:26:46,764 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:27689 (size: 4.4 KB, free: 529.9 MB)
2016-12-14 17:26:46,764 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,765 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[52] at map at K_means.scala:139)
2016-12-14 17:26:46,765 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 1 tasks
2016-12-14 17:26:46,766 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 33, localhost, partition 0,PROCESS_LOCAL, 2435 bytes)
2016-12-14 17:26:46,767 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 33)
2016-12-14 17:26:46,771 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,772 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,773 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,773 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,773 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,773 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,773 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,774 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,774 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,774 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,774 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,774 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,775 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,775 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,775 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,775 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,775 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,776 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,776 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,776 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,776 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,776 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,777 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,777 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,777 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,777 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,777 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,778 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,778 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,778 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,778 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,778 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,779 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,779 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,779 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,779 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,779 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,780 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,780 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,780 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,780 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,780 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,781 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,781 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,781 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,781 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,781 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,782 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,782 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,782 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,782 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,782 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,782 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,783 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,783 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,783 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,783 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,783 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,784 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,784 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,784 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,784 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,784 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,785 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,785 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,785 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,785 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,785 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,785 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,786 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,786 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,786 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,786 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,786 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,787 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,787 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,787 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,787 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,787 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,788 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,788 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,788 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,788 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,788 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,789 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,789 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,789 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,789 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,789 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,789 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,790 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,790 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,790 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,790 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,790 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,791 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,791 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,791 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,791 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,791 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,792 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 17:26:46,792 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,792 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,792 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,792 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,792 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,793 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,793 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,793 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,793 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,793 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,794 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,794 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,794 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,794 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,794 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,795 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,795 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,795 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,795 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,795 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,796 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,796 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,796 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,796 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,796 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,796 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,797 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,797 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,797 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,797 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,798 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,798 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,798 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,798 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,798 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,798 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,799 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,799 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,799 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,799 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,799 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,800 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,800 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,800 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,800 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,800 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,800 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,801 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 17:26:46,801 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,801 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 17:26:46,804 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 33). 2057 bytes result sent to driver
2016-12-14 17:26:46,806 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 33) in 40 ms on localhost (1/1)
2016-12-14 17:26:46,806 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (foreach at K_means.scala:141) finished in 0.041 s
2016-12-14 17:26:46,806 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,807 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: foreach at K_means.scala:141, took 0.051585 s
2016-12-14 17:26:46,834 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 17:26:46,836 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 53 (map at Relabel.scala:13)
2016-12-14 17:26:46,836 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 55 (sortBy at Relabel.scala:13)
2016-12-14 17:26:46,837 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (collect at Relabel.scala:14) with 1 output partitions
2016-12-14 17:26:46,837 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 36 (collect at Relabel.scala:14)
2016-12-14 17:26:46,837 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 35)
2016-12-14 17:26:46,837 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 35)
2016-12-14 17:26:46,838 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 34 (MapPartitionsRDD[53] at map at Relabel.scala:13), which has no missing parents
2016-12-14 17:26:46,840 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 9.0 KB, free 771.9 KB)
2016-12-14 17:26:46,845 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.8 KB, free 776.6 KB)
2016-12-14 17:26:46,846 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:27689 (size: 4.8 KB, free: 529.9 MB)
2016-12-14 17:26:46,847 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[53] at map at Relabel.scala:13)
2016-12-14 17:26:46,847 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 1 tasks
2016-12-14 17:26:46,849 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 34, localhost, partition 0,PROCESS_LOCAL, 2424 bytes)
2016-12-14 17:26:46,850 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 34)
2016-12-14 17:26:46,854 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,863 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 34). 2236 bytes result sent to driver
2016-12-14 17:26:46,867 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 34) in 19 ms on localhost (1/1)
2016-12-14 17:26:46,867 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 34 (map at Relabel.scala:13) finished in 0.019 s
2016-12-14 17:26:46,867 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,867 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,868 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,868 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ShuffleMapStage 35, ResultStage 36)
2016-12-14 17:26:46,868 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,869 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 35 (MapPartitionsRDD[55] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 17:26:46,874 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 3.6 KB, free 780.2 KB)
2016-12-14 17:26:46,878 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.0 KB, free 782.2 KB)
2016-12-14 17:26:46,879 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:27689 (size: 2.0 KB, free: 529.9 MB)
2016-12-14 17:26:46,879 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,880 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[55] at sortBy at Relabel.scala:13)
2016-12-14 17:26:46,880 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 1 tasks
2016-12-14 17:26:46,881 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 35, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 17:26:46,882 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 35)
2016-12-14 17:26:46,894 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,894 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:46,909 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 35). 1302 bytes result sent to driver
2016-12-14 17:26:46,913 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 35) in 32 ms on localhost (1/1)
2016-12-14 17:26:46,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 35 (sortBy at Relabel.scala:13) finished in 0.032 s
2016-12-14 17:26:46,913 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,913 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:46,914 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:46,914 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 36)
2016-12-14 17:26:46,914 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:46,914 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 36 (MapPartitionsRDD[57] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 17:26:46,919 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 3.4 KB, free 785.6 KB)
2016-12-14 17:26:46,923 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 1942.0 B, free 787.5 KB)
2016-12-14 17:26:46,923 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:27689 (size: 1942.0 B, free: 529.9 MB)
2016-12-14 17:26:46,924 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,924 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[57] at sortBy at Relabel.scala:13)
2016-12-14 17:26:46,924 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 1 tasks
2016-12-14 17:26:46,925 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 36, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:46,926 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 36)
2016-12-14 17:26:46,934 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:46,934 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:46,957 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 36). 1211 bytes result sent to driver
2016-12-14 17:26:46,959 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 36) in 34 ms on localhost (1/1)
2016-12-14 17:26:46,959 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 17:26:46,959 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 36 (collect at Relabel.scala:14) finished in 0.034 s
2016-12-14 17:26:46,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: collect at Relabel.scala:14, took 0.125316 s
2016-12-14 17:26:46,972 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:145
2016-12-14 17:26:46,973 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (foreach at K_means.scala:145) with 1 output partitions
2016-12-14 17:26:46,973 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (foreach at K_means.scala:145)
2016-12-14 17:26:46,973 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:46,974 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:46,974 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (MapPartitionsRDD[58] at map at Relabel.scala:31), which has no missing parents
2016-12-14 17:26:46,976 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 8.5 KB, free 796.0 KB)
2016-12-14 17:26:46,980 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.5 KB, free 800.5 KB)
2016-12-14 17:26:46,981 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:27689 (size: 4.5 KB, free: 529.9 MB)
2016-12-14 17:26:46,981 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:46,981 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[58] at map at Relabel.scala:31)
2016-12-14 17:26:46,982 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 1 tasks
2016-12-14 17:26:46,983 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 37, localhost, partition 0,PROCESS_LOCAL, 2435 bytes)
2016-12-14 17:26:46,983 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 37)
2016-12-14 17:26:46,988 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:46,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,991 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:46,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,992 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,993 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,994 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,995 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,996 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,997 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,998 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:46,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:46,999 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,000 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,001 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,002 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,003 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,004 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,005 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,006 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,007 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,007 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,007 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,007 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,007 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,008 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,008 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,008 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,008 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,008 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,009 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,009 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,009 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,009 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,009 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,010 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,010 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 17:26:47,010 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,010 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,010 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,010 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,011 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,011 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,011 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,011 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,011 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,012 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,012 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,012 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,012 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,012 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,012 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,013 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,013 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,013 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,013 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,013 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,014 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,014 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,014 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,014 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,014 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,015 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,015 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,015 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,015 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,015 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,015 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,016 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,016 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,016 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,016 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,016 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,017 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,017 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,017 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,017 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,017 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,017 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,018 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,018 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,018 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,018 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,018 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,019 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 17:26:47,019 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,019 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 17:26:47,022 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 37). 2057 bytes result sent to driver
2016-12-14 17:26:47,027 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 37) in 44 ms on localhost (1/1)
2016-12-14 17:26:47,027 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (foreach at K_means.scala:145) finished in 0.045 s
2016-12-14 17:26:47,028 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 17:26:47,028 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: foreach at K_means.scala:145, took 0.056309 s
2016-12-14 17:26:47,040 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 17:26:47,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 59 (map at MulticlassMetrics.scala:46)
2016-12-14 17:26:47,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (collectAsMap at MulticlassMetrics.scala:49) with 1 output partitions
2016-12-14 17:26:47,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 17:26:47,042 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 38)
2016-12-14 17:26:47,043 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 38)
2016-12-14 17:26:47,044 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 38 (MapPartitionsRDD[59] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 17:26:47,046 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 9.4 KB, free 809.9 KB)
2016-12-14 17:26:47,050 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 5.0 KB, free 814.9 KB)
2016-12-14 17:26:47,050 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:27689 (size: 5.0 KB, free: 529.9 MB)
2016-12-14 17:26:47,051 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:47,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[59] at map at MulticlassMetrics.scala:46)
2016-12-14 17:26:47,052 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 1 tasks
2016-12-14 17:26:47,053 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 38, localhost, partition 0,PROCESS_LOCAL, 2424 bytes)
2016-12-14 17:26:47,053 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 38)
2016-12-14 17:26:47,058 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:47,069 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 38). 2236 bytes result sent to driver
2016-12-14 17:26:47,074 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 38) in 21 ms on localhost (1/1)
2016-12-14 17:26:47,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 38 (map at MulticlassMetrics.scala:46) finished in 0.022 s
2016-12-14 17:26:47,075 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 17:26:47,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:47,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:47,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 39)
2016-12-14 17:26:47,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:47,076 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (ShuffledRDD[60] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 17:26:47,078 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 2.6 KB, free 817.5 KB)
2016-12-14 17:26:47,082 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 1592.0 B, free 819.1 KB)
2016-12-14 17:26:47,083 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:27689 (size: 1592.0 B, free: 529.9 MB)
2016-12-14 17:26:47,083 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:47,084 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 39 (ShuffledRDD[60] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 17:26:47,084 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 1 tasks
2016-12-14 17:26:47,085 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 39, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:47,085 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 39)
2016-12-14 17:26:47,087 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:47,088 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 17:26:47,096 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 39). 1163 bytes result sent to driver
2016-12-14 17:26:47,101 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 39) in 16 ms on localhost (1/1)
2016-12-14 17:26:47,102 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.018 s
2016-12-14 17:26:47,102 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 17:26:47,102 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.061501 s
2016-12-14 17:26:47,115 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 17:26:47,116 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 63 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 17:26:47,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (countByValue at MulticlassMetrics.scala:43) with 1 output partitions
2016-12-14 17:26:47,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 17:26:47,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 40)
2016-12-14 17:26:47,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 40)
2016-12-14 17:26:47,118 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 40 (MapPartitionsRDD[63] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 17:26:47,121 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 10.0 KB, free 829.0 KB)
2016-12-14 17:26:47,126 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 5.2 KB, free 834.2 KB)
2016-12-14 17:26:47,126 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:27689 (size: 5.2 KB, free: 529.9 MB)
2016-12-14 17:26:47,127 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:47,127 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[63] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 17:26:47,127 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 1 tasks
2016-12-14 17:26:47,129 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 2424 bytes)
2016-12-14 17:26:47,129 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 40)
2016-12-14 17:26:47,135 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:47,145 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 40). 2236 bytes result sent to driver
2016-12-14 17:26:47,148 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 40) in 20 ms on localhost (1/1)
2016-12-14 17:26:47,148 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 17:26:47,148 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 40 (countByValue at MulticlassMetrics.scala:43) finished in 0.020 s
2016-12-14 17:26:47,148 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 17:26:47,148 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 17:26:47,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 41)
2016-12-14 17:26:47,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 17:26:47,149 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (ShuffledRDD[64] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 17:26:47,151 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 2.6 KB, free 836.8 KB)
2016-12-14 17:26:47,154 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 1560.0 B, free 838.3 KB)
2016-12-14 17:26:47,154 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:27689 (size: 1560.0 B, free: 529.9 MB)
2016-12-14 17:26:47,155 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:47,155 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 41 (ShuffledRDD[64] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 17:26:47,155 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 1 tasks
2016-12-14 17:26:47,157 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 41, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 17:26:47,158 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 41)
2016-12-14 17:26:47,160 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 1 blocks
2016-12-14 17:26:47,160 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 17:26:47,166 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 41). 1163 bytes result sent to driver
2016-12-14 17:26:47,168 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 41) in 12 ms on localhost (1/1)
2016-12-14 17:26:47,168 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 17:26:47,168 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (countByValue at MulticlassMetrics.scala:43) finished in 0.012 s
2016-12-14 17:26:47,169 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: countByValue at MulticlassMetrics.scala:43, took 0.053641 s
2016-12-14 17:26:47,170 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 1.0
2016-12-14 17:26:47,170 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 344.0 B, free 838.7 KB)
2016-12-14 17:26:47,173 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 294.0 B, free 839.0 KB)
2016-12-14 17:26:47,174 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:27689 (size: 294.0 B, free: 529.9 MB)
2016-12-14 17:26:47,174 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at KMeansModel.scala:87
2016-12-14 17:26:47,181 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 17:26:47,182 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (sum at KMeansModel.scala:88) with 1 output partitions
2016-12-14 17:26:47,182 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 42 (sum at KMeansModel.scala:88)
2016-12-14 17:26:47,182 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 17:26:47,183 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 17:26:47,183 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 42 (MapPartitionsRDD[65] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 17:26:47,184 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 8.4 KB, free 847.3 KB)
2016-12-14 17:26:47,187 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 4.5 KB, free 851.8 KB)
2016-12-14 17:26:47,188 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:27689 (size: 4.5 KB, free: 529.9 MB)
2016-12-14 17:26:47,188 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 17:26:47,188 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[65] at map at KMeansModel.scala:88)
2016-12-14 17:26:47,188 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 1 tasks
2016-12-14 17:26:47,189 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 42, localhost, partition 0,PROCESS_LOCAL, 2435 bytes)
2016-12-14 17:26:47,190 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 42)
2016-12-14 17:26:47,195 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_5_0 locally
2016-12-14 17:26:47,197 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 42). 2064 bytes result sent to driver
2016-12-14 17:26:47,200 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 42) in 11 ms on localhost (1/1)
2016-12-14 17:26:47,200 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 42 (sum at KMeansModel.scala:88) finished in 0.011 s
2016-12-14 17:26:47,201 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: sum at KMeansModel.scala:88, took 0.019588 s
2016-12-14 17:26:47,201 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 78.94084142614625
2016-12-14 17:26:47,201 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 17:26:47,201 INFO  com.datageek.test.K_means$ - main: ==(-_-)~====END====(-_-)~==
2016-12-14 17:26:47,249 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
2016-12-14 17:26:47,250 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
2016-12-14 17:26:47,250 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
2016-12-14 17:26:47,250 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
2016-12-14 17:26:47,251 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/SQL,null}
2016-12-14 17:26:47,251 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 17:26:47,251 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 17:26:47,252 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 17:26:47,252 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 17:26:47,252 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 17:26:47,253 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 17:26:47,253 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 17:26:47,253 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 17:26:47,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 17:26:47,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 17:26:47,254 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 17:26:47,255 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 17:26:47,255 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 17:26:47,255 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 17:26:47,256 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 17:26:47,256 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 17:26:47,256 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 17:26:47,257 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 17:26:47,257 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 17:26:47,257 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 17:26:47,258 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 17:26:47,258 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 17:26:47,258 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 17:26:47,259 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 17:26:47,259 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 17:26:47,314 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 17:26:47,385 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 17:26:47,396 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 17:26:47,396 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 17:26:47,397 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 17:26:47,399 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 17:26:47,406 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 17:26:47,417 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 17:26:47,421 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 17:26:47,423 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-e479e051-5a61-4c56-bd6c-88e047cf59c4
2016-12-14 17:26:47,424 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 17:26:47,424 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-3a9b8d6e-ba43-407d-b91a-042c19c93c30
2016-12-14 17:26:47,469 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 17:26:47,469 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
