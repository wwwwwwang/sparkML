2016-12-14 14:07:08,745 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 14:07:09,805 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 14:07:09,811 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 14:07:09,812 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 14:07:10,207 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 46744.
2016-12-14 14:07:10,545 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 14:07:10,589 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 14:07:10,762 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:62671]
2016-12-14 14:07:10,764 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:62671]
2016-12-14 14:07:10,770 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 62671.
2016-12-14 14:07:10,785 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 14:07:10,800 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 14:07:10,812 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-1ca0004b-fefd-4a5d-9208-3b2d0977b360
2016-12-14 14:07:10,824 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 14:07:10,883 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 14:07:11,028 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 14:07:11,077 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:07:11,078 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:07:11,079 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 14:07:11,107 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:46744/jars/mysql-connector-java-5.1.25.jar with timestamp 1481695631107
2016-12-14 14:07:11,108 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:46744/jars/ojdbc6.jar with timestamp 1481695631108
2016-12-14 14:07:11,108 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:46744/jars/orai18n.jar with timestamp 1481695631108
2016-12-14 14:07:11,108 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:46744/jars/machine_learning_2.10-1.0.jar with timestamp 1481695631108
2016-12-14 14:07:11,211 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 14:07:11,243 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 19371.
2016-12-14 14:07:11,244 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 19371
2016-12-14 14:07:11,249 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 14:07:11,250 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 14:07:11,254 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:19371 with 530.0 MB RAM, BlockManagerId(driver, localhost, 19371)
2016-12-14 14:07:11,258 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 14:07:12,931 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481695631160
2016-12-14 14:07:12,988 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/iris.txt
2016-12-14 14:07:12,988 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 14:07:12,988 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 14:07:12,988 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 14:07:12,989 INFO  com.datageek.test.K_means$ - main: #####################savePath = /usr/machine_learning/model/k_mean_test
2016-12-14 14:07:12,989 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 14:07:13,590 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 14:07:13,921 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 14:07:13,925 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:19371 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 14:07:13,934 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:91
2016-12-14 14:07:14,050 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:07:14,160 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 14:07:14,190 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:07:14,214 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:07:14,214 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (takeSample at KMeans.scala:378)
2016-12-14 14:07:14,215 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:14,220 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:14,228 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210), which has no missing parents
2016-12-14 14:07:14,282 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 305.3 KB)
2016-12-14 14:07:14,306 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 307.7 KB)
2016-12-14 14:07:14,308 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:19371 (size: 2.4 KB, free: 530.0 MB)
2016-12-14 14:07:14,310 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:14,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210)
2016-12-14 14:07:14,318 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 2 tasks
2016-12-14 14:07:14,387 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:07:14,390 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:07:14,405 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:07:14,405 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 0.0 (TID 1)
2016-12-14 14:07:14,420 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 14:07:14,421 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:46744/jars/ojdbc6.jar with timestamp 1481695631108
2016-12-14 14:07:14,546 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:46744/jars/ojdbc6.jar to /tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/fetchFileTemp4389867822216908694.tmp
2016-12-14 14:07:14,665 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/ojdbc6.jar to class loader
2016-12-14 14:07:14,665 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:46744/jars/mysql-connector-java-5.1.25.jar with timestamp 1481695631107
2016-12-14 14:07:14,666 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:46744/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/fetchFileTemp91599900634965840.tmp
2016-12-14 14:07:14,680 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 14:07:14,681 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:46744/jars/orai18n.jar with timestamp 1481695631108
2016-12-14 14:07:14,682 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:46744/jars/orai18n.jar to /tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/fetchFileTemp2217764235315975286.tmp
2016-12-14 14:07:14,701 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/orai18n.jar to class loader
2016-12-14 14:07:14,702 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:46744/jars/machine_learning_2.10-1.0.jar with timestamp 1481695631108
2016-12-14 14:07:14,703 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:46744/jars/machine_learning_2.10-1.0.jar to /tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/fetchFileTemp5403873101509939403.tmp
2016-12-14 14:07:14,713 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26/userFiles-2d5205a1-8c54-4f4e-889c-e96b7015d26d/machine_learning_2.10-1.0.jar to class loader
2016-12-14 14:07:14,782 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 14:07:14,782 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 14:07:14,788 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:1428+1428
2016-12-14 14:07:14,788 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:0+1428
2016-12-14 14:07:14,815 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 14:07:14,816 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 14:07:14,816 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 14:07:14,816 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 14:07:14,816 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 14:07:14,870 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 6.8 KB, free 314.4 KB)
2016-12-14 14:07:14,871 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:19371 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:07:14,871 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 6.8 KB, free 321.2 KB)
2016-12-14 14:07:14,873 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:19371 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:07:14,874 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_0 not found, computing it
2016-12-14 14:07:14,874 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_1 not found, computing it
2016-12-14 14:07:14,874 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:14,875 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:14,880 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_0 stored as values in memory (estimated size 2.1 KB, free 323.2 KB)
2016-12-14 14:07:14,881 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_0 in memory on localhost:19371 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:07:14,884 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_1 stored as values in memory (estimated size 2.1 KB, free 325.3 KB)
2016-12-14 14:07:14,885 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_1 in memory on localhost:19371 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:07:14,923 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2638 bytes result sent to driver
2016-12-14 14:07:14,923 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 0.0 (TID 1). 2638 bytes result sent to driver
2016-12-14 14:07:14,953 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 601 ms on localhost (1/2)
2016-12-14 14:07:14,954 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 0.0 (TID 1) in 565 ms on localhost (2/2)
2016-12-14 14:07:14,955 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:07:14,958 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (takeSample at KMeans.scala:378) finished in 0.628 s
2016-12-14 14:07:14,968 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: takeSample at KMeans.scala:378, took 0.777652 s
2016-12-14 14:07:15,021 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:07:15,024 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:07:15,024 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (takeSample at KMeans.scala:378)
2016-12-14 14:07:15,025 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,029 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,030 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 14:07:15,035 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 21.3 KB, free 346.6 KB)
2016-12-14 14:07:15,045 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.9 KB, free 355.5 KB)
2016-12-14 14:07:15,048 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:19371 (size: 8.9 KB, free: 530.0 MB)
2016-12-14 14:07:15,049 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,050 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378)
2016-12-14 14:07:15,051 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 2 tasks
2016-12-14 14:07:15,058 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:07:15,059 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:07:15,059 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 2)
2016-12-14 14:07:15,059 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 1.0 (TID 3)
2016-12-14 14:07:15,070 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,070 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,072 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,072 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,100 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 1.0 (TID 3). 3071 bytes result sent to driver
2016-12-14 14:07:15,100 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 2). 2880 bytes result sent to driver
2016-12-14 14:07:15,125 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 2) in 70 ms on localhost (1/2)
2016-12-14 14:07:15,126 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (takeSample at KMeans.scala:378) finished in 0.070 s
2016-12-14 14:07:15,126 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 1.0 (TID 3) in 67 ms on localhost (2/2)
2016-12-14 14:07:15,126 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,127 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: takeSample at KMeans.scala:378, took 0.104696 s
2016-12-14 14:07:15,130 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 2000.0 B, free 357.5 KB)
2016-12-14 14:07:15,142 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 431.0 B, free 357.9 KB)
2016-12-14 14:07:15,144 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:19371 (size: 431.0 B, free: 530.0 MB)
2016-12-14 14:07:15,145 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at KMeans.scala:396
2016-12-14 14:07:15,172 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:07:15,174 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:07:15,174 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (aggregate at KMeans.scala:404)
2016-12-14 14:07:15,174 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,176 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,176 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:07:15,179 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 363.7 KB)
2016-12-14 14:07:15,186 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.0 KB, free 366.7 KB)
2016-12-14 14:07:15,187 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:19371 (size: 3.0 KB, free: 530.0 MB)
2016-12-14 14:07:15,188 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,189 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398)
2016-12-14 14:07:15,189 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 14:07:15,191 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:07:15,192 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:07:15,193 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 5)
2016-12-14 14:07:15,193 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 4)
2016-12-14 14:07:15,202 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_1 not found, computing it
2016-12-14 14:07:15,202 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,202 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,203 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,203 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,204 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_0 not found, computing it
2016-12-14 14:07:15,205 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,205 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,206 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,207 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,224 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 14:07:15,225 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 14:07:15,243 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_0 stored as values in memory (estimated size 7.3 KB, free 374.1 KB)
2016-12-14 14:07:15,244 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_1 stored as values in memory (estimated size 7.3 KB, free 381.4 KB)
2016-12-14 14:07:15,245 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_0 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,245 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_1 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,255 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 4). 2721 bytes result sent to driver
2016-12-14 14:07:15,256 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 5). 2721 bytes result sent to driver
2016-12-14 14:07:15,259 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
2016-12-14 14:07:15,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 5) in 69 ms on localhost (2/2)
2016-12-14 14:07:15,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (aggregate at KMeans.scala:404) finished in 0.071 s
2016-12-14 14:07:15,261 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: aggregate at KMeans.scala:404, took 0.088621 s
2016-12-14 14:07:15,269 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 7 from persistence list
2016-12-14 14:07:15,278 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 7
2016-12-14 14:07:15,301 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:07:15,303 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:07:15,304 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (collect at KMeans.scala:436)
2016-12-14 14:07:15,304 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,307 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,308 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:07:15,311 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 6.0 KB, free 387.4 KB)
2016-12-14 14:07:15,319 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 390.6 KB)
2016-12-14 14:07:15,320 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:19371 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:15,321 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,321 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:07:15,322 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 14:07:15,323 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:07:15,324 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:07:15,325 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 7)
2016-12-14 14:07:15,325 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 6)
2016-12-14 14:07:15,328 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,328 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:07:15,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:07:15,338 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 7). 3544 bytes result sent to driver
2016-12-14 14:07:15,347 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 6). 3919 bytes result sent to driver
2016-12-14 14:07:15,354 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 7) in 29 ms on localhost (1/2)
2016-12-14 14:07:15,355 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 6) in 33 ms on localhost (2/2)
2016-12-14 14:07:15,355 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (collect at KMeans.scala:436) finished in 0.033 s
2016-12-14 14:07:15,356 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,356 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: collect at KMeans.scala:436, took 0.054729 s
2016-12-14 14:07:15,358 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 396.9 KB)
2016-12-14 14:07:15,364 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1473.0 B, free 398.4 KB)
2016-12-14 14:07:15,365 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:19371 (size: 1473.0 B, free: 529.9 MB)
2016-12-14 14:07:15,366 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at KMeans.scala:396
2016-12-14 14:07:15,378 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:07:15,379 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:07:15,380 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (aggregate at KMeans.scala:404)
2016-12-14 14:07:15,380 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,381 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,382 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:07:15,383 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 6.1 KB, free 404.4 KB)
2016-12-14 14:07:15,388 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.1 KB, free 407.5 KB)
2016-12-14 14:07:15,389 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:19371 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:07:15,390 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,390 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398)
2016-12-14 14:07:15,390 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 14:07:15,393 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:07:15,394 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:07:15,394 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 9)
2016-12-14 14:07:15,394 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 8)
2016-12-14 14:07:15,398 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_1 not found, computing it
2016-12-14 14:07:15,398 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,398 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,399 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:07:15,400 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_0 not found, computing it
2016-12-14 14:07:15,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,401 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:07:15,404 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_1 stored as values in memory (estimated size 7.3 KB, free 414.9 KB)
2016-12-14 14:07:15,406 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_1 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,408 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_0 stored as values in memory (estimated size 7.3 KB, free 422.2 KB)
2016-12-14 14:07:15,410 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_0 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,410 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 9). 2721 bytes result sent to driver
2016-12-14 14:07:15,415 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 8). 2721 bytes result sent to driver
2016-12-14 14:07:15,416 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 9) in 23 ms on localhost (1/2)
2016-12-14 14:07:15,419 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 8) in 28 ms on localhost (2/2)
2016-12-14 14:07:15,419 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (aggregate at KMeans.scala:404) finished in 0.028 s
2016-12-14 14:07:15,419 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,420 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: aggregate at KMeans.scala:404, took 0.041263 s
2016-12-14 14:07:15,421 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 10 from persistence list
2016-12-14 14:07:15,422 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:07:15,434 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:07:15,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:07:15,436 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (collect at KMeans.scala:436)
2016-12-14 14:07:15,436 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,437 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,438 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:07:15,440 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.2 KB, free 413.7 KB)
2016-12-14 14:07:15,444 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.2 KB, free 417.0 KB)
2016-12-14 14:07:15,444 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:19371 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:15,445 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:07:15,446 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 14:07:15,448 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:07:15,448 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:07:15,449 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 10)
2016-12-14 14:07:15,449 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 11)
2016-12-14 14:07:15,453 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,453 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,453 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:07:15,455 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,455 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,456 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:07:15,460 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 11). 3933 bytes result sent to driver
2016-12-14 14:07:15,461 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 10). 2922 bytes result sent to driver
2016-12-14 14:07:15,465 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 11) in 17 ms on localhost (1/2)
2016-12-14 14:07:15,467 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 10) in 20 ms on localhost (2/2)
2016-12-14 14:07:15,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (collect at KMeans.scala:436) finished in 0.021 s
2016-12-14 14:07:15,467 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,467 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: collect at KMeans.scala:436, took 0.032553 s
2016-12-14 14:07:15,469 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 5.4 KB, free 422.4 KB)
2016-12-14 14:07:15,474 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1290.0 B, free 423.7 KB)
2016-12-14 14:07:15,475 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:19371 (size: 1290.0 B, free: 529.9 MB)
2016-12-14 14:07:15,476 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at KMeans.scala:396
2016-12-14 14:07:15,488 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:07:15,489 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:07:15,489 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 14:07:15,489 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,491 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,492 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:07:15,494 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 430.0 KB)
2016-12-14 14:07:15,499 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.1 KB, free 433.1 KB)
2016-12-14 14:07:15,499 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:19371 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:07:15,500 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,500 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398)
2016-12-14 14:07:15,500 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 14:07:15,502 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:07:15,504 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:07:15,504 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 12)
2016-12-14 14:07:15,504 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 13)
2016-12-14 14:07:15,508 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_1 not found, computing it
2016-12-14 14:07:15,508 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,508 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,508 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:07:15,510 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_0 not found, computing it
2016-12-14 14:07:15,510 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,510 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_1 stored as values in memory (estimated size 7.3 KB, free 440.5 KB)
2016-12-14 14:07:15,510 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,511 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:07:15,511 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_1 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,515 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 13). 2721 bytes result sent to driver
2016-12-14 14:07:15,515 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_0 stored as values in memory (estimated size 7.3 KB, free 447.8 KB)
2016-12-14 14:07:15,516 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_0 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,522 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 12). 2721 bytes result sent to driver
2016-12-14 14:07:15,525 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 13) in 21 ms on localhost (1/2)
2016-12-14 14:07:15,526 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 12) in 25 ms on localhost (2/2)
2016-12-14 14:07:15,526 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.026 s
2016-12-14 14:07:15,526 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,527 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.038412 s
2016-12-14 14:07:15,528 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 14 from persistence list
2016-12-14 14:07:15,529 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:07:15,540 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:07:15,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:07:15,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 14:07:15,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:07:15,545 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.5 KB, free 439.6 KB)
2016-12-14 14:07:15,551 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 442.9 KB)
2016-12-14 14:07:15,552 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:19371 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,553 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,553 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:07:15,554 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 14:07:15,556 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:07:15,558 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:07:15,559 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 14)
2016-12-14 14:07:15,559 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 15)
2016-12-14 14:07:15,564 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,564 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,565 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,565 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,565 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:07:15,565 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:07:15,570 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 15). 3146 bytes result sent to driver
2016-12-14 14:07:15,571 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 14). 3260 bytes result sent to driver
2016-12-14 14:07:15,578 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 15) in 22 ms on localhost (1/2)
2016-12-14 14:07:15,582 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 14) in 27 ms on localhost (2/2)
2016-12-14 14:07:15,583 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 14:07:15,583 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,584 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.043184 s
2016-12-14 14:07:15,588 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 4.6 KB, free 447.5 KB)
2016-12-14 14:07:15,596 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1104.0 B, free 448.6 KB)
2016-12-14 14:07:15,597 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:19371 (size: 1104.0 B, free: 529.9 MB)
2016-12-14 14:07:15,597 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at KMeans.scala:396
2016-12-14 14:07:15,619 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:07:15,621 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:07:15,621 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 14:07:15,621 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,624 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,624 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:07:15,628 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 6.5 KB, free 455.1 KB)
2016-12-14 14:07:15,635 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.2 KB, free 458.3 KB)
2016-12-14 14:07:15,636 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:19371 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:15,637 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,638 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398)
2016-12-14 14:07:15,638 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 14:07:15,641 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:07:15,641 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:07:15,642 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 16)
2016-12-14 14:07:15,642 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 17)
2016-12-14 14:07:15,646 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_1 not found, computing it
2016-12-14 14:07:15,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:07:15,648 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_0 not found, computing it
2016-12-14 14:07:15,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,649 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:07:15,649 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_1 stored as values in memory (estimated size 7.3 KB, free 465.7 KB)
2016-12-14 14:07:15,650 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_1 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,651 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_0 stored as values in memory (estimated size 7.3 KB, free 473.0 KB)
2016-12-14 14:07:15,652 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_0 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,653 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 17). 2721 bytes result sent to driver
2016-12-14 14:07:15,655 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 16). 2721 bytes result sent to driver
2016-12-14 14:07:15,658 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 16) in 19 ms on localhost (1/2)
2016-12-14 14:07:15,659 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 17) in 18 ms on localhost (2/2)
2016-12-14 14:07:15,660 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,660 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.020 s
2016-12-14 14:07:15,660 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.041001 s
2016-12-14 14:07:15,663 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 18 from persistence list
2016-12-14 14:07:15,664 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:07:15,692 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:07:15,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:07:15,695 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 14:07:15,695 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,697 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,698 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:07:15,699 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.7 KB, free 465.0 KB)
2016-12-14 14:07:15,721 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 14:07:15,723 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 468.4 KB)
2016-12-14 14:07:15,724 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:19371 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:07:15,725 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:07:15,725 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 14:07:15,726 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:19371 in memory (size: 8.9 KB, free: 529.9 MB)
2016-12-14 14:07:15,727 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:07:15,727 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 14:07:15,727 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:07:15,728 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 18)
2016-12-14 14:07:15,728 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 19)
2016-12-14 14:07:15,728 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:19371 in memory (size: 2.4 KB, free: 529.9 MB)
2016-12-14 14:07:15,729 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 14:07:15,730 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:19371 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:15,731 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 14:07:15,732 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:19371 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,732 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 14:07:15,732 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,732 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,732 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:07:15,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,733 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:19371 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:07:15,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:07:15,733 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 14:07:15,734 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:19371 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:15,735 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 14:07:15,735 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:19371 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:07:15,736 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 14:07:15,736 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:19371 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:15,739 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 19). 3923 bytes result sent to driver
2016-12-14 14:07:15,739 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 14:07:15,740 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:19371 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:07:15,739 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 18). 3091 bytes result sent to driver
2016-12-14 14:07:15,744 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 19) in 17 ms on localhost (1/2)
2016-12-14 14:07:15,750 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 18) in 23 ms on localhost (2/2)
2016-12-14 14:07:15,750 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.024 s
2016-12-14 14:07:15,750 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,750 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.057742 s
2016-12-14 14:07:15,754 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 5.5 KB, free 371.5 KB)
2016-12-14 14:07:15,766 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 1336.0 B, free 372.8 KB)
2016-12-14 14:07:15,767 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:19371 (size: 1336.0 B, free: 529.9 MB)
2016-12-14 14:07:15,768 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at KMeans.scala:396
2016-12-14 14:07:15,789 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:07:15,791 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:07:15,791 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 14:07:15,791 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,793 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,794 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:07:15,796 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 6.8 KB, free 379.5 KB)
2016-12-14 14:07:15,800 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.3 KB, free 382.8 KB)
2016-12-14 14:07:15,800 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:19371 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,801 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,801 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398)
2016-12-14 14:07:15,802 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 14:07:15,804 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:07:15,805 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:07:15,806 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 20)
2016-12-14 14:07:15,806 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 21)
2016-12-14 14:07:15,810 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_1 not found, computing it
2016-12-14 14:07:15,810 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,810 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,810 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:07:15,811 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_0 not found, computing it
2016-12-14 14:07:15,811 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,812 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,812 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:07:15,812 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_1 stored as values in memory (estimated size 7.3 KB, free 390.1 KB)
2016-12-14 14:07:15,813 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_1 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,816 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_0 stored as values in memory (estimated size 7.3 KB, free 397.5 KB)
2016-12-14 14:07:15,817 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 21). 2721 bytes result sent to driver
2016-12-14 14:07:15,817 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_0 in memory on localhost:19371 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:07:15,820 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 21) in 15 ms on localhost (1/2)
2016-12-14 14:07:15,822 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 20). 2721 bytes result sent to driver
2016-12-14 14:07:15,830 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 20) in 27 ms on localhost (2/2)
2016-12-14 14:07:15,830 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.027 s
2016-12-14 14:07:15,830 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.041173 s
2016-12-14 14:07:15,832 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 22 from persistence list
2016-12-14 14:07:15,833 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:07:15,844 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:07:15,846 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:07:15,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 14:07:15,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:15,849 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:15,850 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:07:15,853 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 6.9 KB, free 389.7 KB)
2016-12-14 14:07:15,859 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.4 KB, free 393.2 KB)
2016-12-14 14:07:15,860 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:19371 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:07:15,861 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:07:15,862 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 14:07:15,864 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:07:15,865 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:07:15,866 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 22)
2016-12-14 14:07:15,866 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 23)
2016-12-14 14:07:15,869 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,869 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,869 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_1 locally
2016-12-14 14:07:15,871 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,871 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:15,872 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_0 locally
2016-12-14 14:07:15,874 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 23). 3929 bytes result sent to driver
2016-12-14 14:07:15,877 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 22). 3593 bytes result sent to driver
2016-12-14 14:07:15,883 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 23) in 17 ms on localhost (1/2)
2016-12-14 14:07:15,888 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 22) in 25 ms on localhost (2/2)
2016-12-14 14:07:15,888 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.025 s
2016-12-14 14:07:15,888 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:07:15,889 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.044135 s
2016-12-14 14:07:15,890 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 26 from persistence list
2016-12-14 14:07:15,891 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:07:15,893 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 25.9 KB, free 404.4 KB)
2016-12-14 14:07:15,903 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 408.1 KB)
2016-12-14 14:07:15,904 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:19371 (size: 3.7 KB, free: 530.0 MB)
2016-12-14 14:07:15,905 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at KMeans.scala:450
2016-12-14 14:07:15,955 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 14:07:15,964 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 29 (flatMap at KMeans.scala:451)
2016-12-14 14:07:15,965 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 14:07:15,965 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collectAsMap at KMeans.scala:455)
2016-12-14 14:07:15,965 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 12)
2016-12-14 14:07:15,965 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 12)
2016-12-14 14:07:15,967 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 14:07:15,972 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 5.9 KB, free 414.0 KB)
2016-12-14 14:07:15,976 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.2 KB, free 417.1 KB)
2016-12-14 14:07:15,976 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:19371 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:15,977 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:15,979 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451)
2016-12-14 14:07:15,979 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 14:07:15,982 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:15,983 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:15,983 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 24)
2016-12-14 14:07:15,983 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 25)
2016-12-14 14:07:15,991 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:15,991 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:15,991 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:15,991 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:16,105 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 25). 2237 bytes result sent to driver
2016-12-14 14:07:16,106 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 24). 2237 bytes result sent to driver
2016-12-14 14:07:16,114 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 25) in 130 ms on localhost (1/2)
2016-12-14 14:07:16,116 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 24) in 136 ms on localhost (2/2)
2016-12-14 14:07:16,116 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,116 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 12 (flatMap at KMeans.scala:451) finished in 0.137 s
2016-12-14 14:07:16,117 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:16,118 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:16,119 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 13)
2016-12-14 14:07:16,119 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:16,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 14:07:16,129 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 2.6 KB, free 419.7 KB)
2016-12-14 14:07:16,135 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1555.0 B, free 421.2 KB)
2016-12-14 14:07:16,137 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:19371 (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:07:16,138 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,138 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455)
2016-12-14 14:07:16,138 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 14:07:16,142 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 26, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,143 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 27, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,143 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 26)
2016-12-14 14:07:16,143 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 27)
2016-12-14 14:07:16,153 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,154 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,155 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 4 ms
2016-12-14 14:07:16,155 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 4 ms
2016-12-14 14:07:16,222 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 27). 4206 bytes result sent to driver
2016-12-14 14:07:16,223 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 26). 4374 bytes result sent to driver
2016-12-14 14:07:16,226 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 26) in 86 ms on localhost (1/2)
2016-12-14 14:07:16,227 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 27) in 84 ms on localhost (2/2)
2016-12-14 14:07:16,227 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collectAsMap at KMeans.scala:455) finished in 0.087 s
2016-12-14 14:07:16,227 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,228 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: collectAsMap at KMeans.scala:455, took 0.272058 s
2016-12-14 14:07:16,388 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:07:16,390 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 7 iterations.
2016-12-14 14:07:16,389 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:07:16,389 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:07:16,389 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:07:16,389 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:07:16,389 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:07:16,388 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:07:16,390 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 7 iterations.
2016-12-14 14:07:16,390 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 14:07:16,416 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 2.337 seconds.
2016-12-14 14:07:16,421 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 3.0 KB, free 424.2 KB)
2016-12-14 14:07:16,428 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1346.0 B, free 425.5 KB)
2016-12-14 14:07:16,430 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:19371 (size: 1346.0 B, free: 529.9 MB)
2016-12-14 14:07:16,431 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at KMeans.scala:276
2016-12-14 14:07:16,471 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:16,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 31 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:16,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:16,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 14)
2016-12-14 14:07:16,474 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 14)
2016-12-14 14:07:16,475 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:16,479 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 6.9 KB, free 432.4 KB)
2016-12-14 14:07:16,485 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.6 KB, free 436.0 KB)
2016-12-14 14:07:16,486 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:19371 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:16,487 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,487 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,487 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 14:07:16,489 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,490 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,490 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 28)
2016-12-14 14:07:16,490 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 29)
2016-12-14 14:07:16,495 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:16,495 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:16,495 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:16,496 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:16,508 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 29). 2516 bytes result sent to driver
2016-12-14 14:07:16,513 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 29) in 22 ms on localhost (1/2)
2016-12-14 14:07:16,513 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 28). 2516 bytes result sent to driver
2016-12-14 14:07:16,520 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 28) in 31 ms on localhost (2/2)
2016-12-14 14:07:16,520 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 14 (mapPartitions at KMeans.scala:279) finished in 0.032 s
2016-12-14 14:07:16,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:16,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:16,520 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 15)
2016-12-14 14:07:16,521 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:16,521 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:16,523 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 2.9 KB, free 438.9 KB)
2016-12-14 14:07:16,527 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1669.0 B, free 440.5 KB)
2016-12-14 14:07:16,528 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:19371 (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:07:16,528 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,529 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:16,529 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 14:07:16,531 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 30, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,531 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 31, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,532 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 30)
2016-12-14 14:07:16,532 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 31)
2016-12-14 14:07:16,534 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,534 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,535 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,535 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,546 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 30). 1963 bytes result sent to driver
2016-12-14 14:07:16,550 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 31). 1964 bytes result sent to driver
2016-12-14 14:07:16,550 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 30) in 20 ms on localhost (1/2)
2016-12-14 14:07:16,557 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 31) in 26 ms on localhost (2/2)
2016-12-14 14:07:16,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collectAsMap at KMeans.scala:302) finished in 0.027 s
2016-12-14 14:07:16,558 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,558 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collectAsMap at KMeans.scala:302, took 0.087270 s
2016-12-14 14:07:16,564 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 3.0 KB, free 443.5 KB)
2016-12-14 14:07:16,571 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 934.0 B, free 444.4 KB)
2016-12-14 14:07:16,571 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:19371 (size: 934.0 B, free: 529.9 MB)
2016-12-14 14:07:16,572 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at KMeans.scala:276
2016-12-14 14:07:16,590 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:16,591 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 33 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,592 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:16,592 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:16,592 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 14:07:16,592 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 14:07:16,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:16,597 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 6.9 KB, free 451.3 KB)
2016-12-14 14:07:16,603 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.6 KB, free 454.8 KB)
2016-12-14 14:07:16,604 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:19371 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:16,605 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,606 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,606 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 14:07:16,608 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,608 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 33, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,608 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 33)
2016-12-14 14:07:16,608 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 32)
2016-12-14 14:07:16,612 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:16,612 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:16,613 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:16,613 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:16,626 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 33). 2516 bytes result sent to driver
2016-12-14 14:07:16,627 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 32). 2516 bytes result sent to driver
2016-12-14 14:07:16,629 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 33) in 21 ms on localhost (1/2)
2016-12-14 14:07:16,632 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 32) in 25 ms on localhost (2/2)
2016-12-14 14:07:16,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (mapPartitions at KMeans.scala:279) finished in 0.025 s
2016-12-14 14:07:16,633 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:16,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:16,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 14:07:16,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:16,634 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:16,636 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 2.9 KB, free 457.8 KB)
2016-12-14 14:07:16,642 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1665.0 B, free 459.4 KB)
2016-12-14 14:07:16,643 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:19371 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:07:16,644 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,645 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:16,645 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 14:07:16,647 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 34, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,647 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 35, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,649 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 34)
2016-12-14 14:07:16,649 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 35)
2016-12-14 14:07:16,651 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,651 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,652 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,652 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,658 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 34). 1963 bytes result sent to driver
2016-12-14 14:07:16,664 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 34) in 18 ms on localhost (1/2)
2016-12-14 14:07:16,667 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 35). 1964 bytes result sent to driver
2016-12-14 14:07:16,673 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 35) in 26 ms on localhost (2/2)
2016-12-14 14:07:16,673 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:302) finished in 0.027 s
2016-12-14 14:07:16,673 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,674 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: collectAsMap at KMeans.scala:302, took 0.083752 s
2016-12-14 14:07:16,676 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 2 iterations
2016-12-14 14:07:16,676 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 2 iterations
2016-12-14 14:07:16,676 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 2 iterations
2016-12-14 14:07:16,676 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 2 iterations
2016-12-14 14:07:16,677 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 1840.0 B, free 461.2 KB)
2016-12-14 14:07:16,680 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 742.0 B, free 461.9 KB)
2016-12-14 14:07:16,681 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:19371 (size: 742.0 B, free: 529.9 MB)
2016-12-14 14:07:16,682 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at KMeans.scala:276
2016-12-14 14:07:16,704 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:16,705 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 35 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,706 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:16,706 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:16,706 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 14:07:16,707 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 14:07:16,708 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:16,710 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 6.7 KB, free 468.6 KB)
2016-12-14 14:07:16,715 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.6 KB, free 472.2 KB)
2016-12-14 14:07:16,716 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:19371 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:16,717 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,718 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 14:07:16,720 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 36, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,721 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 37, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,722 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 36)
2016-12-14 14:07:16,722 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 37)
2016-12-14 14:07:16,724 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:16,725 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:16,726 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:16,727 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:16,733 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 36). 2420 bytes result sent to driver
2016-12-14 14:07:16,738 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 36) in 19 ms on localhost (1/2)
2016-12-14 14:07:16,739 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 37). 2420 bytes result sent to driver
2016-12-14 14:07:16,744 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 37) in 24 ms on localhost (2/2)
2016-12-14 14:07:16,745 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.025 s
2016-12-14 14:07:16,745 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,745 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:16,745 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:16,745 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 14:07:16,746 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:16,746 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:16,748 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 2.9 KB, free 475.1 KB)
2016-12-14 14:07:16,752 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1667.0 B, free 476.7 KB)
2016-12-14 14:07:16,753 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:19371 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:07:16,754 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,754 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:16,754 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 14:07:16,756 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 38, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,756 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 39, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,756 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 38)
2016-12-14 14:07:16,756 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 39)
2016-12-14 14:07:16,758 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,758 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,760 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,760 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,766 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 39). 1645 bytes result sent to driver
2016-12-14 14:07:16,771 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 39) in 15 ms on localhost (1/2)
2016-12-14 14:07:16,775 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 38). 1646 bytes result sent to driver
2016-12-14 14:07:16,780 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 38) in 25 ms on localhost (2/2)
2016-12-14 14:07:16,780 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.025 s
2016-12-14 14:07:16,780 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collectAsMap at KMeans.scala:302, took 0.076405 s
2016-12-14 14:07:16,782 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 3 iterations
2016-12-14 14:07:16,782 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 1544.0 B, free 478.2 KB)
2016-12-14 14:07:16,785 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 651.0 B, free 478.9 KB)
2016-12-14 14:07:16,786 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:19371 (size: 651.0 B, free: 529.9 MB)
2016-12-14 14:07:16,786 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at KMeans.scala:276
2016-12-14 14:07:16,794 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:16,795 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 37 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:16,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:16,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 14:07:16,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 14:07:16,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:16,798 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 6.7 KB, free 485.6 KB)
2016-12-14 14:07:16,803 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.6 KB, free 489.1 KB)
2016-12-14 14:07:16,803 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:19371 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:16,804 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,804 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,804 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 14:07:16,806 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,807 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 41, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,808 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 40)
2016-12-14 14:07:16,808 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 41)
2016-12-14 14:07:16,812 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:16,812 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:16,813 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:16,813 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:16,817 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 41). 2396 bytes result sent to driver
2016-12-14 14:07:16,821 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 41) in 14 ms on localhost (1/2)
2016-12-14 14:07:16,822 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 40). 2396 bytes result sent to driver
2016-12-14 14:07:16,826 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 40) in 20 ms on localhost (2/2)
2016-12-14 14:07:16,826 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.021 s
2016-12-14 14:07:16,826 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,827 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:16,827 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:16,827 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 14:07:16,827 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:16,828 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:16,830 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 2.9 KB, free 492.0 KB)
2016-12-14 14:07:16,834 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1666.0 B, free 493.6 KB)
2016-12-14 14:07:16,835 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:19371 (size: 1666.0 B, free: 529.9 MB)
2016-12-14 14:07:16,835 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,836 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:16,836 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 14:07:16,837 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 42, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,838 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 43, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,838 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 43)
2016-12-14 14:07:16,838 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 42)
2016-12-14 14:07:16,841 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,841 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,841 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,841 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,850 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 42). 1540 bytes result sent to driver
2016-12-14 14:07:16,853 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 42) in 16 ms on localhost (1/2)
2016-12-14 14:07:16,853 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 43). 1592 bytes result sent to driver
2016-12-14 14:07:16,858 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 43) in 20 ms on localhost (2/2)
2016-12-14 14:07:16,858 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,858 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:07:16,858 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:302, took 0.063799 s
2016-12-14 14:07:16,860 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 4 iterations
2016-12-14 14:07:16,861 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 1240.0 B, free 494.9 KB)
2016-12-14 14:07:16,866 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 561.0 B, free 495.4 KB)
2016-12-14 14:07:16,866 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:19371 (size: 561.0 B, free: 529.9 MB)
2016-12-14 14:07:16,867 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at KMeans.scala:276
2016-12-14 14:07:16,875 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:16,876 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 39 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,876 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:16,877 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:16,877 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 14:07:16,877 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 14:07:16,879 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:16,881 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 6.6 KB, free 502.0 KB)
2016-12-14 14:07:16,899 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 14:07:16,901 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:07:16,903 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 18
2016-12-14 14:07:16,903 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.6 KB, free 505.6 KB)
2016-12-14 14:07:16,903 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:19371 in memory (size: 1290.0 B, free: 529.9 MB)
2016-12-14 14:07:16,904 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:19371 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:16,904 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,905 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:07:16,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,905 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 14:07:16,905 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 14
2016-12-14 14:07:16,906 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:19371 in memory (size: 1473.0 B, free: 529.9 MB)
2016-12-14 14:07:16,907 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 44, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,907 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:07:16,907 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 45, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,908 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 44)
2016-12-14 14:07:16,908 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 45)
2016-12-14 14:07:16,908 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 10
2016-12-14 14:07:16,910 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:19371 in memory (size: 431.0 B, free: 529.9 MB)
2016-12-14 14:07:16,910 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 14:07:16,911 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 14:07:16,911 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 14:07:16,911 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 14:07:16,911 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 14:07:16,912 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:19371 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:07:16,912 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:16,913 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 14:07:16,913 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:16,913 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:16,913 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:19371 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:07:16,913 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:16,914 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 14:07:16,917 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 14:07:16,918 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:19371 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:07:16,920 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:19371 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:07:16,920 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 14:07:16,921 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:19371 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:07:16,922 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 45). 2372 bytes result sent to driver
2016-12-14 14:07:16,922 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 14:07:16,922 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:07:16,923 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 26
2016-12-14 14:07:16,924 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:19371 in memory (size: 1336.0 B, free: 529.9 MB)
2016-12-14 14:07:16,924 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 44). 2372 bytes result sent to driver
2016-12-14 14:07:16,925 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:19371 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:07:16,925 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 14:07:16,926 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:07:16,927 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 22
2016-12-14 14:07:16,927 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 45) in 20 ms on localhost (1/2)
2016-12-14 14:07:16,928 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:19371 in memory (size: 1104.0 B, free: 529.9 MB)
2016-12-14 14:07:16,928 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 44) in 22 ms on localhost (2/2)
2016-12-14 14:07:16,928 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.022 s
2016-12-14 14:07:16,928 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:16,928 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:16,928 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,929 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 14:07:16,929 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 14:07:16,929 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:16,930 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:16,930 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:19371 in memory (size: 1346.0 B, free: 529.9 MB)
2016-12-14 14:07:16,930 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 14:07:16,931 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 14:07:16,931 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 14:07:16,931 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 14:07:16,931 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 14:07:16,931 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 2.9 KB, free 401.7 KB)
2016-12-14 14:07:16,931 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 14:07:16,932 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 14:07:16,932 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 14:07:16,932 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 14:07:16,932 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 14:07:16,932 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 14:07:16,933 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 14:07:16,933 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 14:07:16,934 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:19371 in memory (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:07:16,935 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 14:07:16,936 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:19371 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:16,936 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1664.0 B, free 395.2 KB)
2016-12-14 14:07:16,936 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 14:07:16,936 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:19371 (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:07:16,936 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 14:07:16,937 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 14:07:16,937 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 14:07:16,937 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 14:07:16,937 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,937 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:16,938 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:19371 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:07:16,938 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 14:07:16,938 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 14:07:16,939 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 46, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,939 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:19371 in memory (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:07:16,939 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 47, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:16,940 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 47)
2016-12-14 14:07:16,940 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 46)
2016-12-14 14:07:16,941 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 14:07:16,941 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:19371 in memory (size: 934.0 B, free: 530.0 MB)
2016-12-14 14:07:16,942 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 14:07:16,942 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 14:07:16,942 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,942 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:16,942 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:16,943 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:19371 in memory (size: 1666.0 B, free: 530.0 MB)
2016-12-14 14:07:16,943 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:16,943 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 14:07:16,945 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:19371 in memory (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:07:16,945 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 14:07:16,945 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 14:07:16,946 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:19371 in memory (size: 651.0 B, free: 530.0 MB)
2016-12-14 14:07:16,947 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 14:07:16,947 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 14:07:16,947 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 14:07:16,947 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 14:07:16,947 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 14:07:16,948 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:19371 in memory (size: 1667.0 B, free: 530.0 MB)
2016-12-14 14:07:16,949 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 14:07:16,950 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:19371 in memory (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:07:16,950 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 14:07:16,951 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 14:07:16,952 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:19371 in memory (size: 742.0 B, free: 530.0 MB)
2016-12-14 14:07:16,952 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 14:07:16,953 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 14:07:16,954 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 47). 1487 bytes result sent to driver
2016-12-14 14:07:16,955 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 46). 1486 bytes result sent to driver
2016-12-14 14:07:16,958 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 47) in 19 ms on localhost (1/2)
2016-12-14 14:07:16,960 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 46) in 20 ms on localhost (2/2)
2016-12-14 14:07:16,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:07:16,960 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:07:16,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.085324 s
2016-12-14 14:07:16,962 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 1240.0 B, free 336.4 KB)
2016-12-14 14:07:16,964 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 554.0 B, free 336.9 KB)
2016-12-14 14:07:16,965 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:19371 (size: 554.0 B, free: 530.0 MB)
2016-12-14 14:07:16,965 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at KMeans.scala:276
2016-12-14 14:07:16,973 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:16,974 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 41 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,974 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:16,975 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:16,975 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 14:07:16,975 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 14:07:16,977 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:16,979 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 6.6 KB, free 343.5 KB)
2016-12-14 14:07:16,983 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.6 KB, free 347.1 KB)
2016-12-14 14:07:16,984 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:19371 (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:07:16,985 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:16,985 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:16,985 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 14:07:16,987 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 48, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,988 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 49, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:16,988 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 48)
2016-12-14 14:07:16,988 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 49)
2016-12-14 14:07:16,993 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:16,993 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:16,993 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:16,994 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:17,002 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 48). 2372 bytes result sent to driver
2016-12-14 14:07:17,002 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 49). 2372 bytes result sent to driver
2016-12-14 14:07:17,004 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 48) in 17 ms on localhost (1/2)
2016-12-14 14:07:17,005 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 49) in 18 ms on localhost (2/2)
2016-12-14 14:07:17,006 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.019 s
2016-12-14 14:07:17,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 14:07:17,006 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,007 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:17,009 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 2.9 KB, free 350.0 KB)
2016-12-14 14:07:17,013 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1668.0 B, free 351.6 KB)
2016-12-14 14:07:17,014 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:19371 (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:07:17,015 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,015 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:17,015 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 14:07:17,016 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 50, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,017 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 51, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,017 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 50)
2016-12-14 14:07:17,017 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 51)
2016-12-14 14:07:17,020 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,020 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,021 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,021 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,028 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 51). 1487 bytes result sent to driver
2016-12-14 14:07:17,030 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 50). 1486 bytes result sent to driver
2016-12-14 14:07:17,031 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 51) in 13 ms on localhost (1/2)
2016-12-14 14:07:17,035 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 50) in 18 ms on localhost (2/2)
2016-12-14 14:07:17,035 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 14:07:17,035 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,036 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.062345 s
2016-12-14 14:07:17,036 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 6 iterations
2016-12-14 14:07:17,037 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 6 iterations
2016-12-14 14:07:17,037 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 640.0 B, free 352.3 KB)
2016-12-14 14:07:17,039 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 346.0 B, free 352.6 KB)
2016-12-14 14:07:17,040 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:19371 (size: 346.0 B, free: 530.0 MB)
2016-12-14 14:07:17,040 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at KMeans.scala:276
2016-12-14 14:07:17,048 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:17,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 43 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:17,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:17,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:17,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 14:07:17,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 14:07:17,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:17,055 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 6.6 KB, free 359.2 KB)
2016-12-14 14:07:17,058 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.5 KB, free 362.7 KB)
2016-12-14 14:07:17,059 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:19371 (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:07:17,060 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,060 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:17,060 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 14:07:17,062 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 52, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:17,062 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 53, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:17,063 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 53)
2016-12-14 14:07:17,063 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 52)
2016-12-14 14:07:17,067 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,067 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:17,069 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,069 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:17,075 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 52). 2324 bytes result sent to driver
2016-12-14 14:07:17,077 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 52) in 16 ms on localhost (1/2)
2016-12-14 14:07:17,081 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 53). 2324 bytes result sent to driver
2016-12-14 14:07:17,088 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 53) in 25 ms on localhost (2/2)
2016-12-14 14:07:17,088 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.027 s
2016-12-14 14:07:17,088 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,088 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,089 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,089 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 14:07:17,089 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,090 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:17,091 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 2.9 KB, free 365.6 KB)
2016-12-14 14:07:17,095 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1668.0 B, free 367.2 KB)
2016-12-14 14:07:17,095 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:19371 (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:07:17,096 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[44] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:17,096 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 14:07:17,098 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 54, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,099 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 55, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,099 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 54)
2016-12-14 14:07:17,099 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 55)
2016-12-14 14:07:17,101 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,101 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,102 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,102 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,107 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 54). 1324 bytes result sent to driver
2016-12-14 14:07:17,109 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 54) in 12 ms on localhost (1/2)
2016-12-14 14:07:17,110 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 55). 1324 bytes result sent to driver
2016-12-14 14:07:17,115 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 55) in 17 ms on localhost (2/2)
2016-12-14 14:07:17,115 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.018 s
2016-12-14 14:07:17,115 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,116 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.067813 s
2016-12-14 14:07:17,117 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 7 iterations
2016-12-14 14:07:17,117 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 344.0 B, free 367.6 KB)
2016-12-14 14:07:17,119 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 244.0 B, free 367.8 KB)
2016-12-14 14:07:17,119 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:19371 (size: 244.0 B, free: 530.0 MB)
2016-12-14 14:07:17,120 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at KMeans.scala:276
2016-12-14 14:07:17,128 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:17,128 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 45 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:17,129 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:17,129 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:17,129 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 14:07:17,129 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 14:07:17,131 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:17,132 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 6.5 KB, free 374.3 KB)
2016-12-14 14:07:17,136 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.5 KB, free 377.8 KB)
2016-12-14 14:07:17,137 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:19371 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:07:17,137 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,138 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[45] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:17,138 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 14:07:17,139 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 56, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:17,140 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 57, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:17,141 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 56)
2016-12-14 14:07:17,141 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 57)
2016-12-14 14:07:17,143 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,143 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:17,145 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,145 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:17,148 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 57). 2300 bytes result sent to driver
2016-12-14 14:07:17,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 57) in 10 ms on localhost (1/2)
2016-12-14 14:07:17,150 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 56). 2300 bytes result sent to driver
2016-12-14 14:07:17,152 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 56) in 13 ms on localhost (2/2)
2016-12-14 14:07:17,153 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 14:07:17,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 14:07:17,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,154 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:17,155 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 2.9 KB, free 380.8 KB)
2016-12-14 14:07:17,159 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1668.0 B, free 382.4 KB)
2016-12-14 14:07:17,159 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:19371 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:07:17,160 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,160 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[46] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:17,160 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 14:07:17,161 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 58, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,162 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 59, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,162 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 59)
2016-12-14 14:07:17,162 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 58)
2016-12-14 14:07:17,163 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,163 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,164 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,165 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,168 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 58). 1218 bytes result sent to driver
2016-12-14 14:07:17,171 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 58) in 10 ms on localhost (1/2)
2016-12-14 14:07:17,175 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 59). 1271 bytes result sent to driver
2016-12-14 14:07:17,179 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 59) in 18 ms on localhost (2/2)
2016-12-14 14:07:17,179 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.018 s
2016-12-14 14:07:17,179 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,180 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.051867 s
2016-12-14 14:07:17,181 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 344.0 B, free 382.7 KB)
2016-12-14 14:07:17,183 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 246.0 B, free 383.0 KB)
2016-12-14 14:07:17,183 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:19371 (size: 246.0 B, free: 529.9 MB)
2016-12-14 14:07:17,184 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at KMeans.scala:276
2016-12-14 14:07:17,191 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:07:17,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 47 (mapPartitions at KMeans.scala:279)
2016-12-14 14:07:17,193 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:07:17,193 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 14:07:17,193 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 14:07:17,194 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 14:07:17,195 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:07:17,197 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 6.5 KB, free 389.5 KB)
2016-12-14 14:07:17,201 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.5 KB, free 393.0 KB)
2016-12-14 14:07:17,202 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:19371 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:07:17,203 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,203 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[47] at mapPartitions at KMeans.scala:279)
2016-12-14 14:07:17,203 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 14:07:17,205 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 60, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:17,205 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 61, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:07:17,206 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 60)
2016-12-14 14:07:17,206 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 61)
2016-12-14 14:07:17,208 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,208 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:07:17,210 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,210 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:07:17,212 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 61). 2300 bytes result sent to driver
2016-12-14 14:07:17,215 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 61) in 10 ms on localhost (1/2)
2016-12-14 14:07:17,218 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 60). 2300 bytes result sent to driver
2016-12-14 14:07:17,220 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 60) in 16 ms on localhost (2/2)
2016-12-14 14:07:17,220 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,220 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 14:07:17,220 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,220 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,220 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 14:07:17,221 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,221 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:07:17,223 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 2.9 KB, free 395.9 KB)
2016-12-14 14:07:17,227 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1668.0 B, free 397.5 KB)
2016-12-14 14:07:17,227 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:19371 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:07:17,228 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,229 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[48] at reduceByKey at KMeans.scala:302)
2016-12-14 14:07:17,229 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 14:07:17,230 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 62, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,230 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 63, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,230 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 62)
2016-12-14 14:07:17,231 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 63)
2016-12-14 14:07:17,232 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,232 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,233 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,233 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,237 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 63). 1271 bytes result sent to driver
2016-12-14 14:07:17,240 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 63) in 10 ms on localhost (1/2)
2016-12-14 14:07:17,244 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 62). 1218 bytes result sent to driver
2016-12-14 14:07:17,248 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 62) in 18 ms on localhost (2/2)
2016-12-14 14:07:17,249 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 14:07:17,249 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,249 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.057756 s
2016-12-14 14:07:17,250 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 9 iterations
2016-12-14 14:07:17,251 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.833 seconds.
2016-12-14 14:07:17,252 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 9 iterations.
2016-12-14 14:07:17,253 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 78.94084142614686.
2016-12-14 14:07:17,254 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 4 from persistence list
2016-12-14 14:07:17,255 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:07:17,256 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:07:17,257 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 344.0 B, free 393.7 KB)
2016-12-14 14:07:17,259 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 298.0 B, free 394.0 KB)
2016-12-14 14:07:17,260 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:19371 (size: 298.0 B, free: 529.9 MB)
2016-12-14 14:07:17,261 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at KMeansModel.scala:87
2016-12-14 14:07:17,267 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 14:07:17,268 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 14:07:17,268 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 32 (sum at KMeansModel.scala:88)
2016-12-14 14:07:17,268 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:17,269 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:17,270 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 32 (MapPartitionsRDD[49] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 14:07:17,271 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 4.2 KB, free 398.2 KB)
2016-12-14 14:07:17,275 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.4 KB, free 400.7 KB)
2016-12-14 14:07:17,276 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:19371 (size: 2.4 KB, free: 529.9 MB)
2016-12-14 14:07:17,276 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,277 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[49] at map at KMeansModel.scala:88)
2016-12-14 14:07:17,277 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 14:07:17,278 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 64, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,278 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 65, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,279 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 64)
2016-12-14 14:07:17,279 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 65)
2016-12-14 14:07:17,281 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,283 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 65). 2064 bytes result sent to driver
2016-12-14 14:07:17,286 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 64). 2064 bytes result sent to driver
2016-12-14 14:07:17,286 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 65) in 8 ms on localhost (1/2)
2016-12-14 14:07:17,288 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 64) in 10 ms on localhost (2/2)
2016-12-14 14:07:17,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 32 (sum at KMeansModel.scala:88) finished in 0.011 s
2016-12-14 14:07:17,288 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: sum at KMeansModel.scala:88, took 0.020912 s
2016-12-14 14:07:17,289 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 78.94084142614686
2016-12-14 14:07:17,303 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:114
2016-12-14 14:07:17,304 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (foreach at K_means.scala:114) with 2 output partitions
2016-12-14 14:07:17,304 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (foreach at K_means.scala:114)
2016-12-14 14:07:17,304 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:17,305 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:17,305 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (MapPartitionsRDD[3] at map at K_means.scala:101), which has no missing parents
2016-12-14 14:07:17,306 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 4.0 KB, free 404.7 KB)
2016-12-14 14:07:17,308 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.3 KB, free 407.0 KB)
2016-12-14 14:07:17,309 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:19371 (size: 2.3 KB, free: 529.9 MB)
2016-12-14 14:07:17,309 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,310 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[3] at map at K_means.scala:101)
2016-12-14 14:07:17,310 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 14:07:17,311 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 66, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,312 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 67, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,312 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 67)
2016-12-14 14:07:17,312 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 66)
2016-12-14 14:07:17,314 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,316 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.6,3.0,4.4,1.4] belong to cluster 0
2016-12-14 14:07:17,316 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,2.8,4.8,1.4] belong to cluster 0
2016-12-14 14:07:17,316 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.0,5.0,1.7] belong to cluster 2
2016-12-14 14:07:17,316 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,317 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.9,4.5,1.5] belong to cluster 0
2016-12-14 14:07:17,317 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.5,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,317 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.6,3.5,1.0] belong to cluster 0
2016-12-14 14:07:17,317 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.0,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,317 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.4,3.8,1.1] belong to cluster 0
2016-12-14 14:07:17,318 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.7,3.2,1.3,0.2] belong to cluster 1
2016-12-14 14:07:17,318 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.4,3.7,1.0] belong to cluster 0
2016-12-14 14:07:17,318 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.1,1.5,0.2] belong to cluster 1
2016-12-14 14:07:17,318 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,3.9,1.2] belong to cluster 0
2016-12-14 14:07:17,318 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.6,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,318 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.7,5.1,1.6] belong to cluster 0
2016-12-14 14:07:17,319 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.9,1.7,0.4] belong to cluster 1
2016-12-14 14:07:17,319 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.0,4.5,1.5] belong to cluster 0
2016-12-14 14:07:17,319 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.4,1.4,0.3] belong to cluster 1
2016-12-14 14:07:17,319 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,3.4,4.5,1.6] belong to cluster 0
2016-12-14 14:07:17,319 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.4,1.5,0.2] belong to cluster 1
2016-12-14 14:07:17,319 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,4.7,1.5] belong to cluster 0
2016-12-14 14:07:17,319 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,2.9,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,320 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.3,4.4,1.3] belong to cluster 0
2016-12-14 14:07:17,320 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 1
2016-12-14 14:07:17,320 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,3.0,4.1,1.3] belong to cluster 0
2016-12-14 14:07:17,320 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.7,1.5,0.2] belong to cluster 1
2016-12-14 14:07:17,320 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.5,4.0,1.3] belong to cluster 0
2016-12-14 14:07:17,320 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.4,1.6,0.2] belong to cluster 1
2016-12-14 14:07:17,320 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.6,4.4,1.2] belong to cluster 0
2016-12-14 14:07:17,321 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.0,1.4,0.1] belong to cluster 1
2016-12-14 14:07:17,321 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,3.0,4.6,1.4] belong to cluster 0
2016-12-14 14:07:17,321 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.3,3.0,1.1,0.1] belong to cluster 1
2016-12-14 14:07:17,321 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.6,4.0,1.2] belong to cluster 0
2016-12-14 14:07:17,321 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,4.0,1.2,0.2] belong to cluster 1
2016-12-14 14:07:17,321 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,2.3,3.3,1.0] belong to cluster 0
2016-12-14 14:07:17,322 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,4.4,1.5,0.4] belong to cluster 1
2016-12-14 14:07:17,322 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.7,4.2,1.3] belong to cluster 0
2016-12-14 14:07:17,322 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.9,1.3,0.4] belong to cluster 1
2016-12-14 14:07:17,322 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,3.0,4.2,1.2] belong to cluster 0
2016-12-14 14:07:17,322 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.5,1.4,0.3] belong to cluster 1
2016-12-14 14:07:17,322 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.9,4.2,1.3] belong to cluster 0
2016-12-14 14:07:17,323 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,3.8,1.7,0.3] belong to cluster 1
2016-12-14 14:07:17,323 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.9,4.3,1.3] belong to cluster 0
2016-12-14 14:07:17,323 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.5,0.3] belong to cluster 1
2016-12-14 14:07:17,323 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,2.5,3.0,1.1] belong to cluster 0
2016-12-14 14:07:17,323 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.4,1.7,0.2] belong to cluster 1
2016-12-14 14:07:17,323 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.8,4.1,1.3] belong to cluster 0
2016-12-14 14:07:17,324 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.7,1.5,0.4] belong to cluster 1
2016-12-14 14:07:17,324 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.3,6.0,2.5] belong to cluster 2
2016-12-14 14:07:17,324 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.6,1.0,0.2] belong to cluster 1
2016-12-14 14:07:17,324 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,5.1,1.9] belong to cluster 0
2016-12-14 14:07:17,324 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.3,1.7,0.5] belong to cluster 1
2016-12-14 14:07:17,324 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.1,3.0,5.9,2.1] belong to cluster 2
2016-12-14 14:07:17,325 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.4,1.9,0.2] belong to cluster 1
2016-12-14 14:07:17,325 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.9,5.6,1.8] belong to cluster 2
2016-12-14 14:07:17,325 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.0,1.6,0.2] belong to cluster 1
2016-12-14 14:07:17,325 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.8,2.2] belong to cluster 2
2016-12-14 14:07:17,325 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.4,1.6,0.4] belong to cluster 1
2016-12-14 14:07:17,325 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.6,3.0,6.6,2.1] belong to cluster 2
2016-12-14 14:07:17,325 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,3.5,1.5,0.2] belong to cluster 1
2016-12-14 14:07:17,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,2.5,4.5,1.7] belong to cluster 0
2016-12-14 14:07:17,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,3.4,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.3,2.9,6.3,1.8] belong to cluster 2
2016-12-14 14:07:17,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.7,3.2,1.6,0.2] belong to cluster 1
2016-12-14 14:07:17,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,2.5,5.8,1.8] belong to cluster 2
2016-12-14 14:07:17,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.1,1.6,0.2] belong to cluster 1
2016-12-14 14:07:17,326 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.6,6.1,2.5] belong to cluster 2
2016-12-14 14:07:17,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.4,3.4,1.5,0.4] belong to cluster 1
2016-12-14 14:07:17,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.2,5.1,2.0] belong to cluster 2
2016-12-14 14:07:17,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,4.1,1.5,0.1] belong to cluster 1
2016-12-14 14:07:17,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.7,5.3,1.9] belong to cluster 2
2016-12-14 14:07:17,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,4.2,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,327 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,3.0,5.5,2.1] belong to cluster 2
2016-12-14 14:07:17,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 1
2016-12-14 14:07:17,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.5,5.0,2.0] belong to cluster 0
2016-12-14 14:07:17,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.2,1.2,0.2] belong to cluster 1
2016-12-14 14:07:17,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.8,5.1,2.4] belong to cluster 0
2016-12-14 14:07:17,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,3.5,1.3,0.2] belong to cluster 1
2016-12-14 14:07:17,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.2,5.3,2.3] belong to cluster 2
2016-12-14 14:07:17,328 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,3.1,1.5,0.1] belong to cluster 1
2016-12-14 14:07:17,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.5,1.8] belong to cluster 2
2016-12-14 14:07:17,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,3.0,1.3,0.2] belong to cluster 1
2016-12-14 14:07:17,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,3.8,6.7,2.2] belong to cluster 2
2016-12-14 14:07:17,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.4,1.5,0.2] belong to cluster 1
2016-12-14 14:07:17,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,2.6,6.9,2.3] belong to cluster 2
2016-12-14 14:07:17,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.5,1.3,0.3] belong to cluster 1
2016-12-14 14:07:17,329 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.2,5.0,1.5] belong to cluster 0
2016-12-14 14:07:17,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.5,2.3,1.3,0.3] belong to cluster 1
2016-12-14 14:07:17,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.2,5.7,2.3] belong to cluster 2
2016-12-14 14:07:17,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.4,3.2,1.3,0.2] belong to cluster 1
2016-12-14 14:07:17,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.8,4.9,2.0] belong to cluster 0
2016-12-14 14:07:17,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.5,1.6,0.6] belong to cluster 1
2016-12-14 14:07:17,330 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,2.8,6.7,2.0] belong to cluster 2
2016-12-14 14:07:17,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.9,0.4] belong to cluster 1
2016-12-14 14:07:17,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.7,4.9,1.8] belong to cluster 0
2016-12-14 14:07:17,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.8,3.0,1.4,0.3] belong to cluster 1
2016-12-14 14:07:17,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.3,5.7,2.1] belong to cluster 2
2016-12-14 14:07:17,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.1,3.8,1.6,0.2] belong to cluster 1
2016-12-14 14:07:17,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.2,6.0,1.8] belong to cluster 2
2016-12-14 14:07:17,331 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.6,3.2,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.8,4.8,1.8] belong to cluster 0
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.3,3.7,1.5,0.2] belong to cluster 1
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,3.0,4.9,1.8] belong to cluster 0
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,3.3,1.4,0.2] belong to cluster 1
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.8,5.6,2.1] belong to cluster 2
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.0,3.2,4.7,1.4] belong to cluster 0
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.2,3.0,5.8,1.6] belong to cluster 2
2016-12-14 14:07:17,332 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.2,4.5,1.5] belong to cluster 0
2016-12-14 14:07:17,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.4,2.8,6.1,1.9] belong to cluster 2
2016-12-14 14:07:17,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,4.9,1.5] belong to cluster 2
2016-12-14 14:07:17,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.9,3.8,6.4,2.0] belong to cluster 2
2016-12-14 14:07:17,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.5,2.3,4.0,1.3] belong to cluster 0
2016-12-14 14:07:17,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.8,5.6,2.2] belong to cluster 2
2016-12-14 14:07:17,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,2.8,4.6,1.5] belong to cluster 0
2016-12-14 14:07:17,333 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.8,5.1,1.5] belong to cluster 0
2016-12-14 14:07:17,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.7,2.8,4.5,1.3] belong to cluster 0
2016-12-14 14:07:17,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.6,5.6,1.4] belong to cluster 2
2016-12-14 14:07:17,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.3,4.7,1.6] belong to cluster 0
2016-12-14 14:07:17,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[7.7,3.0,6.1,2.3] belong to cluster 2
2016-12-14 14:07:17,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[4.9,2.4,3.3,1.0] belong to cluster 0
2016-12-14 14:07:17,334 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,3.4,5.6,2.4] belong to cluster 2
2016-12-14 14:07:17,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.6,2.9,4.6,1.3] belong to cluster 0
2016-12-14 14:07:17,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,3.1,5.5,1.8] belong to cluster 2
2016-12-14 14:07:17,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.2,2.7,3.9,1.4] belong to cluster 0
2016-12-14 14:07:17,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,3.0,4.8,1.8] belong to cluster 0
2016-12-14 14:07:17,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.0,2.0,3.5,1.0] belong to cluster 0
2016-12-14 14:07:17,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,5.4,2.1] belong to cluster 2
2016-12-14 14:07:17,335 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.0,4.2,1.5] belong to cluster 0
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,5.6,2.4] belong to cluster 2
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.0,2.2,4.0,1.0] belong to cluster 0
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.9,3.1,5.1,2.3] belong to cluster 2
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.9,4.7,1.4] belong to cluster 0
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,5.1,1.9] belong to cluster 0
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.9,3.6,1.3] belong to cluster 0
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.8,3.2,5.9,2.3] belong to cluster 2
2016-12-14 14:07:17,336 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.1,4.4,1.4] belong to cluster 0
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.3,5.7,2.5] belong to cluster 2
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,3.0,4.5,1.5] belong to cluster 0
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.7,3.0,5.2,2.3] belong to cluster 2
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.8,2.7,4.1,1.0] belong to cluster 0
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.5,5.0,1.9] belong to cluster 0
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,2.2,4.5,1.5] belong to cluster 0
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.5,3.0,5.2,2.0] belong to cluster 2
2016-12-14 14:07:17,337 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.6,2.5,3.9,1.1] belong to cluster 0
2016-12-14 14:07:17,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.2,3.4,5.4,2.3] belong to cluster 2
2016-12-14 14:07:17,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.2,4.8,1.8] belong to cluster 0
2016-12-14 14:07:17,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[5.9,3.0,5.1,1.8] belong to cluster 0
2016-12-14 14:07:17,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.8,4.0,1.3] belong to cluster 0
2016-12-14 14:07:17,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.3,2.5,4.9,1.5] belong to cluster 0
2016-12-14 14:07:17,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.1,2.8,4.7,1.2] belong to cluster 0
2016-12-14 14:07:17,338 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[6.4,2.9,4.3,1.3] belong to cluster 0
2016-12-14 14:07:17,340 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 67). 2057 bytes result sent to driver
2016-12-14 14:07:17,340 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 66). 2057 bytes result sent to driver
2016-12-14 14:07:17,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 67) in 30 ms on localhost (1/2)
2016-12-14 14:07:17,343 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 66) in 32 ms on localhost (2/2)
2016-12-14 14:07:17,344 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (foreach at K_means.scala:114) finished in 0.033 s
2016-12-14 14:07:17,344 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,344 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: foreach at K_means.scala:114, took 0.041044 s
2016-12-14 14:07:17,362 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:125
2016-12-14 14:07:17,363 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (foreach at K_means.scala:125) with 2 output partitions
2016-12-14 14:07:17,364 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 34 (foreach at K_means.scala:125)
2016-12-14 14:07:17,364 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:17,364 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:17,365 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 34 (MapPartitionsRDD[50] at map at K_means.scala:123), which has no missing parents
2016-12-14 14:07:17,367 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 4.0 KB, free 411.0 KB)
2016-12-14 14:07:17,371 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.3 KB, free 413.3 KB)
2016-12-14 14:07:17,371 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:19371 (size: 2.3 KB, free: 529.9 MB)
2016-12-14 14:07:17,372 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 34 (MapPartitionsRDD[50] at map at K_means.scala:123)
2016-12-14 14:07:17,373 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 14:07:17,374 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 68, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,375 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 69, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,375 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 69)
2016-12-14 14:07:17,375 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 68)
2016-12-14 14:07:17,377 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,377 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,378 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,378 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,378 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,378 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,378 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,378 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:07:17,379 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,379 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,379 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,379 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,379 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,379 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,379 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,380 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,381 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,382 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,383 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,384 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,385 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,386 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,387 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,388 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,389 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,389 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,389 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,389 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,389 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,389 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,389 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,390 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,391 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,392 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,393 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,394 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,395 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,396 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,396 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,396 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:07:17,396 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,396 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:07:17,396 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,396 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,397 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,397 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:07:17,398 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 69). 2057 bytes result sent to driver
2016-12-14 14:07:17,399 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 68). 2057 bytes result sent to driver
2016-12-14 14:07:17,400 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 68) in 27 ms on localhost (1/2)
2016-12-14 14:07:17,403 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 69) in 29 ms on localhost (2/2)
2016-12-14 14:07:17,403 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 34 (foreach at K_means.scala:125) finished in 0.030 s
2016-12-14 14:07:17,404 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,404 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: foreach at K_means.scala:125, took 0.041439 s
2016-12-14 14:07:17,425 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:14
2016-12-14 14:07:17,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 51 (map at Relabel.scala:14)
2016-12-14 14:07:17,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (sortBy at Relabel.scala:14) with 2 output partitions
2016-12-14 14:07:17,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 36 (sortBy at Relabel.scala:14)
2016-12-14 14:07:17,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 35)
2016-12-14 14:07:17,428 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 35)
2016-12-14 14:07:17,429 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 35 (MapPartitionsRDD[51] at map at Relabel.scala:14), which has no missing parents
2016-12-14 14:07:17,430 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 4.8 KB, free 418.1 KB)
2016-12-14 14:07:17,434 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.8 KB, free 420.8 KB)
2016-12-14 14:07:17,435 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:19371 (size: 2.8 KB, free: 529.9 MB)
2016-12-14 14:07:17,436 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,436 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[51] at map at Relabel.scala:14)
2016-12-14 14:07:17,436 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 14:07:17,438 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:07:17,438 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:07:17,438 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 70)
2016-12-14 14:07:17,438 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 71)
2016-12-14 14:07:17,440 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,441 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,448 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 71). 2237 bytes result sent to driver
2016-12-14 14:07:17,450 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 71) in 12 ms on localhost (1/2)
2016-12-14 14:07:17,450 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 70). 2237 bytes result sent to driver
2016-12-14 14:07:17,453 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 70) in 16 ms on localhost (2/2)
2016-12-14 14:07:17,454 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,454 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 35 (map at Relabel.scala:14) finished in 0.016 s
2016-12-14 14:07:17,454 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,454 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,454 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 36)
2016-12-14 14:07:17,454 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,455 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 36 (MapPartitionsRDD[55] at sortBy at Relabel.scala:14), which has no missing parents
2016-12-14 14:07:17,457 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 3.5 KB, free 424.4 KB)
2016-12-14 14:07:17,460 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 2022.0 B, free 426.4 KB)
2016-12-14 14:07:17,461 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:19371 (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:07:17,462 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,462 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 36 (MapPartitionsRDD[55] at sortBy at Relabel.scala:14)
2016-12-14 14:07:17,462 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 14:07:17,463 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 72, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,464 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 73, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,464 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 72)
2016-12-14 14:07:17,464 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 73)
2016-12-14 14:07:17,466 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,467 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,467 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,468 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,475 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 72). 1160 bytes result sent to driver
2016-12-14 14:07:17,476 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 73). 1152 bytes result sent to driver
2016-12-14 14:07:17,478 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 72) in 14 ms on localhost (1/2)
2016-12-14 14:07:17,479 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 73) in 16 ms on localhost (2/2)
2016-12-14 14:07:17,479 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 36 (sortBy at Relabel.scala:14) finished in 0.016 s
2016-12-14 14:07:17,479 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: sortBy at Relabel.scala:14, took 0.054072 s
2016-12-14 14:07:17,652 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 14:07:17,654 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:19371 in memory (size: 346.0 B, free: 529.9 MB)
2016-12-14 14:07:17,654 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 14:07:17,654 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 14:07:17,655 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:19371 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:07:17,655 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 14:07:17,656 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:19371 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:17,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 14:07:17,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 14:07:17,658 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:19371 in memory (size: 554.0 B, free: 529.9 MB)
2016-12-14 14:07:17,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 14:07:17,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 14:07:17,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 14:07:17,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 14:07:17,660 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:19371 in memory (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:07:17,660 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 14:07:17,661 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:19371 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:07:17,662 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 14:07:17,662 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 14:07:17,663 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:19371 in memory (size: 561.0 B, free: 529.9 MB)
2016-12-14 14:07:17,663 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 14:07:17,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 14:07:17,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 14:07:17,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 14:07:17,665 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 4
2016-12-14 14:07:17,665 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 4
2016-12-14 14:07:17,666 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:15
2016-12-14 14:07:17,667 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:19371 in memory (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:07:17,667 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 14:07:17,668 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:19371 in memory (size: 2.8 KB, free: 530.0 MB)
2016-12-14 14:07:17,669 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 14:07:17,670 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:19371 in memory (size: 2.3 KB, free: 530.0 MB)
2016-12-14 14:07:17,670 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 14:07:17,671 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:19371 in memory (size: 2.3 KB, free: 530.0 MB)
2016-12-14 14:07:17,671 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 14:07:17,672 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:19371 in memory (size: 2.4 KB, free: 530.0 MB)
2016-12-14 14:07:17,672 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 14:07:17,673 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 10 is 155 bytes
2016-12-14 14:07:17,673 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:19371 in memory (size: 298.0 B, free: 530.0 MB)
2016-12-14 14:07:17,674 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:19371 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:07:17,675 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 14:07:17,676 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:19371 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:07:17,676 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 14:07:17,676 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 14:07:17,677 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:19371 in memory (size: 246.0 B, free: 530.0 MB)
2016-12-14 14:07:17,677 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 14:07:17,679 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:19371 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:07:17,680 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 14:07:17,680 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:19371 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:07:17,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 53 (sortBy at Relabel.scala:14)
2016-12-14 14:07:17,681 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 14:07:17,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (collect at Relabel.scala:15) with 2 output partitions
2016-12-14 14:07:17,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (collect at Relabel.scala:15)
2016-12-14 14:07:17,681 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 38)
2016-12-14 14:07:17,682 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 14:07:17,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 38)
2016-12-14 14:07:17,682 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:19371 in memory (size: 244.0 B, free: 530.0 MB)
2016-12-14 14:07:17,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 38 (MapPartitionsRDD[53] at sortBy at Relabel.scala:14), which has no missing parents
2016-12-14 14:07:17,683 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 14:07:17,683 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:19371 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:07:17,684 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 14:07:17,685 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:19371 in memory (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:07:17,685 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 14:07:17,689 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 3.6 KB, free 318.1 KB)
2016-12-14 14:07:17,692 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.0 KB, free 320.1 KB)
2016-12-14 14:07:17,693 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:19371 (size: 2.0 KB, free: 530.0 MB)
2016-12-14 14:07:17,693 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[53] at sortBy at Relabel.scala:14)
2016-12-14 14:07:17,694 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 2 tasks
2016-12-14 14:07:17,695 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 74, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 14:07:17,696 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 38.0 (TID 75, localhost, partition 1,NODE_LOCAL, 2132 bytes)
2016-12-14 14:07:17,696 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 38.0 (TID 75)
2016-12-14 14:07:17,696 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 74)
2016-12-14 14:07:17,708 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,708 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,708 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,709 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,725 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 38.0 (TID 75). 1303 bytes result sent to driver
2016-12-14 14:07:17,727 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 74). 1303 bytes result sent to driver
2016-12-14 14:07:17,727 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 38.0 (TID 75) in 31 ms on localhost (1/2)
2016-12-14 14:07:17,728 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 74) in 33 ms on localhost (2/2)
2016-12-14 14:07:17,729 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,729 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 38 (sortBy at Relabel.scala:14) finished in 0.035 s
2016-12-14 14:07:17,729 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,729 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,729 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 39)
2016-12-14 14:07:17,729 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,730 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (MapPartitionsRDD[57] at sortBy at Relabel.scala:14), which has no missing parents
2016-12-14 14:07:17,735 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 3.4 KB, free 323.5 KB)
2016-12-14 14:07:17,738 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 1945.0 B, free 325.4 KB)
2016-12-14 14:07:17,739 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:19371 (size: 1945.0 B, free: 530.0 MB)
2016-12-14 14:07:17,740 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,740 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[57] at sortBy at Relabel.scala:14)
2016-12-14 14:07:17,741 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 2 tasks
2016-12-14 14:07:17,742 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 76, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,742 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 39.0 (TID 77, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,742 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 39.0 (TID 77)
2016-12-14 14:07:17,742 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 76)
2016-12-14 14:07:17,750 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,750 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,753 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,754 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,771 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 39.0 (TID 77). 1211 bytes result sent to driver
2016-12-14 14:07:17,772 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 76). 1182 bytes result sent to driver
2016-12-14 14:07:17,774 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 76) in 32 ms on localhost (1/2)
2016-12-14 14:07:17,774 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 39.0 (TID 77) in 32 ms on localhost (2/2)
2016-12-14 14:07:17,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (collect at Relabel.scala:15) finished in 0.033 s
2016-12-14 14:07:17,774 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,775 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: collect at Relabel.scala:15, took 0.108805 s
2016-12-14 14:07:17,785 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:129
2016-12-14 14:07:17,786 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (foreach at K_means.scala:129) with 2 output partitions
2016-12-14 14:07:17,786 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 40 (foreach at K_means.scala:129)
2016-12-14 14:07:17,787 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:07:17,787 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:07:17,788 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 40 (MapPartitionsRDD[58] at map at Relabel.scala:36), which has no missing parents
2016-12-14 14:07:17,790 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 4.4 KB, free 329.8 KB)
2016-12-14 14:07:17,794 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.5 KB, free 332.3 KB)
2016-12-14 14:07:17,795 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:19371 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:07:17,795 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[58] at map at Relabel.scala:36)
2016-12-14 14:07:17,796 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 2 tasks
2016-12-14 14:07:17,797 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 78, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,798 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 40.0 (TID 79, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:07:17,798 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 40.0 (TID 79)
2016-12-14 14:07:17,798 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 78)
2016-12-14 14:07:17,800 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,801 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,802 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,802 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,803 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,803 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,803 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:07:17,803 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,803 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,804 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,804 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,804 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,804 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,804 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,805 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,805 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,805 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,805 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,805 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,805 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,806 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,806 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,806 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,806 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,806 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,806 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,807 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,807 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,807 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,807 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,807 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,807 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,807 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,808 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,808 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,808 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,808 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,808 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,808 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,808 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,809 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,809 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,809 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,809 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,809 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,809 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,810 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,811 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,812 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,813 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,814 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,815 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,816 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,817 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,818 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,818 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,818 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,818 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,818 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,818 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,818 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,819 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,819 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,819 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,819 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,819 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,819 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,820 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,820 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,820 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,820 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,820 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,820 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,820 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,821 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,821 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,821 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,821 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,821 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,821 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,822 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,822 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,822 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,822 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,822 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,822 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,823 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:07:17,823 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,823 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:07:17,823 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:07:17,826 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 78). 2057 bytes result sent to driver
2016-12-14 14:07:17,826 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 40.0 (TID 79). 2057 bytes result sent to driver
2016-12-14 14:07:17,828 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 78) in 31 ms on localhost (1/2)
2016-12-14 14:07:17,830 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 40.0 (TID 79) in 32 ms on localhost (2/2)
2016-12-14 14:07:17,830 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 40 (foreach at K_means.scala:129) finished in 0.033 s
2016-12-14 14:07:17,830 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,831 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: foreach at K_means.scala:129, took 0.045013 s
2016-12-14 14:07:17,841 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 14:07:17,842 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 59 (map at MulticlassMetrics.scala:46)
2016-12-14 14:07:17,843 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 14:07:17,843 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 42 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 14:07:17,843 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 41)
2016-12-14 14:07:17,843 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 41)
2016-12-14 14:07:17,844 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 41 (MapPartitionsRDD[59] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 14:07:17,846 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 5.3 KB, free 337.6 KB)
2016-12-14 14:07:17,849 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.0 KB, free 340.6 KB)
2016-12-14 14:07:17,850 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:19371 (size: 3.0 KB, free: 530.0 MB)
2016-12-14 14:07:17,851 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[59] at map at MulticlassMetrics.scala:46)
2016-12-14 14:07:17,851 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 14:07:17,853 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 80, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:07:17,853 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 81, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:07:17,853 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 81)
2016-12-14 14:07:17,853 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 80)
2016-12-14 14:07:17,855 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,855 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,864 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 81). 2237 bytes result sent to driver
2016-12-14 14:07:17,865 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 80). 2237 bytes result sent to driver
2016-12-14 14:07:17,867 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 81) in 13 ms on localhost (1/2)
2016-12-14 14:07:17,868 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 80) in 16 ms on localhost (2/2)
2016-12-14 14:07:17,868 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 41 (map at MulticlassMetrics.scala:46) finished in 0.016 s
2016-12-14 14:07:17,869 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,869 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,869 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,869 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 42)
2016-12-14 14:07:17,869 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,870 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 42 (ShuffledRDD[60] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 14:07:17,871 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 2.6 KB, free 343.3 KB)
2016-12-14 14:07:17,875 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 1593.0 B, free 344.8 KB)
2016-12-14 14:07:17,876 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:19371 (size: 1593.0 B, free: 530.0 MB)
2016-12-14 14:07:17,877 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,878 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 42 (ShuffledRDD[60] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 14:07:17,878 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 14:07:17,880 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 82, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,881 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 83, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:07:17,882 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 83)
2016-12-14 14:07:17,882 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 82)
2016-12-14 14:07:17,884 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,884 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,885 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,885 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,890 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 83). 1124 bytes result sent to driver
2016-12-14 14:07:17,891 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 82). 1163 bytes result sent to driver
2016-12-14 14:07:17,892 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 83) in 11 ms on localhost (1/2)
2016-12-14 14:07:17,893 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 82) in 14 ms on localhost (2/2)
2016-12-14 14:07:17,893 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 42 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.014 s
2016-12-14 14:07:17,893 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,894 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.052330 s
2016-12-14 14:07:17,907 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 14:07:17,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 63 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:07:17,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 14:07:17,908 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 44 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:07:17,909 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 43)
2016-12-14 14:07:17,909 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 43)
2016-12-14 14:07:17,910 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 43 (MapPartitionsRDD[63] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:07:17,912 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 5.8 KB, free 350.7 KB)
2016-12-14 14:07:17,916 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.2 KB, free 353.9 KB)
2016-12-14 14:07:17,917 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:19371 (size: 3.2 KB, free: 530.0 MB)
2016-12-14 14:07:17,918 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,918 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[63] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:07:17,919 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 14:07:17,920 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 84, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:07:17,920 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 85, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:07:17,921 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 85)
2016-12-14 14:07:17,921 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 84)
2016-12-14 14:07:17,924 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:07:17,924 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:07:17,930 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 85). 2237 bytes result sent to driver
2016-12-14 14:07:17,930 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 84). 2237 bytes result sent to driver
2016-12-14 14:07:17,932 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 85) in 12 ms on localhost (1/2)
2016-12-14 14:07:17,934 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 84) in 14 ms on localhost (2/2)
2016-12-14 14:07:17,934 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 43 (countByValue at MulticlassMetrics.scala:43) finished in 0.015 s
2016-12-14 14:07:17,935 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,935 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:07:17,935 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:07:17,935 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 44)
2016-12-14 14:07:17,935 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:07:17,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 44 (ShuffledRDD[64] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:07:17,937 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 2.6 KB, free 356.5 KB)
2016-12-14 14:07:17,941 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 1561.0 B, free 358.0 KB)
2016-12-14 14:07:17,942 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:19371 (size: 1561.0 B, free: 530.0 MB)
2016-12-14 14:07:17,943 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:07:17,943 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 44 (ShuffledRDD[64] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:07:17,944 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 2 tasks
2016-12-14 14:07:17,945 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 86, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:07:17,945 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 44.0 (TID 87, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:07:17,946 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 86)
2016-12-14 14:07:17,946 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 44.0 (TID 87)
2016-12-14 14:07:17,948 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:07:17,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:07:17,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:07:17,955 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 44.0 (TID 87). 1124 bytes result sent to driver
2016-12-14 14:07:17,956 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 86). 1163 bytes result sent to driver
2016-12-14 14:07:17,958 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 44.0 (TID 87) in 12 ms on localhost (1/2)
2016-12-14 14:07:17,959 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 86) in 15 ms on localhost (2/2)
2016-12-14 14:07:17,959 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 44 (countByValue at MulticlassMetrics.scala:43) finished in 0.015 s
2016-12-14 14:07:17,959 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:07:17,959 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: countByValue at MulticlassMetrics.scala:43, took 0.052192 s
2016-12-14 14:07:17,961 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.8933333333333333
2016-12-14 14:07:17,961 INFO  com.datageek.test.K_means$ - main: ======(-_-)~==================END=================(-_-)~======
2016-12-14 14:07:18,048 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:07:18,049 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:07:18,049 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:07:18,050 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:07:18,050 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:07:18,051 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:07:18,051 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:07:18,051 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:07:18,052 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:07:18,052 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:07:18,052 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:07:18,053 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:07:18,053 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:07:18,053 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:07:18,054 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:07:18,054 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:07:18,054 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:07:18,055 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:07:18,055 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:07:18,055 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:07:18,056 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:07:18,056 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:07:18,056 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:07:18,056 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:07:18,057 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:07:18,110 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 14:07:18,200 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:07:18,221 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 14:07:18,222 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 14:07:18,223 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 14:07:18,226 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 14:07:18,235 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 14:07:18,237 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 14:07:18,239 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 14:07:18,239 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:07:18,241 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-dd126b8d-bcd6-472f-9d1f-2bd6bab1ae26
2016-12-14 14:07:18,266 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 14:07:18,266 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 14:08:22,647 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 14:08:23,793 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 14:08:23,799 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 14:08:23,800 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 14:08:24,190 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 37287.
2016-12-14 14:08:24,753 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 14:08:24,821 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 14:08:24,970 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:41345]
2016-12-14 14:08:24,972 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:41345]
2016-12-14 14:08:24,977 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 41345.
2016-12-14 14:08:24,993 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 14:08:25,008 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 14:08:25,020 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-3764a688-1af3-44f4-9065-d581730b2d60
2016-12-14 14:08:25,033 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 14:08:25,096 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 14:08:25,244 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 14:08:25,295 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:08:25,296 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:08:25,298 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 14:08:25,326 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:37287/jars/mysql-connector-java-5.1.25.jar with timestamp 1481695705326
2016-12-14 14:08:25,326 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:37287/jars/ojdbc6.jar with timestamp 1481695705326
2016-12-14 14:08:25,327 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:37287/jars/orai18n.jar with timestamp 1481695705327
2016-12-14 14:08:25,327 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:37287/jars/machine_learning_2.10-1.0.jar with timestamp 1481695705327
2016-12-14 14:08:25,386 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 14:08:25,405 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39370.
2016-12-14 14:08:25,406 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 39370
2016-12-14 14:08:25,408 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 14:08:25,409 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 14:08:25,412 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:39370 with 530.0 MB RAM, BlockManagerId(driver, localhost, 39370)
2016-12-14 14:08:25,415 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 14:08:26,815 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481695705359
2016-12-14 14:08:26,849 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/iris.txt
2016-12-14 14:08:26,849 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 14:08:26,849 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 14:08:26,849 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 14:08:26,849 INFO  com.datageek.test.K_means$ - main: #####################savePath = /usr/machine_learning/model/k_mean_test
2016-12-14 14:08:26,849 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 14:08:27,509 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 14:08:27,875 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 14:08:27,880 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:39370 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 14:08:27,885 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:91
2016-12-14 14:08:28,055 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 14:08:28,150 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 14:08:28,184 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (first at PCA.scala:42) with 1 output partitions
2016-12-14 14:08:28,185 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (first at PCA.scala:42)
2016-12-14 14:08:28,186 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:28,193 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:28,208 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:103), which has no missing parents
2016-12-14 14:08:28,232 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 304.6 KB)
2016-12-14 14:08:28,259 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 306.7 KB)
2016-12-14 14:08:28,260 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:39370 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:08:28,262 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:28,267 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:103)
2016-12-14 14:08:28,270 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 1 tasks
2016-12-14 14:08:28,342 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:28,356 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:08:28,367 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:37287/jars/machine_learning_2.10-1.0.jar with timestamp 1481695705327
2016-12-14 14:08:28,369 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 14:08:28,471 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:37287/jars/machine_learning_2.10-1.0.jar to /tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/fetchFileTemp4095669440265154766.tmp
2016-12-14 14:08:28,566 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/machine_learning_2.10-1.0.jar to class loader
2016-12-14 14:08:28,567 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:37287/jars/mysql-connector-java-5.1.25.jar with timestamp 1481695705326
2016-12-14 14:08:28,567 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:37287/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/fetchFileTemp3488933077879460422.tmp
2016-12-14 14:08:28,581 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 14:08:28,582 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:37287/jars/ojdbc6.jar with timestamp 1481695705326
2016-12-14 14:08:28,582 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:37287/jars/ojdbc6.jar to /tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/fetchFileTemp906233001244970231.tmp
2016-12-14 14:08:28,604 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/ojdbc6.jar to class loader
2016-12-14 14:08:28,604 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:37287/jars/orai18n.jar with timestamp 1481695705327
2016-12-14 14:08:28,605 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:37287/jars/orai18n.jar to /tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/fetchFileTemp6623251687676807761.tmp
2016-12-14 14:08:28,616 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9/userFiles-6b102135-c6e6-4625-8a26-160eefd937df/orai18n.jar to class loader
2016-12-14 14:08:28,634 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 14:08:28,638 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:0+1428
2016-12-14 14:08:28,650 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 14:08:28,651 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 14:08:28,651 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 14:08:28,651 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 14:08:28,651 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 14:08:28,711 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 6.8 KB, free 313.5 KB)
2016-12-14 14:08:28,712 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:39370 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:08:28,775 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2701 bytes result sent to driver
2016-12-14 14:08:28,811 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 498 ms on localhost (1/1)
2016-12-14 14:08:28,814 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:08:28,817 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (first at PCA.scala:42) finished in 0.528 s
2016-12-14 14:08:28,827 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: first at PCA.scala:42, took 0.675422 s
2016-12-14 14:08:28,863 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 14:08:28,866 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 14:08:28,866 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (first at RowMatrix.scala:61)
2016-12-14 14:08:28,867 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:28,870 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:28,871 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:103), which has no missing parents
2016-12-14 14:08:28,876 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 3.6 KB, free 317.1 KB)
2016-12-14 14:08:28,888 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 319.2 KB)
2016-12-14 14:08:28,890 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:39370 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:08:28,891 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:28,892 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:103)
2016-12-14 14:08:28,892 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 1 tasks
2016-12-14 14:08:28,900 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:28,901 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 14:08:28,912 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:28,923 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 1). 2176 bytes result sent to driver
2016-12-14 14:08:28,937 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (1/1)
2016-12-14 14:08:28,937 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (first at RowMatrix.scala:61) finished in 0.040 s
2016-12-14 14:08:28,938 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:08:28,938 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: first at RowMatrix.scala:61, took 0.074284 s
2016-12-14 14:08:29,499 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 14:08:29,502 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 14:08:29,503 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:331)
2016-12-14 14:08:29,503 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:29,504 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:29,505 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 14:08:29,510 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 4.5 KB, free 323.7 KB)
2016-12-14 14:08:29,520 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 326.1 KB)
2016-12-14 14:08:29,521 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:39370 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:29,522 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:29,523 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331)
2016-12-14 14:08:29,523 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 14:08:29,526 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:29,528 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:29,528 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 2)
2016-12-14 14:08:29,529 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 3)
2016-12-14 14:08:29,535 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:29,536 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 14:08:29,536 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:1428+1428
2016-12-14 14:08:29,552 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 2). 2136 bytes result sent to driver
2016-12-14 14:08:29,554 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 6.8 KB, free 332.9 KB)
2016-12-14 14:08:29,555 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:39370 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:08:29,564 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 2) in 38 ms on localhost (1/2)
2016-12-14 14:08:29,568 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 3). 2716 bytes result sent to driver
2016-12-14 14:08:29,580 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 3) in 53 ms on localhost (2/2)
2016-12-14 14:08:29,581 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (treeAggregate at RowMatrix.scala:331) finished in 0.056 s
2016-12-14 14:08:29,581 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:08:29,584 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 14:08:29,585 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 14:08:29,590 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: treeAggregate at RowMatrix.scala:331, took 0.089905 s
2016-12-14 14:08:29,606 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 14:08:29,607 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 14:08:29,607 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (treeAggregate at RowMatrix.scala:121)
2016-12-14 14:08:29,607 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:29,608 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:29,608 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 14:08:29,611 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 4.6 KB, free 337.5 KB)
2016-12-14 14:08:29,615 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.5 KB, free 339.9 KB)
2016-12-14 14:08:29,616 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:39370 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:29,617 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:29,618 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121)
2016-12-14 14:08:29,618 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 14:08:29,620 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:29,622 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:29,623 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 4)
2016-12-14 14:08:29,623 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 5)
2016-12-14 14:08:29,627 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:29,628 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:29,635 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 5). 2179 bytes result sent to driver
2016-12-14 14:08:29,635 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 4). 2179 bytes result sent to driver
2016-12-14 14:08:29,641 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 5) in 20 ms on localhost (1/2)
2016-12-14 14:08:29,641 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 4) in 22 ms on localhost (2/2)
2016-12-14 14:08:29,642 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (treeAggregate at RowMatrix.scala:121) finished in 0.023 s
2016-12-14 14:08:29,642 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:08:29,643 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: treeAggregate at RowMatrix.scala:121, took 0.036448 s
2016-12-14 14:08:29,871 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:39370 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:29,879 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 14:08:29,881 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:39370 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:29,882 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 14:08:29,883 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:39370 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:08:29,884 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 14:08:29,886 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:39370 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:08:29,886 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 14:08:30,298 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2016-12-14 14:08:30,299 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2016-12-14 14:08:30,464 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:08:30,506 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:08:30,509 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:08:30,509 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (takeSample at KMeans.scala:378)
2016-12-14 14:08:30,509 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:30,511 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:30,512 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210), which has no missing parents
2016-12-14 14:08:30,524 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 4.8 KB, free 319.3 KB)
2016-12-14 14:08:30,533 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.7 KB, free 322.0 KB)
2016-12-14 14:08:30,534 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:39370 (size: 2.7 KB, free: 530.0 MB)
2016-12-14 14:08:30,535 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:30,536 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210)
2016-12-14 14:08:30,536 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 14:08:30,539 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:08:30,540 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:08:30,540 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 7)
2016-12-14 14:08:30,540 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 6)
2016-12-14 14:08:30,545 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:30,545 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:30,545 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_1 not found, computing it
2016-12-14 14:08:30,546 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_0 not found, computing it
2016-12-14 14:08:30,546 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:30,546 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:30,555 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_1 stored as values in memory (estimated size 2.1 KB, free 324.0 KB)
2016-12-14 14:08:30,556 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_0 stored as values in memory (estimated size 2.1 KB, free 326.1 KB)
2016-12-14 14:08:30,556 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_1 in memory on localhost:39370 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:08:30,558 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_0 in memory on localhost:39370 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:08:30,562 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 7). 2638 bytes result sent to driver
2016-12-14 14:08:30,564 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 6). 2638 bytes result sent to driver
2016-12-14 14:08:30,570 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 7) in 31 ms on localhost (1/2)
2016-12-14 14:08:30,572 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 6) in 34 ms on localhost (2/2)
2016-12-14 14:08:30,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (takeSample at KMeans.scala:378) finished in 0.034 s
2016-12-14 14:08:30,572 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:08:30,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: takeSample at KMeans.scala:378, took 0.066035 s
2016-12-14 14:08:30,667 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:08:30,669 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:08:30,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (takeSample at KMeans.scala:378)
2016-12-14 14:08:30,670 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:30,672 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:30,673 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 14:08:30,678 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 21.8 KB, free 347.8 KB)
2016-12-14 14:08:30,682 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.2 KB, free 357.1 KB)
2016-12-14 14:08:30,682 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:39370 (size: 9.2 KB, free: 530.0 MB)
2016-12-14 14:08:30,683 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:30,683 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378)
2016-12-14 14:08:30,684 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 14:08:30,686 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:08:30,686 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:08:30,686 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 8)
2016-12-14 14:08:30,686 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 9)
2016-12-14 14:08:30,692 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:30,692 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:30,692 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:30,692 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:30,704 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 9). 2842 bytes result sent to driver
2016-12-14 14:08:30,704 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 8). 2854 bytes result sent to driver
2016-12-14 14:08:30,710 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 9) in 24 ms on localhost (1/2)
2016-12-14 14:08:30,711 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (takeSample at KMeans.scala:378) finished in 0.027 s
2016-12-14 14:08:30,711 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 8) in 27 ms on localhost (2/2)
2016-12-14 14:08:30,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: takeSample at KMeans.scala:378, took 0.043841 s
2016-12-14 14:08:30,712 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:08:30,718 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 1840.0 B, free 358.9 KB)
2016-12-14 14:08:30,728 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 430.0 B, free 359.3 KB)
2016-12-14 14:08:30,729 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:39370 (size: 430.0 B, free: 530.0 MB)
2016-12-14 14:08:30,729 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at KMeans.scala:396
2016-12-14 14:08:30,763 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:08:30,765 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:08:30,765 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 14:08:30,766 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:30,768 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:30,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:08:30,773 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.3 KB, free 365.6 KB)
2016-12-14 14:08:30,781 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.3 KB, free 368.8 KB)
2016-12-14 14:08:30,782 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:39370 (size: 3.3 KB, free: 530.0 MB)
2016-12-14 14:08:30,783 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:30,783 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398)
2016-12-14 14:08:30,784 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 14:08:30,785 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:08:30,786 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:08:30,786 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 11)
2016-12-14 14:08:30,786 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 10)
2016-12-14 14:08:30,790 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_0 not found, computing it
2016-12-14 14:08:30,790 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_1 not found, computing it
2016-12-14 14:08:30,790 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:30,790 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:30,790 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:30,790 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:30,791 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:30,791 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:30,791 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:30,791 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:30,804 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_1 stored as values in memory (estimated size 7.3 KB, free 376.2 KB)
2016-12-14 14:08:30,805 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_0 stored as values in memory (estimated size 7.3 KB, free 383.5 KB)
2016-12-14 14:08:30,805 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_1 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:30,806 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_0 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:30,809 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 11). 2721 bytes result sent to driver
2016-12-14 14:08:30,809 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 10). 2721 bytes result sent to driver
2016-12-14 14:08:30,815 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 11) in 30 ms on localhost (1/2)
2016-12-14 14:08:30,816 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 10) in 31 ms on localhost (2/2)
2016-12-14 14:08:30,816 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.032 s
2016-12-14 14:08:30,816 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:08:30,817 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.053233 s
2016-12-14 14:08:30,820 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 12 from persistence list
2016-12-14 14:08:30,825 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 12
2016-12-14 14:08:30,850 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:08:30,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:08:30,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 14:08:30,852 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:30,854 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:30,854 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:08:30,858 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 6.5 KB, free 390.0 KB)
2016-12-14 14:08:30,865 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.4 KB, free 393.4 KB)
2016-12-14 14:08:30,867 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:39370 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:08:30,868 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:30,868 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:08:30,869 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 14:08:30,870 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:08:30,871 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:08:30,872 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 13)
2016-12-14 14:08:30,872 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 12)
2016-12-14 14:08:30,877 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:30,877 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:30,878 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:30,878 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:30,878 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 14:08:30,878 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 14:08:30,896 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 12). 3141 bytes result sent to driver
2016-12-14 14:08:30,896 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 13). 2903 bytes result sent to driver
2016-12-14 14:08:30,903 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 12) in 32 ms on localhost (1/2)
2016-12-14 14:08:30,904 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 13) in 34 ms on localhost (2/2)
2016-12-14 14:08:30,904 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.035 s
2016-12-14 14:08:30,904 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:08:30,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.054665 s
2016-12-14 14:08:30,907 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 4.7 KB, free 398.1 KB)
2016-12-14 14:08:30,913 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1440.0 B, free 399.5 KB)
2016-12-14 14:08:30,914 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:39370 (size: 1440.0 B, free: 529.9 MB)
2016-12-14 14:08:30,914 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at KMeans.scala:396
2016-12-14 14:08:30,928 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:08:30,930 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:08:30,930 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 14:08:30,930 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:30,932 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:30,932 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:08:30,934 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.5 KB, free 406.1 KB)
2016-12-14 14:08:30,938 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 409.4 KB)
2016-12-14 14:08:30,939 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:39370 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:08:30,939 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:30,940 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398)
2016-12-14 14:08:30,940 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 14:08:30,942 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:08:30,942 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:08:30,943 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 14)
2016-12-14 14:08:30,943 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 15)
2016-12-14 14:08:30,945 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_0 not found, computing it
2016-12-14 14:08:30,946 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:30,946 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:30,946 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 14:08:30,949 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_1 not found, computing it
2016-12-14 14:08:30,949 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:30,950 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:30,950 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 14:08:30,954 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_0 stored as values in memory (estimated size 7.3 KB, free 416.8 KB)
2016-12-14 14:08:30,954 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_0 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:30,960 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_1 stored as values in memory (estimated size 7.3 KB, free 424.1 KB)
2016-12-14 14:08:30,960 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 14). 2721 bytes result sent to driver
2016-12-14 14:08:30,962 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_1 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:30,967 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 15). 2721 bytes result sent to driver
2016-12-14 14:08:30,967 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 14) in 27 ms on localhost (1/2)
2016-12-14 14:08:30,976 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 15) in 34 ms on localhost (2/2)
2016-12-14 14:08:30,976 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.036 s
2016-12-14 14:08:30,977 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:08:30,977 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.048323 s
2016-12-14 14:08:30,978 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 15 from persistence list
2016-12-14 14:08:30,981 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 14:08:31,009 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:08:31,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:08:31,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 14:08:31,011 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:31,012 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:31,013 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:08:31,015 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 6.7 KB, free 416.1 KB)
2016-12-14 14:08:31,019 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.5 KB, free 419.6 KB)
2016-12-14 14:08:31,020 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:39370 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:08:31,021 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,021 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:08:31,021 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 14:08:31,023 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:08:31,023 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:08:31,024 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 16)
2016-12-14 14:08:31,024 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 17)
2016-12-14 14:08:31,030 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,030 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,030 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,030 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,031 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 14:08:31,031 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 14:08:31,041 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 16). 3026 bytes result sent to driver
2016-12-14 14:08:31,041 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 17). 3137 bytes result sent to driver
2016-12-14 14:08:31,047 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 16) in 25 ms on localhost (1/2)
2016-12-14 14:08:31,051 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 17) in 28 ms on localhost (2/2)
2016-12-14 14:08:31,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.030 s
2016-12-14 14:08:31,051 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.042314 s
2016-12-14 14:08:31,055 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 4.9 KB, free 424.6 KB)
2016-12-14 14:08:31,068 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1538.0 B, free 426.1 KB)
2016-12-14 14:08:31,070 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:39370 (size: 1538.0 B, free: 529.9 MB)
2016-12-14 14:08:31,071 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at KMeans.scala:396
2016-12-14 14:08:31,102 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:08:31,104 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:08:31,104 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 14:08:31,105 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:31,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:31,108 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:08:31,110 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.8 KB, free 432.9 KB)
2016-12-14 14:08:31,117 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 436.3 KB)
2016-12-14 14:08:31,118 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:39370 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:08:31,118 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,119 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398)
2016-12-14 14:08:31,119 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 14:08:31,121 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:08:31,122 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:08:31,122 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 18)
2016-12-14 14:08:31,122 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 19)
2016-12-14 14:08:31,128 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_1 not found, computing it
2016-12-14 14:08:31,128 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,128 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_0 not found, computing it
2016-12-14 14:08:31,128 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,129 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,129 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 14:08:31,129 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,130 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 14:08:31,135 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_1 stored as values in memory (estimated size 7.3 KB, free 443.6 KB)
2016-12-14 14:08:31,135 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_0 stored as values in memory (estimated size 7.3 KB, free 451.0 KB)
2016-12-14 14:08:31,135 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_1 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,136 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_0 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,143 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 18). 2721 bytes result sent to driver
2016-12-14 14:08:31,143 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 19). 2721 bytes result sent to driver
2016-12-14 14:08:31,150 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 18) in 28 ms on localhost (1/2)
2016-12-14 14:08:31,152 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 19) in 31 ms on localhost (2/2)
2016-12-14 14:08:31,152 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.032 s
2016-12-14 14:08:31,152 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.050128 s
2016-12-14 14:08:31,154 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 19 from persistence list
2016-12-14 14:08:31,155 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 14:08:31,175 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:08:31,176 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:08:31,177 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 14:08:31,177 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:31,179 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:31,179 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:08:31,183 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 6.9 KB, free 443.2 KB)
2016-12-14 14:08:31,190 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.6 KB, free 446.8 KB)
2016-12-14 14:08:31,191 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:39370 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:08:31,192 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:08:31,192 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 14:08:31,194 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:08:31,195 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:08:31,195 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 21)
2016-12-14 14:08:31,195 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 20)
2016-12-14 14:08:31,201 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,201 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,201 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 14:08:31,201 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,202 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,202 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 14:08:31,208 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 21). 3260 bytes result sent to driver
2016-12-14 14:08:31,208 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 20). 2938 bytes result sent to driver
2016-12-14 14:08:31,213 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 21) in 18 ms on localhost (1/2)
2016-12-14 14:08:31,216 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 20) in 22 ms on localhost (2/2)
2016-12-14 14:08:31,216 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.023 s
2016-12-14 14:08:31,217 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,217 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.042085 s
2016-12-14 14:08:31,220 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 4.9 KB, free 451.7 KB)
2016-12-14 14:08:31,228 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1569.0 B, free 453.2 KB)
2016-12-14 14:08:31,229 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:39370 (size: 1569.0 B, free: 529.9 MB)
2016-12-14 14:08:31,230 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at KMeans.scala:396
2016-12-14 14:08:31,256 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:08:31,258 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:08:31,259 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 12 (aggregate at KMeans.scala:404)
2016-12-14 14:08:31,259 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:31,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:31,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:08:31,265 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 460.2 KB)
2016-12-14 14:08:31,271 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 463.7 KB)
2016-12-14 14:08:31,272 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:39370 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:08:31,273 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,273 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398)
2016-12-14 14:08:31,273 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 14:08:31,276 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:08:31,277 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:08:31,278 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 22)
2016-12-14 14:08:31,278 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 23)
2016-12-14 14:08:31,281 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_1 not found, computing it
2016-12-14 14:08:31,281 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_0 not found, computing it
2016-12-14 14:08:31,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,282 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 14:08:31,283 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 14:08:31,288 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_0 stored as values in memory (estimated size 7.3 KB, free 471.1 KB)
2016-12-14 14:08:31,288 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_1 stored as values in memory (estimated size 7.3 KB, free 478.4 KB)
2016-12-14 14:08:31,288 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_0 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,289 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_1 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,294 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 23). 2721 bytes result sent to driver
2016-12-14 14:08:31,294 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 22). 2721 bytes result sent to driver
2016-12-14 14:08:31,300 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 23) in 24 ms on localhost (1/2)
2016-12-14 14:08:31,301 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 22) in 26 ms on localhost (2/2)
2016-12-14 14:08:31,301 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 12 (aggregate at KMeans.scala:404) finished in 0.027 s
2016-12-14 14:08:31,302 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,302 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: aggregate at KMeans.scala:404, took 0.045418 s
2016-12-14 14:08:31,304 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 23 from persistence list
2016-12-14 14:08:31,304 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 14:08:31,328 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:08:31,330 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:08:31,330 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collect at KMeans.scala:436)
2016-12-14 14:08:31,330 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:31,331 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:31,332 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:08:31,334 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 7.2 KB, free 470.9 KB)
2016-12-14 14:08:31,337 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.6 KB, free 474.5 KB)
2016-12-14 14:08:31,338 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:39370 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:08:31,339 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,339 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:08:31,339 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 14:08:31,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:08:31,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:08:31,342 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 25)
2016-12-14 14:08:31,342 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 24)
2016-12-14 14:08:31,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 14:08:31,345 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 14:08:31,349 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 24). 3098 bytes result sent to driver
2016-12-14 14:08:31,349 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 25). 3057 bytes result sent to driver
2016-12-14 14:08:31,354 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 24) in 14 ms on localhost (1/2)
2016-12-14 14:08:31,356 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 25) in 14 ms on localhost (2/2)
2016-12-14 14:08:31,356 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collect at KMeans.scala:436) finished in 0.016 s
2016-12-14 14:08:31,356 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,356 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collect at KMeans.scala:436, took 0.027537 s
2016-12-14 14:08:31,358 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 4.8 KB, free 479.3 KB)
2016-12-14 14:08:31,366 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1530.0 B, free 480.8 KB)
2016-12-14 14:08:31,368 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:39370 (size: 1530.0 B, free: 529.9 MB)
2016-12-14 14:08:31,369 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at KMeans.scala:396
2016-12-14 14:08:31,389 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:08:31,390 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:08:31,390 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 14 (aggregate at KMeans.scala:404)
2016-12-14 14:08:31,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:31,392 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:31,392 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:08:31,394 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 7.3 KB, free 488.0 KB)
2016-12-14 14:08:31,398 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.5 KB, free 491.6 KB)
2016-12-14 14:08:31,399 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:39370 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:08:31,399 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,399 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398)
2016-12-14 14:08:31,400 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 14:08:31,401 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 26, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:08:31,401 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 27, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:08:31,402 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 26)
2016-12-14 14:08:31,402 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 27)
2016-12-14 14:08:31,405 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_0 not found, computing it
2016-12-14 14:08:31,405 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_1 not found, computing it
2016-12-14 14:08:31,405 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,405 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,405 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,405 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,406 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 14:08:31,406 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 14:08:31,408 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_1 stored as values in memory (estimated size 7.3 KB, free 498.9 KB)
2016-12-14 14:08:31,409 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_1 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,409 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_0 stored as values in memory (estimated size 7.3 KB, free 506.3 KB)
2016-12-14 14:08:31,411 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_0 in memory on localhost:39370 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,413 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 27). 2721 bytes result sent to driver
2016-12-14 14:08:31,414 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 26). 2721 bytes result sent to driver
2016-12-14 14:08:31,415 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 27) in 14 ms on localhost (1/2)
2016-12-14 14:08:31,418 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 26) in 18 ms on localhost (2/2)
2016-12-14 14:08:31,418 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 14 (aggregate at KMeans.scala:404) finished in 0.018 s
2016-12-14 14:08:31,418 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,418 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: aggregate at KMeans.scala:404, took 0.029194 s
2016-12-14 14:08:31,421 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 27 from persistence list
2016-12-14 14:08:31,422 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 14:08:31,442 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:08:31,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:08:31,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collect at KMeans.scala:436)
2016-12-14 14:08:31,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:31,446 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:31,446 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:08:31,459 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 7.4 KB, free 495.5 KB)
2016-12-14 14:08:31,459 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:39370 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:08:31,460 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 14:08:31,462 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:39370 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,463 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 14:08:31,465 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 475.6 KB)
2016-12-14 14:08:31,466 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:39370 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:08:31,467 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:39370 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:08:31,467 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 14:08:31,467 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,468 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:08:31,468 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 14:08:31,468 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:39370 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:08:31,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 14:08:31,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 14:08:31,470 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:08:31,470 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:39370 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:08:31,470 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:08:31,471 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 14:08:31,471 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 28)
2016-12-14 14:08:31,471 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 29)
2016-12-14 14:08:31,472 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:39370 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:08:31,474 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:39370 in memory (size: 9.2 KB, free: 529.9 MB)
2016-12-14 14:08:31,475 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 14:08:31,476 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:39370 in memory (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:08:31,477 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,477 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 14:08:31,477 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,477 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,478 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,478 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_1 locally
2016-12-14 14:08:31,479 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_0 locally
2016-12-14 14:08:31,479 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:39370 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:08:31,480 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 14:08:31,481 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:39370 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:08:31,482 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 14:08:31,483 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:39370 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:08:31,484 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 14:08:31,487 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 28). 3137 bytes result sent to driver
2016-12-14 14:08:31,487 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 29). 3305 bytes result sent to driver
2016-12-14 14:08:31,492 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 28) in 23 ms on localhost (1/2)
2016-12-14 14:08:31,492 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 29) in 22 ms on localhost (2/2)
2016-12-14 14:08:31,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collect at KMeans.scala:436) finished in 0.023 s
2016-12-14 14:08:31,493 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collect at KMeans.scala:436, took 0.051063 s
2016-12-14 14:08:31,496 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 31 from persistence list
2016-12-14 14:08:31,497 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 14:08:31,500 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 22.2 KB, free 379.5 KB)
2016-12-14 14:08:31,509 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.5 KB, free 384.0 KB)
2016-12-14 14:08:31,510 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:39370 (size: 4.5 KB, free: 530.0 MB)
2016-12-14 14:08:31,511 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at KMeans.scala:450
2016-12-14 14:08:31,566 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 14:08:31,583 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 34 (flatMap at KMeans.scala:451)
2016-12-14 14:08:31,584 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 14:08:31,584 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:455)
2016-12-14 14:08:31,585 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 14:08:31,585 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 14:08:31,587 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 14:08:31,596 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 6.4 KB, free 390.3 KB)
2016-12-14 14:08:31,603 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.5 KB, free 393.8 KB)
2016-12-14 14:08:31,604 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:39370 (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:08:31,605 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,608 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451)
2016-12-14 14:08:31,609 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 14:08:31,614 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:31,615 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:31,616 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 30)
2016-12-14 14:08:31,616 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 31)
2016-12-14 14:08:31,624 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:31,624 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:31,624 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:31,624 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:31,761 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 30). 2237 bytes result sent to driver
2016-12-14 14:08:31,761 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 31). 2237 bytes result sent to driver
2016-12-14 14:08:31,775 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 31) in 160 ms on localhost (1/2)
2016-12-14 14:08:31,775 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 30) in 165 ms on localhost (2/2)
2016-12-14 14:08:31,775 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,776 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (flatMap at KMeans.scala:451) finished in 0.166 s
2016-12-14 14:08:31,777 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:31,777 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:31,778 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 14:08:31,778 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:31,779 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 14:08:31,785 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 2.6 KB, free 396.4 KB)
2016-12-14 14:08:31,792 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1555.0 B, free 397.9 KB)
2016-12-14 14:08:31,793 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:39370 (size: 1555.0 B, free: 530.0 MB)
2016-12-14 14:08:31,794 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:31,795 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455)
2016-12-14 14:08:31,795 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 14:08:31,799 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 32, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:31,799 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 33, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:31,799 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 32)
2016-12-14 14:08:31,799 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 33)
2016-12-14 14:08:31,819 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:31,819 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:31,822 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 8 ms
2016-12-14 14:08:31,822 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 8 ms
2016-12-14 14:08:31,873 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 32). 4566 bytes result sent to driver
2016-12-14 14:08:31,873 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 33). 4332 bytes result sent to driver
2016-12-14 14:08:31,877 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 32) in 80 ms on localhost (1/2)
2016-12-14 14:08:31,878 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 33) in 78 ms on localhost (2/2)
2016-12-14 14:08:31,878 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:455) finished in 0.082 s
2016-12-14 14:08:31,878 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31,878 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:455, took 0.311521 s
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:08:32,046 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:08:32,047 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 7 iterations.
2016-12-14 14:08:32,047 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 8 iterations.
2016-12-14 14:08:32,069 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 1.585 seconds.
2016-12-14 14:08:32,074 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 2.5 KB, free 400.4 KB)
2016-12-14 14:08:32,081 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 950.0 B, free 401.3 KB)
2016-12-14 14:08:32,082 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:39370 (size: 950.0 B, free: 529.9 MB)
2016-12-14 14:08:32,083 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,118 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,120 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 36 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,121 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,121 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,121 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 14:08:32,122 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 14:08:32,124 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,127 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 7.4 KB, free 408.7 KB)
2016-12-14 14:08:32,133 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.9 KB, free 412.5 KB)
2016-12-14 14:08:32,134 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:39370 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,135 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,136 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,136 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 14:08:32,138 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 34, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,138 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 35, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,139 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 35)
2016-12-14 14:08:32,139 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 34)
2016-12-14 14:08:32,142 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,142 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,143 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,143 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,161 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 35). 2516 bytes result sent to driver
2016-12-14 14:08:32,161 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 34). 2516 bytes result sent to driver
2016-12-14 14:08:32,165 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 34) in 28 ms on localhost (1/2)
2016-12-14 14:08:32,166 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 35) in 28 ms on localhost (2/2)
2016-12-14 14:08:32,166 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,166 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.029 s
2016-12-14 14:08:32,166 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,166 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,166 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 14:08:32,167 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,167 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,168 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 2.9 KB, free 415.4 KB)
2016-12-14 14:08:32,171 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 1668.0 B, free 417.1 KB)
2016-12-14 14:08:32,171 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:39370 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:32,172 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,172 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,172 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 14:08:32,173 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 36, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,174 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 37, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,174 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 36)
2016-12-14 14:08:32,174 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 37)
2016-12-14 14:08:32,177 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,177 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,178 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,178 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,192 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 36). 1725 bytes result sent to driver
2016-12-14 14:08:32,192 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 37). 1724 bytes result sent to driver
2016-12-14 14:08:32,196 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 36) in 23 ms on localhost (1/2)
2016-12-14 14:08:32,196 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 37) in 23 ms on localhost (2/2)
2016-12-14 14:08:32,196 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,196 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.024 s
2016-12-14 14:08:32,196 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.077531 s
2016-12-14 14:08:32,200 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 2.5 KB, free 419.6 KB)
2016-12-14 14:08:32,205 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 707.0 B, free 420.3 KB)
2016-12-14 14:08:32,206 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:39370 (size: 707.0 B, free: 529.9 MB)
2016-12-14 14:08:32,207 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,225 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,227 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 38 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,227 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,227 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,228 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 14:08:32,228 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 14:08:32,229 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,231 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 7.4 KB, free 427.6 KB)
2016-12-14 14:08:32,236 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.9 KB, free 431.5 KB)
2016-12-14 14:08:32,236 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:39370 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,237 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,237 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,237 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 14:08:32,238 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 38, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,239 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 39, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,239 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 38)
2016-12-14 14:08:32,239 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 39)
2016-12-14 14:08:32,244 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,244 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,245 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,245 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,258 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 39). 2516 bytes result sent to driver
2016-12-14 14:08:32,258 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 38). 2516 bytes result sent to driver
2016-12-14 14:08:32,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 39) in 22 ms on localhost (1/2)
2016-12-14 14:08:32,261 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 38) in 23 ms on localhost (2/2)
2016-12-14 14:08:32,261 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.024 s
2016-12-14 14:08:32,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 14:08:32,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,264 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 2.9 KB, free 434.4 KB)
2016-12-14 14:08:32,267 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 1665.0 B, free 436.0 KB)
2016-12-14 14:08:32,267 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:39370 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:08:32,268 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,268 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,269 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 14:08:32,270 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,271 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,271 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 40)
2016-12-14 14:08:32,271 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 41)
2016-12-14 14:08:32,272 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,272 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,273 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,273 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,280 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 41). 1723 bytes result sent to driver
2016-12-14 14:08:32,280 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 40). 1724 bytes result sent to driver
2016-12-14 14:08:32,283 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 41) in 12 ms on localhost (1/2)
2016-12-14 14:08:32,283 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 40) in 13 ms on localhost (2/2)
2016-12-14 14:08:32,283 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.014 s
2016-12-14 14:08:32,283 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,283 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.058169 s
2016-12-14 14:08:32,286 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 2 iterations
2016-12-14 14:08:32,286 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 2 iterations
2016-12-14 14:08:32,286 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 2 iterations
2016-12-14 14:08:32,287 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 1808.0 B, free 437.8 KB)
2016-12-14 14:08:32,292 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 470.0 B, free 438.3 KB)
2016-12-14 14:08:32,293 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:39370 (size: 470.0 B, free: 529.9 MB)
2016-12-14 14:08:32,294 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,311 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 40 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 14:08:32,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 14:08:32,318 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,320 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 7.2 KB, free 445.5 KB)
2016-12-14 14:08:32,324 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KB, free 449.4 KB)
2016-12-14 14:08:32,325 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:39370 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,326 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,327 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,327 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 14:08:32,329 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 42, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,329 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 43, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,329 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 42)
2016-12-14 14:08:32,329 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 43)
2016-12-14 14:08:32,331 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,332 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,332 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,332 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,338 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 43). 2444 bytes result sent to driver
2016-12-14 14:08:32,338 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 42). 2444 bytes result sent to driver
2016-12-14 14:08:32,341 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 43) in 12 ms on localhost (1/2)
2016-12-14 14:08:32,342 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 42) in 14 ms on localhost (2/2)
2016-12-14 14:08:32,342 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 14:08:32,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 14:08:32,342 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,343 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,344 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 2.9 KB, free 452.3 KB)
2016-12-14 14:08:32,346 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 1667.0 B, free 453.9 KB)
2016-12-14 14:08:32,347 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:39370 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:08:32,347 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,347 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,347 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 14:08:32,348 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 44, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,349 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 45, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,350 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 44)
2016-12-14 14:08:32,350 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 45)
2016-12-14 14:08:32,351 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,351 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,351 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:32,352 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,357 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 44). 1538 bytes result sent to driver
2016-12-14 14:08:32,357 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 45). 1575 bytes result sent to driver
2016-12-14 14:08:32,361 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 45) in 11 ms on localhost (1/2)
2016-12-14 14:08:32,361 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 44) in 13 ms on localhost (2/2)
2016-12-14 14:08:32,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.013 s
2016-12-14 14:08:32,361 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.049675 s
2016-12-14 14:08:32,363 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 3 iterations
2016-12-14 14:08:32,364 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 1552.0 B, free 455.4 KB)
2016-12-14 14:08:32,369 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 406.0 B, free 455.8 KB)
2016-12-14 14:08:32,370 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:39370 (size: 406.0 B, free: 529.9 MB)
2016-12-14 14:08:32,371 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,387 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,388 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 42 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 14:08:32,389 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 14:08:32,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,392 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 7.2 KB, free 463.0 KB)
2016-12-14 14:08:32,395 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.9 KB, free 466.9 KB)
2016-12-14 14:08:32,396 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:39370 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,396 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,397 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,397 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 14:08:32,398 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 46, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,399 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 47, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,400 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 47)
2016-12-14 14:08:32,400 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 46)
2016-12-14 14:08:32,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,402 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,403 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,408 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 46). 2420 bytes result sent to driver
2016-12-14 14:08:32,408 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 47). 2420 bytes result sent to driver
2016-12-14 14:08:32,411 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 46) in 14 ms on localhost (1/2)
2016-12-14 14:08:32,411 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 47) in 12 ms on localhost (2/2)
2016-12-14 14:08:32,411 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,411 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 14:08:32,411 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,412 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,412 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 14:08:32,412 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,412 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,414 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 2.9 KB, free 469.8 KB)
2016-12-14 14:08:32,419 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1668.0 B, free 471.4 KB)
2016-12-14 14:08:32,420 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:39370 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:32,421 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,421 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,421 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 14:08:32,423 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 48, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,424 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 49, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,425 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 49)
2016-12-14 14:08:32,425 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 48)
2016-12-14 14:08:32,426 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,426 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,427 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,427 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,433 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 48). 1501 bytes result sent to driver
2016-12-14 14:08:32,433 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 49). 1501 bytes result sent to driver
2016-12-14 14:08:32,436 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 48) in 13 ms on localhost (1/2)
2016-12-14 14:08:32,436 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 49) in 12 ms on localhost (2/2)
2016-12-14 14:08:32,436 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.014 s
2016-12-14 14:08:32,436 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,437 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.049339 s
2016-12-14 14:08:32,439 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 1552.0 B, free 472.9 KB)
2016-12-14 14:08:32,443 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 356.0 B, free 473.3 KB)
2016-12-14 14:08:32,444 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:39370 (size: 356.0 B, free: 529.9 MB)
2016-12-14 14:08:32,445 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,462 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,463 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 44 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,463 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,464 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,464 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 14:08:32,464 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 14:08:32,466 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,468 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 7.2 KB, free 480.5 KB)
2016-12-14 14:08:32,473 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.9 KB, free 484.3 KB)
2016-12-14 14:08:32,474 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:39370 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,475 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,475 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,475 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 14:08:32,478 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 50, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,479 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 51, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,480 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 50)
2016-12-14 14:08:32,480 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 51)
2016-12-14 14:08:32,482 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,482 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,482 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,482 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,488 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 51). 2420 bytes result sent to driver
2016-12-14 14:08:32,488 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 50). 2420 bytes result sent to driver
2016-12-14 14:08:32,492 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 51) in 13 ms on localhost (1/2)
2016-12-14 14:08:32,492 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 50) in 15 ms on localhost (2/2)
2016-12-14 14:08:32,492 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.016 s
2016-12-14 14:08:32,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 14:08:32,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,494 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,496 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 2.9 KB, free 487.2 KB)
2016-12-14 14:08:32,500 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 1664.0 B, free 488.8 KB)
2016-12-14 14:08:32,500 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:39370 (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:08:32,501 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,502 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,502 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 14:08:32,503 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 52, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,504 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 53, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,504 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 52)
2016-12-14 14:08:32,504 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 53)
2016-12-14 14:08:32,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:32,506 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:32,512 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 52). 1501 bytes result sent to driver
2016-12-14 14:08:32,512 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 53). 1501 bytes result sent to driver
2016-12-14 14:08:32,514 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 52) in 11 ms on localhost (1/2)
2016-12-14 14:08:32,515 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 53) in 11 ms on localhost (2/2)
2016-12-14 14:08:32,515 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.012 s
2016-12-14 14:08:32,515 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,515 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.053366 s
2016-12-14 14:08:32,517 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 1552.0 B, free 490.4 KB)
2016-12-14 14:08:32,521 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 356.0 B, free 490.7 KB)
2016-12-14 14:08:32,522 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:39370 (size: 356.0 B, free: 529.9 MB)
2016-12-14 14:08:32,522 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,539 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,540 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 46 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,541 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 14:08:32,542 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 14:08:32,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,546 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 7.2 KB, free 497.9 KB)
2016-12-14 14:08:32,550 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.9 KB, free 501.8 KB)
2016-12-14 14:08:32,550 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:39370 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,551 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,552 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,552 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 14:08:32,554 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 54, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,555 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 55, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,555 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 55)
2016-12-14 14:08:32,555 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 54)
2016-12-14 14:08:32,558 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,558 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,558 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,558 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,563 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 55). 2420 bytes result sent to driver
2016-12-14 14:08:32,563 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 54). 2420 bytes result sent to driver
2016-12-14 14:08:32,566 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 55) in 12 ms on localhost (1/2)
2016-12-14 14:08:32,567 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 54) in 13 ms on localhost (2/2)
2016-12-14 14:08:32,567 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 14:08:32,567 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,567 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,567 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,567 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 14:08:32,568 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,568 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,570 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 2.9 KB, free 504.7 KB)
2016-12-14 14:08:32,574 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 1668.0 B, free 506.3 KB)
2016-12-14 14:08:32,575 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:39370 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:32,576 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,576 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,576 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 14:08:32,578 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 56, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,578 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 57, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,579 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 56)
2016-12-14 14:08:32,579 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 57)
2016-12-14 14:08:32,580 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,581 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,581 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,581 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:32,591 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 57). 1501 bytes result sent to driver
2016-12-14 14:08:32,591 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 56). 1501 bytes result sent to driver
2016-12-14 14:08:32,593 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 57) in 15 ms on localhost (1/2)
2016-12-14 14:08:32,594 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 56) in 17 ms on localhost (2/2)
2016-12-14 14:08:32,594 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.017 s
2016-12-14 14:08:32,594 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,594 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.054852 s
2016-12-14 14:08:32,595 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 6 iterations
2016-12-14 14:08:32,596 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 6 iterations
2016-12-14 14:08:32,596 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 1048.0 B, free 507.3 KB)
2016-12-14 14:08:32,598 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 285.0 B, free 507.6 KB)
2016-12-14 14:08:32,599 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:39370 (size: 285.0 B, free: 529.9 MB)
2016-12-14 14:08:32,599 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,607 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,608 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 48 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,609 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,609 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,609 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 14:08:32,609 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 14:08:32,611 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,613 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 7.1 KB, free 514.7 KB)
2016-12-14 14:08:32,625 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:39370 in memory (size: 1569.0 B, free: 529.9 MB)
2016-12-14 14:08:32,627 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.8 KB, free 507.6 KB)
2016-12-14 14:08:32,627 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:39370 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:32,628 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:39370 (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:08:32,628 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 14:08:32,629 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,629 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 14:08:32,629 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:39370 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,630 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 14:08:32,630 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 58, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,631 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 59, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,631 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 59)
2016-12-14 14:08:32,631 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 58)
2016-12-14 14:08:32,633 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 14:08:32,634 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:39370 in memory (size: 356.0 B, free: 529.9 MB)
2016-12-14 14:08:32,634 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,634 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,634 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,634 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,635 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 14:08:32,637 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 31
2016-12-14 14:08:32,638 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:39370 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:08:32,638 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 14:08:32,639 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 14:08:32,640 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:39370 in memory (size: 4.5 KB, free: 529.9 MB)
2016-12-14 14:08:32,640 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 58). 2372 bytes result sent to driver
2016-12-14 14:08:32,640 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 59). 2372 bytes result sent to driver
2016-12-14 14:08:32,641 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:39370 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:08:32,642 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 58) in 12 ms on localhost (1/2)
2016-12-14 14:08:32,643 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 59) in 13 ms on localhost (2/2)
2016-12-14 14:08:32,643 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,643 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.014 s
2016-12-14 14:08:32,643 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:39370 in memory (size: 950.0 B, free: 529.9 MB)
2016-12-14 14:08:32,643 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,644 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,644 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 14:08:32,644 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 14:08:32,644 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,644 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 14:08:32,645 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 14:08:32,645 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 14:08:32,645 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,645 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 14:08:32,646 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 14:08:32,646 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 14:08:32,646 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 14:08:32,646 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 14:08:32,646 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 14:08:32,647 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 2.9 KB, free 446.5 KB)
2016-12-14 14:08:32,647 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:39370 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:08:32,648 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 14:08:32,648 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 14:08:32,648 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 14:08:32,648 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 14:08:32,648 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 14:08:32,649 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 14:08:32,649 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 14:08:32,649 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 14:08:32,649 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 14:08:32,650 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:39370 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:32,650 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 14:08:32,651 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:39370 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,651 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 1668.0 B, free 435.6 KB)
2016-12-14 14:08:32,651 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:39370 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:32,651 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 14:08:32,652 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 14:08:32,652 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,652 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,652 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:39370 in memory (size: 1440.0 B, free: 529.9 MB)
2016-12-14 14:08:32,652 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 14:08:32,653 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:39370 in memory (size: 1538.0 B, free: 529.9 MB)
2016-12-14 14:08:32,653 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 60, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,654 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 61, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,654 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 14:08:32,654 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 61)
2016-12-14 14:08:32,654 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 14:08:32,654 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 14:08:32,654 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 60)
2016-12-14 14:08:32,655 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:39370 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:08:32,655 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 14:08:32,655 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,655 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:32,655 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:39370 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,655 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,656 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,656 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 14:08:32,656 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 14:08:32,656 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:39370 in memory (size: 707.0 B, free: 529.9 MB)
2016-12-14 14:08:32,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 14:08:32,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 14:08:32,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 14:08:32,657 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 14:08:32,657 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:39370 in memory (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:08:32,658 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 14:08:32,658 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:39370 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:08:32,658 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 14:08:32,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 14:08:32,659 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:39370 in memory (size: 470.0 B, free: 530.0 MB)
2016-12-14 14:08:32,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 14:08:32,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 14:08:32,659 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 14:08:32,660 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 14:08:32,660 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:39370 in memory (size: 1530.0 B, free: 530.0 MB)
2016-12-14 14:08:32,660 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 14:08:32,660 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 61). 1390 bytes result sent to driver
2016-12-14 14:08:32,660 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 60). 1390 bytes result sent to driver
2016-12-14 14:08:32,660 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 14:08:32,661 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:39370 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:08:32,661 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 14:08:32,662 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:39370 in memory (size: 3.9 KB, free: 530.0 MB)
2016-12-14 14:08:32,662 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 14:08:32,663 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 14:08:32,663 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:39370 in memory (size: 406.0 B, free: 530.0 MB)
2016-12-14 14:08:32,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 14:08:32,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 14:08:32,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 14:08:32,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 14:08:32,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 14:08:32,664 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 60) in 11 ms on localhost (1/2)
2016-12-14 14:08:32,664 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 14:08:32,665 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 61) in 10 ms on localhost (2/2)
2016-12-14 14:08:32,665 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.012 s
2016-12-14 14:08:32,665 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 14:08:32,665 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,665 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: collectAsMap at KMeans.scala:302, took 0.057604 s
2016-12-14 14:08:32,665 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:39370 in memory (size: 1664.0 B, free: 530.0 MB)
2016-12-14 14:08:32,666 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 14:08:32,666 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:39370 in memory (size: 3.9 KB, free: 530.0 MB)
2016-12-14 14:08:32,667 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 14:08:32,667 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 14:08:32,668 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 1048.0 B, free 340.6 KB)
2016-12-14 14:08:32,668 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:39370 in memory (size: 356.0 B, free: 530.0 MB)
2016-12-14 14:08:32,668 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 14:08:32,669 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 14:08:32,669 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 14:08:32,669 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 14:08:32,669 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 14:08:32,670 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 23
2016-12-14 14:08:32,670 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 14:08:32,671 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 27
2016-12-14 14:08:32,671 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 14:08:32,671 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 14:08:32,671 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 14:08:32,672 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 14:08:32,672 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 15
2016-12-14 14:08:32,673 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 14:08:32,673 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 19
2016-12-14 14:08:32,673 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 282.0 B, free 339.0 KB)
2016-12-14 14:08:32,674 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:39370 (size: 282.0 B, free: 530.0 MB)
2016-12-14 14:08:32,674 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,674 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:39370 in memory (size: 430.0 B, free: 530.0 MB)
2016-12-14 14:08:32,675 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 14:08:32,692 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 50 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,694 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 14:08:32,695 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 14:08:32,696 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,698 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 7.1 KB, free 343.9 KB)
2016-12-14 14:08:32,702 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 3.8 KB, free 347.7 KB)
2016-12-14 14:08:32,703 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:39370 (size: 3.8 KB, free: 530.0 MB)
2016-12-14 14:08:32,704 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,704 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,704 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 14:08:32,706 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 62, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,707 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 63, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,707 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 62)
2016-12-14 14:08:32,707 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 63)
2016-12-14 14:08:32,712 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,712 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,713 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,713 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,719 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 62). 2372 bytes result sent to driver
2016-12-14 14:08:32,719 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 63). 2372 bytes result sent to driver
2016-12-14 14:08:32,724 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 62) in 19 ms on localhost (1/2)
2016-12-14 14:08:32,724 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 63) in 18 ms on localhost (2/2)
2016-12-14 14:08:32,724 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,724 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.019 s
2016-12-14 14:08:32,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 14:08:32,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,725 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,726 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 2.9 KB, free 350.6 KB)
2016-12-14 14:08:32,730 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 1668.0 B, free 352.3 KB)
2016-12-14 14:08:32,731 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:39370 (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:08:32,731 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,732 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,732 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 14:08:32,733 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 64, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,734 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 65, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,734 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 64)
2016-12-14 14:08:32,734 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 65)
2016-12-14 14:08:32,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:32,736 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:32,744 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 65). 1390 bytes result sent to driver
2016-12-14 14:08:32,744 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 64). 1390 bytes result sent to driver
2016-12-14 14:08:32,746 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 65) in 12 ms on localhost (1/2)
2016-12-14 14:08:32,747 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 64) in 14 ms on localhost (2/2)
2016-12-14 14:08:32,747 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.014 s
2016-12-14 14:08:32,747 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,748 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: collectAsMap at KMeans.scala:302, took 0.055253 s
2016-12-14 14:08:32,749 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 8 iterations
2016-12-14 14:08:32,749 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 8 iterations
2016-12-14 14:08:32,750 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 544.0 B, free 352.8 KB)
2016-12-14 14:08:32,754 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 216.0 B, free 353.0 KB)
2016-12-14 14:08:32,754 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:39370 (size: 216.0 B, free: 530.0 MB)
2016-12-14 14:08:32,755 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at KMeans.scala:276
2016-12-14 14:08:32,772 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:08:32,773 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 52 (mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:08:32,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (collectAsMap at KMeans.scala:302)
2016-12-14 14:08:32,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 34)
2016-12-14 14:08:32,774 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 34)
2016-12-14 14:08:32,775 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:08:32,776 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 7.0 KB, free 360.0 KB)
2016-12-14 14:08:32,778 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.8 KB, free 363.9 KB)
2016-12-14 14:08:32,779 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:39370 (size: 3.8 KB, free: 530.0 MB)
2016-12-14 14:08:32,779 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,780 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279)
2016-12-14 14:08:32,780 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 14:08:32,781 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 66, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,782 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 67, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:08:32,782 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 66)
2016-12-14 14:08:32,782 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 67)
2016-12-14 14:08:32,785 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,786 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:08:32,786 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,786 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:08:32,792 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 67). 2324 bytes result sent to driver
2016-12-14 14:08:32,793 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 66). 2324 bytes result sent to driver
2016-12-14 14:08:32,794 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 67) in 11 ms on localhost (1/2)
2016-12-14 14:08:32,794 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 66) in 13 ms on localhost (2/2)
2016-12-14 14:08:32,794 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 34 (mapPartitions at KMeans.scala:279) finished in 0.013 s
2016-12-14 14:08:32,794 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,794 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:32,795 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:32,795 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 35)
2016-12-14 14:08:32,795 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:32,795 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:08:32,797 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 2.9 KB, free 366.8 KB)
2016-12-14 14:08:32,800 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 1668.0 B, free 368.4 KB)
2016-12-14 14:08:32,801 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:39370 (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:08:32,801 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302)
2016-12-14 14:08:32,802 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 14:08:32,803 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 68, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,803 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 69, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:32,803 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 69)
2016-12-14 14:08:32,803 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 68)
2016-12-14 14:08:32,804 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,804 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:32,805 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,805 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:32,809 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 69). 1276 bytes result sent to driver
2016-12-14 14:08:32,809 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 68). 1276 bytes result sent to driver
2016-12-14 14:08:32,812 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 68) in 9 ms on localhost (1/2)
2016-12-14 14:08:32,812 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 69) in 9 ms on localhost (2/2)
2016-12-14 14:08:32,812 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (collectAsMap at KMeans.scala:302) finished in 0.010 s
2016-12-14 14:08:32,812 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,813 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: collectAsMap at KMeans.scala:302, took 0.040601 s
2016-12-14 14:08:32,814 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 9 iterations
2016-12-14 14:08:32,814 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 9 iterations
2016-12-14 14:08:32,816 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.744 seconds.
2016-12-14 14:08:32,817 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 9 iterations.
2016-12-14 14:08:32,820 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 63.87383806036277.
2016-12-14 14:08:32,821 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 9 from persistence list
2016-12-14 14:08:32,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 14:08:32,823 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:08:32,825 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 296.0 B, free 364.6 KB)
2016-12-14 14:08:32,831 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 248.0 B, free 364.8 KB)
2016-12-14 14:08:32,832 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:39370 (size: 248.0 B, free: 530.0 MB)
2016-12-14 14:08:32,832 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at KMeansModel.scala:87
2016-12-14 14:08:32,846 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 14:08:32,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 14:08:32,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 36 (sum at KMeansModel.scala:88)
2016-12-14 14:08:32,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:32,848 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:32,848 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 36 (MapPartitionsRDD[54] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 14:08:32,850 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 4.7 KB, free 369.5 KB)
2016-12-14 14:08:32,855 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.7 KB, free 372.2 KB)
2016-12-14 14:08:32,855 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:39370 (size: 2.7 KB, free: 530.0 MB)
2016-12-14 14:08:32,856 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,856 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 36 (MapPartitionsRDD[54] at map at KMeansModel.scala:88)
2016-12-14 14:08:32,857 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 14:08:32,858 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:32,858 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:32,858 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 70)
2016-12-14 14:08:32,858 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 71)
2016-12-14 14:08:32,861 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,861 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,865 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 71). 2064 bytes result sent to driver
2016-12-14 14:08:32,865 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 70). 2064 bytes result sent to driver
2016-12-14 14:08:32,867 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 71) in 8 ms on localhost (1/2)
2016-12-14 14:08:32,867 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 70) in 10 ms on localhost (2/2)
2016-12-14 14:08:32,867 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 36 (sum at KMeansModel.scala:88) finished in 0.010 s
2016-12-14 14:08:32,867 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,867 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: sum at KMeansModel.scala:88, took 0.021097 s
2016-12-14 14:08:32,868 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 63.87383806036277
2016-12-14 14:08:32,880 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:114
2016-12-14 14:08:32,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (foreach at K_means.scala:114) with 2 output partitions
2016-12-14 14:08:32,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (foreach at K_means.scala:114)
2016-12-14 14:08:32,881 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:32,882 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:32,882 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (MapPartitionsRDD[8] at map at K_means.scala:105), which has no missing parents
2016-12-14 14:08:32,884 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 4.4 KB, free 376.7 KB)
2016-12-14 14:08:32,888 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.5 KB, free 379.2 KB)
2016-12-14 14:08:32,888 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:39370 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:32,889 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,889 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[8] at map at K_means.scala:105)
2016-12-14 14:08:32,890 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 2 tasks
2016-12-14 14:08:32,891 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 72, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:32,891 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 37.0 (TID 73, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:32,891 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 37.0 (TID 73)
2016-12-14 14:08:32,891 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 72)
2016-12-14 14:08:32,893 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:32,893 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,893 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.410983961066749,-5.644334710390876] belong to cluster 2
2016-12-14 14:08:32,893 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8271359726790233,-5.641331045573369] belong to cluster 1
2016-12-14 14:08:32,893 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.8423845166376935,-5.559393251411284] belong to cluster 2
2016-12-14 14:08:32,893 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7959524821488415,-5.145166883252961] belong to cluster 1
2016-12-14 14:08:32,893 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.068739369853676,-5.582116315621753] belong to cluster 0
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.621523558165056,-5.177378121203952] belong to cluster 1
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.323798646780975,-5.1523921559303485] belong to cluster 2
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.764905900474237,-5.003599415056986] belong to cluster 1
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.204008342119569,-4.949637118042831] belong to cluster 2
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7827501159516568,-5.648648294377431] belong to cluster 1
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.441000208833702,-4.612185799078262] belong to cluster 2
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2314457367733738,-6.062506444034109] belong to cluster 1
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.319458605679827,-4.6372331864346314] belong to cluster 2
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.690452415602341,-5.232619219784294] belong to cluster 1
2016-12-14 14:08:32,894 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.646338048234346,-5.003014088105591] belong to cluster 2
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.884861104459153,-5.485129079769269] belong to cluster 1
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.890080080558556,-4.893518592594351] belong to cluster 2
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.623384532447338,-4.743925704477388] belong to cluster 1
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.098617951362883,-4.8314394630914865] belong to cluster 2
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8374984110638515,-5.208032027056244] belong to cluster 1
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.318548594459688,-5.509777694580084] belong to cluster 2
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.004816308444068,-5.966658744481553] belong to cluster 1
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.731772064027652,-5.722759067810006] belong to cluster 2
2016-12-14 14:08:32,895 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.898200379511916,-5.336244362769233] belong to cluster 1
2016-12-14 14:08:32,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.324210888152043,-4.94404473249009] belong to cluster 2
2016-12-14 14:08:32,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.723909121785875,-5.086983541937878] belong to cluster 1
2016-12-14 14:08:32,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.756538259473318,-5.047995695147128] belong to cluster 2
2016-12-14 14:08:32,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.2861426515079915,-4.811443821323552] belong to cluster 1
2016-12-14 14:08:32,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.675856526152229,-4.635062261498171] belong to cluster 2
2016-12-14 14:08:32,896 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8677998808418255,-6.500918630222436] belong to cluster 1
2016-12-14 14:08:32,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.974374086654397,-4.645197184272854] belong to cluster 2
2016-12-14 14:08:32,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.127473773983595,-6.6594780753688365] belong to cluster 1
2016-12-14 14:08:32,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.401503543434129,-5.280911288062217] belong to cluster 2
2016-12-14 14:08:32,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.888816894657163,-6.132813405405575] belong to cluster 1
2016-12-14 14:08:32,897 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.740222147752621,-4.912466110630076] belong to cluster 2
2016-12-14 14:08:32,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.863020365303845,-5.633860398559866] belong to cluster 1
2016-12-14 14:08:32,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.804261813862112,-4.306298969030525] belong to cluster 2
2016-12-14 14:08:32,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.312265136352209,-6.19396781890072] belong to cluster 1
2016-12-14 14:08:32,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.866876136970037,-4.811505243406318] belong to cluster 2
2016-12-14 14:08:32,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.923996908865233,-5.835197369614942] belong to cluster 1
2016-12-14 14:08:32,898 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.842470045115695,-5.103543590146349] belong to cluster 2
2016-12-14 14:08:32,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2008113964698386,-5.712591552397877] belong to cluster 1
2016-12-14 14:08:32,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.886581326729738,-5.023101706000198] belong to cluster 2
2016-12-14 14:08:32,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.968108190479276,-5.754755485468792] belong to cluster 1
2016-12-14 14:08:32,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.153033375949516,-5.333794907300257] belong to cluster 2
2016-12-14 14:08:32,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.2954854028828655,-5.456339302434558] belong to cluster 1
2016-12-14 14:08:32,899 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.602879764659478,-4.563155005639502] belong to cluster 2
2016-12-14 14:08:32,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2082145601190897,-5.420246409238966] belong to cluster 1
2016-12-14 14:08:32,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.809151005189907,-4.967707209210419] belong to cluster 2
2016-12-14 14:08:32,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1551720110990735,-5.283514141740633] belong to cluster 1
2016-12-14 14:08:32,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.043070078222529,-5.302881494168668] belong to cluster 0
2016-12-14 14:08:32,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0034258709450925,-5.1756673908958115] belong to cluster 1
2016-12-14 14:08:32,900 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.92541532295673,-4.739798674896673] belong to cluster 2
2016-12-14 14:08:32,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.042287100237849,-5.452611045399396] belong to cluster 1
2016-12-14 14:08:32,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.127827706067016,-5.656659017796284] belong to cluster 0
2016-12-14 14:08:32,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.948952150946221,-5.6894082935590875] belong to cluster 1
2016-12-14 14:08:32,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.482158043689454,-5.133598036104063] belong to cluster 0
2016-12-14 14:08:32,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8715218294063902,-5.634013796769307] belong to cluster 1
2016-12-14 14:08:32,901 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.861101081733914,-5.272841181154137] belong to cluster 0
2016-12-14 14:08:32,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8784951897522135,-5.1246479001753515] belong to cluster 1
2016-12-14 14:08:32,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.908223018461111,-5.861891777039142] belong to cluster 0
2016-12-14 14:08:32,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9228810464795805,-5.117330651371289] belong to cluster 1
2016-12-14 14:08:32,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.030726342867909,-4.123372041758317] belong to cluster 2
2016-12-14 14:08:32,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1012657606613763,-5.732803739056605] belong to cluster 1
2016-12-14 14:08:32,902 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.443348194774275,-5.667100736989847] belong to cluster 0
2016-12-14 14:08:32,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.86370642438607,-6.134706363368474] belong to cluster 1
2016-12-14 14:08:32,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.831015891657026,-5.069175560202079] belong to cluster 0
2016-12-14 14:08:32,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9141836207070524,-6.414745658816243] belong to cluster 1
2016-12-14 14:08:32,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.429477331427224,-6.095104360181011] belong to cluster 0
2016-12-14 14:08:32,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8374984110638515,-5.208032027056244] belong to cluster 1
2016-12-14 14:08:32,903 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.1732780448024585,-5.556762131846504] belong to cluster 0
2016-12-14 14:08:32,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.644343250850438,-5.391916826532574] belong to cluster 1
2016-12-14 14:08:32,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.313683550443706,-5.0985691241824505] belong to cluster 0
2016-12-14 14:08:32,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8861146331025513,-5.921523739230576] belong to cluster 1
2016-12-14 14:08:32,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.67672196073637,-5.530004014181995] belong to cluster 0
2016-12-14 14:08:32,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8374984110638515,-5.208032027056244] belong to cluster 1
2016-12-14 14:08:32,904 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.855937315292797,-4.538308305632156] belong to cluster 2
2016-12-14 14:08:32,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5295004329290633,-4.834473681952901] belong to cluster 1
2016-12-14 14:08:32,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.096610397091617,-4.775416676961808] belong to cluster 2
2016-12-14 14:08:32,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.921020072197298,-5.5507830680978545] belong to cluster 1
2016-12-14 14:08:32,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.416086675996883,-5.433542721791678] belong to cluster 0
2016-12-14 14:08:32,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7412041870366477,-5.585783150574148] belong to cluster 1
2016-12-14 14:08:32,905 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.46059187964747,-5.3554539902367475] belong to cluster 0
2016-12-14 14:08:32,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.659132016216582,-4.38185836333945] belong to cluster 1
2016-12-14 14:08:32,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.000108477439358,-6.486268275072539] belong to cluster 0
2016-12-14 14:08:32,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5130466549506205,-4.9804161562181966] belong to cluster 1
2016-12-14 14:08:32,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.306029958992944,-5.567989301781532] belong to cluster 0
2016-12-14 14:08:32,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1058289964982704,-5.51064098850504] belong to cluster 1
2016-12-14 14:08:32,906 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.80967292235079,-4.553709794287482] belong to cluster 2
2016-12-14 14:08:32,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.3025101436062654,-5.757419761229973] belong to cluster 1
2016-12-14 14:08:32,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.939510356803821,-5.691505702063138] belong to cluster 0
2016-12-14 14:08:32,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.795677907035518,-5.072042247910873] belong to cluster 1
2016-12-14 14:08:32,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.7094404700579355,-4.70914476904438] belong to cluster 2
2016-12-14 14:08:32,907 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.973769726769464,-5.825091276285579] belong to cluster 1
2016-12-14 14:08:32,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.01060858208193,-5.771497197773067] belong to cluster 0
2016-12-14 14:08:32,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.671021800955963,-5.094147392532501] belong to cluster 1
2016-12-14 14:08:32,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.89901134796453,-5.110692744238834] belong to cluster 2
2016-12-14 14:08:32,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.968657340705923,-5.901004756152968] belong to cluster 1
2016-12-14 14:08:32,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.787196747088665,-5.648110256565619] belong to cluster 0
2016-12-14 14:08:32,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.807430782919322,-5.429734582979489] belong to cluster 1
2016-12-14 14:08:32,908 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.125536928481306,-5.873090681087805] belong to cluster 0
2016-12-14 14:08:32,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.796137685628044,-6.000162916941911] belong to cluster 0
2016-12-14 14:08:32,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.76896828070811,-5.135586733385764] belong to cluster 2
2016-12-14 14:08:32,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.44375385076589,-5.633921820642632] belong to cluster 2
2016-12-14 14:08:32,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.8020127455205746,-5.198298478979607] belong to cluster 2
2016-12-14 14:08:32,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.9754044205620485,-5.818913563781444] belong to cluster 0
2016-12-14 14:08:32,909 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.634197078291286,-5.103868846259493] belong to cluster 0
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.692310304130672,-4.489119787232876] belong to cluster 2
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.898907500152001,-5.777242981535249] belong to cluster 0
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.598477584989974,-5.390114120097761] belong to cluster 2
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.352304023068358,-5.6874663218580155] belong to cluster 0
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.151779847306118,-4.897400247838951] belong to cluster 2
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.743685996078847,-6.685247766785315] belong to cluster 0
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.6065668077214506,-5.598614941747458] belong to cluster 2
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.670081470916108,-5.09639819924599] belong to cluster 0
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.759875957134746,-4.313616217834587] belong to cluster 2
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.954445702158948,-5.1709224417262565] belong to cluster 2
2016-12-14 14:08:32,910 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.554640878489254,-5.543680639585998] belong to cluster 2
2016-12-14 14:08:32,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.290983204681542,-4.81325893610296] belong to cluster 0
2016-12-14 14:08:32,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.5011530270551185,-4.594148864107075] belong to cluster 2
2016-12-14 14:08:32,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.587864718803637,-6.000488173055055] belong to cluster 0
2016-12-14 14:08:32,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.000256901887883,-4.052231776946848] belong to cluster 2
2016-12-14 14:08:32,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.656329954492275,-5.453630339686286] belong to cluster 0
2016-12-14 14:08:32,911 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.0224411584664495,-5.212439625763012] belong to cluster 2
2016-12-14 14:08:32,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.416206022920104,-5.36277123904081] belong to cluster 0
2016-12-14 14:08:32,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.773678853936154,-4.766830432783661] belong to cluster 2
2016-12-14 14:08:32,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.680196567253375,-5.150221230993888] belong to cluster 2
2016-12-14 14:08:32,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.4953876429524025,-5.190363310586703] belong to cluster 2
2016-12-14 14:08:32,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.618996828956242,-5.686205979986095] belong to cluster 0
2016-12-14 14:08:32,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.3364790958172765,-5.0629081597288135] belong to cluster 2
2016-12-14 14:08:32,912 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.82564649241252,-5.4973325816026835] belong to cluster 0
2016-12-14 14:08:32,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.438916039815672,-5.782959935852109] belong to cluster 2
2016-12-14 14:08:32,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.433793982618726,-5.72399490698769] belong to cluster 0
2016-12-14 14:08:32,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.170935886839173,-4.9627474397486555] belong to cluster 2
2016-12-14 14:08:32,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.92541532295673,-4.739798674896673] belong to cluster 2
2016-12-14 14:08:32,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.745883684042808,-4.982801901446863] belong to cluster 2
2016-12-14 14:08:32,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.074665810123781,-5.590698233048819] belong to cluster 0
2016-12-14 14:08:32,913 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.453704805181816,-4.772901472658986] belong to cluster 2
2016-12-14 14:08:32,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.930734317587952,-5.618227668511609] belong to cluster 0
2016-12-14 14:08:32,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.554589498111678,-4.7332342841966275] belong to cluster 2
2016-12-14 14:08:32,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.455360146660711,-5.502138952855004] belong to cluster 0
2016-12-14 14:08:32,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.627583821536788,-5.230509716930599] belong to cluster 2
2016-12-14 14:08:32,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.037006729096846,-4.939702882617169] belong to cluster 2
2016-12-14 14:08:32,914 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.868129665613434,-5.2478999028676245] belong to cluster 2
2016-12-14 14:08:32,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.275389033309955,-5.393242917238342] belong to cluster 0
2016-12-14 14:08:32,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.807811948068508,-4.987162211014047] belong to cluster 2
2016-12-14 14:08:32,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.4129721730712035,-5.430600479056936] belong to cluster 0
2016-12-14 14:08:32,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.431845746691982,-5.13233336748106] belong to cluster 2
2016-12-14 14:08:32,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.901009231102389,-5.031837021636704] belong to cluster 2
2016-12-14 14:08:32,915 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.225351311425806,-5.465102883957428] belong to cluster 2
2016-12-14 14:08:32,918 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 37.0 (TID 73). 2057 bytes result sent to driver
2016-12-14 14:08:32,918 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 72). 2057 bytes result sent to driver
2016-12-14 14:08:32,919 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 37.0 (TID 73) in 28 ms on localhost (1/2)
2016-12-14 14:08:32,920 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 72) in 29 ms on localhost (2/2)
2016-12-14 14:08:32,920 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (foreach at K_means.scala:114) finished in 0.030 s
2016-12-14 14:08:32,920 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,920 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: foreach at K_means.scala:114, took 0.040209 s
2016-12-14 14:08:32,932 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 14:08:32,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (first at PCA.scala:42) with 1 output partitions
2016-12-14 14:08:32,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 38 (first at PCA.scala:42)
2016-12-14 14:08:32,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:32,934 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:32,934 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 38 (MapPartitionsRDD[55] at map at K_means.scala:119), which has no missing parents
2016-12-14 14:08:32,936 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 3.6 KB, free 382.8 KB)
2016-12-14 14:08:32,940 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.1 KB, free 384.9 KB)
2016-12-14 14:08:32,940 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:39370 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:08:32,941 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,941 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[55] at map at K_means.scala:119)
2016-12-14 14:08:32,941 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 1 tasks
2016-12-14 14:08:32,943 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 74, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:32,943 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 74)
2016-12-14 14:08:32,945 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,948 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 74). 2176 bytes result sent to driver
2016-12-14 14:08:32,953 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 74) in 10 ms on localhost (1/1)
2016-12-14 14:08:32,953 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 38 (first at PCA.scala:42) finished in 0.011 s
2016-12-14 14:08:32,953 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,953 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: first at PCA.scala:42, took 0.021140 s
2016-12-14 14:08:32,960 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 14:08:32,961 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 14:08:32,961 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (first at RowMatrix.scala:61)
2016-12-14 14:08:32,961 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:32,962 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:32,963 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (MapPartitionsRDD[55] at map at K_means.scala:119), which has no missing parents
2016-12-14 14:08:32,964 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 3.6 KB, free 388.5 KB)
2016-12-14 14:08:32,968 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.1 KB, free 390.6 KB)
2016-12-14 14:08:32,969 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:39370 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:08:32,969 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,970 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[55] at map at K_means.scala:119)
2016-12-14 14:08:32,970 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 1 tasks
2016-12-14 14:08:32,971 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 75, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:32,972 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 75)
2016-12-14 14:08:32,974 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:32,976 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 75). 2176 bytes result sent to driver
2016-12-14 14:08:32,981 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 75) in 10 ms on localhost (1/1)
2016-12-14 14:08:32,981 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (first at RowMatrix.scala:61) finished in 0.011 s
2016-12-14 14:08:32,981 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32,981 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: first at RowMatrix.scala:61, took 0.020909 s
2016-12-14 14:08:32,989 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 14:08:32,990 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 14:08:32,990 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 40 (treeAggregate at RowMatrix.scala:331)
2016-12-14 14:08:32,990 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:32,991 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:32,991 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 40 (MapPartitionsRDD[56] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 14:08:32,993 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 4.5 KB, free 395.1 KB)
2016-12-14 14:08:32,997 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.5 KB, free 397.5 KB)
2016-12-14 14:08:32,997 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:39370 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:08:32,998 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:32,998 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[56] at treeAggregate at RowMatrix.scala:331)
2016-12-14 14:08:32,999 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 2 tasks
2016-12-14 14:08:33,000 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 76, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,001 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 40.0 (TID 77, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,001 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 76)
2016-12-14 14:08:33,001 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 40.0 (TID 77)
2016-12-14 14:08:33,003 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:33,003 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:33,005 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 40.0 (TID 77). 2136 bytes result sent to driver
2016-12-14 14:08:33,006 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 76). 2136 bytes result sent to driver
2016-12-14 14:08:33,007 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 40.0 (TID 77) in 7 ms on localhost (1/2)
2016-12-14 14:08:33,009 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 76) in 9 ms on localhost (2/2)
2016-12-14 14:08:33,009 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 40 (treeAggregate at RowMatrix.scala:331) finished in 0.010 s
2016-12-14 14:08:33,009 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,009 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: treeAggregate at RowMatrix.scala:331, took 0.020074 s
2016-12-14 14:08:33,017 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 14:08:33,018 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 31 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 14:08:33,018 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (treeAggregate at RowMatrix.scala:121)
2016-12-14 14:08:33,018 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:33,019 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:33,019 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (MapPartitionsRDD[57] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 14:08:33,021 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 4.6 KB, free 402.1 KB)
2016-12-14 14:08:33,024 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KB, free 404.6 KB)
2016-12-14 14:08:33,025 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:39370 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:08:33,026 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,026 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 41 (MapPartitionsRDD[57] at treeAggregate at RowMatrix.scala:121)
2016-12-14 14:08:33,026 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 14:08:33,027 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 78, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,028 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 79, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,028 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 78)
2016-12-14 14:08:33,028 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 79)
2016-12-14 14:08:33,029 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:33,029 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:33,031 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 79). 2179 bytes result sent to driver
2016-12-14 14:08:33,031 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 78). 2179 bytes result sent to driver
2016-12-14 14:08:33,035 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 79) in 8 ms on localhost (1/2)
2016-12-14 14:08:33,036 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 78) in 9 ms on localhost (2/2)
2016-12-14 14:08:33,036 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (treeAggregate at RowMatrix.scala:121) finished in 0.009 s
2016-12-14 14:08:33,036 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,036 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 31 finished: treeAggregate at RowMatrix.scala:121, took 0.019159 s
2016-12-14 14:08:33,055 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:125
2016-12-14 14:08:33,056 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 32 (foreach at K_means.scala:125) with 2 output partitions
2016-12-14 14:08:33,056 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 42 (foreach at K_means.scala:125)
2016-12-14 14:08:33,056 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:33,057 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:33,057 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 42 (MapPartitionsRDD[59] at map at K_means.scala:121), which has no missing parents
2016-12-14 14:08:33,059 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 4.4 KB, free 409.0 KB)
2016-12-14 14:08:33,063 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.5 KB, free 411.5 KB)
2016-12-14 14:08:33,064 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:39370 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:08:33,064 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,064 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[59] at map at K_means.scala:121)
2016-12-14 14:08:33,064 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 14:08:33,065 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 80, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,066 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 81, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,066 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 80)
2016-12-14 14:08:33,066 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 81)
2016-12-14 14:08:33,068 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:33,068 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:33,070 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,070 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,070 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,070 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,070 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:08:33,070 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,071 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,071 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,071 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,071 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,071 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,071 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,072 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,072 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,072 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,072 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,072 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,072 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,072 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,073 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,073 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,073 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,073 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,073 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,074 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,074 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,074 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,074 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,074 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,074 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,074 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,075 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,075 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,075 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,075 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,075 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,075 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,076 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,076 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,076 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,076 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,076 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,076 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,077 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,077 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,077 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,077 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,077 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,077 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,078 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,078 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,078 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,078 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,078 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,078 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,079 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,079 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,079 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,079 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,079 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,080 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,080 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,080 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,080 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,080 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,080 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,081 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,081 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,081 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,081 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,081 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,081 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,081 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,082 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,082 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,082 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,082 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,082 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,082 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,083 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,083 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,083 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,083 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,083 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,083 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,084 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,085 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,085 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,085 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,085 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,085 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,085 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,085 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,086 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:08:33,086 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,086 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:08:33,086 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,086 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,086 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,087 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:08:33,087 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,087 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,087 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,087 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,087 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,088 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,089 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:08:33,090 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,091 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,092 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:08:33,092 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:08:33,092 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 80). 2057 bytes result sent to driver
2016-12-14 14:08:33,093 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 81). 2057 bytes result sent to driver
2016-12-14 14:08:33,094 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 80) in 29 ms on localhost (1/2)
2016-12-14 14:08:33,094 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 81) in 29 ms on localhost (2/2)
2016-12-14 14:08:33,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 42 (foreach at K_means.scala:125) finished in 0.029 s
2016-12-14 14:08:33,094 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,094 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 32 finished: foreach at K_means.scala:125, took 0.039107 s
2016-12-14 14:08:33,138 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:14
2016-12-14 14:08:33,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 60 (map at Relabel.scala:14)
2016-12-14 14:08:33,139 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 33 (sortBy at Relabel.scala:14) with 2 output partitions
2016-12-14 14:08:33,140 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 44 (sortBy at Relabel.scala:14)
2016-12-14 14:08:33,140 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 43)
2016-12-14 14:08:33,140 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 43)
2016-12-14 14:08:33,141 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 43 (MapPartitionsRDD[60] at map at Relabel.scala:14), which has no missing parents
2016-12-14 14:08:33,143 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 5.2 KB, free 416.7 KB)
2016-12-14 14:08:33,146 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.0 KB, free 419.7 KB)
2016-12-14 14:08:33,146 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:39370 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:08:33,147 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,147 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[60] at map at Relabel.scala:14)
2016-12-14 14:08:33,147 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 14:08:33,148 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 82, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:08:33,149 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 83, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:08:33,149 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 82)
2016-12-14 14:08:33,149 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 83)
2016-12-14 14:08:33,151 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:33,151 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:33,159 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 83). 2237 bytes result sent to driver
2016-12-14 14:08:33,159 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 82). 2237 bytes result sent to driver
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 82) in 15 ms on localhost (1/2)
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 83) in 15 ms on localhost (2/2)
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 43 (map at Relabel.scala:14) finished in 0.016 s
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 44)
2016-12-14 14:08:33,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:33,164 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 44 (MapPartitionsRDD[64] at sortBy at Relabel.scala:14), which has no missing parents
2016-12-14 14:08:33,165 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 3.5 KB, free 423.2 KB)
2016-12-14 14:08:33,167 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2022.0 B, free 425.2 KB)
2016-12-14 14:08:33,168 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:39370 (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:08:33,168 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,169 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 44 (MapPartitionsRDD[64] at sortBy at Relabel.scala:14)
2016-12-14 14:08:33,169 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 44.0 with 2 tasks
2016-12-14 14:08:33,170 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 44.0 (TID 84, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:33,171 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 44.0 (TID 85, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:33,171 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 44.0 (TID 85)
2016-12-14 14:08:33,171 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 44.0 (TID 84)
2016-12-14 14:08:33,172 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,172 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,173 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:33,173 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:33,176 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 44.0 (TID 84). 1160 bytes result sent to driver
2016-12-14 14:08:33,176 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 44.0 (TID 85). 1152 bytes result sent to driver
2016-12-14 14:08:33,178 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 44.0 (TID 85) in 7 ms on localhost (1/2)
2016-12-14 14:08:33,179 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 44.0 (TID 84) in 9 ms on localhost (2/2)
2016-12-14 14:08:33,179 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 44 (sortBy at Relabel.scala:14) finished in 0.009 s
2016-12-14 14:08:33,179 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,179 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 33 finished: sortBy at Relabel.scala:14, took 0.041137 s
2016-12-14 14:08:33,204 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:15
2016-12-14 14:08:33,209 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 10 is 155 bytes
2016-12-14 14:08:33,213 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 62 (sortBy at Relabel.scala:14)
2016-12-14 14:08:33,213 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 34 (collect at Relabel.scala:15) with 2 output partitions
2016-12-14 14:08:33,213 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 47 (collect at Relabel.scala:15)
2016-12-14 14:08:33,213 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 46)
2016-12-14 14:08:33,214 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 46)
2016-12-14 14:08:33,214 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 46 (MapPartitionsRDD[62] at sortBy at Relabel.scala:14), which has no missing parents
2016-12-14 14:08:33,217 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 3.6 KB, free 428.8 KB)
2016-12-14 14:08:33,220 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.0 KB, free 430.8 KB)
2016-12-14 14:08:33,221 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:39370 (size: 2.0 KB, free: 529.9 MB)
2016-12-14 14:08:33,221 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,221 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[62] at sortBy at Relabel.scala:14)
2016-12-14 14:08:33,221 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 46.0 with 2 tasks
2016-12-14 14:08:33,222 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 46.0 (TID 86, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 14:08:33,223 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 46.0 (TID 87, localhost, partition 1,NODE_LOCAL, 2132 bytes)
2016-12-14 14:08:33,223 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 46.0 (TID 86)
2016-12-14 14:08:33,223 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 46.0 (TID 87)
2016-12-14 14:08:33,235 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,235 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,235 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:33,236 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:33,256 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 46.0 (TID 87). 1303 bytes result sent to driver
2016-12-14 14:08:33,256 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 46.0 (TID 86). 1303 bytes result sent to driver
2016-12-14 14:08:33,259 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 46.0 (TID 87) in 36 ms on localhost (1/2)
2016-12-14 14:08:33,260 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 46.0 (TID 86) in 38 ms on localhost (2/2)
2016-12-14 14:08:33,260 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 46 (sortBy at Relabel.scala:14) finished in 0.038 s
2016-12-14 14:08:33,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:33,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:33,260 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 47)
2016-12-14 14:08:33,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:33,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 47 (MapPartitionsRDD[66] at sortBy at Relabel.scala:14), which has no missing parents
2016-12-14 14:08:33,266 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 3.4 KB, free 434.2 KB)
2016-12-14 14:08:33,269 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 1946.0 B, free 436.1 KB)
2016-12-14 14:08:33,270 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:39370 (size: 1946.0 B, free: 529.9 MB)
2016-12-14 14:08:33,271 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,271 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[66] at sortBy at Relabel.scala:14)
2016-12-14 14:08:33,271 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 47.0 with 2 tasks
2016-12-14 14:08:33,272 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 47.0 (TID 88, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:33,273 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 47.0 (TID 89, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:33,273 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 47.0 (TID 88)
2016-12-14 14:08:33,273 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 47.0 (TID 89)
2016-12-14 14:08:33,278 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,278 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,278 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:33,279 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:33,291 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 47.0 (TID 89). 1211 bytes result sent to driver
2016-12-14 14:08:33,291 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 47.0 (TID 88). 1182 bytes result sent to driver
2016-12-14 14:08:33,293 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 47.0 (TID 89) in 20 ms on localhost (1/2)
2016-12-14 14:08:33,293 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 47.0 (TID 88) in 21 ms on localhost (2/2)
2016-12-14 14:08:33,293 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 47 (collect at Relabel.scala:15) finished in 0.021 s
2016-12-14 14:08:33,293 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,294 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 34 finished: collect at Relabel.scala:15, took 0.089078 s
2016-12-14 14:08:33,314 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:129
2016-12-14 14:08:33,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 35 (foreach at K_means.scala:129) with 2 output partitions
2016-12-14 14:08:33,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 48 (foreach at K_means.scala:129)
2016-12-14 14:08:33,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:08:33,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:08:33,316 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 48 (MapPartitionsRDD[67] at map at Relabel.scala:36), which has no missing parents
2016-12-14 14:08:33,318 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64 stored as values in memory (estimated size 4.8 KB, free 440.9 KB)
2016-12-14 14:08:33,322 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.7 KB, free 443.6 KB)
2016-12-14 14:08:33,323 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_64_piece0 in memory on localhost:39370 (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:08:33,324 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,324 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 48 (MapPartitionsRDD[67] at map at Relabel.scala:36)
2016-12-14 14:08:33,324 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 48.0 with 2 tasks
2016-12-14 14:08:33,326 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 48.0 (TID 90, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,327 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 48.0 (TID 91, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:08:33,327 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 48.0 (TID 90)
2016-12-14 14:08:33,327 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 48.0 (TID 91)
2016-12-14 14:08:33,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:33,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:33,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:08:33,331 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,332 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,333 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,334 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,335 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,336 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,337 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,338 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,339 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,340 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,341 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,342 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,343 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,344 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,345 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:08:33,346 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,347 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:08:33,347 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:08:33,348 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 48.0 (TID 91). 2057 bytes result sent to driver
2016-12-14 14:08:33,348 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 48.0 (TID 90). 2057 bytes result sent to driver
2016-12-14 14:08:33,351 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 48.0 (TID 91) in 25 ms on localhost (1/2)
2016-12-14 14:08:33,352 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 48.0 (TID 90) in 27 ms on localhost (2/2)
2016-12-14 14:08:33,352 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 48 (foreach at K_means.scala:129) finished in 0.027 s
2016-12-14 14:08:33,352 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,352 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 35 finished: foreach at K_means.scala:129, took 0.038568 s
2016-12-14 14:08:33,372 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 14:08:33,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 68 (map at MulticlassMetrics.scala:46)
2016-12-14 14:08:33,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 36 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 14:08:33,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 50 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 14:08:33,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 49)
2016-12-14 14:08:33,375 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 49)
2016-12-14 14:08:33,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 49 (MapPartitionsRDD[68] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 14:08:33,377 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65 stored as values in memory (estimated size 5.7 KB, free 449.3 KB)
2016-12-14 14:08:33,382 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.2 KB, free 452.5 KB)
2016-12-14 14:08:33,382 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_65_piece0 in memory on localhost:39370 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:08:33,383 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,384 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[68] at map at MulticlassMetrics.scala:46)
2016-12-14 14:08:33,384 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 49.0 with 2 tasks
2016-12-14 14:08:33,385 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 49.0 (TID 92, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:08:33,385 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 49.0 (TID 93, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:08:33,386 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 49.0 (TID 92)
2016-12-14 14:08:33,386 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 49.0 (TID 93)
2016-12-14 14:08:33,388 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:33,388 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:33,393 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 49.0 (TID 93). 2237 bytes result sent to driver
2016-12-14 14:08:33,393 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 49.0 (TID 92). 2237 bytes result sent to driver
2016-12-14 14:08:33,395 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 49.0 (TID 93) in 10 ms on localhost (1/2)
2016-12-14 14:08:33,396 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 49.0 (TID 92) in 10 ms on localhost (2/2)
2016-12-14 14:08:33,396 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,396 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 49 (map at MulticlassMetrics.scala:46) finished in 0.012 s
2016-12-14 14:08:33,396 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:33,396 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:33,396 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 50)
2016-12-14 14:08:33,396 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:33,397 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 50 (ShuffledRDD[69] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 14:08:33,398 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66 stored as values in memory (estimated size 2.6 KB, free 455.2 KB)
2016-12-14 14:08:33,402 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66_piece0 stored as bytes in memory (estimated size 1593.0 B, free 456.7 KB)
2016-12-14 14:08:33,402 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_66_piece0 in memory on localhost:39370 (size: 1593.0 B, free: 529.9 MB)
2016-12-14 14:08:33,403 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,404 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 50 (ShuffledRDD[69] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 14:08:33,404 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 50.0 with 2 tasks
2016-12-14 14:08:33,405 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 50.0 (TID 94, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:33,405 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 50.0 (TID 95, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:08:33,406 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 50.0 (TID 94)
2016-12-14 14:08:33,406 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 50.0 (TID 95)
2016-12-14 14:08:33,408 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,408 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,408 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:33,408 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:08:33,414 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 50.0 (TID 95). 1124 bytes result sent to driver
2016-12-14 14:08:33,415 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 50.0 (TID 94). 1163 bytes result sent to driver
2016-12-14 14:08:33,417 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 50.0 (TID 95) in 12 ms on localhost (1/2)
2016-12-14 14:08:33,417 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 50.0 (TID 94) in 12 ms on localhost (2/2)
2016-12-14 14:08:33,417 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 50 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.013 s
2016-12-14 14:08:33,417 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 50.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,417 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 36 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.044809 s
2016-12-14 14:08:33,443 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 14:08:33,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 72 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:08:33,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 37 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 14:08:33,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 52 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:08:33,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 51)
2016-12-14 14:08:33,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 51)
2016-12-14 14:08:33,446 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 51 (MapPartitionsRDD[72] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:08:33,458 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 91
2016-12-14 14:08:33,458 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 14:08:33,459 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 9
2016-12-14 14:08:33,460 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_66_piece0 on localhost:39370 in memory (size: 1593.0 B, free: 529.9 MB)
2016-12-14 14:08:33,460 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67 stored as values in memory (estimated size 6.3 KB, free 461.4 KB)
2016-12-14 14:08:33,461 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 105
2016-12-14 14:08:33,462 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_65_piece0 on localhost:39370 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:08:33,463 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 104
2016-12-14 14:08:33,463 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 12
2016-12-14 14:08:33,464 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_64_piece0 on localhost:39370 in memory (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:08:33,465 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.4 KB, free 445.7 KB)
2016-12-14 14:08:33,465 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 103
2016-12-14 14:08:33,465 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 14:08:33,465 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_67_piece0 in memory on localhost:39370 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:08:33,465 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 82
2016-12-14 14:08:33,466 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,466 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[72] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:08:33,466 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 51.0 with 2 tasks
2016-12-14 14:08:33,467 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:39370 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:33,467 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 81
2016-12-14 14:08:33,468 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 51.0 (TID 96, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:08:33,468 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:39370 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:08:33,469 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 51.0 (TID 97, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:08:33,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 14:08:33,469 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 51.0 (TID 96)
2016-12-14 14:08:33,469 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 51.0 (TID 97)
2016-12-14 14:08:33,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 14:08:33,470 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:39370 in memory (size: 285.0 B, free: 529.9 MB)
2016-12-14 14:08:33,471 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 14:08:33,471 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 14:08:33,471 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 14:08:33,471 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:08:33,471 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:39370 in memory (size: 216.0 B, free: 529.9 MB)
2016-12-14 14:08:33,471 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:08:33,472 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 89
2016-12-14 14:08:33,472 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 88
2016-12-14 14:08:33,472 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:39370 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:33,473 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 87
2016-12-14 14:08:33,473 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:39370 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:08:33,473 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 86
2016-12-14 14:08:33,474 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 14:08:33,474 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:39370 in memory (size: 282.0 B, free: 529.9 MB)
2016-12-14 14:08:33,475 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 85
2016-12-14 14:08:33,475 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 84
2016-12-14 14:08:33,475 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 83
2016-12-14 14:08:33,476 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_55_piece0 on localhost:39370 in memory (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:08:33,476 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 94
2016-12-14 14:08:33,477 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:39370 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:08:33,477 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 51.0 (TID 97). 2237 bytes result sent to driver
2016-12-14 14:08:33,477 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 51.0 (TID 96). 2237 bytes result sent to driver
2016-12-14 14:08:33,477 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 93
2016-12-14 14:08:33,478 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:39370 in memory (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:08:33,479 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 92
2016-12-14 14:08:33,479 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 51.0 (TID 96) in 12 ms on localhost (1/2)
2016-12-14 14:08:33,479 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:39370 in memory (size: 248.0 B, free: 529.9 MB)
2016-12-14 14:08:33,480 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 51.0 (TID 97) in 12 ms on localhost (2/2)
2016-12-14 14:08:33,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 51 (countByValue at MulticlassMetrics.scala:43) finished in 0.013 s
2016-12-14 14:08:33,480 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:39370 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:08:33,480 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 51.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,480 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:08:33,481 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:08:33,481 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 52)
2016-12-14 14:08:33,481 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:08:33,482 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:39370 in memory (size: 3.8 KB, free: 530.0 MB)
2016-12-14 14:08:33,482 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 52 (ShuffledRDD[73] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:08:33,482 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 90
2016-12-14 14:08:33,483 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 14:08:33,483 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 99
2016-12-14 14:08:33,483 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 14:08:33,483 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68 stored as values in memory (estimated size 2.6 KB, free 378.0 KB)
2016-12-14 14:08:33,484 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_59_piece0 on localhost:39370 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:33,485 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 98
2016-12-14 14:08:33,486 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_58_piece0 on localhost:39370 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:33,486 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 97
2016-12-14 14:08:33,487 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_57_piece0 on localhost:39370 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:08:33,487 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68_piece0 stored as bytes in memory (estimated size 1561.0 B, free 363.1 KB)
2016-12-14 14:08:33,488 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 96
2016-12-14 14:08:33,488 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_68_piece0 in memory on localhost:39370 (size: 1561.0 B, free: 530.0 MB)
2016-12-14 14:08:33,488 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:08:33,489 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 52 (ShuffledRDD[73] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:08:33,489 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_56_piece0 on localhost:39370 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:08:33,489 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 52.0 with 2 tasks
2016-12-14 14:08:33,490 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 95
2016-12-14 14:08:33,491 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_63_piece0 on localhost:39370 in memory (size: 1946.0 B, free: 530.0 MB)
2016-12-14 14:08:33,491 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 52.0 (TID 98, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:08:33,491 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 102
2016-12-14 14:08:33,491 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 52.0 (TID 99, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:08:33,492 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 52.0 (TID 99)
2016-12-14 14:08:33,492 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_62_piece0 on localhost:39370 in memory (size: 2.0 KB, free: 530.0 MB)
2016-12-14 14:08:33,492 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 52.0 (TID 98)
2016-12-14 14:08:33,493 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 101
2016-12-14 14:08:33,493 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 11
2016-12-14 14:08:33,493 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,494 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_61_piece0 on localhost:39370 in memory (size: 2022.0 B, free: 530.0 MB)
2016-12-14 14:08:33,494 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:08:33,494 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:33,494 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 100
2016-12-14 14:08:33,494 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:08:33,495 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_60_piece0 on localhost:39370 in memory (size: 3.0 KB, free: 530.0 MB)
2016-12-14 14:08:33,497 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 52.0 (TID 99). 1124 bytes result sent to driver
2016-12-14 14:08:33,497 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 52.0 (TID 98). 1163 bytes result sent to driver
2016-12-14 14:08:33,500 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 52.0 (TID 99) in 9 ms on localhost (1/2)
2016-12-14 14:08:33,500 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 52.0 (TID 98) in 10 ms on localhost (2/2)
2016-12-14 14:08:33,500 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 52 (countByValue at MulticlassMetrics.scala:43) finished in 0.010 s
2016-12-14 14:08:33,500 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 52.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33,500 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 37 finished: countByValue at MulticlassMetrics.scala:43, took 0.056967 s
2016-12-14 14:08:33,501 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.8866666666666667
2016-12-14 14:08:33,502 INFO  com.datageek.test.K_means$ - main: ======(-_-)~==================END=================(-_-)~======
2016-12-14 14:08:33,588 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:08:33,589 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:08:33,589 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:08:33,589 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:08:33,590 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:08:33,590 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:08:33,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:08:33,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:08:33,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:08:33,591 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:08:33,592 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:08:33,592 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:08:33,592 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:08:33,593 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:08:33,593 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:08:33,593 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:08:33,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:08:33,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:08:33,594 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:08:33,595 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:08:33,595 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:08:33,595 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:08:33,596 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:08:33,596 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:08:33,596 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:08:33,655 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 14:08:33,744 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:08:33,763 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 14:08:33,764 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 14:08:33,765 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 14:08:33,768 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 14:08:33,779 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 14:08:33,780 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 14:08:33,783 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 14:08:33,785 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-dd8bc922-6dec-4980-95e9-6b78bae642a9
2016-12-14 14:08:33,785 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:08:33,833 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 14:08:33,834 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 14:21:07,519 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 14:21:08,598 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 14:21:08,603 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 14:21:08,605 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 14:21:09,000 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 41634.
2016-12-14 14:21:09,596 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 14:21:09,664 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 14:21:09,887 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:2402]
2016-12-14 14:21:09,890 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:2402]
2016-12-14 14:21:09,901 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 2402.
2016-12-14 14:21:09,932 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 14:21:09,963 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 14:21:09,989 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-1e9c1024-22a9-48c2-9540-6b81e74c07f4
2016-12-14 14:21:10,016 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 14:21:10,121 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 14:21:10,412 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 14:21:10,506 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:21:10,507 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:21:10,510 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 14:21:10,561 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:41634/jars/mysql-connector-java-5.1.25.jar with timestamp 1481696470560
2016-12-14 14:21:10,562 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:41634/jars/ojdbc6.jar with timestamp 1481696470561
2016-12-14 14:21:10,562 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:41634/jars/orai18n.jar with timestamp 1481696470562
2016-12-14 14:21:10,563 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:41634/jars/machine_learning_2.10-1.0.jar with timestamp 1481696470562
2016-12-14 14:21:10,667 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 14:21:10,702 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 30140.
2016-12-14 14:21:10,703 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 30140
2016-12-14 14:21:10,707 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 14:21:10,708 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 14:21:10,712 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:30140 with 530.0 MB RAM, BlockManagerId(driver, localhost, 30140)
2016-12-14 14:21:10,714 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 14:21:12,655 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481696470616
2016-12-14 14:21:12,711 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/iris.txt
2016-12-14 14:21:12,711 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 14:21:12,712 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 14:21:12,712 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 14:21:12,713 INFO  com.datageek.test.K_means$ - main: #####################savePath = /usr/machine_learning/model/k_mean_test
2016-12-14 14:21:12,714 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 14:21:13,381 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 14:21:13,771 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 14:21:13,776 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:30140 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 14:21:13,780 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:90
2016-12-14 14:21:13,934 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 14:21:14,011 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 14:21:14,049 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (first at PCA.scala:42) with 1 output partitions
2016-12-14 14:21:14,050 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (first at PCA.scala:42)
2016-12-14 14:21:14,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:14,058 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:14,075 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:102), which has no missing parents
2016-12-14 14:21:14,101 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 304.6 KB)
2016-12-14 14:21:14,124 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 306.7 KB)
2016-12-14 14:21:14,125 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:30140 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:14,126 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:14,132 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at K_means.scala:102)
2016-12-14 14:21:14,135 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 1 tasks
2016-12-14 14:21:14,206 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:14,222 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:21:14,232 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:41634/jars/orai18n.jar with timestamp 1481696470562
2016-12-14 14:21:14,233 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 14:21:14,338 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:41634/jars/orai18n.jar to /tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/fetchFileTemp3305903924238836465.tmp
2016-12-14 14:21:14,441 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/orai18n.jar to class loader
2016-12-14 14:21:14,442 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:41634/jars/mysql-connector-java-5.1.25.jar with timestamp 1481696470560
2016-12-14 14:21:14,442 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:41634/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/fetchFileTemp7892490998273453394.tmp
2016-12-14 14:21:14,460 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 14:21:14,460 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:41634/jars/ojdbc6.jar with timestamp 1481696470561
2016-12-14 14:21:14,460 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:41634/jars/ojdbc6.jar to /tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/fetchFileTemp897250919002111377.tmp
2016-12-14 14:21:14,479 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/ojdbc6.jar to class loader
2016-12-14 14:21:14,480 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:41634/jars/machine_learning_2.10-1.0.jar with timestamp 1481696470562
2016-12-14 14:21:14,481 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:41634/jars/machine_learning_2.10-1.0.jar to /tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/fetchFileTemp2189327225403085593.tmp
2016-12-14 14:21:14,489 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7/userFiles-5c104353-a44a-4f17-afa3-8a2004eab1c8/machine_learning_2.10-1.0.jar to class loader
2016-12-14 14:21:14,536 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 14:21:14,543 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:0+1428
2016-12-14 14:21:14,556 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 14:21:14,556 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 14:21:14,556 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 14:21:14,556 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 14:21:14,556 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 14:21:14,587 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 6.8 KB, free 313.5 KB)
2016-12-14 14:21:14,589 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:30140 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:21:14,629 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2701 bytes result sent to driver
2016-12-14 14:21:14,664 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 487 ms on localhost (1/1)
2016-12-14 14:21:14,666 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:21:14,667 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (first at PCA.scala:42) finished in 0.515 s
2016-12-14 14:21:14,674 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: first at PCA.scala:42, took 0.662067 s
2016-12-14 14:21:14,717 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 14:21:14,719 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 14:21:14,719 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (first at RowMatrix.scala:61)
2016-12-14 14:21:14,720 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:14,722 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:14,723 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:102), which has no missing parents
2016-12-14 14:21:14,726 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 3.6 KB, free 317.1 KB)
2016-12-14 14:21:14,736 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 319.2 KB)
2016-12-14 14:21:14,737 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:30140 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:14,738 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:14,739 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at K_means.scala:102)
2016-12-14 14:21:14,739 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 1 tasks
2016-12-14 14:21:14,747 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:14,747 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 14:21:14,756 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:14,766 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 1). 2176 bytes result sent to driver
2016-12-14 14:21:14,775 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (1/1)
2016-12-14 14:21:14,775 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (first at RowMatrix.scala:61) finished in 0.031 s
2016-12-14 14:21:14,775 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:21:14,776 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: first at RowMatrix.scala:61, took 0.058380 s
2016-12-14 14:21:15,326 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 14:21:15,329 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 14:21:15,329 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:331)
2016-12-14 14:21:15,329 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:15,331 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:15,332 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 14:21:15,337 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 4.5 KB, free 323.7 KB)
2016-12-14 14:21:15,347 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 326.1 KB)
2016-12-14 14:21:15,348 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:30140 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:15,349 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:15,349 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:331)
2016-12-14 14:21:15,350 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 14:21:15,352 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:15,355 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:15,356 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 2)
2016-12-14 14:21:15,357 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 3)
2016-12-14 14:21:15,364 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:15,367 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 14:21:15,368 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:1428+1428
2016-12-14 14:21:15,382 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 2). 2136 bytes result sent to driver
2016-12-14 14:21:15,391 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 2) in 40 ms on localhost (1/2)
2016-12-14 14:21:15,392 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 6.8 KB, free 332.9 KB)
2016-12-14 14:21:15,393 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:30140 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:21:15,400 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 3). 2716 bytes result sent to driver
2016-12-14 14:21:15,414 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 3) in 60 ms on localhost (2/2)
2016-12-14 14:21:15,414 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (treeAggregate at RowMatrix.scala:331) finished in 0.063 s
2016-12-14 14:21:15,414 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:21:15,420 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 14:21:15,423 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 14:21:15,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: treeAggregate at RowMatrix.scala:331, took 0.108307 s
2016-12-14 14:21:15,450 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 14:21:15,451 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 14:21:15,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (treeAggregate at RowMatrix.scala:121)
2016-12-14 14:21:15,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:15,452 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:15,453 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 14:21:15,455 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 4.6 KB, free 337.5 KB)
2016-12-14 14:21:15,460 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.5 KB, free 339.9 KB)
2016-12-14 14:21:15,461 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:30140 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:15,462 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:15,462 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:121)
2016-12-14 14:21:15,462 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 14:21:15,464 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:15,466 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:15,467 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 4)
2016-12-14 14:21:15,467 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 5)
2016-12-14 14:21:15,471 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:15,474 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:15,479 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 5). 2179 bytes result sent to driver
2016-12-14 14:21:15,481 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 4). 2179 bytes result sent to driver
2016-12-14 14:21:15,487 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 5) in 23 ms on localhost (1/2)
2016-12-14 14:21:15,491 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 4) in 28 ms on localhost (2/2)
2016-12-14 14:21:15,491 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (treeAggregate at RowMatrix.scala:121) finished in 0.028 s
2016-12-14 14:21:15,492 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:21:15,492 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: treeAggregate at RowMatrix.scala:121, took 0.041933 s
2016-12-14 14:21:15,710 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:30140 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:15,716 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 14:21:15,718 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:30140 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:15,719 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 14:21:15,720 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:30140 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:15,721 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 14:21:15,722 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:30140 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:15,723 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 14:21:16,134 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2016-12-14 14:21:16,136 WARN  com.github.fommil.netlib.LAPACK - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2016-12-14 14:21:16,297 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:21:16,344 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:21:16,346 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:21:16,346 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (takeSample at KMeans.scala:378)
2016-12-14 14:21:16,347 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:16,349 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:16,350 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210), which has no missing parents
2016-12-14 14:21:16,363 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 4.8 KB, free 319.3 KB)
2016-12-14 14:21:16,371 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.7 KB, free 322.0 KB)
2016-12-14 14:21:16,372 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:30140 (size: 2.7 KB, free: 530.0 MB)
2016-12-14 14:21:16,373 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:16,374 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at map at KMeans.scala:210)
2016-12-14 14:21:16,374 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 14:21:16,379 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:21:16,380 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2567 bytes)
2016-12-14 14:21:16,381 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 7)
2016-12-14 14:21:16,381 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 6)
2016-12-14 14:21:16,386 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,387 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_1 not found, computing it
2016-12-14 14:21:16,387 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,389 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,390 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_9_0 not found, computing it
2016-12-14 14:21:16,390 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,392 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_1 stored as values in memory (estimated size 2.1 KB, free 324.0 KB)
2016-12-14 14:21:16,393 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_1 in memory on localhost:30140 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:16,397 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_9_0 stored as values in memory (estimated size 2.1 KB, free 326.1 KB)
2016-12-14 14:21:16,398 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_9_0 in memory on localhost:30140 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:16,402 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 7). 2638 bytes result sent to driver
2016-12-14 14:21:16,406 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 6). 2638 bytes result sent to driver
2016-12-14 14:21:16,411 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 7) in 30 ms on localhost (1/2)
2016-12-14 14:21:16,415 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 6) in 39 ms on localhost (2/2)
2016-12-14 14:21:16,415 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (takeSample at KMeans.scala:378) finished in 0.040 s
2016-12-14 14:21:16,415 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:21:16,416 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: takeSample at KMeans.scala:378, took 0.071365 s
2016-12-14 14:21:16,511 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:21:16,512 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:21:16,512 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (takeSample at KMeans.scala:378)
2016-12-14 14:21:16,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:16,514 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:16,516 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 14:21:16,520 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 21.8 KB, free 347.8 KB)
2016-12-14 14:21:16,528 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.2 KB, free 357.1 KB)
2016-12-14 14:21:16,529 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:30140 (size: 9.2 KB, free: 530.0 MB)
2016-12-14 14:21:16,530 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:16,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (PartitionwiseSampledRDD[13] at takeSample at KMeans.scala:378)
2016-12-14 14:21:16,531 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 14:21:16,534 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:21:16,536 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2676 bytes)
2016-12-14 14:21:16,536 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 9)
2016-12-14 14:21:16,536 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 8)
2016-12-14 14:21:16,542 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,542 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:16,542 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,543 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:16,553 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 9). 2650 bytes result sent to driver
2016-12-14 14:21:16,554 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 8). 2659 bytes result sent to driver
2016-12-14 14:21:16,565 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 9) in 30 ms on localhost (1/2)
2016-12-14 14:21:16,569 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (takeSample at KMeans.scala:378) finished in 0.037 s
2016-12-14 14:21:16,570 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 8) in 37 ms on localhost (2/2)
2016-12-14 14:21:16,570 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:21:16,570 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: takeSample at KMeans.scala:378, took 0.058925 s
2016-12-14 14:21:16,577 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 1840.0 B, free 358.9 KB)
2016-12-14 14:21:16,586 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 430.0 B, free 359.3 KB)
2016-12-14 14:21:16,587 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:30140 (size: 430.0 B, free: 530.0 MB)
2016-12-14 14:21:16,588 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at KMeans.scala:396
2016-12-14 14:21:16,622 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:21:16,624 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:21:16,624 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 14:21:16,624 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:16,626 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:16,627 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:21:16,631 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.3 KB, free 365.6 KB)
2016-12-14 14:21:16,638 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.3 KB, free 368.8 KB)
2016-12-14 14:21:16,639 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:30140 (size: 3.3 KB, free: 530.0 MB)
2016-12-14 14:21:16,639 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:16,640 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at map at KMeans.scala:398)
2016-12-14 14:21:16,640 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 14:21:16,642 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:21:16,643 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2599 bytes)
2016-12-14 14:21:16,644 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 10)
2016-12-14 14:21:16,644 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 11)
2016-12-14 14:21:16,647 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_0 not found, computing it
2016-12-14 14:21:16,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,647 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_15_1 not found, computing it
2016-12-14 14:21:16,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:16,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:16,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:16,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:16,662 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_0 stored as values in memory (estimated size 7.3 KB, free 376.2 KB)
2016-12-14 14:21:16,663 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_15_1 stored as values in memory (estimated size 7.3 KB, free 383.5 KB)
2016-12-14 14:21:16,663 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_0 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:16,664 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_15_1 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:16,668 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 11). 2721 bytes result sent to driver
2016-12-14 14:21:16,669 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 10). 2721 bytes result sent to driver
2016-12-14 14:21:16,674 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 11) in 32 ms on localhost (1/2)
2016-12-14 14:21:16,677 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 10) in 35 ms on localhost (2/2)
2016-12-14 14:21:16,677 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.037 s
2016-12-14 14:21:16,677 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:21:16,678 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.054959 s
2016-12-14 14:21:16,680 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 12 from persistence list
2016-12-14 14:21:16,686 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 12
2016-12-14 14:21:16,708 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:21:16,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:21:16,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 14:21:16,710 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:16,712 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:16,713 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:21:16,717 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 6.5 KB, free 390.0 KB)
2016-12-14 14:21:16,724 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.4 KB, free 393.4 KB)
2016-12-14 14:21:16,726 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:30140 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:21:16,726 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:16,727 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:21:16,727 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 14:21:16,729 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:21:16,729 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:21:16,730 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 12)
2016-12-14 14:21:16,730 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 13)
2016-12-14 14:21:16,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:16,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 14:21:16,735 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,735 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:16,735 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 14:21:16,740 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 12). 3092 bytes result sent to driver
2016-12-14 14:21:16,744 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 13). 2899 bytes result sent to driver
2016-12-14 14:21:16,746 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 12) in 18 ms on localhost (1/2)
2016-12-14 14:21:16,757 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 13) in 28 ms on localhost (2/2)
2016-12-14 14:21:16,757 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.029 s
2016-12-14 14:21:16,757 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:21:16,758 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.049252 s
2016-12-14 14:21:16,761 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 4.4 KB, free 397.8 KB)
2016-12-14 14:21:16,770 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1409.0 B, free 399.2 KB)
2016-12-14 14:21:16,771 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:30140 (size: 1409.0 B, free: 529.9 MB)
2016-12-14 14:21:16,772 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at KMeans.scala:396
2016-12-14 14:21:16,794 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:21:16,796 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:21:16,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 14:21:16,797 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:16,800 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:16,800 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:21:16,804 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.5 KB, free 405.7 KB)
2016-12-14 14:21:16,810 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 409.0 KB)
2016-12-14 14:21:16,811 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:30140 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:21:16,811 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:16,812 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[19] at map at KMeans.scala:398)
2016-12-14 14:21:16,812 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 14:21:16,816 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:21:16,818 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)
2016-12-14 14:21:16,818 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 15)
2016-12-14 14:21:16,818 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 14)
2016-12-14 14:21:16,821 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_1 not found, computing it
2016-12-14 14:21:16,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:16,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_1 locally
2016-12-14 14:21:16,826 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_19_0 not found, computing it
2016-12-14 14:21:16,826 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_1 stored as values in memory (estimated size 7.3 KB, free 416.4 KB)
2016-12-14 14:21:16,827 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,827 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:16,827 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_1 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:16,827 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_15_0 locally
2016-12-14 14:21:16,833 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 15). 2721 bytes result sent to driver
2016-12-14 14:21:16,834 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_19_0 stored as values in memory (estimated size 7.3 KB, free 423.7 KB)
2016-12-14 14:21:16,835 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_19_0 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:16,837 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 15) in 21 ms on localhost (1/2)
2016-12-14 14:21:16,839 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 14). 2721 bytes result sent to driver
2016-12-14 14:21:16,846 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 14) in 32 ms on localhost (2/2)
2016-12-14 14:21:16,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.033 s
2016-12-14 14:21:16,847 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:21:16,847 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.052607 s
2016-12-14 14:21:16,850 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 15 from persistence list
2016-12-14 14:21:16,854 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 14:21:16,872 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:21:16,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:21:16,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 14:21:16,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:16,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:16,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:21:16,878 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 6.7 KB, free 415.8 KB)
2016-12-14 14:21:16,883 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.5 KB, free 419.3 KB)
2016-12-14 14:21:16,883 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:30140 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:21:16,884 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:16,884 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[21] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:21:16,884 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 14:21:16,886 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:21:16,887 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:21:16,887 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 16)
2016-12-14 14:21:16,887 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 17)
2016-12-14 14:21:16,891 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,892 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,892 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:16,892 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:16,892 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 14:21:16,892 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 14:21:16,900 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 16). 3172 bytes result sent to driver
2016-12-14 14:21:16,901 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 17). 2981 bytes result sent to driver
2016-12-14 14:21:16,907 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 16) in 21 ms on localhost (1/2)
2016-12-14 14:21:16,917 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 17) in 30 ms on localhost (2/2)
2016-12-14 14:21:16,917 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.031 s
2016-12-14 14:21:16,917 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:21:16,917 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.045000 s
2016-12-14 14:21:16,919 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 4.8 KB, free 424.0 KB)
2016-12-14 14:21:16,925 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1535.0 B, free 425.5 KB)
2016-12-14 14:21:16,926 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:30140 (size: 1535.0 B, free: 529.9 MB)
2016-12-14 14:21:16,926 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at KMeans.scala:396
2016-12-14 14:21:16,943 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:21:16,945 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:21:16,945 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 14:21:16,945 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:16,947 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:16,948 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:21:16,951 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.8 KB, free 432.3 KB)
2016-12-14 14:21:16,958 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 435.7 KB)
2016-12-14 14:21:16,959 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:30140 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:21:16,959 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:16,960 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[23] at map at KMeans.scala:398)
2016-12-14 14:21:16,960 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 14:21:16,963 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:21:16,964 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2663 bytes)
2016-12-14 14:21:16,965 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 18)
2016-12-14 14:21:16,965 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 19)
2016-12-14 14:21:16,968 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_0 not found, computing it
2016-12-14 14:21:16,968 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:16,969 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:16,969 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_0 locally
2016-12-14 14:21:16,970 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_23_1 not found, computing it
2016-12-14 14:21:16,970 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:16,970 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:16,970 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_19_1 locally
2016-12-14 14:21:16,975 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_0 stored as values in memory (estimated size 7.3 KB, free 443.0 KB)
2016-12-14 14:21:16,976 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_0 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:16,976 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_23_1 stored as values in memory (estimated size 7.3 KB, free 450.4 KB)
2016-12-14 14:21:16,977 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_23_1 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:16,982 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 19). 2721 bytes result sent to driver
2016-12-14 14:21:16,985 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 18). 2721 bytes result sent to driver
2016-12-14 14:21:16,991 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 19) in 28 ms on localhost (1/2)
2016-12-14 14:21:16,992 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 18) in 29 ms on localhost (2/2)
2016-12-14 14:21:16,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.030 s
2016-12-14 14:21:16,992 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:21:16,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.048479 s
2016-12-14 14:21:16,993 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 19 from persistence list
2016-12-14 14:21:16,995 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 14:21:17,014 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:21:17,016 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:21:17,017 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 14:21:17,017 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:17,019 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:17,020 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:21:17,023 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 6.9 KB, free 442.6 KB)
2016-12-14 14:21:17,030 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.6 KB, free 446.2 KB)
2016-12-14 14:21:17,031 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:30140 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:21:17,031 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,032 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[25] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:21:17,032 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 14:21:17,034 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:21:17,034 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:21:17,035 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 20)
2016-12-14 14:21:17,035 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 21)
2016-12-14 14:21:17,040 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:17,040 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:17,041 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 14:21:17,041 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,042 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:17,042 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 14:21:17,046 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 20). 2940 bytes result sent to driver
2016-12-14 14:21:17,050 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 21). 3026 bytes result sent to driver
2016-12-14 14:21:17,052 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 20) in 19 ms on localhost (1/2)
2016-12-14 14:21:17,060 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 21) in 25 ms on localhost (2/2)
2016-12-14 14:21:17,060 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 14:21:17,060 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,061 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.046125 s
2016-12-14 14:21:17,063 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 4.6 KB, free 450.8 KB)
2016-12-14 14:21:17,071 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1436.0 B, free 452.2 KB)
2016-12-14 14:21:17,072 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:30140 (size: 1436.0 B, free: 529.9 MB)
2016-12-14 14:21:17,073 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at KMeans.scala:396
2016-12-14 14:21:17,094 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:21:17,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:21:17,096 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 12 (aggregate at KMeans.scala:404)
2016-12-14 14:21:17,097 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:17,098 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:17,099 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:21:17,102 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 459.2 KB)
2016-12-14 14:21:17,108 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 462.7 KB)
2016-12-14 14:21:17,110 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:30140 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:21:17,110 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,111 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at map at KMeans.scala:398)
2016-12-14 14:21:17,111 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 14:21:17,112 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:21:17,113 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2695 bytes)
2016-12-14 14:21:17,113 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 22)
2016-12-14 14:21:17,113 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 23)
2016-12-14 14:21:17,117 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_1 not found, computing it
2016-12-14 14:21:17,117 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,118 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:17,119 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_1 locally
2016-12-14 14:21:17,119 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_27_0 not found, computing it
2016-12-14 14:21:17,119 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:17,120 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:17,120 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_23_0 locally
2016-12-14 14:21:17,123 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_1 stored as values in memory (estimated size 7.3 KB, free 470.0 KB)
2016-12-14 14:21:17,124 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_1 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:17,125 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_27_0 stored as values in memory (estimated size 7.3 KB, free 477.4 KB)
2016-12-14 14:21:17,125 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_27_0 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:17,129 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 23). 2721 bytes result sent to driver
2016-12-14 14:21:17,130 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 22). 2721 bytes result sent to driver
2016-12-14 14:21:17,135 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 23) in 23 ms on localhost (1/2)
2016-12-14 14:21:17,135 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 22) in 23 ms on localhost (2/2)
2016-12-14 14:21:17,135 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 12 (aggregate at KMeans.scala:404) finished in 0.023 s
2016-12-14 14:21:17,136 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,136 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: aggregate at KMeans.scala:404, took 0.041904 s
2016-12-14 14:21:17,138 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 23 from persistence list
2016-12-14 14:21:17,138 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 14:21:17,158 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:21:17,160 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:21:17,161 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collect at KMeans.scala:436)
2016-12-14 14:21:17,161 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:17,162 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:17,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:21:17,165 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 7.2 KB, free 469.8 KB)
2016-12-14 14:21:17,170 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.6 KB, free 473.5 KB)
2016-12-14 14:21:17,171 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:30140 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:21:17,172 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,172 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[29] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:21:17,173 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 14:21:17,175 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:21:17,176 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:21:17,177 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 25)
2016-12-14 14:21:17,177 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 24)
2016-12-14 14:21:17,180 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:17,180 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,180 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:17,181 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:17,181 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 14:21:17,181 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 14:21:17,186 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 24). 2782 bytes result sent to driver
2016-12-14 14:21:17,187 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 25). 3374 bytes result sent to driver
2016-12-14 14:21:17,191 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 24) in 17 ms on localhost (1/2)
2016-12-14 14:21:17,197 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 25) in 21 ms on localhost (2/2)
2016-12-14 14:21:17,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collect at KMeans.scala:436) finished in 0.023 s
2016-12-14 14:21:17,198 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collect at KMeans.scala:436, took 0.040123 s
2016-12-14 14:21:17,201 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 4.8 KB, free 478.2 KB)
2016-12-14 14:21:17,209 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1496.0 B, free 479.7 KB)
2016-12-14 14:21:17,210 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:30140 (size: 1496.0 B, free: 529.9 MB)
2016-12-14 14:21:17,211 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at KMeans.scala:396
2016-12-14 14:21:17,233 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:21:17,235 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:21:17,235 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 14 (aggregate at KMeans.scala:404)
2016-12-14 14:21:17,235 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:17,237 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:17,237 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:21:17,239 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 7.3 KB, free 486.9 KB)
2016-12-14 14:21:17,245 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.5 KB, free 490.4 KB)
2016-12-14 14:21:17,246 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:30140 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:21:17,246 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,247 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[31] at map at KMeans.scala:398)
2016-12-14 14:21:17,247 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 14:21:17,249 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 26, localhost, partition 0,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:21:17,250 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 27, localhost, partition 1,PROCESS_LOCAL, 2727 bytes)
2016-12-14 14:21:17,251 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 27)
2016-12-14 14:21:17,251 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 26)
2016-12-14 14:21:17,254 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_1 not found, computing it
2016-12-14 14:21:17,254 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,255 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:17,255 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_1 locally
2016-12-14 14:21:17,256 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_31_0 not found, computing it
2016-12-14 14:21:17,256 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:17,256 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:17,256 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_27_0 locally
2016-12-14 14:21:17,257 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_1 stored as values in memory (estimated size 7.3 KB, free 497.8 KB)
2016-12-14 14:21:17,258 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_1 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:17,259 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_31_0 stored as values in memory (estimated size 7.3 KB, free 505.1 KB)
2016-12-14 14:21:17,259 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_31_0 in memory on localhost:30140 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:21:17,261 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 27). 2721 bytes result sent to driver
2016-12-14 14:21:17,262 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 26). 2721 bytes result sent to driver
2016-12-14 14:21:17,265 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 27) in 16 ms on localhost (1/2)
2016-12-14 14:21:17,265 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 26) in 17 ms on localhost (2/2)
2016-12-14 14:21:17,265 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 14 (aggregate at KMeans.scala:404) finished in 0.018 s
2016-12-14 14:21:17,266 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,266 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: aggregate at KMeans.scala:404, took 0.032761 s
2016-12-14 14:21:17,268 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 27 from persistence list
2016-12-14 14:21:17,269 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 14:21:17,284 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:21:17,287 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:21:17,287 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collect at KMeans.scala:436)
2016-12-14 14:21:17,287 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:17,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:17,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:21:17,291 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 7.4 KB, free 497.9 KB)
2016-12-14 14:21:17,305 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 14:21:17,307 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:30140 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:21:17,309 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:30140 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:21:17,310 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 481.5 KB)
2016-12-14 14:21:17,311 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 14:21:17,311 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:30140 (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:21:17,311 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,312 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:21:17,312 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 14:21:17,312 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:30140 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:21:17,313 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 14:21:17,313 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:21:17,313 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:30140 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:21:17,314 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2759 bytes)
2016-12-14 14:21:17,314 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 14:21:17,314 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 28)
2016-12-14 14:21:17,314 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 29)
2016-12-14 14:21:17,316 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:30140 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:21:17,317 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 14:21:17,319 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:30140 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:21:17,319 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 14:21:17,320 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:17,320 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:17,320 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_0 locally
2016-12-14 14:21:17,321 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:30140 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:21:17,322 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 14:21:17,322 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,322 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:17,322 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_31_1 locally
2016-12-14 14:21:17,323 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:30140 in memory (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:21:17,323 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 14:21:17,324 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 14:21:17,325 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:30140 in memory (size: 9.2 KB, free: 529.9 MB)
2016-12-14 14:21:17,325 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 28). 2934 bytes result sent to driver
2016-12-14 14:21:17,325 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 14:21:17,326 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:30140 in memory (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:21:17,327 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 14:21:17,327 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:30140 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:21:17,330 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 29). 3143 bytes result sent to driver
2016-12-14 14:21:17,332 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 28) in 18 ms on localhost (1/2)
2016-12-14 14:21:17,339 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 29) in 25 ms on localhost (2/2)
2016-12-14 14:21:17,339 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collect at KMeans.scala:436) finished in 0.027 s
2016-12-14 14:21:17,339 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,340 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collect at KMeans.scala:436, took 0.055021 s
2016-12-14 14:21:17,341 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 31 from persistence list
2016-12-14 14:21:17,342 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 14:21:17,344 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 20.3 KB, free 376.4 KB)
2016-12-14 14:21:17,353 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.4 KB, free 380.8 KB)
2016-12-14 14:21:17,354 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:30140 (size: 4.4 KB, free: 530.0 MB)
2016-12-14 14:21:17,355 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at KMeans.scala:450
2016-12-14 14:21:17,407 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 14:21:17,420 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 34 (flatMap at KMeans.scala:451)
2016-12-14 14:21:17,420 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 14:21:17,420 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:455)
2016-12-14 14:21:17,420 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 14:21:17,420 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 14:21:17,422 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 14:21:17,427 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 6.4 KB, free 387.2 KB)
2016-12-14 14:21:17,430 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.5 KB, free 390.7 KB)
2016-12-14 14:21:17,431 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:30140 (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:21:17,432 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,434 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[34] at flatMap at KMeans.scala:451)
2016-12-14 14:21:17,434 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 14:21:17,438 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:17,439 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:17,439 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 30)
2016-12-14 14:21:17,439 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 31)
2016-12-14 14:21:17,444 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,444 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:17,445 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:17,445 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:17,558 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 31). 2237 bytes result sent to driver
2016-12-14 14:21:17,559 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 30). 2237 bytes result sent to driver
2016-12-14 14:21:17,568 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 30) in 132 ms on localhost (1/2)
2016-12-14 14:21:17,568 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 31) in 130 ms on localhost (2/2)
2016-12-14 14:21:17,568 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,571 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (flatMap at KMeans.scala:451) finished in 0.136 s
2016-12-14 14:21:17,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:17,572 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:17,573 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 14:21:17,574 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:17,576 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 14:21:17,584 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 2.6 KB, free 393.2 KB)
2016-12-14 14:21:17,590 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1555.0 B, free 394.8 KB)
2016-12-14 14:21:17,592 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:30140 (size: 1555.0 B, free: 530.0 MB)
2016-12-14 14:21:17,593 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,593 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[35] at reduceByKey at KMeans.scala:455)
2016-12-14 14:21:17,593 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 14:21:17,598 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 32, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:17,598 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 33, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:17,599 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 32)
2016-12-14 14:21:17,599 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 33)
2016-12-14 14:21:17,622 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:17,622 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:17,625 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 9 ms
2016-12-14 14:21:17,625 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 9 ms
2016-12-14 14:21:17,677 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 32). 4269 bytes result sent to driver
2016-12-14 14:21:17,677 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 33). 3910 bytes result sent to driver
2016-12-14 14:21:17,683 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 32) in 86 ms on localhost (1/2)
2016-12-14 14:21:17,683 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 33) in 85 ms on localhost (2/2)
2016-12-14 14:21:17,684 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:455) finished in 0.088 s
2016-12-14 14:21:17,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:455, took 0.277047 s
2016-12-14 14:21:17,831 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:21:17,832 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 14:21:17,832 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:21:17,831 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:21:17,831 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:21:17,831 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:21:17,831 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:21:17,831 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:21:17,831 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:21:17,832 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:21:17,848 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 1.529 seconds.
2016-12-14 14:21:17,855 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 2.5 KB, free 397.3 KB)
2016-12-14 14:21:17,864 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 953.0 B, free 398.2 KB)
2016-12-14 14:21:17,865 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:30140 (size: 953.0 B, free: 529.9 MB)
2016-12-14 14:21:17,865 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at KMeans.scala:276
2016-12-14 14:21:17,898 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:17,899 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 36 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:17,900 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:17,900 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:17,900 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 14:21:17,900 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 14:21:17,902 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:17,904 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 7.4 KB, free 405.6 KB)
2016-12-14 14:21:17,908 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.9 KB, free 409.4 KB)
2016-12-14 14:21:17,909 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:30140 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:21:17,909 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,909 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[36] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:17,910 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 14:21:17,911 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 34, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:17,912 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 35, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:17,912 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 34)
2016-12-14 14:21:17,912 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 35)
2016-12-14 14:21:17,916 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:17,917 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:17,917 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,917 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:17,931 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 34). 2516 bytes result sent to driver
2016-12-14 14:21:17,932 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 35). 2516 bytes result sent to driver
2016-12-14 14:21:17,934 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 34) in 23 ms on localhost (1/2)
2016-12-14 14:21:17,936 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 35) in 23 ms on localhost (2/2)
2016-12-14 14:21:17,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.026 s
2016-12-14 14:21:17,936 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:17,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:17,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 14:21:17,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:17,937 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:17,938 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 2.9 KB, free 412.3 KB)
2016-12-14 14:21:17,942 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 1668.0 B, free 414.0 KB)
2016-12-14 14:21:17,943 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:30140 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:17,943 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,944 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[37] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:17,944 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 14:21:17,945 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 36, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:17,946 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 37, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:17,946 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 37)
2016-12-14 14:21:17,946 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 36)
2016-12-14 14:21:17,948 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:17,948 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:17,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:17,949 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:17,956 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 37). 1723 bytes result sent to driver
2016-12-14 14:21:17,959 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 37) in 13 ms on localhost (1/2)
2016-12-14 14:21:17,960 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 36). 1725 bytes result sent to driver
2016-12-14 14:21:17,963 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 36) in 18 ms on localhost (2/2)
2016-12-14 14:21:17,963 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.019 s
2016-12-14 14:21:17,963 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:21:17,963 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.065004 s
2016-12-14 14:21:17,966 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 2.5 KB, free 416.5 KB)
2016-12-14 14:21:17,970 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 606.0 B, free 417.1 KB)
2016-12-14 14:21:17,970 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:30140 (size: 606.0 B, free: 529.9 MB)
2016-12-14 14:21:17,971 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at KMeans.scala:276
2016-12-14 14:21:17,980 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:17,981 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 38 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:17,982 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:17,982 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:17,982 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 14:21:17,983 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 14:21:17,984 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:17,986 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 7.4 KB, free 424.4 KB)
2016-12-14 14:21:17,992 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.9 KB, free 428.3 KB)
2016-12-14 14:21:17,992 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:30140 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:21:17,993 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:17,993 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[38] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:17,993 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 14:21:17,995 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 38, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:17,996 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 39, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:17,996 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 39)
2016-12-14 14:21:17,996 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 38)
2016-12-14 14:21:17,999 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:17,999 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,000 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,000 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,005 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 39). 2516 bytes result sent to driver
2016-12-14 14:21:18,008 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 39) in 13 ms on localhost (1/2)
2016-12-14 14:21:18,011 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 38). 2516 bytes result sent to driver
2016-12-14 14:21:18,014 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 38) in 20 ms on localhost (2/2)
2016-12-14 14:21:18,014 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,014 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.020 s
2016-12-14 14:21:18,014 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,014 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,014 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 14:21:18,014 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,015 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,016 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 2.9 KB, free 431.2 KB)
2016-12-14 14:21:18,019 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 1665.0 B, free 432.8 KB)
2016-12-14 14:21:18,020 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:30140 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:21:18,020 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,021 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[39] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,021 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 14:21:18,023 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,024 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,025 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 40)
2016-12-14 14:21:18,025 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 41)
2016-12-14 14:21:18,027 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,027 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:18,027 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,028 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,034 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 41). 1723 bytes result sent to driver
2016-12-14 14:21:18,038 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 41) in 14 ms on localhost (1/2)
2016-12-14 14:21:18,039 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 40). 1724 bytes result sent to driver
2016-12-14 14:21:18,043 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 40) in 21 ms on localhost (2/2)
2016-12-14 14:21:18,043 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:21:18,043 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,043 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.063060 s
2016-12-14 14:21:18,045 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 8 finished in 2 iterations
2016-12-14 14:21:18,046 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 2.3 KB, free 435.1 KB)
2016-12-14 14:21:18,049 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 502.0 B, free 435.6 KB)
2016-12-14 14:21:18,049 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:30140 (size: 502.0 B, free: 529.9 MB)
2016-12-14 14:21:18,050 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at KMeans.scala:276
2016-12-14 14:21:18,063 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:18,066 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 40 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,067 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:18,067 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:18,067 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 14:21:18,067 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 14:21:18,069 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:18,071 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 7.3 KB, free 442.9 KB)
2016-12-14 14:21:18,077 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KB, free 446.8 KB)
2016-12-14 14:21:18,078 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:30140 (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:21:18,079 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,079 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[40] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,079 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 14:21:18,081 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 42, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,081 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 43, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,082 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 42)
2016-12-14 14:21:18,082 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 43)
2016-12-14 14:21:18,086 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,086 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,087 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,087 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,097 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 43). 2492 bytes result sent to driver
2016-12-14 14:21:18,099 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 42). 2492 bytes result sent to driver
2016-12-14 14:21:18,101 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 43) in 20 ms on localhost (1/2)
2016-12-14 14:21:18,103 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 42) in 22 ms on localhost (2/2)
2016-12-14 14:21:18,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.023 s
2016-12-14 14:21:18,103 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,103 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 14:21:18,104 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,104 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,106 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 2.9 KB, free 449.7 KB)
2016-12-14 14:21:18,110 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 1667.0 B, free 451.3 KB)
2016-12-14 14:21:18,110 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:30140 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:21:18,111 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,112 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[41] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,112 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 14:21:18,113 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 44, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,114 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 45, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,114 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 44)
2016-12-14 14:21:18,114 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 45)
2016-12-14 14:21:18,116 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,116 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,116 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:18,117 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,126 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 44). 1687 bytes result sent to driver
2016-12-14 14:21:18,127 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 45). 1649 bytes result sent to driver
2016-12-14 14:21:18,130 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 44) in 17 ms on localhost (1/2)
2016-12-14 14:21:18,133 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 45) in 20 ms on localhost (2/2)
2016-12-14 14:21:18,133 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:21:18,133 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,134 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 19 finished: collectAsMap at KMeans.scala:302, took 0.070574 s
2016-12-14 14:21:18,135 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 3 iterations
2016-12-14 14:21:18,136 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 2 finished in 3 iterations
2016-12-14 14:21:18,136 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 3 iterations
2016-12-14 14:21:18,136 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 3 iterations
2016-12-14 14:21:18,136 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 3 iterations
2016-12-14 14:21:18,137 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 1048.0 B, free 452.3 KB)
2016-12-14 14:21:18,142 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 408.0 B, free 452.7 KB)
2016-12-14 14:21:18,143 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:30140 (size: 408.0 B, free: 529.9 MB)
2016-12-14 14:21:18,144 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at KMeans.scala:276
2016-12-14 14:21:18,161 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:18,162 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 42 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 20 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:18,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:18,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 14:21:18,163 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 14:21:18,164 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:18,166 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 7.1 KB, free 459.8 KB)
2016-12-14 14:21:18,170 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.8 KB, free 463.7 KB)
2016-12-14 14:21:18,171 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:30140 (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:18,172 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,172 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[42] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,172 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 14:21:18,174 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 46, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,174 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 47, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,175 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 47)
2016-12-14 14:21:18,175 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 46)
2016-12-14 14:21:18,178 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,178 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,179 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,179 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,186 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 47). 2372 bytes result sent to driver
2016-12-14 14:21:18,187 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 46). 2372 bytes result sent to driver
2016-12-14 14:21:18,189 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 47) in 14 ms on localhost (1/2)
2016-12-14 14:21:18,191 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 46) in 18 ms on localhost (2/2)
2016-12-14 14:21:18,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:21:18,192 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 14:21:18,192 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,193 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,195 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 2.9 KB, free 466.6 KB)
2016-12-14 14:21:18,200 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1668.0 B, free 468.2 KB)
2016-12-14 14:21:18,201 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:30140 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:18,202 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,202 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[43] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,202 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 14:21:18,204 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 48, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,205 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 49, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,206 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 48)
2016-12-14 14:21:18,206 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 49)
2016-12-14 14:21:18,208 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,208 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:18,208 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,209 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,217 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 49). 1391 bytes result sent to driver
2016-12-14 14:21:18,220 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 48). 1390 bytes result sent to driver
2016-12-14 14:21:18,222 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 49) in 17 ms on localhost (1/2)
2016-12-14 14:21:18,228 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 48) in 24 ms on localhost (2/2)
2016-12-14 14:21:18,228 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.025 s
2016-12-14 14:21:18,228 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,229 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 20 finished: collectAsMap at KMeans.scala:302, took 0.067680 s
2016-12-14 14:21:18,231 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 1048.0 B, free 469.2 KB)
2016-12-14 14:21:18,236 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 407.0 B, free 469.6 KB)
2016-12-14 14:21:18,236 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:30140 (size: 407.0 B, free: 529.9 MB)
2016-12-14 14:21:18,237 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at KMeans.scala:276
2016-12-14 14:21:18,254 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:18,256 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 44 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,256 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 21 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:18,256 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:18,257 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 14:21:18,257 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 14:21:18,258 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:18,261 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 7.1 KB, free 476.8 KB)
2016-12-14 14:21:18,266 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.8 KB, free 480.6 KB)
2016-12-14 14:21:18,266 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:30140 (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:18,267 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,267 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[44] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,268 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 14:21:18,270 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 50, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,271 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 51, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,271 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 51)
2016-12-14 14:21:18,271 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 50)
2016-12-14 14:21:18,275 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,275 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,276 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,276 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,282 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 26.0 (TID 51). 2372 bytes result sent to driver
2016-12-14 14:21:18,284 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 26.0 (TID 50). 2372 bytes result sent to driver
2016-12-14 14:21:18,284 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 26.0 (TID 51) in 14 ms on localhost (1/2)
2016-12-14 14:21:18,288 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 26.0 (TID 50) in 18 ms on localhost (2/2)
2016-12-14 14:21:18,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 26 (mapPartitions at KMeans.scala:279) finished in 0.020 s
2016-12-14 14:21:18,288 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,288 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 27)
2016-12-14 14:21:18,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,289 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,291 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 2.9 KB, free 483.5 KB)
2016-12-14 14:21:18,296 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 1664.0 B, free 485.1 KB)
2016-12-14 14:21:18,297 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:30140 (size: 1664.0 B, free: 529.9 MB)
2016-12-14 14:21:18,297 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,298 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[45] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,298 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 27.0 with 2 tasks
2016-12-14 14:21:18,299 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 27.0 (TID 52, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,300 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 27.0 (TID 53, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,300 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 27.0 (TID 52)
2016-12-14 14:21:18,300 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 27.0 (TID 53)
2016-12-14 14:21:18,303 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,303 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:18,303 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,304 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,314 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 27.0 (TID 52). 1390 bytes result sent to driver
2016-12-14 14:21:18,316 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 27.0 (TID 53). 1391 bytes result sent to driver
2016-12-14 14:21:18,321 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 27.0 (TID 52) in 22 ms on localhost (1/2)
2016-12-14 14:21:18,322 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 27.0 (TID 53) in 23 ms on localhost (2/2)
2016-12-14 14:21:18,322 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 27 (collectAsMap at KMeans.scala:302) finished in 0.023 s
2016-12-14 14:21:18,322 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,323 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 21 finished: collectAsMap at KMeans.scala:302, took 0.068348 s
2016-12-14 14:21:18,326 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 1048.0 B, free 486.2 KB)
2016-12-14 14:21:18,333 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 406.0 B, free 486.6 KB)
2016-12-14 14:21:18,334 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:30140 (size: 406.0 B, free: 529.9 MB)
2016-12-14 14:21:18,334 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at KMeans.scala:276
2016-12-14 14:21:18,359 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:18,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 46 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 22 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:18,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 29 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:18,361 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 28)
2016-12-14 14:21:18,362 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 28)
2016-12-14 14:21:18,363 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:18,365 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41 stored as values in memory (estimated size 7.1 KB, free 493.7 KB)
2016-12-14 14:21:18,369 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.8 KB, free 497.5 KB)
2016-12-14 14:21:18,370 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_41_piece0 in memory on localhost:30140 (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:18,370 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,371 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[46] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,371 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 28.0 with 2 tasks
2016-12-14 14:21:18,373 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 28.0 (TID 54, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,373 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 28.0 (TID 55, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,374 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 28.0 (TID 54)
2016-12-14 14:21:18,374 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 28.0 (TID 55)
2016-12-14 14:21:18,376 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,376 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,379 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,379 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,381 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 28.0 (TID 54). 2372 bytes result sent to driver
2016-12-14 14:21:18,384 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 28.0 (TID 54) in 12 ms on localhost (1/2)
2016-12-14 14:21:18,386 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 28.0 (TID 55). 2372 bytes result sent to driver
2016-12-14 14:21:18,390 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 28 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:21:18,390 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 29)
2016-12-14 14:21:18,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,390 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 28.0 (TID 55) in 17 ms on localhost (2/2)
2016-12-14 14:21:18,391 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,391 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,393 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42 stored as values in memory (estimated size 2.9 KB, free 500.4 KB)
2016-12-14 14:21:18,396 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_42_piece0 stored as bytes in memory (estimated size 1668.0 B, free 502.1 KB)
2016-12-14 14:21:18,397 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_42_piece0 in memory on localhost:30140 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:18,398 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,398 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[47] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,398 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 29.0 with 2 tasks
2016-12-14 14:21:18,399 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 29.0 (TID 56, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,400 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 29.0 (TID 57, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,400 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 29.0 (TID 57)
2016-12-14 14:21:18,400 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 29.0 (TID 56)
2016-12-14 14:21:18,402 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,403 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,403 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,404 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,414 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 29.0 (TID 57). 1391 bytes result sent to driver
2016-12-14 14:21:18,415 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 29.0 (TID 56). 1390 bytes result sent to driver
2016-12-14 14:21:18,419 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 29.0 (TID 57) in 19 ms on localhost (1/2)
2016-12-14 14:21:18,421 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 29.0 (TID 56) in 22 ms on localhost (2/2)
2016-12-14 14:21:18,421 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 29 (collectAsMap at KMeans.scala:302) finished in 0.022 s
2016-12-14 14:21:18,421 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,421 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 22 finished: collectAsMap at KMeans.scala:302, took 0.061834 s
2016-12-14 14:21:18,422 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43 stored as values in memory (estimated size 1048.0 B, free 503.1 KB)
2016-12-14 14:21:18,425 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_43_piece0 stored as bytes in memory (estimated size 406.0 B, free 503.5 KB)
2016-12-14 14:21:18,425 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_43_piece0 in memory on localhost:30140 (size: 406.0 B, free: 529.9 MB)
2016-12-14 14:21:18,426 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 43 from broadcast at KMeans.scala:276
2016-12-14 14:21:18,434 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:18,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 48 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 23 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:18,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 31 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:18,435 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 30)
2016-12-14 14:21:18,436 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 30)
2016-12-14 14:21:18,437 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:18,439 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44 stored as values in memory (estimated size 7.1 KB, free 510.6 KB)
2016-12-14 14:21:18,443 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.8 KB, free 514.4 KB)
2016-12-14 14:21:18,444 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_44_piece0 in memory on localhost:30140 (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:18,444 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[48] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,444 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 30.0 with 2 tasks
2016-12-14 14:21:18,445 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 30.0 (TID 58, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,446 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 30.0 (TID 59, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,446 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 30.0 (TID 58)
2016-12-14 14:21:18,446 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 30.0 (TID 59)
2016-12-14 14:21:18,448 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,448 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,458 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,459 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 14:21:18,459 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,460 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:30140 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:21:18,461 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 14:21:18,464 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 14:21:18,465 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 30.0 (TID 58). 2372 bytes result sent to driver
2016-12-14 14:21:18,465 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:30140 in memory (size: 3.7 KB, free: 529.9 MB)
2016-12-14 14:21:18,467 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 14:21:18,467 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 14:21:18,467 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 14:21:18,467 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 30.0 (TID 59). 2372 bytes result sent to driver
2016-12-14 14:21:18,468 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:30140 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:21:18,468 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 30.0 (TID 58) in 23 ms on localhost (1/2)
2016-12-14 14:21:18,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 14:21:18,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 14:21:18,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 14:21:18,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 14:21:18,469 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 14:21:18,470 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 14:21:18,470 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 14:21:18,471 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:30140 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:18,472 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 30.0 (TID 59) in 26 ms on localhost (2/2)
2016-12-14 14:21:18,472 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 14:21:18,472 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,472 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 30 (mapPartitions at KMeans.scala:279) finished in 0.027 s
2016-12-14 14:21:18,472 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 14:21:18,472 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 31)
2016-12-14 14:21:18,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,473 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_30_piece0 on localhost:30140 in memory (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:21:18,473 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,474 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 14:21:18,474 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:30140 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:21:18,475 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45 stored as values in memory (estimated size 2.9 KB, free 478.0 KB)
2016-12-14 14:21:18,476 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 14:21:18,476 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 14:21:18,477 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:30140 in memory (size: 606.0 B, free: 529.9 MB)
2016-12-14 14:21:18,478 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 14:21:18,479 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 14:21:18,479 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 14:21:18,479 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 14:21:18,479 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_45_piece0 stored as bytes in memory (estimated size 1668.0 B, free 469.2 KB)
2016-12-14 14:21:18,479 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 14:21:18,480 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_45_piece0 in memory on localhost:30140 (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:18,481 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,481 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:30140 in memory (size: 1496.0 B, free: 529.9 MB)
2016-12-14 14:21:18,481 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[49] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,481 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 31.0 with 2 tasks
2016-12-14 14:21:18,481 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 14:21:18,482 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 14:21:18,482 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 31.0 (TID 60, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,483 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_31_piece0 on localhost:30140 in memory (size: 502.0 B, free: 529.9 MB)
2016-12-14 14:21:18,483 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 31.0 (TID 61, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,483 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 31.0 (TID 60)
2016-12-14 14:21:18,483 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 51
2016-12-14 14:21:18,483 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 31.0 (TID 61)
2016-12-14 14:21:18,483 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 50
2016-12-14 14:21:18,484 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 49
2016-12-14 14:21:18,484 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 48
2016-12-14 14:21:18,484 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 47
2016-12-14 14:21:18,484 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 46
2016-12-14 14:21:18,484 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 14:21:18,485 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 14:21:18,485 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 57
2016-12-14 14:21:18,485 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 56
2016-12-14 14:21:18,485 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 55
2016-12-14 14:21:18,485 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,485 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 54
2016-12-14 14:21:18,486 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,486 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,487 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,487 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_33_piece0 on localhost:30140 in memory (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:21:18,488 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 53
2016-12-14 14:21:18,488 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_32_piece0 on localhost:30140 in memory (size: 3.9 KB, free: 529.9 MB)
2016-12-14 14:21:18,489 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 52
2016-12-14 14:21:18,489 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 5
2016-12-14 14:21:18,490 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_37_piece0 on localhost:30140 in memory (size: 407.0 B, free: 529.9 MB)
2016-12-14 14:21:18,491 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 63
2016-12-14 14:21:18,491 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 62
2016-12-14 14:21:18,491 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 61
2016-12-14 14:21:18,491 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 60
2016-12-14 14:21:18,492 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_36_piece0 on localhost:30140 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:18,492 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 59
2016-12-14 14:21:18,493 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_35_piece0 on localhost:30140 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:18,494 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 58
2016-12-14 14:21:18,494 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 4
2016-12-14 14:21:18,495 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_34_piece0 on localhost:30140 in memory (size: 408.0 B, free: 529.9 MB)
2016-12-14 14:21:18,495 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 14:21:18,496 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 31.0 (TID 60). 1390 bytes result sent to driver
2016-12-14 14:21:18,496 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:30140 in memory (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:21:18,496 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 14:21:18,497 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:30140 in memory (size: 953.0 B, free: 529.9 MB)
2016-12-14 14:21:18,497 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 31.0 (TID 61). 1391 bytes result sent to driver
2016-12-14 14:21:18,499 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_38_piece0 on localhost:30140 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:18,499 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 64
2016-12-14 14:21:18,500 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 31.0 (TID 60) in 17 ms on localhost (1/2)
2016-12-14 14:21:18,500 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:30140 in memory (size: 1535.0 B, free: 529.9 MB)
2016-12-14 14:21:18,501 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:30140 in memory (size: 4.4 KB, free: 530.0 MB)
2016-12-14 14:21:18,502 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 14:21:18,502 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 14:21:18,503 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 31.0 (TID 61) in 20 ms on localhost (2/2)
2016-12-14 14:21:18,503 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 31 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:21:18,503 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_40_piece0 on localhost:30140 in memory (size: 406.0 B, free: 530.0 MB)
2016-12-14 14:21:18,503 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,504 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 23 finished: collectAsMap at KMeans.scala:302, took 0.069785 s
2016-12-14 14:21:18,504 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 69
2016-12-14 14:21:18,504 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 68
2016-12-14 14:21:18,505 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 67
2016-12-14 14:21:18,505 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 66
2016-12-14 14:21:18,505 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 7 iterations
2016-12-14 14:21:18,505 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_39_piece0 on localhost:30140 in memory (size: 1664.0 B, free: 530.0 MB)
2016-12-14 14:21:18,506 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 65
2016-12-14 14:21:18,506 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46 stored as values in memory (estimated size 800.0 B, free 365.8 KB)
2016-12-14 14:21:18,507 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 31
2016-12-14 14:21:18,509 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 31
2016-12-14 14:21:18,509 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 14:21:18,510 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_42_piece0 on localhost:30140 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:21:18,511 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 71
2016-12-14 14:21:18,511 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_46_piece0 stored as bytes in memory (estimated size 351.0 B, free 361.6 KB)
2016-12-14 14:21:18,512 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_46_piece0 in memory on localhost:30140 (size: 351.0 B, free: 530.0 MB)
2016-12-14 14:21:18,512 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_41_piece0 on localhost:30140 in memory (size: 3.8 KB, free: 530.0 MB)
2016-12-14 14:21:18,512 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 46 from broadcast at KMeans.scala:276
2016-12-14 14:21:18,513 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 70
2016-12-14 14:21:18,514 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 6
2016-12-14 14:21:18,514 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 23
2016-12-14 14:21:18,515 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 23
2016-12-14 14:21:18,515 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 27
2016-12-14 14:21:18,516 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 27
2016-12-14 14:21:18,516 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 14:21:18,517 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 19
2016-12-14 14:21:18,517 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 19
2016-12-14 14:21:18,518 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:30140 in memory (size: 1409.0 B, free: 530.0 MB)
2016-12-14 14:21:18,519 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 15
2016-12-14 14:21:18,520 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 15
2016-12-14 14:21:18,521 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:30140 in memory (size: 430.0 B, free: 530.0 MB)
2016-12-14 14:21:18,522 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:30140 in memory (size: 1436.0 B, free: 530.0 MB)
2016-12-14 14:21:18,522 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 14:21:18,529 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:18,530 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 50 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 24 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:18,531 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 33 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:18,532 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 32)
2016-12-14 14:21:18,532 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 32)
2016-12-14 14:21:18,534 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:18,536 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47 stored as values in memory (estimated size 7.1 KB, free 343.8 KB)
2016-12-14 14:21:18,541 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_47_piece0 stored as bytes in memory (estimated size 3.8 KB, free 347.6 KB)
2016-12-14 14:21:18,542 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_47_piece0 in memory on localhost:30140 (size: 3.8 KB, free: 530.0 MB)
2016-12-14 14:21:18,542 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[50] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,543 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 32.0 with 2 tasks
2016-12-14 14:21:18,545 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 32.0 (TID 62, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,545 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 32.0 (TID 63, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,546 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 32.0 (TID 62)
2016-12-14 14:21:18,546 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 32.0 (TID 63)
2016-12-14 14:21:18,550 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,551 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,551 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,551 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,558 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 32.0 (TID 62). 2348 bytes result sent to driver
2016-12-14 14:21:18,559 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 32.0 (TID 63). 2348 bytes result sent to driver
2016-12-14 14:21:18,564 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 32.0 (TID 63) in 19 ms on localhost (1/2)
2016-12-14 14:21:18,565 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 32.0 (TID 62) in 20 ms on localhost (2/2)
2016-12-14 14:21:18,565 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 32 (mapPartitions at KMeans.scala:279) finished in 0.021 s
2016-12-14 14:21:18,565 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,565 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,565 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,565 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 33)
2016-12-14 14:21:18,565 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,566 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,567 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48 stored as values in memory (estimated size 2.9 KB, free 350.5 KB)
2016-12-14 14:21:18,569 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_48_piece0 stored as bytes in memory (estimated size 1668.0 B, free 352.2 KB)
2016-12-14 14:21:18,570 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_48_piece0 in memory on localhost:30140 (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:21:18,570 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,570 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 33 (ShuffledRDD[51] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,570 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 33.0 with 2 tasks
2016-12-14 14:21:18,571 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 33.0 (TID 64, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,572 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 33.0 (TID 65, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,572 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 33.0 (TID 64)
2016-12-14 14:21:18,573 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 33.0 (TID 65)
2016-12-14 14:21:18,575 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,575 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:18,575 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,575 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:18,586 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 33.0 (TID 64). 1313 bytes result sent to driver
2016-12-14 14:21:18,590 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 33.0 (TID 65). 1351 bytes result sent to driver
2016-12-14 14:21:18,590 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 33.0 (TID 64) in 19 ms on localhost (1/2)
2016-12-14 14:21:18,594 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 33.0 (TID 65) in 22 ms on localhost (2/2)
2016-12-14 14:21:18,594 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 33 (collectAsMap at KMeans.scala:302) finished in 0.023 s
2016-12-14 14:21:18,594 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 24 finished: collectAsMap at KMeans.scala:302, took 0.065577 s
2016-12-14 14:21:18,596 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 8 iterations
2016-12-14 14:21:18,596 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 8 iterations
2016-12-14 14:21:18,597 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49 stored as values in memory (estimated size 296.0 B, free 352.5 KB)
2016-12-14 14:21:18,601 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_49_piece0 stored as bytes in memory (estimated size 204.0 B, free 352.6 KB)
2016-12-14 14:21:18,602 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_49_piece0 in memory on localhost:30140 (size: 204.0 B, free: 530.0 MB)
2016-12-14 14:21:18,603 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 49 from broadcast at KMeans.scala:276
2016-12-14 14:21:18,622 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:21:18,623 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 52 (mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,623 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 25 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:21:18,623 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 35 (collectAsMap at KMeans.scala:302)
2016-12-14 14:21:18,623 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 34)
2016-12-14 14:21:18,624 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 34)
2016-12-14 14:21:18,625 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:21:18,626 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50 stored as values in memory (estimated size 7.0 KB, free 359.7 KB)
2016-12-14 14:21:18,630 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.8 KB, free 363.5 KB)
2016-12-14 14:21:18,631 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_50_piece0 in memory on localhost:30140 (size: 3.8 KB, free: 530.0 MB)
2016-12-14 14:21:18,632 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[52] at mapPartitions at KMeans.scala:279)
2016-12-14 14:21:18,633 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 34.0 with 2 tasks
2016-12-14 14:21:18,634 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 34.0 (TID 66, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,635 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 34.0 (TID 67, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
2016-12-14 14:21:18,635 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 34.0 (TID 67)
2016-12-14 14:21:18,635 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 34.0 (TID 66)
2016-12-14 14:21:18,639 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,639 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_1 locally
2016-12-14 14:21:18,640 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,640 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_9_0 locally
2016-12-14 14:21:18,646 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 34.0 (TID 67). 2300 bytes result sent to driver
2016-12-14 14:21:18,650 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 34.0 (TID 67) in 15 ms on localhost (1/2)
2016-12-14 14:21:18,651 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 34.0 (TID 66). 2300 bytes result sent to driver
2016-12-14 14:21:18,655 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 34.0 (TID 66) in 21 ms on localhost (2/2)
2016-12-14 14:21:18,655 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 34 (mapPartitions at KMeans.scala:279) finished in 0.022 s
2016-12-14 14:21:18,655 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,656 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,656 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,656 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 35)
2016-12-14 14:21:18,656 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,657 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:21:18,660 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51 stored as values in memory (estimated size 2.9 KB, free 366.4 KB)
2016-12-14 14:21:18,665 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_51_piece0 stored as bytes in memory (estimated size 1668.0 B, free 368.0 KB)
2016-12-14 14:21:18,666 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_51_piece0 in memory on localhost:30140 (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:21:18,667 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,667 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 35 (ShuffledRDD[53] at reduceByKey at KMeans.scala:302)
2016-12-14 14:21:18,668 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 35.0 with 2 tasks
2016-12-14 14:21:18,669 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 35.0 (TID 68, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,670 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 35.0 (TID 69, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:18,670 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 35.0 (TID 69)
2016-12-14 14:21:18,670 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 35.0 (TID 68)
2016-12-14 14:21:18,672 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,672 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:18,672 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:18,673 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:18,682 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 35.0 (TID 68). 1202 bytes result sent to driver
2016-12-14 14:21:18,685 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 35.0 (TID 69). 1239 bytes result sent to driver
2016-12-14 14:21:18,687 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 35.0 (TID 68) in 18 ms on localhost (1/2)
2016-12-14 14:21:18,690 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 35.0 (TID 69) in 20 ms on localhost (2/2)
2016-12-14 14:21:18,690 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 35 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:21:18,690 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,690 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 25 finished: collectAsMap at KMeans.scala:302, took 0.068414 s
2016-12-14 14:21:18,691 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 9 iterations
2016-12-14 14:21:18,693 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Iterations took 0.841 seconds.
2016-12-14 14:21:18,694 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: KMeans converged in 9 iterations.
2016-12-14 14:21:18,697 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: The cost for the best run is 63.87383806036277.
2016-12-14 14:21:18,699 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 9 from persistence list
2016-12-14 14:21:18,700 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 14:21:18,701 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:21:18,712 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:110
2016-12-14 14:21:18,714 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 26 (foreach at K_means.scala:110) with 2 output partitions
2016-12-14 14:21:18,714 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 36 (foreach at K_means.scala:110)
2016-12-14 14:21:18,714 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:18,715 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:18,716 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 36 (MapPartitionsRDD[8] at map at K_means.scala:104), which has no missing parents
2016-12-14 14:21:18,718 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52 stored as values in memory (estimated size 4.4 KB, free 368.3 KB)
2016-12-14 14:21:18,725 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.5 KB, free 370.8 KB)
2016-12-14 14:21:18,725 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_52_piece0 in memory on localhost:30140 (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:18,726 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,727 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 36 (MapPartitionsRDD[8] at map at K_means.scala:104)
2016-12-14 14:21:18,727 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 36.0 with 2 tasks
2016-12-14 14:21:18,728 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 36.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,729 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 36.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,729 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 36.0 (TID 70)
2016-12-14 14:21:18,729 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 36.0 (TID 71)
2016-12-14 14:21:18,732 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,733 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8271359726790233,-5.641331045573369] belong to cluster 1
2016-12-14 14:21:18,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.410983961066749,-5.644334710390876] belong to cluster 2
2016-12-14 14:21:18,733 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7959524821488415,-5.145166883252961] belong to cluster 1
2016-12-14 14:21:18,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.8423845166376935,-5.559393251411284] belong to cluster 2
2016-12-14 14:21:18,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.621523558165056,-5.177378121203952] belong to cluster 1
2016-12-14 14:21:18,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.068739369853676,-5.582116315621753] belong to cluster 0
2016-12-14 14:21:18,734 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.764905900474237,-5.003599415056986] belong to cluster 1
2016-12-14 14:21:18,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.323798646780975,-5.1523921559303485] belong to cluster 2
2016-12-14 14:21:18,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7827501159516568,-5.648648294377431] belong to cluster 1
2016-12-14 14:21:18,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.204008342119569,-4.949637118042831] belong to cluster 2
2016-12-14 14:21:18,735 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2314457367733738,-6.062506444034109] belong to cluster 1
2016-12-14 14:21:18,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.441000208833702,-4.612185799078262] belong to cluster 2
2016-12-14 14:21:18,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.690452415602341,-5.232619219784294] belong to cluster 1
2016-12-14 14:21:18,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.319458605679827,-4.6372331864346314] belong to cluster 2
2016-12-14 14:21:18,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.884861104459153,-5.485129079769269] belong to cluster 1
2016-12-14 14:21:18,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.646338048234346,-5.003014088105591] belong to cluster 2
2016-12-14 14:21:18,736 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.623384532447338,-4.743925704477388] belong to cluster 1
2016-12-14 14:21:18,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.890080080558556,-4.893518592594351] belong to cluster 2
2016-12-14 14:21:18,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8374984110638515,-5.208032027056244] belong to cluster 1
2016-12-14 14:21:18,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.098617951362883,-4.8314394630914865] belong to cluster 2
2016-12-14 14:21:18,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.004816308444068,-5.966658744481553] belong to cluster 1
2016-12-14 14:21:18,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.318548594459688,-5.509777694580084] belong to cluster 2
2016-12-14 14:21:18,737 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.898200379511916,-5.336244362769233] belong to cluster 1
2016-12-14 14:21:18,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.731772064027652,-5.722759067810006] belong to cluster 2
2016-12-14 14:21:18,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.723909121785875,-5.086983541937878] belong to cluster 1
2016-12-14 14:21:18,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.324210888152043,-4.94404473249009] belong to cluster 2
2016-12-14 14:21:18,738 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.2861426515079915,-4.811443821323552] belong to cluster 1
2016-12-14 14:21:18,739 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.756538259473318,-5.047995695147128] belong to cluster 2
2016-12-14 14:21:18,739 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8677998808418255,-6.500918630222436] belong to cluster 1
2016-12-14 14:21:18,739 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.675856526152229,-4.635062261498171] belong to cluster 2
2016-12-14 14:21:18,739 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.127473773983595,-6.6594780753688365] belong to cluster 1
2016-12-14 14:21:18,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.974374086654397,-4.645197184272854] belong to cluster 2
2016-12-14 14:21:18,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.888816894657163,-6.132813405405575] belong to cluster 1
2016-12-14 14:21:18,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.401503543434129,-5.280911288062217] belong to cluster 2
2016-12-14 14:21:18,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.863020365303845,-5.633860398559866] belong to cluster 1
2016-12-14 14:21:18,740 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.740222147752621,-4.912466110630076] belong to cluster 2
2016-12-14 14:21:18,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.312265136352209,-6.19396781890072] belong to cluster 1
2016-12-14 14:21:18,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.804261813862112,-4.306298969030525] belong to cluster 2
2016-12-14 14:21:18,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.923996908865233,-5.835197369614942] belong to cluster 1
2016-12-14 14:21:18,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.866876136970037,-4.811505243406318] belong to cluster 2
2016-12-14 14:21:18,741 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2008113964698386,-5.712591552397877] belong to cluster 1
2016-12-14 14:21:18,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.842470045115695,-5.103543590146349] belong to cluster 2
2016-12-14 14:21:18,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.968108190479276,-5.754755485468792] belong to cluster 1
2016-12-14 14:21:18,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.886581326729738,-5.023101706000198] belong to cluster 2
2016-12-14 14:21:18,742 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.2954854028828655,-5.456339302434558] belong to cluster 1
2016-12-14 14:21:18,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.153033375949516,-5.333794907300257] belong to cluster 2
2016-12-14 14:21:18,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.2082145601190897,-5.420246409238966] belong to cluster 1
2016-12-14 14:21:18,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.602879764659478,-4.563155005639502] belong to cluster 2
2016-12-14 14:21:18,743 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1551720110990735,-5.283514141740633] belong to cluster 1
2016-12-14 14:21:18,744 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.809151005189907,-4.967707209210419] belong to cluster 2
2016-12-14 14:21:18,744 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.0034258709450925,-5.1756673908958115] belong to cluster 1
2016-12-14 14:21:18,744 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.043070078222529,-5.302881494168668] belong to cluster 0
2016-12-14 14:21:18,744 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.042287100237849,-5.452611045399396] belong to cluster 1
2016-12-14 14:21:18,744 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.92541532295673,-4.739798674896673] belong to cluster 2
2016-12-14 14:21:18,745 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.948952150946221,-5.6894082935590875] belong to cluster 1
2016-12-14 14:21:18,745 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.127827706067016,-5.656659017796284] belong to cluster 0
2016-12-14 14:21:18,745 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8715218294063902,-5.634013796769307] belong to cluster 1
2016-12-14 14:21:18,745 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.482158043689454,-5.133598036104063] belong to cluster 0
2016-12-14 14:21:18,745 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8784951897522135,-5.1246479001753515] belong to cluster 1
2016-12-14 14:21:18,746 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.861101081733914,-5.272841181154137] belong to cluster 0
2016-12-14 14:21:18,746 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9228810464795805,-5.117330651371289] belong to cluster 1
2016-12-14 14:21:18,746 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.908223018461111,-5.861891777039142] belong to cluster 0
2016-12-14 14:21:18,746 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1012657606613763,-5.732803739056605] belong to cluster 1
2016-12-14 14:21:18,747 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.030726342867909,-4.123372041758317] belong to cluster 2
2016-12-14 14:21:18,747 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.86370642438607,-6.134706363368474] belong to cluster 1
2016-12-14 14:21:18,747 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.443348194774275,-5.667100736989847] belong to cluster 0
2016-12-14 14:21:18,747 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.9141836207070524,-6.414745658816243] belong to cluster 1
2016-12-14 14:21:18,747 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.831015891657026,-5.069175560202079] belong to cluster 0
2016-12-14 14:21:18,748 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8374984110638515,-5.208032027056244] belong to cluster 1
2016-12-14 14:21:18,748 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.429477331427224,-6.095104360181011] belong to cluster 0
2016-12-14 14:21:18,748 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.644343250850438,-5.391916826532574] belong to cluster 1
2016-12-14 14:21:18,748 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.1732780448024585,-5.556762131846504] belong to cluster 0
2016-12-14 14:21:18,748 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8861146331025513,-5.921523739230576] belong to cluster 1
2016-12-14 14:21:18,749 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.313683550443706,-5.0985691241824505] belong to cluster 0
2016-12-14 14:21:18,749 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.8374984110638515,-5.208032027056244] belong to cluster 1
2016-12-14 14:21:18,749 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.67672196073637,-5.530004014181995] belong to cluster 0
2016-12-14 14:21:18,749 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5295004329290633,-4.834473681952901] belong to cluster 1
2016-12-14 14:21:18,750 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.855937315292797,-4.538308305632156] belong to cluster 2
2016-12-14 14:21:18,750 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.921020072197298,-5.5507830680978545] belong to cluster 1
2016-12-14 14:21:18,750 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.096610397091617,-4.775416676961808] belong to cluster 2
2016-12-14 14:21:18,750 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.7412041870366477,-5.585783150574148] belong to cluster 1
2016-12-14 14:21:18,751 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.416086675996883,-5.433542721791678] belong to cluster 0
2016-12-14 14:21:18,751 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.659132016216582,-4.38185836333945] belong to cluster 1
2016-12-14 14:21:18,751 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.46059187964747,-5.3554539902367475] belong to cluster 0
2016-12-14 14:21:18,751 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.5130466549506205,-4.9804161562181966] belong to cluster 1
2016-12-14 14:21:18,751 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.000108477439358,-6.486268275072539] belong to cluster 0
2016-12-14 14:21:18,752 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.1058289964982704,-5.51064098850504] belong to cluster 1
2016-12-14 14:21:18,752 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.306029958992944,-5.567989301781532] belong to cluster 0
2016-12-14 14:21:18,752 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-3.3025101436062654,-5.757419761229973] belong to cluster 1
2016-12-14 14:21:18,752 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.80967292235079,-4.553709794287482] belong to cluster 2
2016-12-14 14:21:18,752 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.795677907035518,-5.072042247910873] belong to cluster 1
2016-12-14 14:21:18,753 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.939510356803821,-5.691505702063138] belong to cluster 0
2016-12-14 14:21:18,753 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.973769726769464,-5.825091276285579] belong to cluster 1
2016-12-14 14:21:18,753 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.7094404700579355,-4.70914476904438] belong to cluster 2
2016-12-14 14:21:18,753 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.671021800955963,-5.094147392532501] belong to cluster 1
2016-12-14 14:21:18,754 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-9.01060858208193,-5.771497197773067] belong to cluster 0
2016-12-14 14:21:18,754 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.968657340705923,-5.901004756152968] belong to cluster 1
2016-12-14 14:21:18,754 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.89901134796453,-5.110692744238834] belong to cluster 2
2016-12-14 14:21:18,754 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-2.807430782919322,-5.429734582979489] belong to cluster 1
2016-12-14 14:21:18,754 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.787196747088665,-5.648110256565619] belong to cluster 0
2016-12-14 14:21:18,754 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.796137685628044,-6.000162916941911] belong to cluster 0
2016-12-14 14:21:18,755 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.125536928481306,-5.873090681087805] belong to cluster 0
2016-12-14 14:21:18,755 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.44375385076589,-5.633921820642632] belong to cluster 2
2016-12-14 14:21:18,755 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.76896828070811,-5.135586733385764] belong to cluster 2
2016-12-14 14:21:18,755 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.9754044205620485,-5.818913563781444] belong to cluster 0
2016-12-14 14:21:18,755 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.8020127455205746,-5.198298478979607] belong to cluster 2
2016-12-14 14:21:18,755 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.692310304130672,-4.489119787232876] belong to cluster 2
2016-12-14 14:21:18,756 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.634197078291286,-5.103868846259493] belong to cluster 0
2016-12-14 14:21:18,756 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.598477584989974,-5.390114120097761] belong to cluster 2
2016-12-14 14:21:18,756 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.898907500152001,-5.777242981535249] belong to cluster 0
2016-12-14 14:21:18,756 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.151779847306118,-4.897400247838951] belong to cluster 2
2016-12-14 14:21:18,756 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.352304023068358,-5.6874663218580155] belong to cluster 0
2016-12-14 14:21:18,756 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.6065668077214506,-5.598614941747458] belong to cluster 2
2016-12-14 14:21:18,756 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.743685996078847,-6.685247766785315] belong to cluster 0
2016-12-14 14:21:18,757 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-4.759875957134746,-4.313616217834587] belong to cluster 2
2016-12-14 14:21:18,757 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.670081470916108,-5.09639819924599] belong to cluster 0
2016-12-14 14:21:18,757 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.554640878489254,-5.543680639585998] belong to cluster 2
2016-12-14 14:21:18,757 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.954445702158948,-5.1709224417262565] belong to cluster 2
2016-12-14 14:21:18,757 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.5011530270551185,-4.594148864107075] belong to cluster 2
2016-12-14 14:21:18,757 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.290983204681542,-4.81325893610296] belong to cluster 0
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.000256901887883,-4.052231776946848] belong to cluster 2
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.587864718803637,-6.000488173055055] belong to cluster 0
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.0224411584664495,-5.212439625763012] belong to cluster 2
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.656329954492275,-5.453630339686286] belong to cluster 0
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.773678853936154,-4.766830432783661] belong to cluster 2
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.416206022920104,-5.36277123904081] belong to cluster 0
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.4953876429524025,-5.190363310586703] belong to cluster 2
2016-12-14 14:21:18,758 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.680196567253375,-5.150221230993888] belong to cluster 2
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.3364790958172765,-5.0629081597288135] belong to cluster 2
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.618996828956242,-5.686205979986095] belong to cluster 0
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.438916039815672,-5.782959935852109] belong to cluster 2
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.82564649241252,-5.4973325816026835] belong to cluster 0
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.170935886839173,-4.9627474397486555] belong to cluster 2
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.433793982618726,-5.72399490698769] belong to cluster 0
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.745883684042808,-4.982801901446863] belong to cluster 2
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.92541532295673,-4.739798674896673] belong to cluster 2
2016-12-14 14:21:18,759 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.453704805181816,-4.772901472658986] belong to cluster 2
2016-12-14 14:21:18,760 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-8.074665810123781,-5.590698233048819] belong to cluster 0
2016-12-14 14:21:18,760 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.554589498111678,-4.7332342841966275] belong to cluster 2
2016-12-14 14:21:18,760 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.930734317587952,-5.618227668511609] belong to cluster 0
2016-12-14 14:21:18,760 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.627583821536788,-5.230509716930599] belong to cluster 2
2016-12-14 14:21:18,760 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.455360146660711,-5.502138952855004] belong to cluster 0
2016-12-14 14:21:18,760 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-5.868129665613434,-5.2478999028676245] belong to cluster 2
2016-12-14 14:21:18,761 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.037006729096846,-4.939702882617169] belong to cluster 2
2016-12-14 14:21:18,761 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.807811948068508,-4.987162211014047] belong to cluster 2
2016-12-14 14:21:18,761 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.275389033309955,-5.393242917238342] belong to cluster 0
2016-12-14 14:21:18,761 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.431845746691982,-5.13233336748106] belong to cluster 2
2016-12-14 14:21:18,761 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-7.4129721730712035,-5.430600479056936] belong to cluster 0
2016-12-14 14:21:18,761 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.225351311425806,-5.465102883957428] belong to cluster 2
2016-12-14 14:21:18,761 INFO  com.datageek.test.K_means$ - apply: #####################whsh--->[-6.901009231102389,-5.031837021636704] belong to cluster 2
2016-12-14 14:21:18,764 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 36.0 (TID 71). 2057 bytes result sent to driver
2016-12-14 14:21:18,764 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 36.0 (TID 70). 2057 bytes result sent to driver
2016-12-14 14:21:18,767 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 36.0 (TID 71) in 39 ms on localhost (1/2)
2016-12-14 14:21:18,768 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 36.0 (TID 70) in 40 ms on localhost (2/2)
2016-12-14 14:21:18,768 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 36 (foreach at K_means.scala:110) finished in 0.040 s
2016-12-14 14:21:18,768 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 26 finished: foreach at K_means.scala:110, took 0.055832 s
2016-12-14 14:21:18,779 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at PCA.scala:42
2016-12-14 14:21:18,780 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 27 (first at PCA.scala:42) with 1 output partitions
2016-12-14 14:21:18,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 37 (first at PCA.scala:42)
2016-12-14 14:21:18,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:18,781 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:18,782 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 37 (MapPartitionsRDD[54] at map at K_means.scala:115), which has no missing parents
2016-12-14 14:21:18,783 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53 stored as values in memory (estimated size 3.6 KB, free 374.4 KB)
2016-12-14 14:21:18,789 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.1 KB, free 376.5 KB)
2016-12-14 14:21:18,790 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_53_piece0 in memory on localhost:30140 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:18,790 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,791 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[54] at map at K_means.scala:115)
2016-12-14 14:21:18,791 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 37.0 with 1 tasks
2016-12-14 14:21:18,793 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 37.0 (TID 72, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,793 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 37.0 (TID 72)
2016-12-14 14:21:18,794 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,796 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 37.0 (TID 72). 2176 bytes result sent to driver
2016-12-14 14:21:18,801 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 37.0 (TID 72) in 9 ms on localhost (1/1)
2016-12-14 14:21:18,801 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 37 (first at PCA.scala:42) finished in 0.009 s
2016-12-14 14:21:18,801 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,801 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 27 finished: first at PCA.scala:42, took 0.021569 s
2016-12-14 14:21:18,807 INFO  org.apache.spark.SparkContext - logInfo: Starting job: first at RowMatrix.scala:61
2016-12-14 14:21:18,808 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 28 (first at RowMatrix.scala:61) with 1 output partitions
2016-12-14 14:21:18,809 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 38 (first at RowMatrix.scala:61)
2016-12-14 14:21:18,809 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:18,809 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:18,810 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 38 (MapPartitionsRDD[54] at map at K_means.scala:115), which has no missing parents
2016-12-14 14:21:18,810 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54 stored as values in memory (estimated size 3.6 KB, free 380.1 KB)
2016-12-14 14:21:18,814 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.1 KB, free 382.2 KB)
2016-12-14 14:21:18,815 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_54_piece0 in memory on localhost:30140 (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:21:18,816 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,816 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[54] at map at K_means.scala:115)
2016-12-14 14:21:18,816 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 38.0 with 1 tasks
2016-12-14 14:21:18,817 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 38.0 (TID 73, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,818 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 38.0 (TID 73)
2016-12-14 14:21:18,819 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,820 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 38.0 (TID 73). 2176 bytes result sent to driver
2016-12-14 14:21:18,826 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 38.0 (TID 73) in 9 ms on localhost (1/1)
2016-12-14 14:21:18,826 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 38 (first at RowMatrix.scala:61) finished in 0.009 s
2016-12-14 14:21:18,827 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,827 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 28 finished: first at RowMatrix.scala:61, took 0.018986 s
2016-12-14 14:21:18,834 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:331
2016-12-14 14:21:18,835 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 29 (treeAggregate at RowMatrix.scala:331) with 2 output partitions
2016-12-14 14:21:18,835 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 39 (treeAggregate at RowMatrix.scala:331)
2016-12-14 14:21:18,835 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:18,835 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:18,836 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 39 (MapPartitionsRDD[55] at treeAggregate at RowMatrix.scala:331), which has no missing parents
2016-12-14 14:21:18,837 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55 stored as values in memory (estimated size 4.5 KB, free 386.7 KB)
2016-12-14 14:21:18,839 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.5 KB, free 389.2 KB)
2016-12-14 14:21:18,839 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_55_piece0 in memory on localhost:30140 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:21:18,840 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,840 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[55] at treeAggregate at RowMatrix.scala:331)
2016-12-14 14:21:18,840 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 39.0 with 2 tasks
2016-12-14 14:21:18,841 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 39.0 (TID 74, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,842 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 39.0 (TID 75, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,842 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 39.0 (TID 74)
2016-12-14 14:21:18,842 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 39.0 (TID 75)
2016-12-14 14:21:18,843 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,843 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,846 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 39.0 (TID 74). 2136 bytes result sent to driver
2016-12-14 14:21:18,847 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 39.0 (TID 75). 2136 bytes result sent to driver
2016-12-14 14:21:18,850 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 39.0 (TID 74) in 9 ms on localhost (1/2)
2016-12-14 14:21:18,852 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 39.0 (TID 75) in 11 ms on localhost (2/2)
2016-12-14 14:21:18,852 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 39 (treeAggregate at RowMatrix.scala:331) finished in 0.012 s
2016-12-14 14:21:18,852 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,853 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 29 finished: treeAggregate at RowMatrix.scala:331, took 0.018584 s
2016-12-14 14:21:18,860 INFO  org.apache.spark.SparkContext - logInfo: Starting job: treeAggregate at RowMatrix.scala:121
2016-12-14 14:21:18,860 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 30 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
2016-12-14 14:21:18,860 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 40 (treeAggregate at RowMatrix.scala:121)
2016-12-14 14:21:18,860 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:18,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:18,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 40 (MapPartitionsRDD[56] at treeAggregate at RowMatrix.scala:121), which has no missing parents
2016-12-14 14:21:18,862 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56 stored as values in memory (estimated size 4.6 KB, free 393.8 KB)
2016-12-14 14:21:18,864 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.5 KB, free 396.2 KB)
2016-12-14 14:21:18,865 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_56_piece0 in memory on localhost:30140 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:21:18,865 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,865 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[56] at treeAggregate at RowMatrix.scala:121)
2016-12-14 14:21:18,865 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 40.0 with 2 tasks
2016-12-14 14:21:18,866 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 40.0 (TID 76, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,867 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 40.0 (TID 77, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,868 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 40.0 (TID 77)
2016-12-14 14:21:18,868 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 40.0 (TID 76)
2016-12-14 14:21:18,869 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,869 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,870 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 40.0 (TID 77). 2179 bytes result sent to driver
2016-12-14 14:21:18,870 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 40.0 (TID 76). 2179 bytes result sent to driver
2016-12-14 14:21:18,873 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 40.0 (TID 77) in 6 ms on localhost (1/2)
2016-12-14 14:21:18,873 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 40.0 (TID 76) in 7 ms on localhost (2/2)
2016-12-14 14:21:18,873 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 40 (treeAggregate at RowMatrix.scala:121) finished in 0.007 s
2016-12-14 14:21:18,873 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 30 finished: treeAggregate at RowMatrix.scala:121, took 0.014009 s
2016-12-14 14:21:18,892 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:121
2016-12-14 14:21:18,893 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 31 (foreach at K_means.scala:121) with 2 output partitions
2016-12-14 14:21:18,893 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 41 (foreach at K_means.scala:121)
2016-12-14 14:21:18,893 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:18,894 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:18,894 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 41 (MapPartitionsRDD[58] at map at K_means.scala:117), which has no missing parents
2016-12-14 14:21:18,895 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57 stored as values in memory (estimated size 4.4 KB, free 400.6 KB)
2016-12-14 14:21:18,899 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.5 KB, free 403.1 KB)
2016-12-14 14:21:18,900 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_57_piece0 in memory on localhost:30140 (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:21:18,900 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,901 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 41 (MapPartitionsRDD[58] at map at K_means.scala:117)
2016-12-14 14:21:18,901 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 41.0 with 2 tasks
2016-12-14 14:21:18,902 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 41.0 (TID 78, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,903 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 41.0 (TID 79, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:18,903 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 41.0 (TID 79)
2016-12-14 14:21:18,903 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 41.0 (TID 78)
2016-12-14 14:21:18,905 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,905 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,905 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,905 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,905 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,906 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,907 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,908 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,909 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,910 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,911 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,912 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,913 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,914 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,915 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 0.0 --- 1.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,916 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 0.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,917 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,918 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,919 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,920 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 0.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,921 INFO  com.datageek.test.K_means$ - apply: old label pair: 2.0 --- 2.0
2016-12-14 14:21:18,922 INFO  com.datageek.test.K_means$ - apply: old label pair: 1.0 --- 2.0
2016-12-14 14:21:18,923 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 41.0 (TID 79). 2057 bytes result sent to driver
2016-12-14 14:21:18,923 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 41.0 (TID 78). 2057 bytes result sent to driver
2016-12-14 14:21:18,926 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 41.0 (TID 78) in 24 ms on localhost (1/2)
2016-12-14 14:21:18,926 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 41.0 (TID 79) in 23 ms on localhost (2/2)
2016-12-14 14:21:18,926 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 41 (foreach at K_means.scala:121) finished in 0.024 s
2016-12-14 14:21:18,926 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,927 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 31 finished: foreach at K_means.scala:121, took 0.034814 s
2016-12-14 14:21:18,968 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sortBy at Relabel.scala:13
2016-12-14 14:21:18,969 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 59 (map at Relabel.scala:13)
2016-12-14 14:21:18,970 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 32 (sortBy at Relabel.scala:13) with 2 output partitions
2016-12-14 14:21:18,970 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 43 (sortBy at Relabel.scala:13)
2016-12-14 14:21:18,970 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 42)
2016-12-14 14:21:18,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 42)
2016-12-14 14:21:18,971 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 42 (MapPartitionsRDD[59] at map at Relabel.scala:13), which has no missing parents
2016-12-14 14:21:18,973 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58 stored as values in memory (estimated size 5.2 KB, free 408.3 KB)
2016-12-14 14:21:18,976 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.0 KB, free 411.3 KB)
2016-12-14 14:21:18,977 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_58_piece0 in memory on localhost:30140 (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:21:18,977 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:18,978 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[59] at map at Relabel.scala:13)
2016-12-14 14:21:18,978 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 42.0 with 2 tasks
2016-12-14 14:21:18,979 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 42.0 (TID 80, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:21:18,980 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 42.0 (TID 81, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:21:18,981 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 42.0 (TID 81)
2016-12-14 14:21:18,981 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 42.0 (TID 80)
2016-12-14 14:21:18,982 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:18,982 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:18,989 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 42.0 (TID 81). 2237 bytes result sent to driver
2016-12-14 14:21:18,989 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 42.0 (TID 80). 2237 bytes result sent to driver
2016-12-14 14:21:18,991 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 42.0 (TID 81) in 11 ms on localhost (1/2)
2016-12-14 14:21:18,992 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 42.0 (TID 80) in 12 ms on localhost (2/2)
2016-12-14 14:21:18,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 42 (map at Relabel.scala:13) finished in 0.014 s
2016-12-14 14:21:18,992 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:21:18,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:18,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:18,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 43)
2016-12-14 14:21:18,992 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:18,993 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 43 (MapPartitionsRDD[63] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:21:18,995 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59 stored as values in memory (estimated size 3.5 KB, free 414.8 KB)
2016-12-14 14:21:18,999 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2022.0 B, free 416.8 KB)
2016-12-14 14:21:19,000 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_59_piece0 in memory on localhost:30140 (size: 2022.0 B, free: 529.9 MB)
2016-12-14 14:21:19,000 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,001 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[63] at sortBy at Relabel.scala:13)
2016-12-14 14:21:19,001 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 43.0 with 2 tasks
2016-12-14 14:21:19,002 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 43.0 (TID 82, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:19,003 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 43.0 (TID 83, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:19,003 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 43.0 (TID 82)
2016-12-14 14:21:19,003 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 43.0 (TID 83)
2016-12-14 14:21:19,005 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,005 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:19,005 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,006 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:19,011 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 43.0 (TID 83). 1152 bytes result sent to driver
2016-12-14 14:21:19,012 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 43.0 (TID 82). 1160 bytes result sent to driver
2016-12-14 14:21:19,014 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 43.0 (TID 83) in 12 ms on localhost (1/2)
2016-12-14 14:21:19,014 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 43.0 (TID 82) in 12 ms on localhost (2/2)
2016-12-14 14:21:19,014 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 43 (sortBy at Relabel.scala:13) finished in 0.013 s
2016-12-14 14:21:19,014 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,015 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 32 finished: sortBy at Relabel.scala:13, took 0.046166 s
2016-12-14 14:21:19,039 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at Relabel.scala:14
2016-12-14 14:21:19,047 INFO  org.apache.spark.MapOutputTrackerMaster - logInfo: Size of output statuses for shuffle 10 is 155 bytes
2016-12-14 14:21:19,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 61 (sortBy at Relabel.scala:13)
2016-12-14 14:21:19,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 33 (collect at Relabel.scala:14) with 2 output partitions
2016-12-14 14:21:19,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 46 (collect at Relabel.scala:14)
2016-12-14 14:21:19,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 45)
2016-12-14 14:21:19,053 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 45)
2016-12-14 14:21:19,054 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 45 (MapPartitionsRDD[61] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:21:19,059 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60 stored as values in memory (estimated size 3.6 KB, free 420.4 KB)
2016-12-14 14:21:19,062 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.0 KB, free 422.4 KB)
2016-12-14 14:21:19,063 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_60_piece0 in memory on localhost:30140 (size: 2.0 KB, free: 529.9 MB)
2016-12-14 14:21:19,063 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,064 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[61] at sortBy at Relabel.scala:13)
2016-12-14 14:21:19,064 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 45.0 with 2 tasks
2016-12-14 14:21:19,065 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 45.0 (TID 84, localhost, partition 0,NODE_LOCAL, 2132 bytes)
2016-12-14 14:21:19,066 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 45.0 (TID 85, localhost, partition 1,NODE_LOCAL, 2132 bytes)
2016-12-14 14:21:19,066 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 45.0 (TID 84)
2016-12-14 14:21:19,066 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 45.0 (TID 85)
2016-12-14 14:21:19,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,079 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 1 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,080 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:19,080 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:19,103 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 45.0 (TID 85). 1303 bytes result sent to driver
2016-12-14 14:21:19,103 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 45.0 (TID 84). 1303 bytes result sent to driver
2016-12-14 14:21:19,104 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 45.0 (TID 85) in 38 ms on localhost (1/2)
2016-12-14 14:21:19,106 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 45.0 (TID 84) in 41 ms on localhost (2/2)
2016-12-14 14:21:19,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 45 (sortBy at Relabel.scala:13) finished in 0.041 s
2016-12-14 14:21:19,107 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:19,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:19,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 46)
2016-12-14 14:21:19,107 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:19,108 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 46 (MapPartitionsRDD[65] at sortBy at Relabel.scala:13), which has no missing parents
2016-12-14 14:21:19,112 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61 stored as values in memory (estimated size 3.4 KB, free 425.8 KB)
2016-12-14 14:21:19,116 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_61_piece0 stored as bytes in memory (estimated size 1946.0 B, free 427.7 KB)
2016-12-14 14:21:19,117 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_61_piece0 in memory on localhost:30140 (size: 1946.0 B, free: 529.9 MB)
2016-12-14 14:21:19,118 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,118 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[65] at sortBy at Relabel.scala:13)
2016-12-14 14:21:19,118 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 46.0 with 2 tasks
2016-12-14 14:21:19,119 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 46.0 (TID 86, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:19,120 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 46.0 (TID 87, localhost, partition 1,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:19,120 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 46.0 (TID 86)
2016-12-14 14:21:19,120 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 46.0 (TID 87)
2016-12-14 14:21:19,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:19,128 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,129 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:19,141 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 46.0 (TID 87). 1211 bytes result sent to driver
2016-12-14 14:21:19,142 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 46.0 (TID 86). 1182 bytes result sent to driver
2016-12-14 14:21:19,143 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 46.0 (TID 87) in 23 ms on localhost (1/2)
2016-12-14 14:21:19,143 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 46.0 (TID 86) in 24 ms on localhost (2/2)
2016-12-14 14:21:19,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 46 (collect at Relabel.scala:14) finished in 0.025 s
2016-12-14 14:21:19,144 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,144 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 33 finished: collect at Relabel.scala:14, took 0.104258 s
2016-12-14 14:21:19,163 INFO  org.apache.spark.SparkContext - logInfo: Starting job: foreach at K_means.scala:125
2016-12-14 14:21:19,164 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 34 (foreach at K_means.scala:125) with 2 output partitions
2016-12-14 14:21:19,164 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 47 (foreach at K_means.scala:125)
2016-12-14 14:21:19,164 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:19,165 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:19,166 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 47 (MapPartitionsRDD[66] at map at Relabel.scala:31), which has no missing parents
2016-12-14 14:21:19,167 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62 stored as values in memory (estimated size 4.8 KB, free 432.5 KB)
2016-12-14 14:21:19,171 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.7 KB, free 435.2 KB)
2016-12-14 14:21:19,172 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_62_piece0 in memory on localhost:30140 (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:21:19,173 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,173 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[66] at map at Relabel.scala:31)
2016-12-14 14:21:19,173 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 47.0 with 2 tasks
2016-12-14 14:21:19,174 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 47.0 (TID 88, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:19,175 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 47.0 (TID 89, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:19,175 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 47.0 (TID 88)
2016-12-14 14:21:19,175 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 47.0 (TID 89)
2016-12-14 14:21:19,178 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:19,179 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:19,181 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,181 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,181 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,181 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,182 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,182 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:21:19,182 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,182 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,183 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,183 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,183 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,183 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,183 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,184 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,184 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,184 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,184 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,185 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,185 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,185 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,185 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,186 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,186 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,186 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,186 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,187 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,187 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,187 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,187 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,188 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,188 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,188 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,188 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,189 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,189 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,189 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,189 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,189 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,189 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,190 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,190 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,190 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,190 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,190 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,190 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,191 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,191 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,191 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,191 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,191 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,191 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,191 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,192 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,192 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,192 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,192 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,192 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,192 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,193 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,193 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,193 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,193 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,193 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,193 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,194 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,194 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,194 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,194 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,194 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,194 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,194 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,195 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,195 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,195 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,195 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,195 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,195 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,195 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,196 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,196 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,196 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,196 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,196 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,196 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,197 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,198 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,198 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,198 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,198 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,198 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,198 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,199 INFO  com.datageek.test.K_means$ - apply: new label pair: 0.0 --- 0.0
2016-12-14 14:21:19,199 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,199 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:21:19,199 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,199 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,199 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,200 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 2.0
2016-12-14 14:21:19,200 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,200 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,200 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,200 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,200 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,200 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,201 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,201 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,201 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,201 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,201 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,201 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,201 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,202 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,203 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,203 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,203 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,203 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,203 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,203 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,204 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,205 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,205 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,205 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,205 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,205 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,205 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,206 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,206 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 2.0
2016-12-14 14:21:19,206 INFO  com.datageek.test.K_means$ - apply: new label pair: 1.0 --- 1.0
2016-12-14 14:21:19,206 INFO  com.datageek.test.K_means$ - apply: new label pair: 2.0 --- 1.0
2016-12-14 14:21:19,208 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 47.0 (TID 89). 2057 bytes result sent to driver
2016-12-14 14:21:19,209 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 47.0 (TID 88). 2057 bytes result sent to driver
2016-12-14 14:21:19,210 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 47.0 (TID 89) in 34 ms on localhost (1/2)
2016-12-14 14:21:19,212 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 47.0 (TID 88) in 38 ms on localhost (2/2)
2016-12-14 14:21:19,212 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 47 (foreach at K_means.scala:125) finished in 0.038 s
2016-12-14 14:21:19,212 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,212 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 34 finished: foreach at K_means.scala:125, took 0.049412 s
2016-12-14 14:21:19,230 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at MulticlassMetrics.scala:49
2016-12-14 14:21:19,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 67 (map at MulticlassMetrics.scala:46)
2016-12-14 14:21:19,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 35 (collectAsMap at MulticlassMetrics.scala:49) with 2 output partitions
2016-12-14 14:21:19,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 49 (collectAsMap at MulticlassMetrics.scala:49)
2016-12-14 14:21:19,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 48)
2016-12-14 14:21:19,231 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 48)
2016-12-14 14:21:19,232 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 48 (MapPartitionsRDD[67] at map at MulticlassMetrics.scala:46), which has no missing parents
2016-12-14 14:21:19,233 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63 stored as values in memory (estimated size 5.7 KB, free 441.0 KB)
2016-12-14 14:21:19,237 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.2 KB, free 444.2 KB)
2016-12-14 14:21:19,237 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_63_piece0 in memory on localhost:30140 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:21:19,238 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,238 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[67] at map at MulticlassMetrics.scala:46)
2016-12-14 14:21:19,238 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 48.0 with 2 tasks
2016-12-14 14:21:19,240 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 48.0 (TID 90, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:21:19,240 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 48.0 (TID 91, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:21:19,241 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 48.0 (TID 90)
2016-12-14 14:21:19,241 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 48.0 (TID 91)
2016-12-14 14:21:19,243 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:19,243 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:19,248 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 48.0 (TID 90). 2237 bytes result sent to driver
2016-12-14 14:21:19,249 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 48.0 (TID 91). 2237 bytes result sent to driver
2016-12-14 14:21:19,251 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 48.0 (TID 90) in 12 ms on localhost (1/2)
2016-12-14 14:21:19,253 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 48.0 (TID 91) in 12 ms on localhost (2/2)
2016-12-14 14:21:19,253 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 48 (map at MulticlassMetrics.scala:46) finished in 0.013 s
2016-12-14 14:21:19,253 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,253 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:19,253 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:19,253 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 49)
2016-12-14 14:21:19,254 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:19,254 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 49 (ShuffledRDD[68] at reduceByKey at MulticlassMetrics.scala:48), which has no missing parents
2016-12-14 14:21:19,255 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64 stored as values in memory (estimated size 2.6 KB, free 446.8 KB)
2016-12-14 14:21:19,260 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_64_piece0 stored as bytes in memory (estimated size 1593.0 B, free 448.3 KB)
2016-12-14 14:21:19,260 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_64_piece0 in memory on localhost:30140 (size: 1593.0 B, free: 529.9 MB)
2016-12-14 14:21:19,261 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,261 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 49 (ShuffledRDD[68] at reduceByKey at MulticlassMetrics.scala:48)
2016-12-14 14:21:19,262 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 49.0 with 2 tasks
2016-12-14 14:21:19,263 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 49.0 (TID 92, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:19,264 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 49.0 (TID 93, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:21:19,264 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 49.0 (TID 92)
2016-12-14 14:21:19,264 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 49.0 (TID 93)
2016-12-14 14:21:19,265 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,265 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:19,266 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,266 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:21:19,269 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 49.0 (TID 92). 1163 bytes result sent to driver
2016-12-14 14:21:19,272 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 49.0 (TID 92) in 8 ms on localhost (1/2)
2016-12-14 14:21:19,273 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 49.0 (TID 93). 1124 bytes result sent to driver
2016-12-14 14:21:19,275 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 49.0 (TID 93) in 12 ms on localhost (2/2)
2016-12-14 14:21:19,275 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 49 (collectAsMap at MulticlassMetrics.scala:49) finished in 0.013 s
2016-12-14 14:21:19,276 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,276 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 35 finished: collectAsMap at MulticlassMetrics.scala:49, took 0.046126 s
2016-12-14 14:21:19,304 INFO  org.apache.spark.SparkContext - logInfo: Starting job: countByValue at MulticlassMetrics.scala:43
2016-12-14 14:21:19,305 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 71 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:21:19,305 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 36 (countByValue at MulticlassMetrics.scala:43) with 2 output partitions
2016-12-14 14:21:19,306 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 51 (countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:21:19,306 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 50)
2016-12-14 14:21:19,306 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 50)
2016-12-14 14:21:19,306 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 50 (MapPartitionsRDD[71] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:21:19,309 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65 stored as values in memory (estimated size 6.3 KB, free 454.6 KB)
2016-12-14 14:21:19,313 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.4 KB, free 458.0 KB)
2016-12-14 14:21:19,314 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_65_piece0 in memory on localhost:30140 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:21:19,314 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,315 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[71] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:21:19,315 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 50.0 with 2 tasks
2016-12-14 14:21:19,317 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 50.0 (TID 94, localhost, partition 0,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:21:19,317 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 50.0 (TID 95, localhost, partition 1,PROCESS_LOCAL, 2382 bytes)
2016-12-14 14:21:19,318 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 50.0 (TID 95)
2016-12-14 14:21:19,318 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 50.0 (TID 94)
2016-12-14 14:21:19,320 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:19,321 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:19,330 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 50.0 (TID 95). 2237 bytes result sent to driver
2016-12-14 14:21:19,331 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 50.0 (TID 94). 2237 bytes result sent to driver
2016-12-14 14:21:19,331 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 50.0 (TID 95) in 14 ms on localhost (1/2)
2016-12-14 14:21:19,332 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 50.0 (TID 94) in 16 ms on localhost (2/2)
2016-12-14 14:21:19,332 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 50 (countByValue at MulticlassMetrics.scala:43) finished in 0.016 s
2016-12-14 14:21:19,333 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 50.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,333 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:21:19,333 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:21:19,333 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 51)
2016-12-14 14:21:19,333 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:21:19,334 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 51 (ShuffledRDD[72] at countByValue at MulticlassMetrics.scala:43), which has no missing parents
2016-12-14 14:21:19,335 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66 stored as values in memory (estimated size 2.6 KB, free 460.6 KB)
2016-12-14 14:21:19,339 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_66_piece0 stored as bytes in memory (estimated size 1561.0 B, free 462.1 KB)
2016-12-14 14:21:19,340 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_66_piece0 in memory on localhost:30140 (size: 1561.0 B, free: 529.9 MB)
2016-12-14 14:21:19,341 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,341 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 51 (ShuffledRDD[72] at countByValue at MulticlassMetrics.scala:43)
2016-12-14 14:21:19,341 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 51.0 with 2 tasks
2016-12-14 14:21:19,342 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 51.0 (TID 96, localhost, partition 0,NODE_LOCAL, 2143 bytes)
2016-12-14 14:21:19,343 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 51.0 (TID 97, localhost, partition 1,PROCESS_LOCAL, 2143 bytes)
2016-12-14 14:21:19,343 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 51.0 (TID 96)
2016-12-14 14:21:19,343 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 51.0 (TID 97)
2016-12-14 14:21:19,345 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,345 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 0 non-empty blocks out of 2 blocks
2016-12-14 14:21:19,346 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:19,346 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:21:19,353 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 51.0 (TID 97). 1124 bytes result sent to driver
2016-12-14 14:21:19,353 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 51.0 (TID 96). 1163 bytes result sent to driver
2016-12-14 14:21:19,354 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 51.0 (TID 96) in 12 ms on localhost (1/2)
2016-12-14 14:21:19,355 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 51.0 (TID 97) in 12 ms on localhost (2/2)
2016-12-14 14:21:19,355 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 51 (countByValue at MulticlassMetrics.scala:43) finished in 0.013 s
2016-12-14 14:21:19,355 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 51.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,356 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 36 finished: countByValue at MulticlassMetrics.scala:43, took 0.051200 s
2016-12-14 14:21:19,356 INFO  com.datageek.test.K_means$ - main: #####################F_measure = 0.8866666666666667
2016-12-14 14:21:19,357 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67 stored as values in memory (estimated size 296.0 B, free 462.4 KB)
2016-12-14 14:21:19,368 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 86
2016-12-14 14:21:19,368 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 79
2016-12-14 14:21:19,368 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 78
2016-12-14 14:21:19,369 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_45_piece0 on localhost:30140 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:19,370 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 77
2016-12-14 14:21:19,370 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_67_piece0 stored as bytes in memory (estimated size 248.0 B, free 458.1 KB)
2016-12-14 14:21:19,370 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_67_piece0 in memory on localhost:30140 (size: 248.0 B, free: 529.9 MB)
2016-12-14 14:21:19,371 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_44_piece0 on localhost:30140 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:19,371 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 67 from broadcast at KMeansModel.scala:87
2016-12-14 14:21:19,371 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 76
2016-12-14 14:21:19,371 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 7
2016-12-14 14:21:19,372 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_43_piece0 on localhost:30140 in memory (size: 406.0 B, free: 529.9 MB)
2016-12-14 14:21:19,372 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 75
2016-12-14 14:21:19,373 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 9
2016-12-14 14:21:19,373 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_49_piece0 on localhost:30140 in memory (size: 204.0 B, free: 529.9 MB)
2016-12-14 14:21:19,374 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 83
2016-12-14 14:21:19,375 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_48_piece0 on localhost:30140 in memory (size: 1668.0 B, free: 529.9 MB)
2016-12-14 14:21:19,376 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 82
2016-12-14 14:21:19,376 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_47_piece0 on localhost:30140 in memory (size: 3.8 KB, free: 529.9 MB)
2016-12-14 14:21:19,377 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 81
2016-12-14 14:21:19,377 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 8
2016-12-14 14:21:19,378 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_46_piece0 on localhost:30140 in memory (size: 351.0 B, free: 529.9 MB)
2016-12-14 14:21:19,379 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 80
2016-12-14 14:21:19,379 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_66_piece0 on localhost:30140 in memory (size: 1561.0 B, free: 529.9 MB)
2016-12-14 14:21:19,380 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 100
2016-12-14 14:21:19,381 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_65_piece0 on localhost:30140 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:21:19,381 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 99
2016-12-14 14:21:19,382 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 13
2016-12-14 14:21:19,383 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_64_piece0 on localhost:30140 in memory (size: 1593.0 B, free: 529.9 MB)
2016-12-14 14:21:19,383 INFO  org.apache.spark.SparkContext - logInfo: Starting job: sum at KMeansModel.scala:88
2016-12-14 14:21:19,383 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 98
2016-12-14 14:21:19,384 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 37 (sum at KMeansModel.scala:88) with 2 output partitions
2016-12-14 14:21:19,384 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 52 (sum at KMeansModel.scala:88)
2016-12-14 14:21:19,384 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:21:19,384 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_63_piece0 on localhost:30140 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:21:19,385 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:21:19,385 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 97
2016-12-14 14:21:19,385 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 12
2016-12-14 14:21:19,386 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_62_piece0 on localhost:30140 in memory (size: 2.7 KB, free: 529.9 MB)
2016-12-14 14:21:19,386 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 52 (MapPartitionsRDD[73] at map at KMeansModel.scala:88), which has no missing parents
2016-12-14 14:21:19,386 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 96
2016-12-14 14:21:19,387 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_53_piece0 on localhost:30140 in memory (size: 2.1 KB, free: 529.9 MB)
2016-12-14 14:21:19,388 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68 stored as values in memory (estimated size 4.7 KB, free 393.2 KB)
2016-12-14 14:21:19,388 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 87
2016-12-14 14:21:19,389 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_52_piece0 on localhost:30140 in memory (size: 2.5 KB, free: 529.9 MB)
2016-12-14 14:21:19,390 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_51_piece0 on localhost:30140 in memory (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:21:19,390 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 85
2016-12-14 14:21:19,391 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_50_piece0 on localhost:30140 in memory (size: 3.8 KB, free: 530.0 MB)
2016-12-14 14:21:19,392 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 84
2016-12-14 14:21:19,392 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_68_piece0 stored as bytes in memory (estimated size 2.7 KB, free 373.7 KB)
2016-12-14 14:21:19,392 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 9
2016-12-14 14:21:19,392 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_68_piece0 in memory on localhost:30140 (size: 2.7 KB, free: 530.0 MB)
2016-12-14 14:21:19,393 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 9
2016-12-14 14:21:19,393 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:21:19,393 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 52 (MapPartitionsRDD[73] at map at KMeansModel.scala:88)
2016-12-14 14:21:19,393 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_58_piece0 on localhost:30140 in memory (size: 3.0 KB, free: 530.0 MB)
2016-12-14 14:21:19,393 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 52.0 with 2 tasks
2016-12-14 14:21:19,394 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 92
2016-12-14 14:21:19,394 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 10
2016-12-14 14:21:19,395 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 52.0 (TID 98, localhost, partition 0,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:19,395 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_57_piece0 on localhost:30140 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:19,396 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 52.0 (TID 99, localhost, partition 1,PROCESS_LOCAL, 2393 bytes)
2016-12-14 14:21:19,396 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 91
2016-12-14 14:21:19,396 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 52.0 (TID 98)
2016-12-14 14:21:19,396 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 52.0 (TID 99)
2016-12-14 14:21:19,397 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_56_piece0 on localhost:30140 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:19,398 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 90
2016-12-14 14:21:19,398 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:21:19,398 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_55_piece0 on localhost:30140 in memory (size: 2.5 KB, free: 530.0 MB)
2016-12-14 14:21:19,399 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 89
2016-12-14 14:21:19,399 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:21:19,400 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_54_piece0 on localhost:30140 in memory (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:21:19,400 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 52.0 (TID 98). 2064 bytes result sent to driver
2016-12-14 14:21:19,400 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 88
2016-12-14 14:21:19,401 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_61_piece0 on localhost:30140 in memory (size: 1946.0 B, free: 530.0 MB)
2016-12-14 14:21:19,401 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 95
2016-12-14 14:21:19,402 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 52.0 (TID 98) in 8 ms on localhost (1/2)
2016-12-14 14:21:19,402 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_60_piece0 on localhost:30140 in memory (size: 2.0 KB, free: 530.0 MB)
2016-12-14 14:21:19,402 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 52.0 (TID 99). 2064 bytes result sent to driver
2016-12-14 14:21:19,403 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 94
2016-12-14 14:21:19,403 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 11
2016-12-14 14:21:19,404 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_59_piece0 on localhost:30140 in memory (size: 2022.0 B, free: 530.0 MB)
2016-12-14 14:21:19,404 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 93
2016-12-14 14:21:19,404 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 74
2016-12-14 14:21:19,405 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 72
2016-12-14 14:21:19,405 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 73
2016-12-14 14:21:19,405 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 52.0 (TID 99) in 10 ms on localhost (2/2)
2016-12-14 14:21:19,405 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 52.0, whose tasks have all completed, from pool 
2016-12-14 14:21:19,405 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 52 (sum at KMeansModel.scala:88) finished in 0.011 s
2016-12-14 14:21:19,406 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 37 finished: sum at KMeansModel.scala:88, took 0.022397 s
2016-12-14 14:21:19,406 INFO  com.datageek.test.K_means$ - main: #####################Within Set Sum of Squared Errors = 63.87383806036277
2016-12-14 14:21:19,406 INFO  com.datageek.test.K_means$ - main: ==(-_-)~====END====(-_-)~==
2016-12-14 14:21:19,504 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:21:19,505 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:21:19,505 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:21:19,505 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:21:19,506 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:21:19,506 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:21:19,506 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:21:19,507 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:21:19,507 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:21:19,507 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:21:19,508 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:21:19,508 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:21:19,508 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:21:19,509 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:21:19,509 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:21:19,509 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:21:19,510 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:21:19,510 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:21:19,510 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:21:19,510 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:21:19,511 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:21:19,511 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:21:19,511 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:21:19,512 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:21:19,512 INFO  org.spark-project.jetty.server.handler.ContextHandler - doStop: stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:21:19,568 INFO  org.apache.spark.ui.SparkUI - logInfo: Stopped Spark web UI at http://172.31.18.13:4040
2016-12-14 14:21:19,659 INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - logInfo: MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:21:19,678 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore cleared
2016-12-14 14:21:19,679 INFO  org.apache.spark.storage.BlockManager - logInfo: BlockManager stopped
2016-12-14 14:21:19,680 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: BlockManagerMaster stopped
2016-12-14 14:21:19,684 INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - logInfo: OutputCommitCoordinator stopped!
2016-12-14 14:21:19,694 INFO  org.apache.spark.SparkContext - logInfo: Successfully stopped SparkContext
2016-12-14 14:21:19,694 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Shutting down remote daemon.
2016-12-14 14:21:19,699 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Shutdown hook called
2016-12-14 14:21:19,700 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:21:19,700 INFO  org.apache.spark.util.ShutdownHookManager - logInfo: Deleting directory /tmp/spark-77172ee4-610b-4fff-b790-8e6c8be0dbd7
2016-12-14 14:21:19,745 INFO  Remoting - apply$mcV$sp: Remoting shut down
2016-12-14 14:21:19,745 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator - apply$mcV$sp: Remoting shut down.
2016-12-14 14:26:34,772 INFO  org.apache.spark.SparkContext - logInfo: Running Spark version 1.6.0
2016-12-14 14:26:35,861 INFO  org.apache.spark.SecurityManager - logInfo: Changing view acls to: root
2016-12-14 14:26:35,867 INFO  org.apache.spark.SecurityManager - logInfo: Changing modify acls to: root
2016-12-14 14:26:35,868 INFO  org.apache.spark.SecurityManager - logInfo: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
2016-12-14 14:26:36,257 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriver' on port 2496.
2016-12-14 14:26:36,842 INFO  akka.event.slf4j.Slf4jLogger - applyOrElse: Slf4jLogger started
2016-12-14 14:26:36,923 INFO  Remoting - apply$mcV$sp: Starting remoting
2016-12-14 14:26:37,167 INFO  Remoting - apply$mcV$sp: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.31.18.13:25814]
2016-12-14 14:26:37,170 INFO  Remoting - apply$mcV$sp: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@172.31.18.13:25814]
2016-12-14 14:26:37,181 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'sparkDriverActorSystem' on port 25814.
2016-12-14 14:26:37,213 INFO  org.apache.spark.SparkEnv - logInfo: Registering MapOutputTracker
2016-12-14 14:26:37,243 INFO  org.apache.spark.SparkEnv - logInfo: Registering BlockManagerMaster
2016-12-14 14:26:37,267 INFO  org.apache.spark.storage.DiskBlockManager - logInfo: Created local directory at /tmp/blockmgr-566aa4db-bd57-417c-8623-182cc9edd122
2016-12-14 14:26:37,289 INFO  org.apache.spark.storage.MemoryStore - logInfo: MemoryStore started with capacity 530.0 MB
2016-12-14 14:26:37,421 INFO  org.apache.spark.SparkEnv - logInfo: Registering OutputCommitCoordinator
2016-12-14 14:26:37,700 INFO  org.spark-project.jetty.server.Server - doStart: jetty-8.y.z-SNAPSHOT
2016-12-14 14:26:37,787 INFO  org.spark-project.jetty.server.AbstractConnector - doStart: Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:26:37,790 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:26:37,793 INFO  org.apache.spark.ui.SparkUI - logInfo: Started SparkUI at http://172.31.18.13:4040
2016-12-14 14:26:37,842 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/mysql-connector-java-5.1.25.jar at spark://172.31.18.13:2496/jars/mysql-connector-java-5.1.25.jar with timestamp 1481696797841
2016-12-14 14:26:37,843 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/ojdbc6.jar at spark://172.31.18.13:2496/jars/ojdbc6.jar with timestamp 1481696797843
2016-12-14 14:26:37,843 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/lib/orai18n.jar at spark://172.31.18.13:2496/jars/orai18n.jar with timestamp 1481696797843
2016-12-14 14:26:37,844 INFO  org.apache.spark.SparkContext - logInfo: Added JAR file:/opt/whsh/mltest/machine_learning_2.10-1.0.jar at spark://172.31.18.13:2496/jars/machine_learning_2.10-1.0.jar with timestamp 1481696797844
2016-12-14 14:26:37,954 INFO  org.apache.spark.executor.Executor - logInfo: Starting executor ID driver on host localhost
2016-12-14 14:26:37,987 INFO  org.apache.spark.util.Utils - logInfo: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55377.
2016-12-14 14:26:37,988 INFO  org.apache.spark.network.netty.NettyBlockTransferService - logInfo: Server created on 55377
2016-12-14 14:26:37,993 INFO  org.apache.spark.storage.BlockManager - logInfo: external shuffle service port = 7337
2016-12-14 14:26:37,993 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Trying to register BlockManager
2016-12-14 14:26:37,999 INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - logInfo: Registering block manager localhost:55377 with 530.0 MB RAM, BlockManagerId(driver, localhost, 55377)
2016-12-14 14:26:38,002 INFO  org.apache.spark.storage.BlockManagerMaster - logInfo: Registered BlockManager
2016-12-14 14:26:39,804 INFO  org.apache.spark.scheduler.EventLoggingListener - logInfo: Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1481696797904
2016-12-14 14:26:39,864 INFO  com.datageek.test.K_means$ - main: #####################path = file:///opt/whsh/data/whsh/datasets/iris.txt
2016-12-14 14:26:39,865 INFO  com.datageek.test.K_means$ - main: #####################numIterations = 50
2016-12-14 14:26:39,865 INFO  com.datageek.test.K_means$ - main: #####################numClusters = 3
2016-12-14 14:26:39,866 INFO  com.datageek.test.K_means$ - main: #####################runs = 10
2016-12-14 14:26:39,866 INFO  com.datageek.test.K_means$ - main: #####################savePath = /usr/machine_learning/model/k_mean_test
2016-12-14 14:26:39,866 INFO  com.datageek.test.K_means$ - main: #####################zeroBased = false
2016-12-14 14:26:40,584 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0 stored as values in memory (estimated size 277.0 KB, free 277.0 KB)
2016-12-14 14:26:40,942 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 301.0 KB)
2016-12-14 14:26:40,946 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_0_piece0 in memory on localhost:55377 (size: 24.0 KB, free: 530.0 MB)
2016-12-14 14:26:40,949 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 0 from textFile at K_means.scala:90
2016-12-14 14:26:41,004 WARN  org.apache.spark.mllib.clustering.KMeans - logWarning: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-12-14 14:26:41,089 INFO  org.apache.hadoop.mapred.FileInputFormat - listStatus: Total input paths to process : 1
2016-12-14 14:26:41,118 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:26:41,151 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 0 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:26:41,152 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 0 (takeSample at KMeans.scala:378)
2016-12-14 14:26:41,153 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:41,161 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:41,172 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210), which has no missing parents
2016-12-14 14:26:41,229 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 305.3 KB)
2016-12-14 14:26:41,253 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 307.7 KB)
2016-12-14 14:26:41,255 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_1_piece0 in memory on localhost:55377 (size: 2.4 KB, free: 530.0 MB)
2016-12-14 14:26:41,256 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:41,262 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at KMeans.scala:210)
2016-12-14 14:26:41,265 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 0.0 with 2 tasks
2016-12-14 14:26:41,337 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2563 bytes)
2016-12-14 14:26:41,342 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2563 bytes)
2016-12-14 14:26:41,352 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:26:41,352 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 0.0 (TID 1)
2016-12-14 14:26:41,361 INFO  org.apache.spark.ExecutorAllocationManager - logInfo: New executor driver has registered (new total is 1)
2016-12-14 14:26:41,365 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2496/jars/mysql-connector-java-5.1.25.jar with timestamp 1481696797841
2016-12-14 14:26:41,481 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2496/jars/mysql-connector-java-5.1.25.jar to /tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/fetchFileTemp2489111305587183383.tmp
2016-12-14 14:26:41,628 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/mysql-connector-java-5.1.25.jar to class loader
2016-12-14 14:26:41,628 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2496/jars/orai18n.jar with timestamp 1481696797843
2016-12-14 14:26:41,629 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2496/jars/orai18n.jar to /tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/fetchFileTemp4942197477576866691.tmp
2016-12-14 14:26:41,649 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/orai18n.jar to class loader
2016-12-14 14:26:41,650 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2496/jars/ojdbc6.jar with timestamp 1481696797843
2016-12-14 14:26:41,651 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2496/jars/ojdbc6.jar to /tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/fetchFileTemp640899568669714298.tmp
2016-12-14 14:26:41,666 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/ojdbc6.jar to class loader
2016-12-14 14:26:41,667 INFO  org.apache.spark.executor.Executor - logInfo: Fetching spark://172.31.18.13:2496/jars/machine_learning_2.10-1.0.jar with timestamp 1481696797844
2016-12-14 14:26:41,668 INFO  org.apache.spark.util.Utils - logInfo: Fetching spark://172.31.18.13:2496/jars/machine_learning_2.10-1.0.jar to /tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/fetchFileTemp5016024285521618078.tmp
2016-12-14 14:26:41,676 INFO  org.apache.spark.executor.Executor - logInfo: Adding file:/tmp/spark-5b333e0e-f731-4570-9897-c8d87faa5824/userFiles-0828fbab-2703-4a47-b466-788b3b4cbd9d/machine_learning_2.10-1.0.jar to class loader
2016-12-14 14:26:41,713 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_0 not found, computing it
2016-12-14 14:26:41,713 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_2_1 not found, computing it
2016-12-14 14:26:41,719 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:1428+1428
2016-12-14 14:26:41,719 INFO  org.apache.spark.rdd.HadoopRDD - logInfo: Input split: file:/opt/whsh/data/whsh/datasets/iris.txt:0+1428
2016-12-14 14:26:41,745 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-12-14 14:26:41,745 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-14 14:26:41,746 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-12-14 14:26:41,746 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-12-14 14:26:41,747 INFO  org.apache.hadoop.conf.Configuration.deprecation - warnOnceIfDeprecated: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-12-14 14:26:41,816 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_0 stored as values in memory (estimated size 6.8 KB, free 314.4 KB)
2016-12-14 14:26:41,817 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_0 in memory on localhost:55377 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:26:41,818 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_2_1 stored as values in memory (estimated size 6.8 KB, free 321.2 KB)
2016-12-14 14:26:41,819 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_2_1 in memory on localhost:55377 (size: 6.8 KB, free: 530.0 MB)
2016-12-14 14:26:41,820 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_0 not found, computing it
2016-12-14 14:26:41,820 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_4_1 not found, computing it
2016-12-14 14:26:41,820 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:41,822 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:41,831 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_0 stored as values in memory (estimated size 2.1 KB, free 323.2 KB)
2016-12-14 14:26:41,832 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_0 in memory on localhost:55377 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:26:41,832 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_4_1 stored as values in memory (estimated size 2.1 KB, free 325.3 KB)
2016-12-14 14:26:41,833 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_4_1 in memory on localhost:55377 (size: 2.1 KB, free: 530.0 MB)
2016-12-14 14:26:41,904 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 0.0 (TID 0). 2638 bytes result sent to driver
2016-12-14 14:26:41,904 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 0.0 (TID 1). 2638 bytes result sent to driver
2016-12-14 14:26:41,932 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 0.0 (TID 1) in 588 ms on localhost (1/2)
2016-12-14 14:26:41,933 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 0.0 (TID 0) in 630 ms on localhost (2/2)
2016-12-14 14:26:41,935 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:26:41,936 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 0 (takeSample at KMeans.scala:378) finished in 0.654 s
2016-12-14 14:26:41,945 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 0 finished: takeSample at KMeans.scala:378, took 0.826127 s
2016-12-14 14:26:42,048 INFO  org.apache.spark.SparkContext - logInfo: Starting job: takeSample at KMeans.scala:378
2016-12-14 14:26:42,051 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 1 (takeSample at KMeans.scala:378) with 2 output partitions
2016-12-14 14:26:42,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 1 (takeSample at KMeans.scala:378)
2016-12-14 14:26:42,052 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,058 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,059 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378), which has no missing parents
2016-12-14 14:26:42,064 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2 stored as values in memory (estimated size 21.3 KB, free 346.6 KB)
2016-12-14 14:26:42,074 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.9 KB, free 355.5 KB)
2016-12-14 14:26:42,076 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_2_piece0 in memory on localhost:55377 (size: 8.9 KB, free: 530.0 MB)
2016-12-14 14:26:42,077 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,077 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[8] at takeSample at KMeans.scala:378)
2016-12-14 14:26:42,078 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 1.0 with 2 tasks
2016-12-14 14:26:42,089 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2672 bytes)
2016-12-14 14:26:42,090 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2672 bytes)
2016-12-14 14:26:42,091 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 1.0 (TID 3)
2016-12-14 14:26:42,091 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 1.0 (TID 2)
2016-12-14 14:26:42,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,105 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,106 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,132 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 1.0 (TID 3). 2970 bytes result sent to driver
2016-12-14 14:26:42,132 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 1.0 (TID 2). 2685 bytes result sent to driver
2016-12-14 14:26:42,156 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 1.0 (TID 3) in 66 ms on localhost (1/2)
2016-12-14 14:26:42,156 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (2/2)
2016-12-14 14:26:42,156 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 1 (takeSample at KMeans.scala:378) finished in 0.069 s
2016-12-14 14:26:42,157 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,158 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 1 finished: takeSample at KMeans.scala:378, took 0.109180 s
2016-12-14 14:26:42,163 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3 stored as values in memory (estimated size 2000.0 B, free 357.5 KB)
2016-12-14 14:26:42,169 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_3_piece0 stored as bytes in memory (estimated size 437.0 B, free 357.9 KB)
2016-12-14 14:26:42,171 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_3_piece0 in memory on localhost:55377 (size: 437.0 B, free: 530.0 MB)
2016-12-14 14:26:42,172 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 3 from broadcast at KMeans.scala:396
2016-12-14 14:26:42,197 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:26:42,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 2 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:26:42,198 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 2 (aggregate at KMeans.scala:404)
2016-12-14 14:26:42,199 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,200 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,201 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:26:42,203 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 363.7 KB)
2016-12-14 14:26:42,208 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.0 KB, free 366.7 KB)
2016-12-14 14:26:42,209 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_4_piece0 in memory on localhost:55377 (size: 3.0 KB, free: 530.0 MB)
2016-12-14 14:26:42,210 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,210 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at map at KMeans.scala:398)
2016-12-14 14:26:42,210 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 2.0 with 2 tasks
2016-12-14 14:26:42,212 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2595 bytes)
2016-12-14 14:26:42,213 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2595 bytes)
2016-12-14 14:26:42,214 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 2.0 (TID 4)
2016-12-14 14:26:42,214 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 2.0 (TID 5)
2016-12-14 14:26:42,221 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_1 not found, computing it
2016-12-14 14:26:42,221 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,222 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,222 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,222 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,224 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_10_0 not found, computing it
2016-12-14 14:26:42,224 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,225 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,225 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,226 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,240 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-12-14 14:26:42,241 WARN  com.github.fommil.netlib.BLAS - <clinit>: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-12-14 14:26:42,256 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_1 stored as values in memory (estimated size 7.3 KB, free 374.1 KB)
2016-12-14 14:26:42,257 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_1 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,257 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_10_0 stored as values in memory (estimated size 7.3 KB, free 381.4 KB)
2016-12-14 14:26:42,258 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_10_0 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,264 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 2.0 (TID 5). 2721 bytes result sent to driver
2016-12-14 14:26:42,268 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 2.0 (TID 4). 2721 bytes result sent to driver
2016-12-14 14:26:42,272 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 2.0 (TID 5) in 59 ms on localhost (1/2)
2016-12-14 14:26:42,276 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 2.0 (TID 4) in 64 ms on localhost (2/2)
2016-12-14 14:26:42,276 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 2 (aggregate at KMeans.scala:404) finished in 0.064 s
2016-12-14 14:26:42,276 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,276 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 2 finished: aggregate at KMeans.scala:404, took 0.079023 s
2016-12-14 14:26:42,281 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 7 from persistence list
2016-12-14 14:26:42,288 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 7
2016-12-14 14:26:42,300 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:26:42,302 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 3 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:26:42,302 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 3 (collect at KMeans.scala:436)
2016-12-14 14:26:42,302 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,304 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,305 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:26:42,307 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5 stored as values in memory (estimated size 6.0 KB, free 387.4 KB)
2016-12-14 14:26:42,316 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 390.6 KB)
2016-12-14 14:26:42,317 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_5_piece0 in memory on localhost:55377 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:42,318 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,318 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:26:42,318 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 3.0 with 2 tasks
2016-12-14 14:26:42,320 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 3.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2627 bytes)
2016-12-14 14:26:42,321 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 3.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2627 bytes)
2016-12-14 14:26:42,322 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 3.0 (TID 6)
2016-12-14 14:26:42,322 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 3.0 (TID 7)
2016-12-14 14:26:42,326 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,326 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,326 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:26:42,328 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,328 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,329 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:26:42,336 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 3.0 (TID 6). 3778 bytes result sent to driver
2016-12-14 14:26:42,341 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 3.0 (TID 7). 3093 bytes result sent to driver
2016-12-14 14:26:42,350 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 3.0 (TID 6) in 30 ms on localhost (1/2)
2016-12-14 14:26:42,352 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 3.0 (TID 7) in 31 ms on localhost (2/2)
2016-12-14 14:26:42,353 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 3 (collect at KMeans.scala:436) finished in 0.034 s
2016-12-14 14:26:42,353 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,353 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 3 finished: collect at KMeans.scala:436, took 0.052595 s
2016-12-14 14:26:42,355 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6 stored as values in memory (estimated size 5.7 KB, free 396.3 KB)
2016-12-14 14:26:42,362 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1299.0 B, free 397.6 KB)
2016-12-14 14:26:42,363 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_6_piece0 in memory on localhost:55377 (size: 1299.0 B, free: 529.9 MB)
2016-12-14 14:26:42,364 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 6 from broadcast at KMeans.scala:396
2016-12-14 14:26:42,375 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:26:42,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 4 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:26:42,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 4 (aggregate at KMeans.scala:404)
2016-12-14 14:26:42,376 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,378 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,378 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:26:42,380 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7 stored as values in memory (estimated size 6.1 KB, free 403.6 KB)
2016-12-14 14:26:42,385 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.1 KB, free 406.7 KB)
2016-12-14 14:26:42,386 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_7_piece0 in memory on localhost:55377 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:26:42,386 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,386 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at map at KMeans.scala:398)
2016-12-14 14:26:42,387 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 4.0 with 2 tasks
2016-12-14 14:26:42,388 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 4.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2627 bytes)
2016-12-14 14:26:42,389 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 4.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2627 bytes)
2016-12-14 14:26:42,389 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 4.0 (TID 8)
2016-12-14 14:26:42,389 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 4.0 (TID 9)
2016-12-14 14:26:42,392 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_1 not found, computing it
2016-12-14 14:26:42,393 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_14_0 not found, computing it
2016-12-14 14:26:42,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_1 locally
2016-12-14 14:26:42,393 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_10_0 locally
2016-12-14 14:26:42,404 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_1 stored as values in memory (estimated size 7.3 KB, free 414.1 KB)
2016-12-14 14:26:42,404 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_14_0 stored as values in memory (estimated size 7.3 KB, free 421.4 KB)
2016-12-14 14:26:42,404 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_1 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,405 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_14_0 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,408 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 4.0 (TID 9). 2721 bytes result sent to driver
2016-12-14 14:26:42,409 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 4.0 (TID 8). 2721 bytes result sent to driver
2016-12-14 14:26:42,415 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 4.0 (TID 9) in 27 ms on localhost (1/2)
2016-12-14 14:26:42,417 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 4.0 (TID 8) in 30 ms on localhost (2/2)
2016-12-14 14:26:42,417 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 4 (aggregate at KMeans.scala:404) finished in 0.030 s
2016-12-14 14:26:42,418 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,418 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 4 finished: aggregate at KMeans.scala:404, took 0.042816 s
2016-12-14 14:26:42,419 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 10 from persistence list
2016-12-14 14:26:42,422 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:26:42,442 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:26:42,443 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 5 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:26:42,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 5 (collect at KMeans.scala:436)
2016-12-14 14:26:42,444 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,445 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,446 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:26:42,448 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8 stored as values in memory (estimated size 6.2 KB, free 412.9 KB)
2016-12-14 14:26:42,453 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.2 KB, free 416.2 KB)
2016-12-14 14:26:42,454 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_8_piece0 in memory on localhost:55377 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:42,455 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,455 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:26:42,455 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 5.0 with 2 tasks
2016-12-14 14:26:42,456 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 5.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2659 bytes)
2016-12-14 14:26:42,457 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 5.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2659 bytes)
2016-12-14 14:26:42,458 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 5.0 (TID 10)
2016-12-14 14:26:42,458 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 5.0 (TID 11)
2016-12-14 14:26:42,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:26:42,461 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:26:42,467 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 5.0 (TID 11). 4114 bytes result sent to driver
2016-12-14 14:26:42,467 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 5.0 (TID 10). 3371 bytes result sent to driver
2016-12-14 14:26:42,478 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 5.0 (TID 11) in 21 ms on localhost (1/2)
2016-12-14 14:26:42,481 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 5.0 (TID 10) in 25 ms on localhost (2/2)
2016-12-14 14:26:42,481 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 5 (collect at KMeans.scala:436) finished in 0.025 s
2016-12-14 14:26:42,482 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,482 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 5 finished: collect at KMeans.scala:436, took 0.039536 s
2016-12-14 14:26:42,485 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9 stored as values in memory (estimated size 6.7 KB, free 422.9 KB)
2016-12-14 14:26:42,493 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1535.0 B, free 424.4 KB)
2016-12-14 14:26:42,494 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_9_piece0 in memory on localhost:55377 (size: 1535.0 B, free: 529.9 MB)
2016-12-14 14:26:42,495 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 9 from broadcast at KMeans.scala:396
2016-12-14 14:26:42,509 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:26:42,511 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 6 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:26:42,511 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 6 (aggregate at KMeans.scala:404)
2016-12-14 14:26:42,511 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,513 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:26:42,515 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 430.7 KB)
2016-12-14 14:26:42,521 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.1 KB, free 433.9 KB)
2016-12-14 14:26:42,521 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_10_piece0 in memory on localhost:55377 (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:26:42,522 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,522 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[18] at map at KMeans.scala:398)
2016-12-14 14:26:42,522 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 6.0 with 2 tasks
2016-12-14 14:26:42,524 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 6.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2659 bytes)
2016-12-14 14:26:42,524 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 6.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2659 bytes)
2016-12-14 14:26:42,524 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 6.0 (TID 12)
2016-12-14 14:26:42,524 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 6.0 (TID 13)
2016-12-14 14:26:42,527 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_1 not found, computing it
2016-12-14 14:26:42,527 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,528 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,528 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_1 locally
2016-12-14 14:26:42,528 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_18_0 not found, computing it
2016-12-14 14:26:42,528 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,529 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,529 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_14_0 locally
2016-12-14 14:26:42,531 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_1 stored as values in memory (estimated size 7.3 KB, free 441.2 KB)
2016-12-14 14:26:42,531 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_1 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,532 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_18_0 stored as values in memory (estimated size 7.3 KB, free 448.6 KB)
2016-12-14 14:26:42,533 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_18_0 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,537 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 6.0 (TID 13). 2721 bytes result sent to driver
2016-12-14 14:26:42,537 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 6.0 (TID 12). 2721 bytes result sent to driver
2016-12-14 14:26:42,542 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 6.0 (TID 12) in 19 ms on localhost (1/2)
2016-12-14 14:26:42,543 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 6.0 (TID 13) in 19 ms on localhost (2/2)
2016-12-14 14:26:42,543 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 6 (aggregate at KMeans.scala:404) finished in 0.020 s
2016-12-14 14:26:42,543 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,544 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 6 finished: aggregate at KMeans.scala:404, took 0.034230 s
2016-12-14 14:26:42,545 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 14 from persistence list
2016-12-14 14:26:42,546 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:26:42,564 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:26:42,566 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 7 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:26:42,566 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 7 (collect at KMeans.scala:436)
2016-12-14 14:26:42,566 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,567 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,568 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:26:42,570 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11 stored as values in memory (estimated size 6.5 KB, free 440.3 KB)
2016-12-14 14:26:42,575 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 443.6 KB)
2016-12-14 14:26:42,576 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_11_piece0 in memory on localhost:55377 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,576 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,577 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[20] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:26:42,577 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 7.0 with 2 tasks
2016-12-14 14:26:42,578 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 7.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2691 bytes)
2016-12-14 14:26:42,579 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 7.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2691 bytes)
2016-12-14 14:26:42,579 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 7.0 (TID 15)
2016-12-14 14:26:42,579 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 7.0 (TID 14)
2016-12-14 14:26:42,582 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,582 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,583 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:26:42,584 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,584 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,584 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:26:42,600 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 7.0 (TID 15). 3485 bytes result sent to driver
2016-12-14 14:26:42,602 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 2
2016-12-14 14:26:42,603 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 7.0 (TID 14). 3542 bytes result sent to driver
2016-12-14 14:26:42,606 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_1_piece0 on localhost:55377 in memory (size: 2.4 KB, free: 529.9 MB)
2016-12-14 14:26:42,606 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 7.0 (TID 15) in 28 ms on localhost (1/2)
2016-12-14 14:26:42,608 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 1
2016-12-14 14:26:42,608 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_8_piece0 on localhost:55377 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:42,609 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 6
2016-12-14 14:26:42,609 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 7 (collect at KMeans.scala:436) finished in 0.032 s
2016-12-14 14:26:42,609 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 7.0 (TID 14) in 32 ms on localhost (2/2)
2016-12-14 14:26:42,610 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 7 finished: collect at KMeans.scala:436, took 0.045009 s
2016-12-14 14:26:42,610 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,610 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_7_piece0 on localhost:55377 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:26:42,611 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 5
2016-12-14 14:26:42,612 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_5_piece0 on localhost:55377 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:42,612 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12 stored as values in memory (estimated size 5.7 KB, free 420.9 KB)
2016-12-14 14:26:42,613 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 4
2016-12-14 14:26:42,614 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_4_piece0 on localhost:55377 in memory (size: 3.0 KB, free: 529.9 MB)
2016-12-14 14:26:42,614 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 3
2016-12-14 14:26:42,615 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_2_piece0 on localhost:55377 in memory (size: 8.9 KB, free: 529.9 MB)
2016-12-14 14:26:42,616 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 7
2016-12-14 14:26:42,616 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_10_piece0 on localhost:55377 in memory (size: 3.1 KB, free: 529.9 MB)
2016-12-14 14:26:42,617 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1371.0 B, free 374.1 KB)
2016-12-14 14:26:42,617 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_12_piece0 in memory on localhost:55377 (size: 1371.0 B, free: 529.9 MB)
2016-12-14 14:26:42,618 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 12 from broadcast at KMeans.scala:396
2016-12-14 14:26:42,630 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:26:42,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 8 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:26:42,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 8 (aggregate at KMeans.scala:404)
2016-12-14 14:26:42,632 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,633 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:26:42,635 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13 stored as values in memory (estimated size 6.5 KB, free 374.3 KB)
2016-12-14 14:26:42,640 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.2 KB, free 377.5 KB)
2016-12-14 14:26:42,640 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_13_piece0 in memory on localhost:55377 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:42,640 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,641 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at map at KMeans.scala:398)
2016-12-14 14:26:42,641 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 8.0 with 2 tasks
2016-12-14 14:26:42,642 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 8.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2691 bytes)
2016-12-14 14:26:42,642 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 8.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2691 bytes)
2016-12-14 14:26:42,643 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 8.0 (TID 16)
2016-12-14 14:26:42,643 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 8.0 (TID 17)
2016-12-14 14:26:42,647 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_1 not found, computing it
2016-12-14 14:26:42,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,647 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_22_0 not found, computing it
2016-12-14 14:26:42,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,647 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_1 locally
2016-12-14 14:26:42,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,648 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_18_0 locally
2016-12-14 14:26:42,653 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_1 stored as values in memory (estimated size 7.3 KB, free 384.9 KB)
2016-12-14 14:26:42,653 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_1 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,655 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_22_0 stored as values in memory (estimated size 7.3 KB, free 392.2 KB)
2016-12-14 14:26:42,656 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_22_0 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,658 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 8.0 (TID 17). 2721 bytes result sent to driver
2016-12-14 14:26:42,661 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 8.0 (TID 16). 2721 bytes result sent to driver
2016-12-14 14:26:42,663 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 8.0 (TID 17) in 21 ms on localhost (1/2)
2016-12-14 14:26:42,665 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 8.0 (TID 16) in 24 ms on localhost (2/2)
2016-12-14 14:26:42,665 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 8 (aggregate at KMeans.scala:404) finished in 0.024 s
2016-12-14 14:26:42,665 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,666 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 8 finished: aggregate at KMeans.scala:404, took 0.035246 s
2016-12-14 14:26:42,667 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 18 from persistence list
2016-12-14 14:26:42,668 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:26:42,680 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:26:42,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 9 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:26:42,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 9 (collect at KMeans.scala:436)
2016-12-14 14:26:42,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,684 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:26:42,687 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14 stored as values in memory (estimated size 6.7 KB, free 384.2 KB)
2016-12-14 14:26:42,694 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 387.6 KB)
2016-12-14 14:26:42,695 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_14_piece0 in memory on localhost:55377 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:26:42,696 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,696 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:26:42,696 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 9.0 with 2 tasks
2016-12-14 14:26:42,698 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 9.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2723 bytes)
2016-12-14 14:26:42,699 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 9.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2723 bytes)
2016-12-14 14:26:42,699 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 9.0 (TID 18)
2016-12-14 14:26:42,699 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 9.0 (TID 19)
2016-12-14 14:26:42,703 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,703 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,703 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:26:42,705 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,705 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,705 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:26:42,707 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 9.0 (TID 19). 3762 bytes result sent to driver
2016-12-14 14:26:42,713 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 9.0 (TID 18). 3262 bytes result sent to driver
2016-12-14 14:26:42,716 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 9.0 (TID 19) in 18 ms on localhost (1/2)
2016-12-14 14:26:42,717 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 9.0 (TID 18) in 19 ms on localhost (2/2)
2016-12-14 14:26:42,717 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 9 (collect at KMeans.scala:436) finished in 0.020 s
2016-12-14 14:26:42,717 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,718 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 9 finished: collect at KMeans.scala:436, took 0.037841 s
2016-12-14 14:26:42,719 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15 stored as values in memory (estimated size 5.7 KB, free 393.3 KB)
2016-12-14 14:26:42,724 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_15_piece0 stored as bytes in memory (estimated size 1352.0 B, free 394.6 KB)
2016-12-14 14:26:42,724 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_15_piece0 in memory on localhost:55377 (size: 1352.0 B, free: 529.9 MB)
2016-12-14 14:26:42,725 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 15 from broadcast at KMeans.scala:396
2016-12-14 14:26:42,735 INFO  org.apache.spark.SparkContext - logInfo: Starting job: aggregate at KMeans.scala:404
2016-12-14 14:26:42,737 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 10 (aggregate at KMeans.scala:404) with 2 output partitions
2016-12-14 14:26:42,737 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 10 (aggregate at KMeans.scala:404)
2016-12-14 14:26:42,737 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,739 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,739 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398), which has no missing parents
2016-12-14 14:26:42,742 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16 stored as values in memory (estimated size 6.8 KB, free 401.4 KB)
2016-12-14 14:26:42,749 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.3 KB, free 404.7 KB)
2016-12-14 14:26:42,750 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_16_piece0 in memory on localhost:55377 (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,750 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,750 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at map at KMeans.scala:398)
2016-12-14 14:26:42,751 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 10.0 with 2 tasks
2016-12-14 14:26:42,752 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 10.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2723 bytes)
2016-12-14 14:26:42,752 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 10.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2723 bytes)
2016-12-14 14:26:42,753 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 10.0 (TID 20)
2016-12-14 14:26:42,753 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 10.0 (TID 21)
2016-12-14 14:26:42,756 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_0 not found, computing it
2016-12-14 14:26:42,756 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,756 INFO  org.apache.spark.CacheManager - logInfo: Partition rdd_26_1 not found, computing it
2016-12-14 14:26:42,756 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,756 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,756 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_0 locally
2016-12-14 14:26:42,756 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,757 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_22_1 locally
2016-12-14 14:26:42,760 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_0 stored as values in memory (estimated size 7.3 KB, free 412.0 KB)
2016-12-14 14:26:42,760 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block rdd_26_1 stored as values in memory (estimated size 7.3 KB, free 419.3 KB)
2016-12-14 14:26:42,760 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_0 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,761 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added rdd_26_1 in memory on localhost:55377 (size: 7.3 KB, free: 529.9 MB)
2016-12-14 14:26:42,763 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 10.0 (TID 20). 2721 bytes result sent to driver
2016-12-14 14:26:42,764 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 10.0 (TID 21). 2721 bytes result sent to driver
2016-12-14 14:26:42,767 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 10.0 (TID 21) in 15 ms on localhost (1/2)
2016-12-14 14:26:42,767 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 10.0 (TID 20) in 16 ms on localhost (2/2)
2016-12-14 14:26:42,768 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 10 (aggregate at KMeans.scala:404) finished in 0.016 s
2016-12-14 14:26:42,768 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,768 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 10 finished: aggregate at KMeans.scala:404, took 0.032159 s
2016-12-14 14:26:42,769 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 22 from persistence list
2016-12-14 14:26:42,769 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:26:42,782 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collect at KMeans.scala:436
2016-12-14 14:26:42,784 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 11 (collect at KMeans.scala:436) with 2 output partitions
2016-12-14 14:26:42,784 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 11 (collect at KMeans.scala:436)
2016-12-14 14:26:42,784 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List()
2016-12-14 14:26:42,786 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List()
2016-12-14 14:26:42,787 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428), which has no missing parents
2016-12-14 14:26:42,791 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17 stored as values in memory (estimated size 6.9 KB, free 411.6 KB)
2016-12-14 14:26:42,800 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.4 KB, free 415.0 KB)
2016-12-14 14:26:42,801 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_17_piece0 in memory on localhost:55377 (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:26:42,801 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,802 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:428)
2016-12-14 14:26:42,802 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 11.0 with 2 tasks
2016-12-14 14:26:42,804 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 11.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2755 bytes)
2016-12-14 14:26:42,804 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 11.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2755 bytes)
2016-12-14 14:26:42,805 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 11.0 (TID 22)
2016-12-14 14:26:42,805 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 11.0 (TID 23)
2016-12-14 14:26:42,808 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,808 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:42,808 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_0 locally
2016-12-14 14:26:42,812 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 11.0 (TID 22). 2985 bytes result sent to driver
2016-12-14 14:26:42,812 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,812 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,813 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_26_1 locally
2016-12-14 14:26:42,819 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 11.0 (TID 22) in 16 ms on localhost (1/2)
2016-12-14 14:26:42,822 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 11.0 (TID 23). 3768 bytes result sent to driver
2016-12-14 14:26:42,828 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 11.0 (TID 23) in 24 ms on localhost (2/2)
2016-12-14 14:26:42,828 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 11 (collect at KMeans.scala:436) finished in 0.025 s
2016-12-14 14:26:42,829 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:26:42,829 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 11 finished: collect at KMeans.scala:436, took 0.046730 s
2016-12-14 14:26:42,830 INFO  org.apache.spark.rdd.MapPartitionsRDD - logInfo: Removing RDD 26 from persistence list
2016-12-14 14:26:42,830 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:26:42,831 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18 stored as values in memory (estimated size 26.9 KB, free 427.3 KB)
2016-12-14 14:26:42,837 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.0 KB, free 431.2 KB)
2016-12-14 14:26:42,838 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_18_piece0 in memory on localhost:55377 (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:26:42,838 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 18 from broadcast at KMeans.scala:450
2016-12-14 14:26:42,868 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:455
2016-12-14 14:26:42,885 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 29 (flatMap at KMeans.scala:451)
2016-12-14 14:26:42,886 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 12 (collectAsMap at KMeans.scala:455) with 2 output partitions
2016-12-14 14:26:42,886 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 13 (collectAsMap at KMeans.scala:455)
2016-12-14 14:26:42,887 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 12)
2016-12-14 14:26:42,887 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 12)
2016-12-14 14:26:42,890 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451), which has no missing parents
2016-12-14 14:26:42,902 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19 stored as values in memory (estimated size 5.9 KB, free 437.1 KB)
2016-12-14 14:26:42,906 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.2 KB, free 440.3 KB)
2016-12-14 14:26:42,907 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_19_piece0 in memory on localhost:55377 (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:42,908 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:42,911 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[29] at flatMap at KMeans.scala:451)
2016-12-14 14:26:42,911 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 12.0 with 2 tasks
2016-12-14 14:26:42,915 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 12.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:42,916 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 12.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:42,916 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 12.0 (TID 24)
2016-12-14 14:26:42,917 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 12.0 (TID 25)
2016-12-14 14:26:42,921 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:42,922 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:42,922 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:42,923 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,010 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 12.0 (TID 25). 2237 bytes result sent to driver
2016-12-14 14:26:43,016 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 12.0 (TID 24). 2237 bytes result sent to driver
2016-12-14 14:26:43,019 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 12.0 (TID 25) in 104 ms on localhost (1/2)
2016-12-14 14:26:43,023 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 12.0 (TID 24) in 110 ms on localhost (2/2)
2016-12-14 14:26:43,023 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 12 (flatMap at KMeans.scala:451) finished in 0.111 s
2016-12-14 14:26:43,023 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,024 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,025 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,026 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 13)
2016-12-14 14:26:43,027 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,030 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455), which has no missing parents
2016-12-14 14:26:43,037 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20 stored as values in memory (estimated size 2.6 KB, free 442.9 KB)
2016-12-14 14:26:43,045 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1555.0 B, free 444.4 KB)
2016-12-14 14:26:43,046 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_20_piece0 in memory on localhost:55377 (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:26:43,047 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,047 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 13 (ShuffledRDD[30] at reduceByKey at KMeans.scala:455)
2016-12-14 14:26:43,048 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 13.0 with 2 tasks
2016-12-14 14:26:43,051 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 13.0 (TID 26, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,052 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 13.0 (TID 27, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,052 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 13.0 (TID 26)
2016-12-14 14:26:43,052 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 13.0 (TID 27)
2016-12-14 14:26:43,065 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,065 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,067 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 6 ms
2016-12-14 14:26:43,067 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 6 ms
2016-12-14 14:26:43,122 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 13.0 (TID 27). 4437 bytes result sent to driver
2016-12-14 14:26:43,123 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 13.0 (TID 26). 4713 bytes result sent to driver
2016-12-14 14:26:43,127 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 13.0 (TID 26) in 77 ms on localhost (1/2)
2016-12-14 14:26:43,127 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 13.0 (TID 27) in 76 ms on localhost (2/2)
2016-12-14 14:26:43,127 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 13 (collectAsMap at KMeans.scala:455) finished in 0.078 s
2016-12-14 14:26:43,127 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,128 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 12 finished: collectAsMap at KMeans.scala:455, took 0.259499 s
2016-12-14 14:26:43,295 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:26:43,296 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 6 iterations.
2016-12-14 14:26:43,296 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 5 iterations.
2016-12-14 14:26:43,295 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:26:43,295 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:26:43,296 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:26:43,295 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:26:43,295 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 2 iterations.
2016-12-14 14:26:43,295 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 4 iterations.
2016-12-14 14:26:43,295 INFO  org.apache.spark.mllib.clustering.LocalKMeans - logInfo: Local KMeans++ converged in 3 iterations.
2016-12-14 14:26:43,315 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Initialization with k-means|| took 2.294 seconds.
2016-12-14 14:26:43,320 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21 stored as values in memory (estimated size 3.0 KB, free 447.4 KB)
2016-12-14 14:26:43,328 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1368.0 B, free 448.7 KB)
2016-12-14 14:26:43,329 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_21_piece0 in memory on localhost:55377 (size: 1368.0 B, free: 529.9 MB)
2016-12-14 14:26:43,330 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 21 from broadcast at KMeans.scala:276
2016-12-14 14:26:43,368 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:43,370 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 31 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,370 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 13 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:43,370 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 15 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:43,370 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 14)
2016-12-14 14:26:43,371 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 14)
2016-12-14 14:26:43,372 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:43,374 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22 stored as values in memory (estimated size 6.9 KB, free 455.6 KB)
2016-12-14 14:26:43,378 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.6 KB, free 459.2 KB)
2016-12-14 14:26:43,380 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_22_piece0 in memory on localhost:55377 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:26:43,381 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,381 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[31] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,382 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 14.0 with 2 tasks
2016-12-14 14:26:43,384 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 14.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,385 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 14.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,385 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 14.0 (TID 28)
2016-12-14 14:26:43,385 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 14.0 (TID 29)
2016-12-14 14:26:43,392 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:43,392 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:43,392 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:43,392 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,418 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 14.0 (TID 28). 2516 bytes result sent to driver
2016-12-14 14:26:43,418 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 14.0 (TID 29). 2516 bytes result sent to driver
2016-12-14 14:26:43,425 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 14.0 (TID 28) in 42 ms on localhost (1/2)
2016-12-14 14:26:43,426 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 14.0 (TID 29) in 42 ms on localhost (2/2)
2016-12-14 14:26:43,426 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 14 (mapPartitions at KMeans.scala:279) finished in 0.043 s
2016-12-14 14:26:43,426 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,426 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 15)
2016-12-14 14:26:43,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,427 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:43,429 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23 stored as values in memory (estimated size 2.9 KB, free 462.1 KB)
2016-12-14 14:26:43,433 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1669.0 B, free 463.7 KB)
2016-12-14 14:26:43,433 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_23_piece0 in memory on localhost:55377 (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:26:43,434 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,434 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[32] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:43,434 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 15.0 with 2 tasks
2016-12-14 14:26:43,435 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 15.0 (TID 30, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,436 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 15.0 (TID 31, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,436 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 15.0 (TID 31)
2016-12-14 14:26:43,436 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 15.0 (TID 30)
2016-12-14 14:26:43,439 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,439 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:43,440 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,440 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:43,448 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 15.0 (TID 31). 1964 bytes result sent to driver
2016-12-14 14:26:43,453 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 15.0 (TID 31) in 18 ms on localhost (1/2)
2016-12-14 14:26:43,454 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 15.0 (TID 30). 1964 bytes result sent to driver
2016-12-14 14:26:43,459 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 15.0 (TID 30) in 24 ms on localhost (2/2)
2016-12-14 14:26:43,460 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,460 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 15 (collectAsMap at KMeans.scala:302) finished in 0.026 s
2016-12-14 14:26:43,460 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 13 finished: collectAsMap at KMeans.scala:302, took 0.091976 s
2016-12-14 14:26:43,465 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24 stored as values in memory (estimated size 3.0 KB, free 466.7 KB)
2016-12-14 14:26:43,470 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_24_piece0 stored as bytes in memory (estimated size 670.0 B, free 467.3 KB)
2016-12-14 14:26:43,471 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_24_piece0 in memory on localhost:55377 (size: 670.0 B, free: 529.9 MB)
2016-12-14 14:26:43,472 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 24 from broadcast at KMeans.scala:276
2016-12-14 14:26:43,488 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:43,490 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 33 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,491 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 14 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:43,491 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 17 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:43,491 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 16)
2016-12-14 14:26:43,491 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 16)
2016-12-14 14:26:43,493 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:43,496 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25 stored as values in memory (estimated size 6.9 KB, free 474.2 KB)
2016-12-14 14:26:43,503 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.6 KB, free 477.8 KB)
2016-12-14 14:26:43,504 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_25_piece0 in memory on localhost:55377 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:26:43,504 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,505 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[33] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,505 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 16.0 with 2 tasks
2016-12-14 14:26:43,507 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 16.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,507 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 16.0 (TID 33, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,508 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 16.0 (TID 33)
2016-12-14 14:26:43,508 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 16.0 (TID 32)
2016-12-14 14:26:43,514 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:43,514 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:43,515 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,515 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:43,531 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 16.0 (TID 32). 2516 bytes result sent to driver
2016-12-14 14:26:43,531 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 16.0 (TID 33). 2516 bytes result sent to driver
2016-12-14 14:26:43,535 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 16.0 (TID 33) in 28 ms on localhost (1/2)
2016-12-14 14:26:43,535 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 16.0 (TID 32) in 29 ms on localhost (2/2)
2016-12-14 14:26:43,536 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,536 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 16 (mapPartitions at KMeans.scala:279) finished in 0.030 s
2016-12-14 14:26:43,536 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,537 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,537 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 17)
2016-12-14 14:26:43,537 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,537 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:43,540 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26 stored as values in memory (estimated size 2.9 KB, free 480.7 KB)
2016-12-14 14:26:43,545 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1665.0 B, free 482.3 KB)
2016-12-14 14:26:43,546 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_26_piece0 in memory on localhost:55377 (size: 1665.0 B, free: 529.9 MB)
2016-12-14 14:26:43,547 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,548 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 17 (ShuffledRDD[34] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:43,548 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 17.0 with 2 tasks
2016-12-14 14:26:43,549 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 17.0 (TID 34, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,550 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 17.0 (TID 35, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,551 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 17.0 (TID 34)
2016-12-14 14:26:43,551 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 17.0 (TID 35)
2016-12-14 14:26:43,553 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,553 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,553 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:43,554 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:43,565 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 17.0 (TID 34). 1963 bytes result sent to driver
2016-12-14 14:26:43,565 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 17.0 (TID 35). 1963 bytes result sent to driver
2016-12-14 14:26:43,567 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 17.0 (TID 34) in 18 ms on localhost (1/2)
2016-12-14 14:26:43,568 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 17 (collectAsMap at KMeans.scala:302) finished in 0.020 s
2016-12-14 14:26:43,568 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 17.0 (TID 35) in 19 ms on localhost (2/2)
2016-12-14 14:26:43,569 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 14 finished: collectAsMap at KMeans.scala:302, took 0.080146 s
2016-12-14 14:26:43,569 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,571 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 0 finished in 2 iterations
2016-12-14 14:26:43,571 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 1 finished in 2 iterations
2016-12-14 14:26:43,571 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 4 finished in 2 iterations
2016-12-14 14:26:43,571 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 5 finished in 2 iterations
2016-12-14 14:26:43,572 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 7 finished in 2 iterations
2016-12-14 14:26:43,573 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27 stored as values in memory (estimated size 1544.0 B, free 483.8 KB)
2016-12-14 14:26:43,579 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_27_piece0 stored as bytes in memory (estimated size 461.0 B, free 484.3 KB)
2016-12-14 14:26:43,579 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_27_piece0 in memory on localhost:55377 (size: 461.0 B, free: 529.9 MB)
2016-12-14 14:26:43,580 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 27 from broadcast at KMeans.scala:276
2016-12-14 14:26:43,592 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:43,594 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 35 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,594 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 15 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:43,594 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 19 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:43,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 18)
2016-12-14 14:26:43,595 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 18)
2016-12-14 14:26:43,597 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:43,599 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28 stored as values in memory (estimated size 6.7 KB, free 490.9 KB)
2016-12-14 14:26:43,606 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.6 KB, free 494.5 KB)
2016-12-14 14:26:43,607 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_28_piece0 in memory on localhost:55377 (size: 3.6 KB, free: 529.9 MB)
2016-12-14 14:26:43,608 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,608 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,608 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 18.0 with 2 tasks
2016-12-14 14:26:43,610 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 18.0 (TID 36, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,610 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 18.0 (TID 37, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,611 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 18.0 (TID 37)
2016-12-14 14:26:43,611 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 18.0 (TID 36)
2016-12-14 14:26:43,614 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:43,615 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:43,615 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:43,615 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,623 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 18.0 (TID 37). 2396 bytes result sent to driver
2016-12-14 14:26:43,623 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 18.0 (TID 36). 2396 bytes result sent to driver
2016-12-14 14:26:43,625 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 18.0 (TID 37) in 15 ms on localhost (1/2)
2016-12-14 14:26:43,629 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 18.0 (TID 36) in 18 ms on localhost (2/2)
2016-12-14 14:26:43,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 18 (mapPartitions at KMeans.scala:279) finished in 0.020 s
2016-12-14 14:26:43,629 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,629 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,630 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,630 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 19)
2016-12-14 14:26:43,630 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,630 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:43,632 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29 stored as values in memory (estimated size 2.9 KB, free 497.4 KB)
2016-12-14 14:26:43,635 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1667.0 B, free 499.0 KB)
2016-12-14 14:26:43,636 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_29_piece0 in memory on localhost:55377 (size: 1667.0 B, free: 529.9 MB)
2016-12-14 14:26:43,636 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,636 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[36] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:43,636 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 19.0 with 2 tasks
2016-12-14 14:26:43,638 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 19.0 (TID 38, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,638 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 19.0 (TID 39, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,639 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 19.0 (TID 38)
2016-12-14 14:26:43,639 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 19.0 (TID 39)
2016-12-14 14:26:43,641 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,642 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,642 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:43,642 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:43,654 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 19.0 (TID 39). 1592 bytes result sent to driver
2016-12-14 14:26:43,656 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 19.0 (TID 38). 1539 bytes result sent to driver
2016-12-14 14:26:43,662 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 19.0 (TID 39) in 24 ms on localhost (1/2)
2016-12-14 14:26:43,663 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 19.0 (TID 38) in 26 ms on localhost (2/2)
2016-12-14 14:26:43,663 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 19 (collectAsMap at KMeans.scala:302) finished in 0.026 s
2016-12-14 14:26:43,663 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,664 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 15 finished: collectAsMap at KMeans.scala:302, took 0.071301 s
2016-12-14 14:26:43,665 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 3 finished in 3 iterations
2016-12-14 14:26:43,665 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 6 finished in 3 iterations
2016-12-14 14:26:43,665 INFO  org.apache.spark.mllib.clustering.KMeans - logInfo: Run 9 finished in 3 iterations
2016-12-14 14:26:43,666 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30 stored as values in memory (estimated size 640.0 B, free 499.7 KB)
2016-12-14 14:26:43,668 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_30_piece0 stored as bytes in memory (estimated size 345.0 B, free 500.0 KB)
2016-12-14 14:26:43,669 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_30_piece0 in memory on localhost:55377 (size: 345.0 B, free: 529.9 MB)
2016-12-14 14:26:43,669 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 30 from broadcast at KMeans.scala:276
2016-12-14 14:26:43,678 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:43,679 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 37 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,679 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 16 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:43,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 21 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:43,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 20)
2016-12-14 14:26:43,680 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 20)
2016-12-14 14:26:43,682 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:43,684 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31 stored as values in memory (estimated size 6.6 KB, free 506.6 KB)
2016-12-14 14:26:43,706 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 26
2016-12-14 14:26:43,708 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.5 KB, free 510.1 KB)
2016-12-14 14:26:43,708 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 26
2016-12-14 14:26:43,709 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_31_piece0 in memory on localhost:55377 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:26:43,709 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,709 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,710 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_15_piece0 on localhost:55377 in memory (size: 1352.0 B, free: 529.9 MB)
2016-12-14 14:26:43,710 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 20.0 with 2 tasks
2016-12-14 14:26:43,711 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_14_piece0 on localhost:55377 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:26:43,712 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 20.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,712 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 10
2016-12-14 14:26:43,712 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 20.0 (TID 41, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,713 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 20.0 (TID 41)
2016-12-14 14:26:43,713 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 20.0 (TID 40)
2016-12-14 14:26:43,714 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_13_piece0 on localhost:55377 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:43,715 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 9
2016-12-14 14:26:43,715 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 22
2016-12-14 14:26:43,716 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 22
2016-12-14 14:26:43,717 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_12_piece0 on localhost:55377 in memory (size: 1371.0 B, free: 529.9 MB)
2016-12-14 14:26:43,717 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:43,718 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:43,718 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:43,718 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,718 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_11_piece0 on localhost:55377 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:26:43,719 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 8
2016-12-14 14:26:43,719 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 18
2016-12-14 14:26:43,720 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 18
2016-12-14 14:26:43,721 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_9_piece0 on localhost:55377 in memory (size: 1535.0 B, free: 529.9 MB)
2016-12-14 14:26:43,723 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 14
2016-12-14 14:26:43,723 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 14
2016-12-14 14:26:43,724 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_6_piece0 on localhost:55377 in memory (size: 1299.0 B, free: 529.9 MB)
2016-12-14 14:26:43,726 INFO  org.apache.spark.storage.BlockManager - logInfo: Removing RDD 10
2016-12-14 14:26:43,726 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned RDD 10
2016-12-14 14:26:43,727 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_3_piece0 on localhost:55377 in memory (size: 437.0 B, free: 529.9 MB)
2016-12-14 14:26:43,727 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 20.0 (TID 40). 2324 bytes result sent to driver
2016-12-14 14:26:43,727 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 20.0 (TID 41). 2324 bytes result sent to driver
2016-12-14 14:26:43,727 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 24
2016-12-14 14:26:43,728 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 23
2016-12-14 14:26:43,728 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 22
2016-12-14 14:26:43,728 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 21
2016-12-14 14:26:43,728 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 20
2016-12-14 14:26:43,728 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 19
2016-12-14 14:26:43,729 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 18
2016-12-14 14:26:43,729 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 17
2016-12-14 14:26:43,729 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 16
2016-12-14 14:26:43,729 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 15
2016-12-14 14:26:43,730 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_20_piece0 on localhost:55377 in memory (size: 1555.0 B, free: 529.9 MB)
2016-12-14 14:26:43,731 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 14
2016-12-14 14:26:43,731 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 20.0 (TID 40) in 19 ms on localhost (1/2)
2016-12-14 14:26:43,731 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_19_piece0 on localhost:55377 in memory (size: 3.2 KB, free: 529.9 MB)
2016-12-14 14:26:43,732 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 13
2016-12-14 14:26:43,732 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 20.0 (TID 41) in 20 ms on localhost (2/2)
2016-12-14 14:26:43,732 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 20 (mapPartitions at KMeans.scala:279) finished in 0.021 s
2016-12-14 14:26:43,733 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,733 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,733 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,733 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 21)
2016-12-14 14:26:43,733 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,734 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:43,736 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32 stored as values in memory (estimated size 2.9 KB, free 438.6 KB)
2016-12-14 14:26:43,736 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 0
2016-12-14 14:26:43,737 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_18_piece0 on localhost:55377 in memory (size: 4.0 KB, free: 529.9 MB)
2016-12-14 14:26:43,738 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_17_piece0 on localhost:55377 in memory (size: 3.4 KB, free: 529.9 MB)
2016-12-14 14:26:43,738 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 12
2016-12-14 14:26:43,739 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_16_piece0 on localhost:55377 in memory (size: 3.3 KB, free: 529.9 MB)
2016-12-14 14:26:43,740 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 11
2016-12-14 14:26:43,740 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1666.0 B, free 388.9 KB)
2016-12-14 14:26:43,740 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 33
2016-12-14 14:26:43,741 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 32
2016-12-14 14:26:43,741 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_32_piece0 in memory on localhost:55377 (size: 1666.0 B, free: 529.9 MB)
2016-12-14 14:26:43,741 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 31
2016-12-14 14:26:43,741 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 30
2016-12-14 14:26:43,742 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,742 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 29
2016-12-14 14:26:43,742 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 28
2016-12-14 14:26:43,742 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[38] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:43,742 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 27
2016-12-14 14:26:43,742 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 21.0 with 2 tasks
2016-12-14 14:26:43,743 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_23_piece0 on localhost:55377 in memory (size: 1669.0 B, free: 529.9 MB)
2016-12-14 14:26:43,744 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 26
2016-12-14 14:26:43,744 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 21.0 (TID 42, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,744 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_22_piece0 on localhost:55377 in memory (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:26:43,744 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 21.0 (TID 43, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,745 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 25
2016-12-14 14:26:43,745 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 21.0 (TID 43)
2016-12-14 14:26:43,745 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 21.0 (TID 42)
2016-12-14 14:26:43,745 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 1
2016-12-14 14:26:43,746 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_21_piece0 on localhost:55377 in memory (size: 1368.0 B, free: 530.0 MB)
2016-12-14 14:26:43,746 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,747 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,747 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:43,747 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:43,747 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_29_piece0 on localhost:55377 in memory (size: 1667.0 B, free: 530.0 MB)
2016-12-14 14:26:43,748 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 45
2016-12-14 14:26:43,748 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_28_piece0 on localhost:55377 in memory (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:26:43,749 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 44
2016-12-14 14:26:43,749 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 3
2016-12-14 14:26:43,750 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_27_piece0 on localhost:55377 in memory (size: 461.0 B, free: 530.0 MB)
2016-12-14 14:26:43,750 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 43
2016-12-14 14:26:43,751 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 42
2016-12-14 14:26:43,751 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 41
2016-12-14 14:26:43,751 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 40
2016-12-14 14:26:43,751 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 39
2016-12-14 14:26:43,751 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_26_piece0 on localhost:55377 in memory (size: 1665.0 B, free: 530.0 MB)
2016-12-14 14:26:43,752 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 38
2016-12-14 14:26:43,753 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_25_piece0 on localhost:55377 in memory (size: 3.6 KB, free: 530.0 MB)
2016-12-14 14:26:43,754 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 37
2016-12-14 14:26:43,754 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned shuffle 2
2016-12-14 14:26:43,755 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 21.0 (TID 42). 1324 bytes result sent to driver
2016-12-14 14:26:43,755 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 21.0 (TID 43). 1324 bytes result sent to driver
2016-12-14 14:26:43,755 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Removed broadcast_24_piece0 on localhost:55377 in memory (size: 670.0 B, free: 530.0 MB)
2016-12-14 14:26:43,756 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 36
2016-12-14 14:26:43,756 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 35
2016-12-14 14:26:43,756 INFO  org.apache.spark.ContextCleaner - logInfo: Cleaned accumulator 34
2016-12-14 14:26:43,760 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 21.0 (TID 43) in 16 ms on localhost (1/2)
2016-12-14 14:26:43,768 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 21.0 (TID 42) in 24 ms on localhost (2/2)
2016-12-14 14:26:43,768 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 21 (collectAsMap at KMeans.scala:302) finished in 0.025 s
2016-12-14 14:26:43,768 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,769 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 16 finished: collectAsMap at KMeans.scala:302, took 0.090679 s
2016-12-14 14:26:43,770 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33 stored as values in memory (estimated size 640.0 B, free 334.9 KB)
2016-12-14 14:26:43,773 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_33_piece0 stored as bytes in memory (estimated size 348.0 B, free 335.2 KB)
2016-12-14 14:26:43,773 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_33_piece0 in memory on localhost:55377 (size: 348.0 B, free: 530.0 MB)
2016-12-14 14:26:43,774 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 33 from broadcast at KMeans.scala:276
2016-12-14 14:26:43,782 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:43,783 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 39 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,783 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 17 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:43,783 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 23 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:43,784 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 22)
2016-12-14 14:26:43,784 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 22)
2016-12-14 14:26:43,785 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:43,786 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34 stored as values in memory (estimated size 6.6 KB, free 341.8 KB)
2016-12-14 14:26:43,790 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.5 KB, free 345.3 KB)
2016-12-14 14:26:43,791 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_34_piece0 in memory on localhost:55377 (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:26:43,792 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,792 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[39] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,792 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 22.0 with 2 tasks
2016-12-14 14:26:43,793 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 22.0 (TID 44, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,793 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 22.0 (TID 45, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,794 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 22.0 (TID 44)
2016-12-14 14:26:43,794 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 22.0 (TID 45)
2016-12-14 14:26:43,796 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:43,796 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:43,798 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:43,798 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,801 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 22.0 (TID 45). 2324 bytes result sent to driver
2016-12-14 14:26:43,803 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 22.0 (TID 45) in 10 ms on localhost (1/2)
2016-12-14 14:26:43,806 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 22.0 (TID 44). 2324 bytes result sent to driver
2016-12-14 14:26:43,810 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 22.0 (TID 44) in 17 ms on localhost (2/2)
2016-12-14 14:26:43,810 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 22 (mapPartitions at KMeans.scala:279) finished in 0.018 s
2016-12-14 14:26:43,810 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,810 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,810 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,810 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 23)
2016-12-14 14:26:43,810 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,811 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:43,812 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35 stored as values in memory (estimated size 2.9 KB, free 348.2 KB)
2016-12-14 14:26:43,814 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1664.0 B, free 349.9 KB)
2016-12-14 14:26:43,814 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_35_piece0 in memory on localhost:55377 (size: 1664.0 B, free: 530.0 MB)
2016-12-14 14:26:43,815 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,815 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[40] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:43,815 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 23.0 with 2 tasks
2016-12-14 14:26:43,816 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 23.0 (TID 46, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,816 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 23.0 (TID 47, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,817 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 23.0 (TID 46)
2016-12-14 14:26:43,817 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 23.0 (TID 47)
2016-12-14 14:26:43,818 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,818 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:43,819 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,819 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:43,824 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 23.0 (TID 47). 1324 bytes result sent to driver
2016-12-14 14:26:43,828 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 23.0 (TID 47) in 12 ms on localhost (1/2)
2016-12-14 14:26:43,830 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 23.0 (TID 46). 1324 bytes result sent to driver
2016-12-14 14:26:43,836 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 23.0 (TID 46) in 20 ms on localhost (2/2)
2016-12-14 14:26:43,836 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 23 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:26:43,837 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,837 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 17 finished: collectAsMap at KMeans.scala:302, took 0.055265 s
2016-12-14 14:26:43,838 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36 stored as values in memory (estimated size 640.0 B, free 350.5 KB)
2016-12-14 14:26:43,841 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_36_piece0 stored as bytes in memory (estimated size 340.0 B, free 350.8 KB)
2016-12-14 14:26:43,841 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_36_piece0 in memory on localhost:55377 (size: 340.0 B, free: 530.0 MB)
2016-12-14 14:26:43,841 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 36 from broadcast at KMeans.scala:276
2016-12-14 14:26:43,850 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:43,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 41 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 18 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:43,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 25 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:43,851 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 24)
2016-12-14 14:26:43,852 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 24)
2016-12-14 14:26:43,853 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:43,855 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37 stored as values in memory (estimated size 6.6 KB, free 357.4 KB)
2016-12-14 14:26:43,859 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.5 KB, free 360.9 KB)
2016-12-14 14:26:43,860 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_37_piece0 in memory on localhost:55377 (size: 3.5 KB, free: 530.0 MB)
2016-12-14 14:26:43,861 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,861 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[41] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,861 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 24.0 with 2 tasks
2016-12-14 14:26:43,863 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 24.0 (TID 48, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,863 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 24.0 (TID 49, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,864 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 24.0 (TID 49)
2016-12-14 14:26:43,864 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 24.0 (TID 48)
2016-12-14 14:26:43,866 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:43,866 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
2016-12-14 14:26:43,867 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_0 locally
2016-12-14 14:26:43,867 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_0 locally
2016-12-14 14:26:43,871 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 24.0 (TID 49). 2324 bytes result sent to driver
2016-12-14 14:26:43,872 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 24.0 (TID 49) in 9 ms on localhost (1/2)
2016-12-14 14:26:43,873 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 24.0 (TID 48). 2324 bytes result sent to driver
2016-12-14 14:26:43,874 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 24.0 (TID 48) in 12 ms on localhost (2/2)
2016-12-14 14:26:43,874 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,874 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ShuffleMapStage 24 (mapPartitions at KMeans.scala:279) finished in 0.012 s
2016-12-14 14:26:43,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: looking for newly runnable stages
2016-12-14 14:26:43,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: running: Set()
2016-12-14 14:26:43,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: waiting: Set(ResultStage 25)
2016-12-14 14:26:43,875 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: failed: Set()
2016-12-14 14:26:43,876 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302), which has no missing parents
2016-12-14 14:26:43,877 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38 stored as values in memory (estimated size 2.9 KB, free 363.8 KB)
2016-12-14 14:26:43,881 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1668.0 B, free 365.5 KB)
2016-12-14 14:26:43,882 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_38_piece0 in memory on localhost:55377 (size: 1668.0 B, free: 530.0 MB)
2016-12-14 14:26:43,882 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,882 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ResultStage 25 (ShuffledRDD[42] at reduceByKey at KMeans.scala:302)
2016-12-14 14:26:43,883 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 25.0 with 2 tasks
2016-12-14 14:26:43,884 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 25.0 (TID 50, localhost, partition 0,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,884 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 25.0 (TID 51, localhost, partition 1,NODE_LOCAL, 2139 bytes)
2016-12-14 14:26:43,885 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 25.0 (TID 51)
2016-12-14 14:26:43,885 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 25.0 (TID 50)
2016-12-14 14:26:43,886 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,886 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 0 ms
2016-12-14 14:26:43,887 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Getting 2 non-empty blocks out of 2 blocks
2016-12-14 14:26:43,888 INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - logInfo: Started 0 remote fetches in 1 ms
2016-12-14 14:26:43,892 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 1.0 in stage 25.0 (TID 51). 1324 bytes result sent to driver
2016-12-14 14:26:43,897 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 1.0 in stage 25.0 (TID 51) in 13 ms on localhost (1/2)
2016-12-14 14:26:43,898 INFO  org.apache.spark.executor.Executor - logInfo: Finished task 0.0 in stage 25.0 (TID 50). 1324 bytes result sent to driver
2016-12-14 14:26:43,904 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Finished task 0.0 in stage 25.0 (TID 50) in 20 ms on localhost (2/2)
2016-12-14 14:26:43,904 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: ResultStage 25 (collectAsMap at KMeans.scala:302) finished in 0.021 s
2016-12-14 14:26:43,904 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:26:43,905 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Job 18 finished: collectAsMap at KMeans.scala:302, took 0.055044 s
2016-12-14 14:26:43,907 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39 stored as values in memory (estimated size 640.0 B, free 366.1 KB)
2016-12-14 14:26:43,911 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_39_piece0 stored as bytes in memory (estimated size 338.0 B, free 366.4 KB)
2016-12-14 14:26:43,912 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_39_piece0 in memory on localhost:55377 (size: 338.0 B, free: 530.0 MB)
2016-12-14 14:26:43,913 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 39 from broadcast at KMeans.scala:276
2016-12-14 14:26:43,929 INFO  org.apache.spark.SparkContext - logInfo: Starting job: collectAsMap at KMeans.scala:302
2016-12-14 14:26:43,931 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Registering RDD 43 (mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,932 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Got job 19 (collectAsMap at KMeans.scala:302) with 2 output partitions
2016-12-14 14:26:43,932 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Final stage: ResultStage 27 (collectAsMap at KMeans.scala:302)
2016-12-14 14:26:43,932 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Parents of final stage: List(ShuffleMapStage 26)
2016-12-14 14:26:43,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Missing parents: List(ShuffleMapStage 26)
2016-12-14 14:26:43,933 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279), which has no missing parents
2016-12-14 14:26:43,935 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40 stored as values in memory (estimated size 6.6 KB, free 373.0 KB)
2016-12-14 14:26:43,939 INFO  org.apache.spark.storage.MemoryStore - logInfo: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.5 KB, free 376.5 KB)
2016-12-14 14:26:43,940 INFO  org.apache.spark.storage.BlockManagerInfo - logInfo: Added broadcast_40_piece0 in memory on localhost:55377 (size: 3.5 KB, free: 529.9 MB)
2016-12-14 14:26:43,940 INFO  org.apache.spark.SparkContext - logInfo: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2016-12-14 14:26:43,940 INFO  org.apache.spark.scheduler.DAGScheduler - logInfo: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[43] at mapPartitions at KMeans.scala:279)
2016-12-14 14:26:43,941 INFO  org.apache.spark.scheduler.TaskSchedulerImpl - logInfo: Adding task set 26.0 with 2 tasks
2016-12-14 14:26:43,942 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 0.0 in stage 26.0 (TID 52, localhost, partition 0,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,943 INFO  org.apache.spark.scheduler.TaskSetManager - logInfo: Starting task 1.0 in stage 26.0 (TID 53, localhost, partition 1,PROCESS_LOCAL, 2552 bytes)
2016-12-14 14:26:43,944 INFO  org.apache.spark.executor.Executor - logInfo: Running task 0.0 in stage 26.0 (TID 52)
2016-12-14 14:26:43,944 INFO  org.apache.spark.executor.Executor - logInfo: Running task 1.0 in stage 26.0 (TID 53)
2016-12-14 14:26:43,947 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_2_1 locally
2016-12-14 14:26:43,948 INFO  org.apache.spark.storage.BlockManager - logInfo: Found block rdd_4_1 locally
